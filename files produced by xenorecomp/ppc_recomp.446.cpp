#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82DBC218"))) PPC_WEAK_FUNC(sub_82DBC218);
PPC_FUNC_IMPL(__imp__sub_82DBC218) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d0
	ctx.lr = 0x82DBC220;
	__savegprlr_22(ctx, base);
	// stwu r1,-704(r1)
	ea = -704 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DBC238;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc470
	if (!ctx.cr6.eq) goto loc_82DBC470;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,512
	ctx.r5.s64 = 512;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC254;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc268
	if (ctx.cr6.eq) goto loc_82DBC268;
loc_82DBC25C:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,704
	ctx.r1.s64 = ctx.r1.s64 + 704;
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DBC268:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,10
	ctx.r5.s64 = 10;
	// addi r4,r11,7252
	ctx.r4.s64 = ctx.r11.s64 + 7252;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC27C;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc25c
	if (!ctx.cr6.eq) goto loc_82DBC25C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,512
	ctx.r5.s64 = 512;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC298;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc46c
	if (!ctx.cr6.eq) goto loc_82DBC46C;
	// lis r11,-32223
	ctx.r11.s64 = -2111766528;
	// li r22,0
	ctx.r22.s64 = 0;
	// addi r27,r11,24552
	ctx.r27.s64 = ctx.r11.s64 + 24552;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r26,r11,7236
	ctx.r26.s64 = ctx.r11.s64 + 7236;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r30,r11,7060
	ctx.r30.s64 = ctx.r11.s64 + 7060;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r25,r11,7228
	ctx.r25.s64 = ctx.r11.s64 + 7228;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r29,r11,-744
	ctx.r29.s64 = ctx.r11.s64 + -744;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r24,r11,7220
	ctx.r24.s64 = ctx.r11.s64 + 7220;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r28,r11,7068
	ctx.r28.s64 = ctx.r11.s64 + 7068;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r23,r11,7212
	ctx.r23.s64 = ctx.r11.s64 + 7212;
loc_82DBC2E4:
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC2F4;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bne cr6,0x82dbc340
	if (!ctx.cr6.eq) goto loc_82DBC340;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,512
	ctx.r5.s64 = 512;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC310;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc46c
	if (!ctx.cr6.eq) goto loc_82DBC46C;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DBC33C;
	sub_82DE89A0(ctx, base);
	// b 0x82dbc450
	goto loc_82DBC450;
loc_82DBC340:
	// li r5,5
	ctx.r5.s64 = 5;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC34C;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bne cr6,0x82dbc398
	if (!ctx.cr6.eq) goto loc_82DBC398;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,512
	ctx.r5.s64 = 512;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC368;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc46c
	if (!ctx.cr6.eq) goto loc_82DBC46C;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DBC394;
	sub_82DE89A0(ctx, base);
	// b 0x82dbc450
	goto loc_82DBC450;
loc_82DBC398:
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC3A4;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bne cr6,0x82dbc408
	if (!ctx.cr6.eq) goto loc_82DBC408;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// li r5,512
	ctx.r5.s64 = 512;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC3C4;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc46c
	if (!ctx.cr6.eq) goto loc_82DBC46C;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stbx r22,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + ctx.r11.u32, ctx.r22.u8);
	// bl 0x82cb6a70
	ctx.lr = 0x82DBC3E0;
	sub_82CB6A70(ctx, base);
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DBC404;
	sub_82DE89A0(ctx, base);
	// b 0x82dbc450
	goto loc_82DBC450;
loc_82DBC408:
	// li r5,15
	ctx.r5.s64 = 15;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC414;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// beq cr6,0x82dbc438
	if (ctx.cr6.eq) goto loc_82DBC438;
	// li r5,7
	ctx.r5.s64 = 7;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC42C;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc450
	if (!ctx.cr6.eq) goto loc_82DBC450;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
loc_82DBC438:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,512
	ctx.r5.s64 = 512;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC448;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc46c
	if (!ctx.cr6.eq) goto loc_82DBC46C;
loc_82DBC450:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,512
	ctx.r5.s64 = 512;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbc00
	ctx.lr = 0x82DBC464;
	sub_82DBBC00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc2e4
	if (ctx.cr6.eq) goto loc_82DBC2E4;
loc_82DBC46C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBC470:
	// addi r1,r1,704
	ctx.r1.s64 = ctx.r1.s64 + 704;
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBC478"))) PPC_WEAK_FUNC(sub_82DBC478);
PPC_FUNC_IMPL(__imp__sub_82DBC478) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-640(r1)
	ea = -640 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DBC4A8;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc51c
	if (!ctx.cr6.eq) goto loc_82DBC51C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbe38
	ctx.lr = 0x82DBC4B8;
	sub_82DBBE38(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc518
	if (!ctx.cr6.eq) goto loc_82DBC518;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r30,r11,7068
	ctx.r30.s64 = ctx.r11.s64 + 7068;
loc_82DBC4C8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,512
	ctx.r5.s64 = 512;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbd98
	ctx.lr = 0x82DBC4DC;
	sub_82DBBD98(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc518
	if (!ctx.cr6.eq) goto loc_82DBC518;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DBC508;
	sub_82DE89A0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbe38
	ctx.lr = 0x82DBC510;
	sub_82DBBE38(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc4c8
	if (ctx.cr6.eq) goto loc_82DBC4C8;
loc_82DBC518:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBC51C:
	// addi r1,r1,640
	ctx.r1.s64 = ctx.r1.s64 + 640;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DBC534"))) PPC_WEAK_FUNC(sub_82DBC534);
PPC_FUNC_IMPL(__imp__sub_82DBC534) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBC538"))) PPC_WEAK_FUNC(sub_82DBC538);
PPC_FUNC_IMPL(__imp__sub_82DBC538) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DBC540;
	__savegprlr_28(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r9,15
	ctx.r9.s64 = 15;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,19872(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19872, ctx.r11.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// stw r9,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r9.u32);
	// stw r28,220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 220, ctx.r28.u32);
	// stw r28,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r28.u32);
	// stw r28,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r28.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DBC57C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc764
	if (!ctx.cr6.eq) goto loc_82DBC764;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbb5d8
	ctx.lr = 0x82DBC590;
	sub_82DBB5D8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc764
	if (!ctx.cr6.eq) goto loc_82DBC764;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// std r28,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r28.u64);
	// std r28,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r28.u64);
	// bl 0x82da76a0
	ctx.lr = 0x82DBC5BC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc5cc
	if (ctx.cr6.eq) goto loc_82DBC5CC;
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82dbc764
	if (!ctx.cr6.eq) goto loc_82DBC764;
loc_82DBC5CC:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,7
	ctx.r5.s64 = 7;
	// addi r3,r11,7076
	ctx.r3.s64 = ctx.r11.s64 + 7076;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC5E0;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc604
	if (!ctx.cr6.eq) goto loc_82DBC604;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbb898
	ctx.lr = 0x82DBC5F0;
	sub_82DBB898(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82dbc744
	if (ctx.cr6.eq) goto loc_82DBC744;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBC604:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,10
	ctx.r5.s64 = 10;
	// addi r3,r11,7312
	ctx.r3.s64 = ctx.r11.s64 + 7312;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC618;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc63c
	if (!ctx.cr6.eq) goto loc_82DBC63C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbc218
	ctx.lr = 0x82DBC628;
	sub_82DBC218(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82dbc744
	if (ctx.cr6.eq) goto loc_82DBC744;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBC63C:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r3,r11,7296
	ctx.r3.s64 = ctx.r11.s64 + 7296;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82da46a0
	ctx.lr = 0x82DBC650;
	sub_82DA46A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc674
	if (!ctx.cr6.eq) goto loc_82DBC674;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbbf50
	ctx.lr = 0x82DBC660;
	sub_82DBBF50(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82dbc744
	if (ctx.cr6.eq) goto loc_82DBC744;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBC674:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da8098
	ctx.lr = 0x82DBC680;
	sub_82DA8098(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbc764
	if (!ctx.cr6.eq) goto loc_82DBC764;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82da4420
	ctx.lr = 0x82DBC690;
	sub_82DA4420(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r4,r11,7288
	ctx.r4.s64 = ctx.r11.s64 + 7288;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,4
	ctx.r5.s64 = 4;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r3,r11,-4
	ctx.r3.s64 = ctx.r11.s64 + -4;
	// bl 0x82da45e8
	ctx.lr = 0x82DBC6B0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc730
	if (ctx.cr6.eq) goto loc_82DBC730;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r4,r10,7280
	ctx.r4.s64 = ctx.r10.s64 + 7280;
	// addi r3,r11,-4
	ctx.r3.s64 = ctx.r11.s64 + -4;
	// bl 0x82da45e8
	ctx.lr = 0x82DBC6D4;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc730
	if (ctx.cr6.eq) goto loc_82DBC730;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r4,r10,7272
	ctx.r4.s64 = ctx.r10.s64 + 7272;
	// addi r3,r11,-4
	ctx.r3.s64 = ctx.r11.s64 + -4;
	// bl 0x82da45e8
	ctx.lr = 0x82DBC6F8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc730
	if (ctx.cr6.eq) goto loc_82DBC730;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r4,r10,7264
	ctx.r4.s64 = ctx.r10.s64 + 7264;
	// addi r3,r11,-4
	ctx.r3.s64 = ctx.r11.s64 + -4;
	// bl 0x82da45e8
	ctx.lr = 0x82DBC71C;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbc730
	if (ctx.cr6.eq) goto loc_82DBC730;
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBC730:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbc478
	ctx.lr = 0x82DBC738;
	sub_82DBC478(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbc760
	if (!ctx.cr6.eq) goto loc_82DBC760;
loc_82DBC744:
	// addi r29,r31,232
	ctx.r29.s64 = ctx.r31.s64 + 232;
	// li r5,296
	ctx.r5.s64 = 296;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBC758;
	sub_82CB16F0(ctx, base);
	// stw r29,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r29.u32);
	// stw r28,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r28.u32);
loc_82DBC760:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82DBC764:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBC76C"))) PPC_WEAK_FUNC(sub_82DBC76C);
PPC_FUNC_IMPL(__imp__sub_82DBC76C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBC770"))) PPC_WEAK_FUNC(sub_82DBC770);
PPC_FUNC_IMPL(__imp__sub_82DBC770) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbc780
	if (!ctx.cr6.eq) goto loc_82DBC780;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBC780:
	// b 0x82dbc538
	sub_82DBC538(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBC784"))) PPC_WEAK_FUNC(sub_82DBC784);
PPC_FUNC_IMPL(__imp__sub_82DBC784) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBC788"))) PPC_WEAK_FUNC(sub_82DBC788);
PPC_FUNC_IMPL(__imp__sub_82DBC788) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,28784
	ctx.r31.s64 = ctx.r11.s64 + 28784;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBC7B0;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r7,-32036
	ctx.r7.s64 = -2099511296;
	// addi r11,r11,7324
	ctx.r11.s64 = ctx.r11.s64 + 7324;
	// lis r8,-32036
	ctx.r8.s64 = -2099511296;
	// lis r9,-32036
	ctx.r9.s64 = -2099511296;
	// lis r10,-32036
	ctx.r10.s64 = -2099511296;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// addi r11,r7,-14480
	ctx.r11.s64 = ctx.r7.s64 + -14480;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r8,-18680
	ctx.r11.s64 = ctx.r8.s64 + -18680;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r9,-18672
	ctx.r11.s64 = ctx.r9.s64 + -18672;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r10,-18664
	ctx.r11.s64 = ctx.r10.s64 + -18664;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// li r11,15
	ctx.r11.s64 = 15;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,528
	ctx.r11.s64 = 528;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DBC828"))) PPC_WEAK_FUNC(sub_82DBC828);
PPC_FUNC_IMPL(__imp__sub_82DBC828) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DBC830;
	__savegprlr_29(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,244(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 244);
	// stw r4,236(r30)
	PPC_STORE_U32(ctx.r30.u32 + 236, ctx.r4.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r4,232(r30)
	PPC_STORE_U32(ctx.r30.u32 + 232, ctx.r4.u32);
	// bne cr6,0x82dbc8a8
	if (!ctx.cr6.eq) goto loc_82DBC8A8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// cmpwi cr6,r4,1
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 1, ctx.xer);
	// addi r5,r11,7352
	ctx.r5.s64 = ctx.r11.s64 + 7352;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lis r7,16
	ctx.r7.s64 = 1048576;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// ble cr6,0x82dbc87c
	if (!ctx.cr6.gt) goto loc_82DBC87C;
	// lis r4,1
	ctx.r4.s64 = 65536;
	// li r6,107
	ctx.r6.s64 = 107;
	// ori r4,r4,18488
	ctx.r4.u64 = ctx.r4.u64 | 18488;
	// b 0x82dbc884
	goto loc_82DBC884;
loc_82DBC87C:
	// li r6,111
	ctx.r6.s64 = 111;
	// li r4,12860
	ctx.r4.s64 = 12860;
loc_82DBC884:
	// bl 0x82d862b0
	ctx.lr = 0x82DBC888;
	sub_82D862B0(ctx, base);
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,240(r30)
	PPC_STORE_U32(ctx.r30.u32 + 240, ctx.r3.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dbc8a4
	if (!ctx.cr6.eq) goto loc_82DBC8A4;
loc_82DBC898:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DBC8A4:
	// stw r11,244(r30)
	PPC_STORE_U32(ctx.r30.u32 + 244, ctx.r11.u32);
loc_82DBC8A8:
	// lwz r11,236(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 236);
	// lwz r31,244(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 244);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x82dbc98c
	if (!ctx.cr6.gt) goto loc_82DBC98C;
	// lis r11,1
	ctx.r11.s64 = 65536;
	// li r10,0
	ctx.r10.s64 = 0;
	// ori r11,r11,18472
	ctx.r11.u64 = ctx.r11.u64 | 18472;
	// addis r29,r31,1
	ctx.r29.s64 = ctx.r31.s64 + 65536;
	// addi r29,r29,18468
	ctx.r29.s64 = ctx.r29.s64 + 18468;
	// stwx r10,r31,r11
	PPC_STORE_U32(ctx.r31.u32 + ctx.r11.u32, ctx.r10.u32);
	// addi r11,r31,2083
	ctx.r11.s64 = ctx.r31.s64 + 2083;
	// rlwinm r11,r11,0,0,20
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF800;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r3,236(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 236);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82dbc924
	if (!ctx.cr6.gt) goto loc_82DBC924;
	// lwz r9,28(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// rotlwi r10,r3,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r7,1024
	ctx.r7.s64 = 1024;
	// li r8,4
	ctx.r8.s64 = 4;
loc_82DBC900:
	// stb r6,4(r11)
	PPC_STORE_U8(ctx.r11.u32 + 4, ctx.r6.u8);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r7,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	// lwz r5,264(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 264);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stb r8,5(r11)
	PPC_STORE_U8(ctx.r11.u32 + 5, ctx.r8.u8);
	// stw r5,-4(r11)
	PPC_STORE_U32(ctx.r11.u32 + -4, ctx.r5.u32);
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// bne cr6,0x82dbc900
	if (!ctx.cr6.eq) goto loc_82DBC900;
loc_82DBC924:
	// addis r6,r31,1
	ctx.r6.s64 = ctx.r31.s64 + 65536;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r6,18480
	ctx.r6.s64 = ctx.r6.s64 + 18480;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82fb9700
	ctx.lr = 0x82DBC940;
	sub_82FB9700(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge cr6,0x82dbc964
	if (!ctx.cr6.lt) goto loc_82DBC964;
loc_82DBC948:
	// lis r11,-32761
	ctx.r11.s64 = -2147024896;
	// ori r11,r11,14
	ctx.r11.u64 = ctx.r11.u64 | 14;
	// cmpw cr6,r3,r11
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dbc898
	if (ctx.cr6.eq) goto loc_82DBC898;
	// li r3,57
	ctx.r3.s64 = 57;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DBC964:
	// lis r10,1
	ctx.r10.s64 = 65536;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r9,r10,18476
	ctx.r9.u64 = ctx.r10.u64 | 18476;
	// addis r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 65536;
	// stwx r11,r31,r9
	PPC_STORE_U32(ctx.r31.u32 + ctx.r9.u32, ctx.r11.u32);
	// stw r10,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r10.u32);
	// stw r10,188(r30)
	PPC_STORE_U32(ctx.r30.u32 + 188, ctx.r10.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DBC98C:
	// addi r11,r31,2083
	ctx.r11.s64 = ctx.r31.s64 + 2083;
	// addi r3,r31,12840
	ctx.r3.s64 = ctx.r31.s64 + 12840;
	// rlwinm r11,r11,0,0,20
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF800;
	// addi r10,r11,2048
	ctx.r10.s64 = ctx.r11.s64 + 2048;
	// addi r9,r11,8192
	ctx.r9.s64 = ctx.r11.s64 + 8192;
	// addi r8,r11,4096
	ctx.r8.s64 = ctx.r11.s64 + 4096;
	// addi r7,r11,8704
	ctx.r7.s64 = ctx.r11.s64 + 8704;
	// stw r11,12836(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12836, ctx.r11.u32);
	// stw r11,12844(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12844, ctx.r11.u32);
	// stw r10,12848(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12848, ctx.r10.u32);
	// stw r9,12856(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12856, ctx.r9.u32);
	// stw r8,12852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12852, ctx.r8.u32);
	// stw r7,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r7.u32);
	// bl 0x833b7fe4
	ctx.lr = 0x82DBC9C4;
	__imp__XMACreateContext(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt cr6,0x82dbc948
	if (ctx.cr6.lt) goto loc_82DBC948;
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,188(r30)
	PPC_STORE_U32(ctx.r30.u32 + 188, ctx.r11.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBC9E0"))) PPC_WEAK_FUNC(sub_82DBC9E0);
PPC_FUNC_IMPL(__imp__sub_82DBC9E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DBC9E8;
	__savegprlr_28(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbca24
	if (!ctx.cr6.gt) goto loc_82DBCA24;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82DBCA08:
	// lwz r9,244(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r28,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r28.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lwz r9,236(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dbca08
	if (ctx.cr6.lt) goto loc_82DBCA08;
loc_82DBCA24:
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r30,244(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// lwz r11,232(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// ble cr6,0x82dbcaf4
	if (!ctx.cr6.gt) goto loc_82DBCAF4;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// li r10,1024
	ctx.r10.s64 = 1024;
	// rlwinm r11,r11,12,0,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFFFF000;
	// ori r9,r9,18476
	ctx.r9.u64 = ctx.r9.u64 | 18476;
	// lis r8,1
	ctx.r8.s64 = 65536;
	// ori r8,r8,18472
	ctx.r8.u64 = ctx.r8.u64 | 18472;
	// stw r10,196(r31)
	PPC_STORE_U32(ctx.r31.u32 + 196, ctx.r10.u32);
	// stw r11,200(r31)
	PPC_STORE_U32(ctx.r31.u32 + 200, ctx.r11.u32);
	// lwzx r3,r30,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r9.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stwx r28,r30,r8
	PPC_STORE_U32(ctx.r30.u32 + ctx.r8.u32, ctx.r28.u32);
	// beq cr6,0x82dbca78
	if (ctx.cr6.eq) goto loc_82DBCA78;
	// lis r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r5,r5,32768
	ctx.r5.u64 = ctx.r5.u64 | 32768;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCA78;
	sub_82CB16F0(ctx, base);
loc_82DBCA78:
	// lis r11,1
	ctx.r11.s64 = 65536;
	// addis r29,r30,1
	ctx.r29.s64 = ctx.r30.s64 + 65536;
	// ori r11,r11,18484
	ctx.r11.u64 = ctx.r11.u64 | 18484;
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r29,r29,18480
	ctx.r29.s64 = ctx.r29.s64 + 18480;
	// stbx r10,r30,r11
	PPC_STORE_U8(ctx.r30.u32 + ctx.r11.u32, ctx.r10.u8);
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82fba6b0
	ctx.lr = 0x82DBCA98;
	sub_82FBA6B0(ctx, base);
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82fba748
	ctx.lr = 0x82DBCAA0;
	sub_82FBA748(ctx, base);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbcae0
	if (!ctx.cr6.gt) goto loc_82DBCAE0;
loc_82DBCAB0:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82fba020
	ctx.lr = 0x82DBCABC;
	sub_82FBA020(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82fba2f8
	ctx.lr = 0x82DBCAD0;
	sub_82FBA2F8(ctx, base);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbcab0
	if (ctx.cr6.lt) goto loc_82DBCAB0;
loc_82DBCAE0:
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82fba960
	ctx.lr = 0x82DBCAE8;
	sub_82FBA960(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBCAF4:
	// li r10,512
	ctx.r10.s64 = 512;
	// rlwinm r5,r11,11,0,20
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 11) & 0xFFFFF800;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r10,196(r31)
	PPC_STORE_U32(ctx.r31.u32 + 196, ctx.r10.u32);
	// stw r5,200(r31)
	PPC_STORE_U32(ctx.r31.u32 + 200, ctx.r5.u32);
	// lwz r3,32(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCB10;
	sub_82CB16F0(ctx, base);
	// lwz r3,12840(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12840);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dbcc60
	if (ctx.cr6.eq) goto loc_82DBCC60;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x833b8024
	ctx.lr = 0x82DBCB24;
	__imp__XMADisableContext(ctx, base);
	// li r5,52
	ctx.r5.s64 = 52;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r28.u32);
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCB38;
	sub_82CB16F0(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,12844(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12844);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCB48;
	sub_82CB16F0(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,12848(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12848);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCB58;
	sub_82CB16F0(ctx, base);
	// li r5,512
	ctx.r5.s64 = 512;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,12856(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12856);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCB68;
	sub_82CB16F0(ctx, base);
	// li r5,4096
	ctx.r5.s64 = 4096;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,12852(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12852);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCB78;
	sub_82CB16F0(ctx, base);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r11,264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbcb94
	if (!ctx.cr6.gt) goto loc_82DBCB94;
	// cmpwi cr6,r11,24000
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 24000, ctx.xer);
	// ble cr6,0x82dbcbe4
	if (!ctx.cr6.gt) goto loc_82DBCBE4;
loc_82DBCB94:
	// cmpwi cr6,r11,24001
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 24001, ctx.xer);
	// blt cr6,0x82dbcbac
	if (ctx.cr6.lt) goto loc_82DBCBAC;
	// cmpwi cr6,r11,32000
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32000, ctx.xer);
	// bgt cr6,0x82dbcbac
	if (ctx.cr6.gt) goto loc_82DBCBAC;
	// mr r28,r9
	ctx.r28.u64 = ctx.r9.u64;
	// b 0x82dbcbe4
	goto loc_82DBCBE4;
loc_82DBCBAC:
	// cmpwi cr6,r11,32001
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32001, ctx.xer);
	// blt cr6,0x82dbcbcc
	if (ctx.cr6.lt) goto loc_82DBCBCC;
	// lis r8,0
	ctx.r8.s64 = 0;
	// ori r8,r8,44100
	ctx.r8.u64 = ctx.r8.u64 | 44100;
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bgt cr6,0x82dbcbcc
	if (ctx.cr6.gt) goto loc_82DBCBCC;
	// li r28,2
	ctx.r28.s64 = 2;
	// b 0x82dbcbe4
	goto loc_82DBCBE4;
loc_82DBCBCC:
	// lis r8,0
	ctx.r8.s64 = 0;
	// li r28,3
	ctx.r28.s64 = 3;
	// ori r8,r8,44101
	ctx.r8.u64 = ctx.r8.u64 | 44101;
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82dbcbe4
	if (!ctx.cr6.lt) goto loc_82DBCBE4;
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82DBCBE4:
	// lwz r11,12844(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12844);
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lwz r11,12848(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12848);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// lwz r11,12856(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12856);
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// li r11,32
	ctx.r11.s64 = 32;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lwz r11,260(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 260);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// li r11,2
	ctx.r11.s64 = 2;
	// bgt cr6,0x82dbcc20
	if (ctx.cr6.gt) goto loc_82DBCC20;
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82DBCC20:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r10,12852(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12852);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,12840(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12840);
	// stw r28,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r28.u32);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// li r11,4
	ctx.r11.s64 = 4;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r11.u32);
	// li r11,8
	ctx.r11.s64 = 8;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// bl 0x833b8014
	ctx.lr = 0x82DBCC50;
	__imp__XMAInitializeContext(ctx, base);
	// lwz r3,12840(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12840);
	// bl 0x833b8004
	ctx.lr = 0x82DBCC58;
	__imp__XMASetOutputBufferValid(ctx, base);
	// lwz r3,12840(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12840);
	// bl 0x833b7ff4
	ctx.lr = 0x82DBCC60;
	__imp__XMAEnableContext(ctx, base);
loc_82DBCC60:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBCC6C"))) PPC_WEAK_FUNC(sub_82DBCC6C);
PPC_FUNC_IMPL(__imp__sub_82DBCC6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBCC70"))) PPC_WEAK_FUNC(sub_82DBCC70);
PPC_FUNC_IMPL(__imp__sub_82DBCC70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d0
	ctx.lr = 0x82DBCC78;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,1
	ctx.r24.s64 = 1;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r5
	ctx.r22.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// stb r24,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r24.u8);
	// lwz r31,244(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 244);
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// stb r24,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r24.u8);
	// mr r29,r26
	ctx.r29.u64 = ctx.r26.u64;
loc_82DBCCA8:
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bne cr6,0x82dbccbc
	if (!ctx.cr6.eq) goto loc_82DBCCBC;
	// bl 0x833b80c4
	ctx.lr = 0x82DBCCB8;
	__imp__XMAIsInputBuffer0Valid(ctx, base);
	// b 0x82dbccc0
	goto loc_82DBCCC0;
loc_82DBCCBC:
	// bl 0x833b80b4
	ctx.lr = 0x82DBCCC0;
	__imp__XMAIsInputBuffer1Valid(ctx, base);
loc_82DBCCC0:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbcd68
	if (!ctx.cr6.eq) goto loc_82DBCD68;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// bl 0x82da8018
	ctx.lr = 0x82DBCCD8;
	sub_82DA8018(ctx, base);
	// lwz r11,28(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
	// lwz r10,156(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 156);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// addi r11,r29,3211
	ctx.r11.s64 = ctx.r29.s64 + 3211;
	// blt cr6,0x82dbcd18
	if (ctx.cr6.lt) goto loc_82DBCD18;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCD0C;
	sub_82CB16F0(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stbx r26,r29,r11
	PPC_STORE_U8(ctx.r29.u32 + ctx.r11.u32, ctx.r26.u8);
	// b 0x82dbcd68
	goto loc_82DBCD68;
loc_82DBCD18:
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2048
	ctx.r6.s64 = 2048;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwzx r4,r30,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r31.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DBCD34;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbcd48
	if (ctx.cr6.eq) goto loc_82DBCD48;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stbx r26,r29,r11
	PPC_STORE_U8(ctx.r29.u32 + ctx.r11.u32, ctx.r26.u8);
	// b 0x82dbcd68
	goto loc_82DBCD68;
loc_82DBCD48:
	// lwzx r11,r30,r31
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r31.u32);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stb r26,3(r11)
	PPC_STORE_U8(ctx.r11.u32 + 3, ctx.r26.u8);
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bne cr6,0x82dbcd64
	if (!ctx.cr6.eq) goto loc_82DBCD64;
	// bl 0x833b80a4
	ctx.lr = 0x82DBCD60;
	__imp__XMASetInputBuffer0Valid(ctx, base);
	// b 0x82dbcd68
	goto loc_82DBCD68;
loc_82DBCD64:
	// bl 0x833b8094
	ctx.lr = 0x82DBCD68;
	__imp__XMASetInputBuffer1Valid(ctx, base);
loc_82DBCD68:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// cmpwi cr6,r29,2
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 2, ctx.xer);
	// blt cr6,0x82dbcca8
	if (ctx.cr6.lt) goto loc_82DBCCA8;
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8084
	ctx.lr = 0x82DBCD7C;
	__imp__XMAGetInputBufferReadOffset(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8074
	ctx.lr = 0x82DBCD88;
	__imp__XMAGetOutputBufferReadOffset(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8064
	ctx.lr = 0x82DBCD94;
	__imp__XMAGetOutputBufferWriteOffset(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8054
	ctx.lr = 0x82DBCDA0;
	__imp__XMAIsOutputBufferValid(ctx, base);
	// cmpw cr6,r30,r29
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r29.s32, ctx.xer);
	// bne cr6,0x82dbce14
	if (!ctx.cr6.eq) goto loc_82DBCE14;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbcde4
	if (!ctx.cr6.eq) goto loc_82DBCDE4;
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8004
	ctx.lr = 0x82DBCDB8;
	__imp__XMASetOutputBufferValid(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8044
	ctx.lr = 0x82DBCDC4;
	__imp__XMASetOutputBufferReadOffset(ctx, base);
	// li r11,2048
	ctx.r11.s64 = 2048;
	// rlwinm r10,r30,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 8) & 0xFFFFFF00;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
	// stw r10,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r10.u32);
	// stw r24,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r24.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DBCDE4:
	// cmpwi cr6,r25,2
	ctx.cr6.compare<int32_t>(ctx.r25.s32, 2, ctx.xer);
	// bne cr6,0x82dbce54
	if (!ctx.cr6.eq) goto loc_82DBCE54;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dbce1c
	if (ctx.cr6.eq) goto loc_82DBCE1C;
	// cmpwi cr6,r28,32
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 32, ctx.xer);
	// bne cr6,0x82dbce1c
	if (!ctx.cr6.eq) goto loc_82DBCE1C;
	// stw r26,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r26.u32);
	// li r3,22
	ctx.r3.s64 = 22;
	// stw r26,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r26.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DBCE14:
	// cmpwi cr6,r25,2
	ctx.cr6.compare<int32_t>(ctx.r25.s32, 2, ctx.xer);
	// bne cr6,0x82dbce54
	if (!ctx.cr6.eq) goto loc_82DBCE54;
loc_82DBCE1C:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbce54
	if (ctx.cr6.eq) goto loc_82DBCE54;
	// lwz r11,12844(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12844);
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm r11,r11,21,17,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x7FFF;
	// addi r4,r11,32
	ctx.r4.s64 = ctx.r11.s64 + 32;
	// bl 0x833b8034
	ctx.lr = 0x82DBCE40;
	__imp__XMASetInputBufferReadOffset(ctx, base);
	// stw r26,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r26.u32);
	// stw r26,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r26.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DBCE54:
	// cmpw cr6,r30,r29
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r29.s32, ctx.xer);
	// subf r11,r30,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r30.s64;
	// ble cr6,0x82dbce64
	if (!ctx.cr6.gt) goto loc_82DBCE64;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
loc_82DBCE64:
	// rlwinm r11,r11,8,0,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFFFFFF00;
	// rlwinm r10,r30,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 8) & 0xFFFFFF00;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
	// stw r10,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r10.u32);
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// stw r24,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r24.u32);
	// bl 0x833b8044
	ctx.lr = 0x82DBCE84;
	__imp__XMASetOutputBufferReadOffset(ctx, base);
	// lwz r3,12840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12840);
	// bl 0x833b8004
	ctx.lr = 0x82DBCE8C;
	__imp__XMASetOutputBufferValid(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBCE98"))) PPC_WEAK_FUNC(sub_82DBCE98);
PPC_FUNC_IMPL(__imp__sub_82DBCE98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DBCEA0;
	__savegprlr_14(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// stw r6,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, ctx.r6.u32);
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r14,r4
	ctx.r14.u64 = ctx.r4.u64;
	// mr r20,r5
	ctx.r20.u64 = ctx.r5.u64;
	// mr r19,r7
	ctx.r19.u64 = ctx.r7.u64;
	// lwz r21,244(r27)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r27.u32 + 244);
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// stw r23,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r23.u32);
	// lwz r10,232(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82dbcef0
	if (!ctx.cr6.gt) goto loc_82DBCEF0;
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
loc_82DBCED8:
	// stw r23,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r23.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r9,232(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dbced8
	if (ctx.cr6.lt) goto loc_82DBCED8;
loc_82DBCEF0:
	// lis r11,1
	ctx.r11.s64 = 65536;
	// addis r24,r21,1
	ctx.r24.s64 = ctx.r21.s64 + 65536;
	// ori r18,r11,18472
	ctx.r18.u64 = ctx.r11.u64 | 18472;
	// lis r11,0
	ctx.r11.s64 = 0;
	// addi r24,r24,18480
	ctx.r24.s64 = ctx.r24.s64 + 18480;
	// ori r22,r11,32768
	ctx.r22.u64 = ctx.r11.u64 | 32768;
	// lis r11,1
	ctx.r11.s64 = 65536;
	// li r15,-1
	ctx.r15.s64 = -1;
	// ori r17,r11,18476
	ctx.r17.u64 = ctx.r11.u64 | 18476;
	// lis r11,1
	ctx.r11.s64 = 65536;
	// ori r16,r11,18484
	ctx.r16.u64 = ctx.r11.u64 | 18484;
loc_82DBCF1C:
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fba6b0
	ctx.lr = 0x82DBCF24;
	sub_82FBA6B0(ctx, base);
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fba748
	ctx.lr = 0x82DBCF2C;
	sub_82FBA748(ctx, base);
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// li r30,1
	ctx.r30.s64 = 1;
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbcf6c
	if (!ctx.cr6.gt) goto loc_82DBCF6C;
loc_82DBCF40:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fb9b90
	ctx.lr = 0x82DBCF4C;
	sub_82FB9B90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbcf68
	if (ctx.cr6.eq) goto loc_82DBCF68;
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmpw cr6,r31,r11
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbcf40
	if (ctx.cr6.lt) goto loc_82DBCF40;
	// b 0x82dbcf6c
	goto loc_82DBCF6C;
loc_82DBCF68:
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
loc_82DBCF6C:
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbd07c
	if (ctx.cr6.eq) goto loc_82DBD07C;
	// add r25,r21,r18
	ctx.r25.u64 = ctx.r21.u64 + ctx.r18.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// mr r31,r22
	ctx.r31.u64 = ctx.r22.u64;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// clrlwi r28,r11,16
	ctx.r28.u64 = ctx.r11.u32 & 0xFFFF;
	// bl 0x82da8018
	ctx.lr = 0x82DBCF98;
	sub_82DA8018(ctx, base);
	// lwz r11,156(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 156);
	// lwz r10,28(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r11.s64;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r8,r8,r22
	ctx.r8.u64 = ctx.r8.u64 + ctx.r22.u64;
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dbcfc8
	if (ctx.cr6.lt) goto loc_82DBCFC8;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// add r31,r10,r11
	ctx.r31.u64 = ctx.r10.u64 + ctx.r11.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dbd07c
	if (ctx.cr6.eq) goto loc_82DBD07C;
loc_82DBCFC8:
	// add r29,r21,r17
	ctx.r29.u64 = ctx.r21.u64 + ctx.r17.u64;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// li r4,255
	ctx.r4.s64 = 255;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// add r3,r11,r28
	ctx.r3.u64 = ctx.r11.u64 + ctx.r28.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBCFE0;
	sub_82CB16F0(ctx, base);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// add r4,r11,r28
	ctx.r4.u64 = ctx.r11.u64 + ctx.r28.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBCFFC;
	sub_82DA76A0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq cr6,0x82dbd010
	if (ctx.cr6.eq) goto loc_82DBD010;
	// cmpwi cr6,r31,22
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 22, ctx.xer);
	// bne cr6,0x82dbd220
	if (!ctx.cr6.eq) goto loc_82DBD220;
loc_82DBD010:
	// add r11,r21,r16
	ctx.r11.u64 = ctx.r21.u64 + ctx.r16.u64;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dbd028
	if (ctx.cr6.eq) goto loc_82DBD028;
	// li r26,2048
	ctx.r26.s64 = 2048;
	// stb r23,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r23.u8);
loc_82DBD028:
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbd070
	if (!ctx.cr6.gt) goto loc_82DBD070;
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
loc_82DBD03C:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// subf r6,r31,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r31.s64;
	// add r5,r11,r28
	ctx.r5.u64 = ctx.r11.u64 + ctx.r28.u64;
	// bl 0x82fb9a38
	ctx.lr = 0x82DBD05C;
	sub_82FB9A38(ctx, base);
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// add r31,r31,r26
	ctx.r31.u64 = ctx.r31.u64 + ctx.r26.u64;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbd03c
	if (ctx.cr6.lt) goto loc_82DBD03C;
loc_82DBD070:
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// add r11,r11,r22
	ctx.r11.u64 = ctx.r11.u64 + ctx.r22.u64;
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
loc_82DBD07C:
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// li r26,512
	ctx.r26.s64 = 512;
	// mr r29,r23
	ctx.r29.u64 = ctx.r23.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbd1c4
	if (!ctx.cr6.gt) goto loc_82DBD1C4;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
	// subf r28,r21,r14
	ctx.r28.s64 = ctx.r14.s64 - ctx.r21.s64;
loc_82DBD098:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fb9c60
	ctx.lr = 0x82DBD0A4;
	sub_82FB9C60(ctx, base);
	// rotlwi r11,r20,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r20.u32, 1);
	// lwz r10,232(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// divw r8,r20,r10
	ctx.r8.s32 = ctx.r20.s32 / ctx.r10.s32;
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// twllei r10,0
	// rlwinm r31,r8,30,2,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0x3FFFFFFF;
	// twlgei r11,-1
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82dbd1b0
	if (!ctx.cr6.eq) goto loc_82DBD1B0;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82dbd168
	if (ctx.cr6.eq) goto loc_82DBD168;
	// cmpw cr6,r5,r31
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r31.s32, ctx.xer);
	// ble cr6,0x82dbd0e8
	if (!ctx.cr6.gt) goto loc_82DBD0E8;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
loc_82DBD0E8:
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// bne cr6,0x82dbd0f8
	if (!ctx.cr6.eq) goto loc_82DBD0F8;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// b 0x82dbd104
	goto loc_82DBD104;
loc_82DBD0F8:
	// cmpw cr6,r5,r26
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r26.s32, ctx.xer);
	// ble cr6,0x82dbd104
	if (!ctx.cr6.gt) goto loc_82DBD104;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82DBD104:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82fb9d38
	ctx.lr = 0x82DBD114;
	sub_82FB9D38(ctx, base);
	// add r11,r28,r30
	ctx.r11.u64 = ctx.r28.u64 + ctx.r30.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dbd160
	if (ctx.cr6.eq) goto loc_82DBD160;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_82DBD128:
	// lhz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// sth r9,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r9.u16);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lhz r9,2(r9)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + 2);
	// sth r9,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r9.u16);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,232(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// bne cr6,0x82dbd128
	if (!ctx.cr6.eq) goto loc_82DBD128;
loc_82DBD160:
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// b 0x82dbd1b0
	goto loc_82DBD1B0;
loc_82DBD168:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fb9bf8
	ctx.lr = 0x82DBD174;
	sub_82FB9BF8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbd1b0
	if (ctx.cr6.eq) goto loc_82DBD1B0;
	// add r11,r28,r30
	ctx.r11.u64 = ctx.r28.u64 + ctx.r30.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// ble cr6,0x82dbd1ac
	if (!ctx.cr6.gt) goto loc_82DBD1AC;
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
loc_82DBD18C:
	// sth r23,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r23.u16);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// sth r23,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r23.u16);
	// lwz r9,232(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// bne cr6,0x82dbd18c
	if (!ctx.cr6.eq) goto loc_82DBD18C;
loc_82DBD1AC:
	// stw r15,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r15.u32);
loc_82DBD1B0:
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbd098
	if (ctx.cr6.lt) goto loc_82DBD098;
loc_82DBD1C4:
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbd1f8
	if (!ctx.cr6.gt) goto loc_82DBD1F8;
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
loc_82DBD1D8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dbd1e8
	if (ctx.cr6.eq) goto loc_82DBD1E8;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82DBD1E8:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dbd1d8
	if (!ctx.cr6.eq) goto loc_82DBD1D8;
loc_82DBD1F8:
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fba960
	ctx.lr = 0x82DBD200;
	sub_82FBA960(ctx, base);
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// ble cr6,0x82dbd234
	if (!ctx.cr6.gt) goto loc_82DBD234;
	// lwz r11,232(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// cmpw cr6,r31,r11
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dbd234
	if (ctx.cr6.eq) goto loc_82DBD234;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82da3e20
	ctx.lr = 0x82DBD21C;
	sub_82DA3E20(ctx, base);
	// b 0x82dbcf1c
	goto loc_82DBCF1C;
loc_82DBD220:
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82fba960
	ctx.lr = 0x82DBD228;
	sub_82FBA960(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DBD234:
	// lwz r9,232(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 232);
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82dbd264
	if (!ctx.cr6.gt) goto loc_82DBD264;
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
loc_82DBD248:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bge cr6,0x82dbd270
	if (!ctx.cr6.lt) goto loc_82DBD270;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dbd248
	if (ctx.cr6.lt) goto loc_82DBD248;
loc_82DBD264:
	// li r3,22
	ctx.r3.s64 = 22;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DBD270:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,300(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwzx r11,r11,r21
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r21.u32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBD294"))) PPC_WEAK_FUNC(sub_82DBD294);
PPC_FUNC_IMPL(__imp__sub_82DBD294) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBD298"))) PPC_WEAK_FUNC(sub_82DBD298);
PPC_FUNC_IMPL(__imp__sub_82DBD298) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DBD2A0;
	__savegprlr_14(ctx, base);
	// stwu r1,-784(r1)
	ea = -784 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r28,0
	ctx.r28.s64 = 0;
	// stw r4,812(r1)
	PPC_STORE_U32(ctx.r1.u32 + 812, ctx.r4.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// li r5,511
	ctx.r5.s64 = 511;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,113
	ctx.r3.s64 = ctx.r1.s64 + 113;
	// stb r28,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, ctx.r28.u8);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r20,r28
	ctx.r20.u64 = ctx.r28.u64;
	// mr r22,r28
	ctx.r22.u64 = ctx.r28.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBD2D4;
	sub_82CB16F0(ctx, base);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DBD2E0;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbd948
	if (!ctx.cr6.eq) goto loc_82DBD948;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r23,4
	ctx.r23.s64 = 4;
	// lis r24,-31909
	ctx.r24.s64 = -2091188224;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r26,1
	ctx.r26.s64 = 1;
	// addi r25,r11,7352
	ctx.r25.s64 = ctx.r11.s64 + 7352;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// addi r19,r11,7452
	ctx.r19.s64 = ctx.r11.s64 + 7452;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7444
	ctx.r11.s64 = ctx.r11.s64 + 7444;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7436
	ctx.r11.s64 = ctx.r11.s64 + 7436;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r21,r11,7428
	ctx.r21.s64 = ctx.r11.s64 + 7428;
loc_82DBD330:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r10,8
	ctx.r4.s64 = ctx.r10.s64 + 8;
	// bl 0x82da7e70
	ctx.lr = 0x82DBD340;
	sub_82DA7E70(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da76a0
	ctx.lr = 0x82DBD364;
	sub_82DA76A0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r10,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82da45e8
	ctx.lr = 0x82DBD3A4;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbd508
	if (!ctx.cr6.eq) goto loc_82DBD508;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r6,32
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 32, ctx.xer);
	// blt cr6,0x82dbd594
	if (ctx.cr6.lt) goto loc_82DBD594;
	// cmpwi cr6,r6,512
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 512, ctx.xer);
	// bgt cr6,0x82dbd594
	if (ctx.cr6.gt) goto loc_82DBD594;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82da76a0
	ctx.lr = 0x82DBD3D4;
	sub_82DA76A0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
	// lhz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 112);
	// lbz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 112);
	// rlwimi r10,r11,8,8,23
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 8) & 0xFFFF00) | (ctx.r10.u64 & 0xFFFFFFFFFF0000FF);
	// clrlwi r11,r10,16
	ctx.r11.u64 = ctx.r10.u32 & 0xFFFF;
	// cmplwi cr6,r11,357
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 357, ctx.xer);
	// sth r11,112(r1)
	PPC_STORE_U16(ctx.r1.u32 + 112, ctx.r11.u16);
	// bne cr6,0x82dbd594
	if (!ctx.cr6.eq) goto loc_82DBD594;
	// lhz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 120);
	// lbz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 120);
	// lhz r9,114(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 114);
	// rlwimi r10,r11,8,8,23
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 8) & 0xFFFF00) | (ctx.r10.u64 & 0xFFFFFFFFFF0000FF);
	// lbz r8,114(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 114);
	// lbz r7,116(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 116);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lhz r6,118(r1)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r1.u32 + 118);
	// lhz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 116);
	// rlwimi r8,r9,8,8,23
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 8) & 0xFFFF00) | (ctx.r8.u64 & 0xFFFFFFFFFF0000FF);
	// lbz r5,118(r1)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r1.u32 + 118);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// rlwimi r7,r10,8,8,23
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0xFFFF00) | (ctx.r7.u64 & 0xFFFFFFFFFF0000FF);
	// rlwimi r5,r6,8,8,23
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r6.u32, 8) & 0xFFFF00) | (ctx.r5.u64 & 0xFFFFFFFFFF0000FF);
	// cmplwi cr6,r11,8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8, ctx.xer);
	// sth r8,114(r1)
	PPC_STORE_U16(ctx.r1.u32 + 114, ctx.r8.u16);
	// sth r11,120(r1)
	PPC_STORE_U16(ctx.r1.u32 + 120, ctx.r11.u16);
	// sth r7,116(r1)
	PPC_STORE_U16(ctx.r1.u32 + 116, ctx.r7.u16);
	// sth r5,118(r1)
	PPC_STORE_U16(ctx.r1.u32 + 118, ctx.r5.u16);
	// bgt cr6,0x82dbd594
	if (ctx.cr6.gt) goto loc_82DBD594;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbd820
	if (!ctx.cr6.gt) goto loc_82DBD820;
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
loc_82DBD45C:
	// lwz r10,-4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mr r17,r10
	ctx.r17.u64 = ctx.r10.u64;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mr r16,r9
	ctx.r16.u64 = ctx.r9.u64;
	// mr r15,r8
	ctx.r15.u64 = ctx.r8.u64;
	// lbz r5,-4(r11)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r11.u32 + -4);
	// mr r14,r7
	ctx.r14.u64 = ctx.r7.u64;
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// rlwimi r17,r10,16,0,15
	ctx.r17.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r17.u64 & 0xFFFFFFFF0000FFFF);
	// lbz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 4);
	// rlwimi r16,r9,16,0,15
	ctx.r16.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0xFFFF0000) | (ctx.r16.u64 & 0xFFFFFFFF0000FFFF);
	// lbz r18,8(r11)
	ctx.r18.u64 = PPC_LOAD_U8(ctx.r11.u32 + 8);
	// rlwimi r15,r8,16,0,15
	ctx.r15.u64 = (__builtin_rotateleft32(ctx.r8.u32, 16) & 0xFFFF0000) | (ctx.r15.u64 & 0xFFFFFFFF0000FFFF);
	// sth r28,14(r11)
	PPC_STORE_U16(ctx.r11.u32 + 14, ctx.r28.u16);
	// rlwimi r14,r7,16,0,15
	ctx.r14.u64 = (__builtin_rotateleft32(ctx.r7.u32, 16) & 0xFFFF0000) | (ctx.r14.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r10,24,16,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwinm r9,r9,24,16,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFF00;
	// rlwinm r8,r8,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 24) & 0xFF00;
	// rlwinm r7,r7,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xFF00;
	// rlwinm r17,r17,8,0,15
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r17.u32 | (ctx.r17.u64 << 32), 8) & 0xFFFF0000;
	// rlwinm r16,r16,8,0,15
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r16.u32 | (ctx.r16.u64 << 32), 8) & 0xFFFF0000;
	// rlwinm r15,r15,8,0,15
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 8) & 0xFFFF0000;
	// rlwinm r14,r14,8,0,15
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r17,r10
	ctx.r10.u64 = ctx.r17.u64 | ctx.r10.u64;
	// or r9,r16,r9
	ctx.r9.u64 = ctx.r16.u64 | ctx.r9.u64;
	// or r8,r15,r8
	ctx.r8.u64 = ctx.r15.u64 | ctx.r8.u64;
	// or r7,r14,r7
	ctx.r7.u64 = ctx.r14.u64 | ctx.r7.u64;
	// or r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 | ctx.r5.u64;
	// or r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 | ctx.r4.u64;
	// or r8,r8,r3
	ctx.r8.u64 = ctx.r8.u64 | ctx.r3.u64;
	// or r7,r7,r18
	ctx.r7.u64 = ctx.r7.u64 | ctx.r18.u64;
	// stw r10,-4(r11)
	PPC_STORE_U32(ctx.r11.u32 + -4, ctx.r10.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r8.u32);
	// stw r7,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r7.u32);
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
	// lhz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 120);
	// cmpw cr6,r6,r10
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dbd45c
	if (ctx.cr6.lt) goto loc_82DBD45C;
	// b 0x82dbd820
	goto loc_82DBD820;
loc_82DBD508:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBD518;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbd5a8
	if (!ctx.cr6.eq) goto loc_82DBD5A8;
	// lwz r11,156(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 156);
	// addi r4,r31,156
	ctx.r4.s64 = ctx.r31.s64 + 156;
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82dbd550
	if (!ctx.cr6.eq) goto loc_82DBD550;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r10,268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 268, ctx.r10.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DBD544;
	sub_82DA8018(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
loc_82DBD550:
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// lwz r11,388(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 388);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbd5a0
	if (ctx.cr6.eq) goto loc_82DBD5A0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82da7e70
	ctx.lr = 0x82DBD570;
	sub_82DA7E70(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82dbd820
	if (ctx.cr6.eq) goto loc_82DBD820;
loc_82DBD57C:
	// clrlwi r11,r22,24
	ctx.r11.u64 = ctx.r22.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbd884
	if (ctx.cr6.eq) goto loc_82DBD884;
	// lbz r11,1(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dbd91c
	if (!ctx.cr6.eq) goto loc_82DBD91C;
loc_82DBD594:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DBD5A0:
	// mr r20,r26
	ctx.r20.u64 = ctx.r26.u64;
	// b 0x82dbd820
	goto loc_82DBD820;
loc_82DBD5A8:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBD5B8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbd604
	if (!ctx.cr6.eq) goto loc_82DBD604;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r6,44
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 44, ctx.xer);
	// blt cr6,0x82dbd594
	if (ctx.cr6.lt) goto loc_82DBD594;
	// cmpwi cr6,r6,512
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 512, ctx.xer);
	// bgt cr6,0x82dbd594
	if (ctx.cr6.gt) goto loc_82DBD594;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBD5E8;
	sub_82DA76A0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
	// lwz r11,28(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// mr r22,r26
	ctx.r22.u64 = ctx.r26.u64;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// b 0x82dbd820
	goto loc_82DBD820;
loc_82DBD604:
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBD614;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbd810
	if (!ctx.cr6.eq) goto loc_82DBD810;
	// clrlwi r11,r22,24
	ctx.r11.u64 = ctx.r22.u32 & 0xFF;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,19872(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 19872);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// beq cr6,0x82dbd6a0
	if (ctx.cr6.eq) goto loc_82DBD6A0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r6,826
	ctx.r6.s64 = 826;
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// bl 0x82d862b0
	ctx.lr = 0x82DBD648;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,248(r31)
	PPC_STORE_U32(ctx.r31.u32 + 248, ctx.r3.u32);
	// beq cr6,0x82dbd878
	if (ctx.cr6.eq) goto loc_82DBD878;
	// stw r26,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r26.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r10,248(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// rlwinm r11,r11,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r11.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// stw r28,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r28.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da76a0
	ctx.lr = 0x82DBD690;
	sub_82DA76A0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
	// b 0x82dbd820
	goto loc_82DBD820;
loc_82DBD6A0:
	// li r6,844
	ctx.r6.s64 = 844;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82d862b0
	ctx.lr = 0x82DBD6AC;
	sub_82D862B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,248(r31)
	PPC_STORE_U32(ctx.r31.u32 + 248, ctx.r4.u32);
	// beq cr6,0x82dbd878
	if (ctx.cr6.eq) goto loc_82DBD878;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82da76a0
	ctx.lr = 0x82DBD6D0;
	sub_82DA76A0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82dbd57c
	if (!ctx.cr6.eq) goto loc_82DBD57C;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r5,r10,24,16,23
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// or r10,r5,r9
	ctx.r10.u64 = ctx.r5.u64 | ctx.r9.u64;
	// rlwinm r9,r8,8,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbd7b4
	if (!ctx.cr6.gt) goto loc_82DBD7B4;
loc_82DBD71C:
	// lwz r9,248(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// lbzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r11.u32);
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// rlwinm r4,r10,24,16,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r5,r10,16,0,15
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r5.u64 & 0xFFFFFFFF0000FFFF);
	// or r10,r4,r8
	ctx.r10.u64 = ctx.r4.u64 | ctx.r8.u64;
	// rlwinm r8,r5,8,0,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + ctx.r11.u32, ctx.r10.u32);
	// lwz r10,248(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82dbd7a0
	if (!ctx.cr6.gt) goto loc_82DBD7A0;
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 + ctx.r7.u64;
loc_82DBD764:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lbz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// rlwinm r3,r10,24,16,23
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r4,r10,16,0,15
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r4.u64 & 0xFFFFFFFF0000FFFF);
	// or r10,r3,r5
	ctx.r10.u64 = ctx.r3.u64 | ctx.r5.u64;
	// rlwinm r5,r4,8,0,15
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r5,r10
	ctx.r10.u64 = ctx.r5.u64 | ctx.r10.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// bne cr6,0x82dbd764
	if (!ctx.cr6.eq) goto loc_82DBD764;
loc_82DBD7A0:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r6,r11
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbd71c
	if (ctx.cr6.lt) goto loc_82DBD71C;
loc_82DBD7B4:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82dbd7ec
	if (!ctx.cr6.eq) goto loc_82DBD7EC;
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r9,124(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// rlwinm r11,r11,11,0,20
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 11) & 0xFFFFF800;
	// lhz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 120);
	// twllei r9,0
	// divwu r11,r11,r9
	ctx.r11.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r10,0
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// b 0x82dbd820
	goto loc_82DBD820;
loc_82DBD7EC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// b 0x82dbd820
	goto loc_82DBD820;
loc_82DBD810:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82da7e70
	ctx.lr = 0x82DBD820;
	sub_82DA7E70(ctx, base);
loc_82DBD820:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// add r10,r11,r23
	ctx.r10.u64 = ctx.r11.u64 + ctx.r23.u64;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r23,r10,8
	ctx.r23.s64 = ctx.r10.s64 + 8;
	// addi r10,r9,8
	ctx.r10.s64 = ctx.r9.s64 + 8;
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// beq cr6,0x82dbd854
	if (ctx.cr6.eq) goto loc_82DBD854;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r23,r23,1
	ctx.r23.s64 = ctx.r23.s64 + 1;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
loc_82DBD854:
	// lwz r11,812(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	// cmplw cr6,r23,r11
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82dbd57c
	if (!ctx.cr6.lt) goto loc_82DBD57C;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dbd57c
	if (ctx.cr6.eq) goto loc_82DBD57C;
	// clrlwi r11,r20,24
	ctx.r11.u64 = ctx.r20.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbd330
	if (ctx.cr6.eq) goto loc_82DBD330;
	// b 0x82dbd57c
	goto loc_82DBD57C;
loc_82DBD878:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DBD884:
	// lhz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 112);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbd594
	if (ctx.cr6.eq) goto loc_82DBD594;
	// lbz r10,123(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 123);
	// li r6,2048
	ctx.r6.s64 = 2048;
	// lhz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 120);
	// lbz r9,122(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 122);
	// lwz r8,132(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// lwz r7,136(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stb r10,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r10.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// stb r9,3(r29)
	PPC_STORE_U8(ctx.r29.u32 + 3, ctx.r9.u8);
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// stw r8,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r8.u32);
	// stw r7,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r7.u32);
	// stw r6,24(r29)
	PPC_STORE_U32(ctx.r29.u32 + 24, ctx.r6.u32);
	// stw r10,12(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12, ctx.r10.u32);
	// stb r11,1(r29)
	PPC_STORE_U8(ctx.r29.u32 + 1, ctx.r11.u8);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// stw r11,28(r29)
	PPC_STORE_U32(ctx.r29.u32 + 28, ctx.r11.u32);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// stw r28,36(r29)
	PPC_STORE_U32(ctx.r29.u32 + 36, ctx.r28.u32);
	// stw r11,32(r29)
	PPC_STORE_U32(ctx.r29.u32 + 32, ctx.r11.u32);
	// beq cr6,0x82dbd91c
	if (ctx.cr6.eq) goto loc_82DBD91C;
	// addi r10,r29,40
	ctx.r10.s64 = ctx.r29.s64 + 40;
	// addi r11,r1,141
	ctx.r11.s64 = ctx.r1.s64 + 141;
loc_82DBD8F4:
	// lhz r8,1(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
	// sth r8,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r8.u16);
	// stb r7,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r7.u8);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lbz r8,1(r29)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1);
	// cmpw cr6,r9,r8
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, ctx.xer);
	// blt cr6,0x82dbd8f4
	if (ctx.cr6.lt) goto loc_82DBD8F4;
loc_82DBD91C:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbd594
	if (ctx.cr6.eq) goto loc_82DBD594;
	// lwz r11,156(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 156);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82dbd944
	if (!ctx.cr6.eq) goto loc_82DBD944;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r28,156(r31)
	PPC_STORE_U32(ctx.r31.u32 + 156, ctx.r28.u32);
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DBD944:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82DBD948:
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBD950"))) PPC_WEAK_FUNC(sub_82DBD950);
PPC_FUNC_IMPL(__imp__sub_82DBD950) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DBD958;
	__savegprlr_26(ctx, base);
	// stwu r1,-672(r1)
	ea = -672 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r26,0
	ctx.r26.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r5,511
	ctx.r5.s64 = 511;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,97
	ctx.r3.s64 = ctx.r1.s64 + 97;
	// stb r26,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, ctx.r26.u8);
	// bl 0x82cb16f0
	ctx.lr = 0x82DBD97C;
	sub_82CB16F0(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lis r30,-31909
	ctx.r30.s64 = -2091188224;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,19872(r30)
	PPC_STORE_U32(ctx.r30.u32 + 19872, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// stw r10,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r10.u32);
	// stw r26,220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 220, ctx.r26.u32);
	// stw r26,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r26.u32);
	// stw r26,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r26.u32);
	// stb r11,229(r31)
	PPC_STORE_U8(ctx.r31.u32 + 229, ctx.r11.u8);
	// bl 0x82da7e70
	ctx.lr = 0x82DBD9B4;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da76a0
	ctx.lr = 0x82DBD9D4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,7028
	ctx.r4.s64 = ctx.r11.s64 + 7028;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBD9F0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbda04
	if (ctx.cr6.eq) goto loc_82DBDA04;
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,672
	ctx.r1.s64 = ctx.r1.s64 + 672;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
loc_82DBDA04:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// bl 0x82da76a0
	ctx.lr = 0x82DBDA1C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r8,-1
	ctx.r8.s64 = -1;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// stw r8,156(r31)
	PPC_STORE_U32(ctx.r31.u32 + 156, ctx.r8.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r6,1055
	ctx.r6.s64 = 1055;
	// addi r5,r11,7352
	ctx.r5.s64 = ctx.r11.s64 + 7352;
	// rlwinm r11,r10,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// li r4,296
	ctx.r4.s64 = 296;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lwz r11,19872(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DBDA70;
	sub_82D862B0(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// bne cr6,0x82dbda8c
	if (!ctx.cr6.eq) goto loc_82DBDA8C;
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,672
	ctx.r1.s64 = ctx.r1.s64 + 672;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
loc_82DBDA8C:
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbd298
	ctx.lr = 0x82DBDAA4;
	sub_82DBD298(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,156(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 156);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DBDABC;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// stw r26,260(r10)
	PPC_STORE_U32(ctx.r10.u32 + 260, ctx.r26.u32);
	// lbz r10,97(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dbdb08
	if (ctx.cr6.eq) goto loc_82DBDB08;
	// addi r10,r1,136
	ctx.r10.s64 = ctx.r1.s64 + 136;
loc_82DBDAE0:
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r7,260(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 260);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// stw r8,260(r9)
	PPC_STORE_U32(ctx.r9.u32 + 260, ctx.r8.u32);
	// lbz r9,97(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dbdae0
	if (ctx.cr6.lt) goto loc_82DBDAE0;
loc_82DBDB08:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r10,264(r11)
	PPC_STORE_U32(ctx.r11.u32 + 264, ctx.r10.u32);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r9,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r9.u32);
	// lbz r11,97(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// ble cr6,0x82dbdb3c
	if (!ctx.cr6.gt) goto loc_82DBDB3C;
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// b 0x82dbdb40
	goto loc_82DBDB40;
loc_82DBDB3C:
	// li r10,2048
	ctx.r10.s64 = 2048;
loc_82DBDB40:
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// rlwinm r11,r29,0,24,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dbdb98
	if (!ctx.cr6.eq) goto loc_82DBDB98;
	// rlwinm r30,r29,0,22,22
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dbdb98
	if (ctx.cr6.eq) goto loc_82DBDB98;
	// lbz r11,97(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82dbdb74
	if (!ctx.cr6.gt) goto loc_82DBDB74;
	// li r3,75
	ctx.r3.s64 = 75;
	// addi r1,r1,672
	ctx.r1.s64 = ctx.r1.s64 + 672;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
loc_82DBDB74:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// li r10,9
	ctx.r10.s64 = 9;
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// stw r10,256(r9)
	PPC_STORE_U32(ctx.r9.u32 + 256, ctx.r10.u32);
	// lwz r11,212(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 212);
	// ori r11,r11,512
	ctx.r11.u64 = ctx.r11.u64 | 512;
	// stw r11,212(r31)
	PPC_STORE_U32(ctx.r31.u32 + 212, ctx.r11.u32);
	// b 0x82dbdbd0
	goto loc_82DBDBD0;
loc_82DBDB98:
	// rlwinm r30,r29,0,22,22
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x200;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dbdbb4
	if (ctx.cr6.eq) goto loc_82DBDBB4;
	// li r10,9
	ctx.r10.s64 = 9;
	// stw r10,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r10.u32);
	// b 0x82dbdbd0
	goto loc_82DBDBD0;
loc_82DBDBB4:
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r10,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r10.u32);
	// lbz r4,97(r1)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// bl 0x82dbc828
	ctx.lr = 0x82DBDBC8;
	sub_82DBC828(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
loc_82DBDBD0:
	// lwz r11,244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbdbe4
	if (ctx.cr6.eq) goto loc_82DBDBE4;
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82dbdbe8
	goto loc_82DBDBE8;
loc_82DBDBE4:
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82DBDBE8:
	// li r9,512
	ctx.r9.s64 = 512;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r11,188(r31)
	PPC_STORE_U32(ctx.r31.u32 + 188, ctx.r11.u32);
	// stw r9,196(r31)
	PPC_STORE_U32(ctx.r31.u32 + 196, ctx.r9.u32);
	// lwz r11,260(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 260);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// li r11,2
	ctx.r11.s64 = 2;
	// bgt cr6,0x82dbdc0c
	if (ctx.cr6.gt) goto loc_82DBDC0C;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82DBDC0C:
	// rlwinm r11,r11,10,0,21
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 10) & 0xFFFFFC00;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// stw r11,200(r31)
	PPC_STORE_U32(ctx.r31.u32 + 200, ctx.r11.u32);
	// beq cr6,0x82dbdce8
	if (ctx.cr6.eq) goto loc_82DBDCE8;
	// rlwinm r11,r29,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbdce8
	if (ctx.cr6.eq) goto loc_82DBDCE8;
	// lwz r11,256(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 256);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82dbdce8
	if (!ctx.cr6.eq) goto loc_82DBDCE8;
	// lis r10,0
	ctx.r10.s64 = 0;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// ori r27,r10,39640
	ctx.r27.u64 = ctx.r10.u64 | 39640;
	// lwzx r10,r11,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dbdce8
	if (!ctx.cr6.eq) goto loc_82DBDCE8;
	// lis r10,0
	ctx.r10.s64 = 0;
	// ori r10,r10,38096
	ctx.r10.u64 = ctx.r10.u64 | 38096;
	// lwzx r6,r11,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r6,0
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// bne cr6,0x82dbdc64
	if (!ctx.cr6.eq) goto loc_82DBDC64;
	// li r6,32
	ctx.r6.s64 = 32;
loc_82DBDC64:
	// addis r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 65536;
	// li r5,512
	ctx.r5.s64 = 512;
	// li r4,3
	ctx.r4.s64 = 3;
	// addi r3,r3,-25900
	ctx.r3.s64 = ctx.r3.s64 + -25900;
	// bl 0x82da9108
	ctx.lr = 0x82DBDC78;
	sub_82DA9108(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// lwzx r11,r11,r27
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbdce8
	if (!ctx.cr6.gt) goto loc_82DBDCE8;
	// lis r11,0
	ctx.r11.s64 = 0;
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// ori r29,r11,39644
	ctx.r29.u64 = ctx.r11.u64 | 39644;
loc_82DBDCA0:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwzx r11,r11,r29
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// lwzx r11,r11,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// lwz r3,1116(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1116);
	// stw r26,156(r3)
	PPC_STORE_U32(ctx.r3.u32 + 156, ctx.r26.u32);
	// stw r26,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r26.u32);
	// stw r26,248(r3)
	PPC_STORE_U32(ctx.r3.u32 + 248, ctx.r26.u32);
	// stw r26,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r26.u32);
	// bl 0x82dbc828
	ctx.lr = 0x82DBDCC8;
	sub_82DBC828(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbdcec
	if (!ctx.cr6.eq) goto loc_82DBDCEC;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// lwzx r11,r11,r27
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbdca0
	if (ctx.cr6.lt) goto loc_82DBDCA0;
loc_82DBDCE8:
	// stw r26,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r26.u32);
loc_82DBDCEC:
	// addi r1,r1,672
	ctx.r1.s64 = ctx.r1.s64 + 672;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBDCF4"))) PPC_WEAK_FUNC(sub_82DBDCF4);
PPC_FUNC_IMPL(__imp__sub_82DBDCF4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBDCF8"))) PPC_WEAK_FUNC(sub_82DBDCF8);
PPC_FUNC_IMPL(__imp__sub_82DBDCF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e4
	ctx.lr = 0x82DBDD00;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lis r27,-31909
	ctx.r27.s64 = -2091188224;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// stw r30,200(r31)
	PPC_STORE_U32(ctx.r31.u32 + 200, ctx.r30.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r28,r11,7352
	ctx.r28.s64 = ctx.r11.s64 + 7352;
	// beq cr6,0x82dbdd50
	if (ctx.cr6.eq) goto loc_82DBDD50;
	// lwz r4,248(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbdd50
	if (ctx.cr6.eq) goto loc_82DBDD50;
	// lwz r11,19872(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1188
	ctx.r6.s64 = 1188;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBDD4C;
	sub_82D861B0(ctx, base);
	// stw r30,248(r31)
	PPC_STORE_U32(ctx.r31.u32 + 248, ctx.r30.u32);
loc_82DBDD50:
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbdd78
	if (ctx.cr6.eq) goto loc_82DBDD78;
	// lwz r11,19872(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1194
	ctx.r6.s64 = 1194;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBDD74;
	sub_82D861B0(ctx, base);
	// stw r30,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r30.u32);
loc_82DBDD78:
	// lwz r29,244(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82dbddf0
	if (ctx.cr6.eq) goto loc_82DBDDF0;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x82dbddb0
	if (!ctx.cr6.gt) goto loc_82DBDDB0;
	// addis r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 65536;
	// addi r29,r29,18480
	ctx.r29.s64 = ctx.r29.s64 + 18480;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dbddc4
	if (ctx.cr6.eq) goto loc_82DBDDC4;
	// bl 0x82fb9900
	ctx.lr = 0x82DBDDA8;
	sub_82FB9900(ctx, base);
	// stw r30,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r30.u32);
	// b 0x82dbddc4
	goto loc_82DBDDC4;
loc_82DBDDB0:
	// lwz r3,12840(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12840);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dbddc4
	if (ctx.cr6.eq) goto loc_82DBDDC4;
	// bl 0x833b80d4
	ctx.lr = 0x82DBDDC0;
	__imp__XMAReleaseContext(ctx, base);
	// stw r30,12840(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12840, ctx.r30.u32);
loc_82DBDDC4:
	// lwz r4,240(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbddec
	if (ctx.cr6.eq) goto loc_82DBDDEC;
	// lwz r11,19872(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 19872);
	// lis r7,16
	ctx.r7.s64 = 1048576;
	// li r6,1223
	ctx.r6.s64 = 1223;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBDDE8;
	sub_82D861B0(ctx, base);
	// stw r30,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r30.u32);
loc_82DBDDEC:
	// stw r30,244(r31)
	PPC_STORE_U32(ctx.r31.u32 + 244, ctx.r30.u32);
loc_82DBDDF0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82cb1134
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBDDFC"))) PPC_WEAK_FUNC(sub_82DBDDFC);
PPC_FUNC_IMPL(__imp__sub_82DBDDFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBDE00"))) PPC_WEAK_FUNC(sub_82DBDE00);
PPC_FUNC_IMPL(__imp__sub_82DBDE00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e4
	ctx.lr = 0x82DBDE08;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x82dbde3c
	if (!ctx.cr6.gt) goto loc_82DBDE3C;
	// lwz r7,224(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82dbce98
	ctx.lr = 0x82DBDE2C;
	sub_82DBCE98(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbdecc
	if (ctx.cr6.eq) goto loc_82DBDECC;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1134
	__restgprlr_27(ctx, base);
	return;
loc_82DBDE3C:
	// lwz r27,244(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,12840(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12840);
	// bl 0x833b8024
	ctx.lr = 0x82DBDE4C;
	__imp__XMADisableContext(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,224(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbcc70
	ctx.lr = 0x82DBDE60;
	sub_82DBCC70(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq cr6,0x82dbde80
	if (ctx.cr6.eq) goto loc_82DBDE80;
	// lwz r3,12840(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12840);
	// bl 0x833b7ff4
	ctx.lr = 0x82DBDE74;
	__imp__XMAEnableContext(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1134
	__restgprlr_27(ctx, base);
	return;
loc_82DBDE80:
	// lwz r31,80(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r29,12852(r27)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12852);
	// add r11,r5,r31
	ctx.r11.u64 = ctx.r5.u64 + ctx.r31.u64;
	// add r4,r29,r31
	ctx.r4.u64 = ctx.r29.u64 + ctx.r31.u64;
	// cmplwi cr6,r11,2048
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2048, ctx.xer);
	// ble cr6,0x82dbdec0
	if (!ctx.cr6.gt) goto loc_82DBDEC0;
	// subfic r5,r31,2048
	ctx.xer.ca = ctx.r31.u32 <= 2048;
	ctx.r5.s64 = 2048 - ctx.r31.s64;
	// bl 0x82cb1160
	ctx.lr = 0x82DBDEA8;
	sub_82CB1160(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r5,r10,-2048
	ctx.r5.s64 = ctx.r10.s64 + -2048;
	// addi r3,r11,2048
	ctx.r3.s64 = ctx.r11.s64 + 2048;
loc_82DBDEC0:
	// bl 0x82cb1160
	ctx.lr = 0x82DBDEC4;
	sub_82CB1160(ctx, base);
	// lwz r3,12840(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12840);
	// bl 0x833b7ff4
	ctx.lr = 0x82DBDECC;
	__imp__XMAEnableContext(ctx, base);
loc_82DBDECC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1134
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBDED8"))) PPC_WEAK_FUNC(sub_82DBDED8);
PPC_FUNC_IMPL(__imp__sub_82DBDED8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DBDEE0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 8, ctx.xer);
	// bne cr6,0x82dbdf10
	if (!ctx.cr6.eq) goto loc_82DBDF10;
	// lwz r11,156(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// add r4,r11,r29
	ctx.r4.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bl 0x82da7e70
	ctx.lr = 0x82DBDF08;
	sub_82DA7E70(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBDF10:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dbc9e0
	ctx.lr = 0x82DBDF18;
	sub_82DBC9E0(ctx, base);
	// lbz r11,229(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 229);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbe030
	if (ctx.cr6.eq) goto loc_82DBE030;
	// lwz r11,236(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 236);
	// li r9,2048
	ctx.r9.s64 = 2048;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x82dbdf3c
	if (!ctx.cr6.gt) goto loc_82DBDF3C;
	// lis r9,0
	ctx.r9.s64 = 0;
	// ori r9,r9,32768
	ctx.r9.u64 = ctx.r9.u64 | 32768;
loc_82DBDF3C:
	// lwz r11,248(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 248);
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82dbdf84
	if (!ctx.cr6.gt) goto loc_82DBDF84;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
loc_82DBDF5C:
	// lwz r8,-4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// cmplw cr6,r29,r8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82dbdf74
	if (ctx.cr6.lt) goto loc_82DBDF74;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r29,r8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x82dbdf84
	if (!ctx.cr6.gt) goto loc_82DBDF84;
loc_82DBDF74:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r31,r10
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dbdf5c
	if (ctx.cr6.lt) goto loc_82DBDF5C;
loc_82DBDF84:
	// lwz r10,156(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	// mullw r11,r31,r9
	ctx.r11.s64 = int64_t(ctx.r31.s32) * int64_t(ctx.r9.s32);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82da7e70
	ctx.lr = 0x82DBDF9C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe100
	if (!ctx.cr6.eq) goto loc_82DBE100;
	// addi r10,r31,2
	ctx.r10.s64 = ctx.r31.s64 + 2;
	// lwz r9,248(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 248);
	// addi r11,r29,384
	ctx.r11.s64 = ctx.r29.s64 + 384;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dbdfc8
	if (!ctx.cr6.lt) goto loc_82DBDFC8;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// b 0x82dbdfcc
	goto loc_82DBDFCC;
loc_82DBDFC8:
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82DBDFCC:
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r10,260(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 260);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// rlwinm r31,r11,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dbe0fc
	if (ctx.cr6.eq) goto loc_82DBE0FC;
	// lis r11,-31894
	ctx.r11.s64 = -2090205184;
	// addi r29,r11,-11984
	ctx.r29.s64 = ctx.r11.s64 + -11984;
loc_82DBDFEC:
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,2048
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 2048, ctx.xer);
	// ble cr6,0x82dbe000
	if (!ctx.cr6.gt) goto loc_82DBE000;
	// li r5,2048
	ctx.r5.s64 = 2048;
loc_82DBE000:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82de8b80
	ctx.lr = 0x82DBE010;
	sub_82DE8B80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe0fc
	if (!ctx.cr6.eq) goto loc_82DBE0FC;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// subf r31,r11,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r11.s64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82dbdfec
	if (!ctx.cr6.eq) goto loc_82DBDFEC;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_82DBE030:
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r10,268(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// rlwinm r9,r10,21,11,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x1FFFFF;
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bgt cr6,0x82dbe050
	if (ctx.cr6.gt) goto loc_82DBE050;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// b 0x82dbe07c
	goto loc_82DBE07C;
loc_82DBE050:
	// clrldi r8,r10,32
	ctx.r8.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// lwz r11,272(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// clrldi r7,r29,32
	ctx.r7.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// addi r10,r9,-2
	ctx.r10.s64 = ctx.r9.s64 + -2;
	// mulld r9,r8,r7
	ctx.r9.s64 = ctx.r8.s64 * ctx.r7.s64;
	// tdllei r11,0
	// divdu r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 / ctx.r11.u64;
	// rlwinm r11,r11,21,11,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1FFFFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dbe07c
	if (!ctx.cr6.gt) goto loc_82DBE07C;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82DBE07C:
	// lwz r10,156(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	// rlwinm r11,r11,11,0,20
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 11) & 0xFFFFF800;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82da7e70
	ctx.lr = 0x82DBE094;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe100
	if (!ctx.cr6.eq) goto loc_82DBE100;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r11,260(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r31,r11,8,0,23
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFFFFFF00;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dbe0fc
	if (ctx.cr6.eq) goto loc_82DBE0FC;
	// lis r11,-31894
	ctx.r11.s64 = -2090205184;
	// addi r29,r11,-14032
	ctx.r29.s64 = ctx.r11.s64 + -14032;
loc_82DBE0C0:
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,2048
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 2048, ctx.xer);
	// ble cr6,0x82dbe0d4
	if (!ctx.cr6.gt) goto loc_82DBE0D4;
	// li r5,2048
	ctx.r5.s64 = 2048;
loc_82DBE0D4:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82de8b80
	ctx.lr = 0x82DBE0E4;
	sub_82DE8B80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe0fc
	if (!ctx.cr6.eq) goto loc_82DBE0FC;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// subf r31,r11,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r11.s64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82dbe0c0
	if (!ctx.cr6.eq) goto loc_82DBE0C0;
loc_82DBE0FC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE100:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE108"))) PPC_WEAK_FUNC(sub_82DBE108);
PPC_FUNC_IMPL(__imp__sub_82DBE108) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbe118
	if (!ctx.cr6.eq) goto loc_82DBE118;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE118:
	// b 0x82dbd950
	sub_82DBD950(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE11C"))) PPC_WEAK_FUNC(sub_82DBE11C);
PPC_FUNC_IMPL(__imp__sub_82DBE11C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBE120"))) PPC_WEAK_FUNC(sub_82DBE120);
PPC_FUNC_IMPL(__imp__sub_82DBE120) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbe130
	if (!ctx.cr6.eq) goto loc_82DBE130;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE130:
	// b 0x82dbdcf8
	sub_82DBDCF8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE134"))) PPC_WEAK_FUNC(sub_82DBE134);
PPC_FUNC_IMPL(__imp__sub_82DBE134) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBE138"))) PPC_WEAK_FUNC(sub_82DBE138);
PPC_FUNC_IMPL(__imp__sub_82DBE138) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbe148
	if (!ctx.cr6.eq) goto loc_82DBE148;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE148:
	// b 0x82dbde00
	sub_82DBDE00(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE14C"))) PPC_WEAK_FUNC(sub_82DBE14C);
PPC_FUNC_IMPL(__imp__sub_82DBE14C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBE150"))) PPC_WEAK_FUNC(sub_82DBE150);
PPC_FUNC_IMPL(__imp__sub_82DBE150) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbe160
	if (!ctx.cr6.eq) goto loc_82DBE160;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE160:
	// b 0x82dbded8
	sub_82DBDED8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE164"))) PPC_WEAK_FUNC(sub_82DBE164);
PPC_FUNC_IMPL(__imp__sub_82DBE164) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBE168"))) PPC_WEAK_FUNC(sub_82DBE168);
PPC_FUNC_IMPL(__imp__sub_82DBE168) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,28880
	ctx.r31.s64 = ctx.r11.s64 + 28880;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBE190;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r7,-32036
	ctx.r7.s64 = -2099511296;
	// addi r11,r11,7460
	ctx.r11.s64 = ctx.r11.s64 + 7460;
	// lis r8,-32036
	ctx.r8.s64 = -2099511296;
	// lis r9,-32036
	ctx.r9.s64 = -2099511296;
	// lis r10,-32036
	ctx.r10.s64 = -2099511296;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,10
	ctx.r11.s64 = 10;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// addi r11,r7,-7928
	ctx.r11.s64 = ctx.r7.s64 + -7928;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r8,-7904
	ctx.r11.s64 = ctx.r8.s64 + -7904;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r9,-7880
	ctx.r11.s64 = ctx.r9.s64 + -7880;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r10,-7856
	ctx.r11.s64 = ctx.r10.s64 + -7856;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// li r11,22
	ctx.r11.s64 = 22;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,252
	ctx.r11.s64 = 252;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DBE208"))) PPC_WEAK_FUNC(sub_82DBE208);
PPC_FUNC_IMPL(__imp__sub_82DBE208) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d8
	ctx.lr = 0x82DBE210;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r24,0
	ctx.r24.s64 = 0;
	// addi r27,r11,7480
	ctx.r27.s64 = ctx.r11.s64 + 7480;
	// lis r26,-31909
	ctx.r26.s64 = -2091188224;
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbe250
	if (ctx.cr6.eq) goto loc_82DBE250;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,705
	ctx.r6.s64 = 705;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBE24C;
	sub_82D861B0(ctx, base);
	// stw r24,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r24.u32);
loc_82DBE250:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbe36c
	if (ctx.cr6.eq) goto loc_82DBE36C;
	// lwz r11,232(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// mr r25,r24
	ctx.r25.u64 = ctx.r24.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbe34c
	if (!ctx.cr6.gt) goto loc_82DBE34C;
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
loc_82DBE270:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r10,268(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dbe30c
	if (ctx.cr6.eq) goto loc_82DBE30C;
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// mr r28,r24
	ctx.r28.u64 = ctx.r24.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82dbe2e8
	if (!ctx.cr6.gt) goto loc_82DBE2E8;
	// mr r29,r24
	ctx.r29.u64 = ctx.r24.u64;
loc_82DBE298:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lwz r4,64(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbe2cc
	if (ctx.cr6.eq) goto loc_82DBE2CC;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,726
	ctx.r6.s64 = 726;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBE2CC;
	sub_82D861B0(ctx, base);
loc_82DBE2CC:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r29,r29,68
	ctx.r29.s64 = ctx.r29.s64 + 68;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82dbe298
	if (ctx.cr6.lt) goto loc_82DBE298;
loc_82DBE2E8:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// li r6,730
	ctx.r6.s64 = 730;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// add r11,r10,r30
	ctx.r11.u64 = ctx.r10.u64 + ctx.r30.u64;
	// lwz r4,268(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// bl 0x82d861b0
	ctx.lr = 0x82DBE30C;
	sub_82D861B0(ctx, base);
loc_82DBE30C:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r4,276(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbe338
	if (ctx.cr6.eq) goto loc_82DBE338;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,734
	ctx.r6.s64 = 734;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBE338;
	sub_82D861B0(ctx, base);
loc_82DBE338:
	// lwz r11,232(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r30,r30,280
	ctx.r30.s64 = ctx.r30.s64 + 280;
	// cmpw cr6,r25,r11
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dbe270
	if (ctx.cr6.lt) goto loc_82DBE270;
loc_82DBE34C:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,738
	ctx.r6.s64 = 738;
	// lwz r4,240(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBE368;
	sub_82D861B0(ctx, base);
	// stw r24,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r24.u32);
loc_82DBE36C:
	// lwz r4,252(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dbe394
	if (ctx.cr6.eq) goto loc_82DBE394;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,744
	ctx.r6.s64 = 744;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DBE390;
	sub_82D861B0(ctx, base);
	// stw r24,252(r31)
	PPC_STORE_U32(ctx.r31.u32 + 252, ctx.r24.u32);
loc_82DBE394:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE3A0"))) PPC_WEAK_FUNC(sub_82DBE3A0);
PPC_FUNC_IMPL(__imp__sub_82DBE3A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DBE3A8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE3CC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbe3dc
	if (ctx.cr6.eq) goto loc_82DBE3DC;
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82dbe480
	if (!ctx.cr6.eq) goto loc_82DBE480;
loc_82DBE3DC:
	// lwz r11,256(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 256);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dbe434
	if (!ctx.cr6.eq) goto loc_82DBE434;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// ble cr6,0x82dbe480
	if (!ctx.cr6.gt) goto loc_82DBE480;
loc_82DBE40C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// xori r9,r9,128
	ctx.r9.u64 = ctx.r9.u64 ^ 128;
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82dbe40c
	if (ctx.cr6.lt) goto loc_82DBE40C;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DBE434:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbe480
	if (ctx.cr6.eq) goto loc_82DBE480;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82DBE44C:
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// extsh r8,r10
	ctx.r8.s64 = ctx.r10.s16;
	// rlwinm r10,r10,24,8,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFFFF;
	// rlwinm r8,r8,8,0,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFFFF00;
	// extsh r8,r8
	ctx.r8.s64 = ctx.r8.s16;
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dbe44c
	if (ctx.cr6.lt) goto loc_82DBE44C;
loc_82DBE480:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE488"))) PPC_WEAK_FUNC(sub_82DBE488);
PPC_FUNC_IMPL(__imp__sub_82DBE488) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbe498
	if (!ctx.cr6.eq) goto loc_82DBE498;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE498:
	// b 0x82dbe208
	sub_82DBE208(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE49C"))) PPC_WEAK_FUNC(sub_82DBE49C);
PPC_FUNC_IMPL(__imp__sub_82DBE49C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBE4A0"))) PPC_WEAK_FUNC(sub_82DBE4A0);
PPC_FUNC_IMPL(__imp__sub_82DBE4A0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dbe4b0
	if (!ctx.cr6.eq) goto loc_82DBE4B0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBE4B0:
	// b 0x82dbe3a0
	sub_82DBE3A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBE4B4"))) PPC_WEAK_FUNC(sub_82DBE4B4);
PPC_FUNC_IMPL(__imp__sub_82DBE4B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBE4B8"))) PPC_WEAK_FUNC(sub_82DBE4B8);
PPC_FUNC_IMPL(__imp__sub_82DBE4B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DBE4C0;
	__savegprlr_14(ctx, base);
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r4,444(r1)
	PPC_STORE_U32(ctx.r1.u32 + 444, ctx.r4.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r5,452(r1)
	PPC_STORE_U32(ctx.r1.u32 + 452, ctx.r5.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DBE4DC;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// li r11,4
	ctx.r11.s64 = 4;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r21,r11,7788
	ctx.r21.s64 = ctx.r11.s64 + 7788;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// addi r20,r11,7780
	ctx.r20.s64 = ctx.r11.s64 + 7780;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r19,r11,7772
	ctx.r19.s64 = ctx.r11.s64 + 7772;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r18,r11,7764
	ctx.r18.s64 = ctx.r11.s64 + 7764;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r17,r11,7756
	ctx.r17.s64 = ctx.r11.s64 + 7756;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r16,r11,7748
	ctx.r16.s64 = ctx.r11.s64 + 7748;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r15,r11,7740
	ctx.r15.s64 = ctx.r11.s64 + 7740;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r14,r11,7732
	ctx.r14.s64 = ctx.r11.s64 + 7732;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7724
	ctx.r11.s64 = ctx.r11.s64 + 7724;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7716
	ctx.r11.s64 = ctx.r11.s64 + 7716;
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7708
	ctx.r11.s64 = ctx.r11.s64 + 7708;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7700
	ctx.r11.s64 = ctx.r11.s64 + 7700;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7692
	ctx.r11.s64 = ctx.r11.s64 + 7692;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7684
	ctx.r11.s64 = ctx.r11.s64 + 7684;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7676
	ctx.r11.s64 = ctx.r11.s64 + 7676;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7668
	ctx.r11.s64 = ctx.r11.s64 + 7668;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7660
	ctx.r11.s64 = ctx.r11.s64 + 7660;
	// stw r11,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7436
	ctx.r11.s64 = ctx.r11.s64 + 7436;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7428
	ctx.r11.s64 = ctx.r11.s64 + 7428;
	// stw r11,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7652
	ctx.r11.s64 = ctx.r11.s64 + 7652;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7644
	ctx.r11.s64 = ctx.r11.s64 + 7644;
	// stw r11,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7636
	ctx.r11.s64 = ctx.r11.s64 + 7636;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7628
	ctx.r11.s64 = ctx.r11.s64 + 7628;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7620
	ctx.r11.s64 = ctx.r11.s64 + 7620;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r26,r11,7612
	ctx.r26.s64 = ctx.r11.s64 + 7612;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7604
	ctx.r11.s64 = ctx.r11.s64 + 7604;
	// stw r11,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r25,r11,7596
	ctx.r25.s64 = ctx.r11.s64 + 7596;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7588
	ctx.r11.s64 = ctx.r11.s64 + 7588;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7580
	ctx.r11.s64 = ctx.r11.s64 + 7580;
	// stw r11,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r28,-31909
	ctx.r28.s64 = -2091188224;
	// addi r29,r11,7480
	ctx.r29.s64 = ctx.r11.s64 + 7480;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r24,0
	ctx.r24.s64 = 0;
	// addi r11,r11,7572
	ctx.r11.s64 = ctx.r11.s64 + 7572;
	// li r27,2
	ctx.r27.s64 = 2;
	// stw r11,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r23,r11,7564
	ctx.r23.s64 = ctx.r11.s64 + 7564;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,7556
	ctx.r11.s64 = ctx.r11.s64 + 7556;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r22,r11,7548
	ctx.r22.s64 = ctx.r11.s64 + 7548;
loc_82DBE668:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r10,8
	ctx.r4.s64 = ctx.r10.s64 + 8;
	// bl 0x82da7e70
	ctx.lr = 0x82DBE678;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE698;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r10,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82da45e8
	ctx.lr = 0x82DBE6D4;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,148(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE6EC;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE704;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,188(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE71C;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r5,4
	ctx.r5.s64 = 4;
	// bne cr6,0x82dbe780
	if (!ctx.cr6.eq) goto loc_82DBE780;
	// addi r30,r31,232
	ctx.r30.s64 = ctx.r31.s64 + 232;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE740;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r6,151
	ctx.r6.s64 = 151;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mulli r4,r10,280
	ctx.r4.s64 = ctx.r10.s64 * 280;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DBE768;
	sub_82D862B0(ctx, base);
	// stw r3,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82dbfd90
	if (!ctx.cr6.eq) goto loc_82DBFD90;
loc_82DBE774:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DBE780:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82da45e8
	ctx.lr = 0x82DBE78C;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r5,4
	ctx.r5.s64 = 4;
	// bne cr6,0x82dbe834
	if (!ctx.cr6.eq) goto loc_82DBE834;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,232
	ctx.r4.s64 = ctx.r1.s64 + 232;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE7AC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// addi r30,r31,244
	ctx.r30.s64 = ctx.r31.s64 + 244;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE7D0;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r6,178
	ctx.r6.s64 = 178;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mulli r4,r10,296
	ctx.r4.s64 = ctx.r10.s64 * 296;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DBE7F8;
	sub_82D862B0(ctx, base);
	// stw r3,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dbe774
	if (ctx.cr6.eq) goto loc_82DBE774;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r6,184
	ctx.r6.s64 = 184;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mulli r4,r10,296
	ctx.r4.s64 = ctx.r10.s64 * 296;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DBE824;
	sub_82D862B0(ctx, base);
	// stw r3,252(r31)
	PPC_STORE_U32(ctx.r31.u32 + 252, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dbe774
	if (ctx.cr6.eq) goto loc_82DBE774;
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBE834:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// bl 0x82da45e8
	ctx.lr = 0x82DBE840;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe8f8
	if (!ctx.cr6.eq) goto loc_82DBE8F8;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE860;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dbe4b8
	ctx.lr = 0x82DBE878;
	sub_82DBE4B8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE890;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe8a8
	if (!ctx.cr6.eq) goto loc_82DBE8A8;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,248(r31)
	PPC_STORE_U32(ctx.r31.u32 + 248, ctx.r11.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBE8A8:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,184(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE8B8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe8d0
	if (!ctx.cr6.eq) goto loc_82DBE8D0;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 236, ctx.r11.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBE8D0:
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE8E0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfd90
	if (!ctx.cr6.eq) goto loc_82DBFD90;
	// lwz r11,260(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,260(r31)
	PPC_STORE_U32(ctx.r31.u32 + 260, ctx.r11.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBE8F8:
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE908;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbe934
	if (!ctx.cr6.eq) goto loc_82DBE934;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,16
	ctx.r6.s64 = 16;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE928;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBE934:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,124(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBE944;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbea80
	if (!ctx.cr6.eq) goto loc_82DBEA80;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// li r6,12
	ctx.r6.s64 = 12;
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r11,256
	ctx.r4.s64 = ctx.r11.s64 + 256;
	// bl 0x82da76a0
	ctx.lr = 0x82DBE974;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// li r6,250
	ctx.r6.s64 = 250;
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r10,256(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lbz r9,256(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 256);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r4,r10,24,16,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 | ctx.r4.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// lbz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 260);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r4,r10,24,16,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 | ctx.r4.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,264(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// lbz r9,264(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 264);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r4,r10,24,16,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 | ctx.r4.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,264(r11)
	PPC_STORE_U32(ctx.r11.u32 + 264, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r11,280
	ctx.r10.s64 = ctx.r11.s64 * 280;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// add r11,r10,r9
	ctx.r11.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// mulli r4,r11,68
	ctx.r4.s64 = ctx.r11.s64 * 68;
	// bl 0x82d862b0
	ctx.lr = 0x82DBEA48;
	sub_82D862B0(ctx, base);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r3,268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 268, ctx.r3.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbe774
	if (ctx.cr6.eq) goto loc_82DBE774;
	// stw r24,260(r31)
	PPC_STORE_U32(ctx.r31.u32 + 260, ctx.r24.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBEA80:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,164(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBEA90;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbec0c
	if (!ctx.cr6.eq) goto loc_82DBEC0C;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// li r6,12
	ctx.r6.s64 = 12;
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// li r5,1
	ctx.r5.s64 = 1;
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBEACC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// lhzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r10.u32);
	// lbzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// sthx r9,r11,r10
	PPC_STORE_U16(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// lbz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// lbz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 4);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,4(r11)
	PPC_STORE_U16(ctx.r11.u32 + 4, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,6(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 6);
	// lbz r9,6(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 6);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,6(r11)
	PPC_STORE_U16(ctx.r11.u32 + 6, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// lbz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 8);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,8(r11)
	PPC_STORE_U16(ctx.r11.u32 + 8, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,10(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// lbz r9,10(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 10);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,10(r11)
	PPC_STORE_U16(ctx.r11.u32 + 10, ctx.r10.u16);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBEC0C:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,132(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBEC1C;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbf168
	if (!ctx.cr6.eq) goto loc_82DBF168;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r30,36
	ctx.r30.s64 = 36;
	// cmplwi cr6,r11,36
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 36, ctx.xer);
	// bge cr6,0x82dbec38
	if (!ctx.cr6.lt) goto loc_82DBEC38;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
loc_82DBEC38:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r3,444(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x82da45e8
	ctx.lr = 0x82DBEC48;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbeeac
	if (!ctx.cr6.eq) goto loc_82DBEEAC;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r11,260
	ctx.r4.s64 = ctx.r11.s64 + 260;
	// bl 0x82da76a0
	ctx.lr = 0x82DBEC78;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// lbz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 260);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,264(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 264);
	// lbz r9,264(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 264);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,264(r11)
	PPC_STORE_U16(ctx.r11.u32 + 264, ctx.r10.u16);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,266(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 266);
	// extsh r9,r10
	ctx.r9.s64 = ctx.r10.s16;
	// rlwinm r10,r10,24,8,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFFFF;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// sth r10,266(r11)
	PPC_STORE_U16(ctx.r11.u32 + 266, ctx.r10.u16);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,268(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// lbz r9,268(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 268);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// or r10,r7,r9
	ctx.r10.u64 = ctx.r7.u64 | ctx.r9.u64;
	// rlwinm r9,r8,8,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 268, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,272(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// lbz r9,272(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 272);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lbz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 280);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,280(r11)
	PPC_STORE_U32(ctx.r11.u32 + 280, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,284(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 284);
	// lbz r9,284(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 284);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,284(r11)
	PPC_STORE_U32(ctx.r11.u32 + 284, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,288(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	// lbz r9,288(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 288);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,288(r11)
	PPC_STORE_U32(ctx.r11.u32 + 288, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,292(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	// lbz r9,292(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 292);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,292(r11)
	PPC_STORE_U32(ctx.r11.u32 + 292, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r27,288(r11)
	PPC_STORE_U32(ctx.r11.u32 + 288, ctx.r27.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r9,252(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,288(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 288);
	// stw r10,280(r11)
	PPC_STORE_U32(ctx.r11.u32 + 280, ctx.r10.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lwz r8,292(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 292);
	// lwz r10,288(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 288);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,284(r11)
	PPC_STORE_U32(ctx.r11.u32 + 284, ctx.r10.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBEEAC:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r3,444(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da45e8
	ctx.lr = 0x82DBEEBC;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfd90
	if (!ctx.cr6.eq) goto loc_82DBFD90;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// bl 0x82da76a0
	ctx.lr = 0x82DBEEFC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lbz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 12);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 16);
	// lbz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 16);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,16(r11)
	PPC_STORE_U16(ctx.r11.u32 + 16, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,18(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 18);
	// extsh r9,r10
	ctx.r9.s64 = ctx.r10.s16;
	// rlwinm r10,r10,24,8,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFFFF;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// sth r10,18(r11)
	PPC_STORE_U16(ctx.r11.u32 + 18, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// lbz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 20);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// or r10,r7,r9
	ctx.r10.u64 = ctx.r7.u64 | ctx.r9.u64;
	// rlwinm r9,r8,8,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lbz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 24);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r10,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stw r10,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r9,268(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,28(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// lbz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 32);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// lbz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 36);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lbz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 40);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,40(r11)
	PPC_STORE_U32(ctx.r11.u32 + 40, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// lbz r9,44(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 44);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,44(r11)
	PPC_STORE_U32(ctx.r11.u32 + 44, ctx.r10.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBF168:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,168(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBF178;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbf2b4
	if (!ctx.cr6.eq) goto loc_82DBF2B4;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// li r6,12
	ctx.r6.s64 = 12;
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r11,48
	ctx.r4.s64 = ctx.r11.s64 + 48;
	// bl 0x82da76a0
	ctx.lr = 0x82DBF1B8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 48);
	// lbz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 48);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,48(r11)
	PPC_STORE_U16(ctx.r11.u32 + 48, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r10,50(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 50);
	// lbz r9,50(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 50);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// sth r10,50(r11)
	PPC_STORE_U16(ctx.r11.u32 + 50, ctx.r10.u16);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// lbz r9,52(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 52);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// lbz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 56);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,56(r11)
	PPC_STORE_U32(ctx.r11.u32 + 56, ctx.r10.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBF2B4:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,140(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBF2C4;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbf72c
	if (!ctx.cr6.eq) goto loc_82DBF72C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// bl 0x82da76a0
	ctx.lr = 0x82DBF2E4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// rlwimi r8,r11,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwimi r9,r11,16,16,31
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r9.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r7,r10,16,16,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF) | (ctx.r7.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r6,r10,16,0,15
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r6.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// rlwinm r9,r7,24,16,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xFFFF;
	// rlwinm r8,r6,8,0,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 | ctx.r10.u64;
	// or r11,r9,r8
	ctx.r11.u64 = ctx.r9.u64 | ctx.r8.u64;
	// cmplwi cr6,r10,8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 8, ctx.xer);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// ble cr6,0x82dbf350
	if (!ctx.cr6.gt) goto loc_82DBF350;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r10,-8
	ctx.r4.s64 = ctx.r10.s64 + -8;
	// bl 0x82da7e70
	ctx.lr = 0x82DBF34C;
	sub_82DA7E70(ctx, base);
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_82DBF350:
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r8,260(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,256(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 256);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// lwz r10,19872(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bge cr6,0x82dbf59c
	if (!ctx.cr6.lt) goto loc_82DBF59C;
	// li r6,380
	ctx.r6.s64 = 380;
	// bl 0x82d862b0
	ctx.lr = 0x82DBF394;
	sub_82D862B0(ctx, base);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r3,64(r11)
	PPC_STORE_U32(ctx.r11.u32 + 64, ctx.r3.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mulli r10,r9,68
	ctx.r10.s64 = ctx.r9.s64 * 68;
	// lwz r11,268(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dbe774
	if (ctx.cr6.eq) goto loc_82DBE774;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r10,60(r11)
	PPC_STORE_U32(ctx.r11.u32 + 60, ctx.r10.u32);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r8,260(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r9,r8,68
	ctx.r9.s64 = ctx.r8.s64 * 68;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r4,64(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82da76a0
	ctx.lr = 0x82DBF430;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
loc_82DBF44C:
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r9,r7,68
	ctx.r9.s64 = ctx.r7.s64 * 68;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// lhzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32);
	// lbzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sthx r9,r10,r11
	PPC_STORE_U16(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r9,r7,68
	ctx.r9.s64 = ctx.r7.s64 * 68;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r9,2(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 2);
	// lbz r7,2(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 2);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r9,r7,68
	ctx.r9.s64 = ctx.r7.s64 * 68;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 4);
	// lbz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 4);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sth r9,4(r10)
	PPC_STORE_U16(ctx.r10.u32 + 4, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r9,r7,68
	ctx.r9.s64 = ctx.r7.s64 * 68;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r9,6(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 6);
	// lbz r7,6(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 6);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sth r9,6(r10)
	PPC_STORE_U16(ctx.r10.u32 + 6, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r9,r7,68
	ctx.r9.s64 = ctx.r7.s64 * 68;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lbz r6,8(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 8);
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// rlwimi r7,r9,16,0,15
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0xFFFF0000) | (ctx.r7.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r9,r9,24,16,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFF00;
	// rlwinm r7,r7,8,0,15
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 8) & 0xFFFF0000;
	// or r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 | ctx.r6.u64;
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dbf44c
	if (ctx.cr6.lt) goto loc_82DBF44C;
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBF59C:
	// li r6,411
	ctx.r6.s64 = 411;
	// bl 0x82d862b0
	ctx.lr = 0x82DBF5A4;
	sub_82D862B0(ctx, base);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r3,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r3.u32);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dbe774
	if (ctx.cr6.eq) goto loc_82DBE774;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r4,276(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 276);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82da76a0
	ctx.lr = 0x82DBF610;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
loc_82DBF62C:
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,276(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 276);
	// lhzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32);
	// lbzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sthx r9,r10,r11
	PPC_STORE_U16(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,276(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 276);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r9,2(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 2);
	// lbz r7,2(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 2);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,276(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 276);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 4);
	// lbz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 4);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sth r9,4(r10)
	PPC_STORE_U16(ctx.r10.u32 + 4, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,276(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 276);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r9,6(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 6);
	// lbz r7,6(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 6);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// sth r9,6(r10)
	PPC_STORE_U16(ctx.r10.u32 + 6, ctx.r9.u16);
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r9,240(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r10,r10,280
	ctx.r10.s64 = ctx.r10.s64 * 280;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,276(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 276);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lbz r7,8(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 8);
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// rlwinm r5,r9,24,16,23
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFF00;
	// rlwimi r6,r9,16,0,15
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0xFFFF0000) | (ctx.r6.u64 & 0xFFFFFFFF0000FFFF);
	// or r9,r5,r7
	ctx.r9.u64 = ctx.r5.u64 | ctx.r7.u64;
	// rlwinm r7,r6,8,0,15
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 8) & 0xFFFF0000;
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dbf62c
	if (ctx.cr6.lt) goto loc_82DBF62C;
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBF72C:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBF73C;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbf98c
	if (!ctx.cr6.eq) goto loc_82DBF98C;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r6,40
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 40, ctx.xer);
	// ble cr6,0x82dbf754
	if (!ctx.cr6.gt) goto loc_82DBF754;
	// li r6,40
	ctx.r6.s64 = 40;
loc_82DBF754:
	// addi r11,r1,192
	ctx.r11.s64 = ctx.r1.s64 + 192;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// std r24,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r24.u64);
	// std r24,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r24.u64);
	// std r24,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r24.u64);
	// std r24,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r24.u64);
	// std r24,32(r11)
	PPC_STORE_U64(ctx.r11.u32 + 32, ctx.r24.u64);
	// bl 0x82da76a0
	ctx.lr = 0x82DBF780;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,40
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 40, ctx.xer);
	// ble cr6,0x82dbf7ac
	if (!ctx.cr6.gt) goto loc_82DBF7AC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r11,-40
	ctx.r4.s64 = ctx.r11.s64 + -40;
	// bl 0x82da7e70
	ctx.lr = 0x82DBF7A4;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
loc_82DBF7AC:
	// lhz r11,206(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 206);
	// lhz r8,194(r1)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 194);
	// rotlwi r10,r11,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 8);
	// lhz r7,204(r1)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r1.u32 + 204);
	// rlwinm r9,r11,24,8,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFFFFFF;
	// lwz r11,196(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// lhz r9,192(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 192);
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// rotlwi r4,r9,8
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// rotlwi r3,r8,8
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r8.u32, 8);
	// rlwimi r6,r11,16,16,31
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r6.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r5,r11,16,0,15
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r5.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r9,r9,24,8,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFFFF;
	// clrlwi r11,r4,16
	ctx.r11.u64 = ctx.r4.u32 & 0xFFFF;
	// clrlwi r4,r3,16
	ctx.r4.u64 = ctx.r3.u32 & 0xFFFF;
	// rlwinm r8,r8,24,8,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 24) & 0xFFFFFF;
	// or r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
	// or r9,r4,r8
	ctx.r9.u64 = ctx.r4.u64 | ctx.r8.u64;
	// rlwinm r6,r6,24,16,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 24) & 0xFFFF;
	// rlwinm r5,r5,8,0,15
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 8) & 0xFFFF0000;
	// rotlwi r30,r7,8
	ctx.r30.u64 = __builtin_rotateleft32(ctx.r7.u32, 8);
	// rlwinm r7,r7,24,8,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xFFFFFF;
	// sth r9,194(r1)
	PPC_STORE_U16(ctx.r1.u32 + 194, ctx.r9.u16);
	// or r9,r6,r5
	ctx.r9.u64 = ctx.r6.u64 | ctx.r5.u64;
	// clrlwi r3,r30,16
	ctx.r3.u64 = ctx.r30.u32 & 0xFFFF;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// addi r10,r10,-8
	ctx.r10.s64 = ctx.r10.s64 + -8;
	// stw r9,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r9.u32);
	// or r9,r3,r7
	ctx.r9.u64 = ctx.r3.u64 | ctx.r7.u64;
	// cmplwi cr6,r10,24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 24, ctx.xer);
	// sth r9,204(r1)
	PPC_STORE_U16(ctx.r1.u32 + 204, ctx.r9.u16);
	// bgt cr6,0x82dbf940
	if (ctx.cr6.gt) goto loc_82DBF940;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,-1968
	ctx.r12.s64 = ctx.r12.s64 + -1968;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DBF8B4;
	case 1:
		goto loc_82DBF940;
	case 2:
		goto loc_82DBF940;
	case 3:
		goto loc_82DBF940;
	case 4:
		goto loc_82DBF940;
	case 5:
		goto loc_82DBF940;
	case 6:
		goto loc_82DBF940;
	case 7:
		goto loc_82DBF940;
	case 8:
		goto loc_82DBF8CC;
	case 9:
		goto loc_82DBF940;
	case 10:
		goto loc_82DBF940;
	case 11:
		goto loc_82DBF940;
	case 12:
		goto loc_82DBF940;
	case 13:
		goto loc_82DBF940;
	case 14:
		goto loc_82DBF940;
	case 15:
		goto loc_82DBF940;
	case 16:
		goto loc_82DBF8E4;
	case 17:
		goto loc_82DBF940;
	case 18:
		goto loc_82DBF940;
	case 19:
		goto loc_82DBF940;
	case 20:
		goto loc_82DBF940;
	case 21:
		goto loc_82DBF940;
	case 22:
		goto loc_82DBF940;
	case 23:
		goto loc_82DBF940;
	case 24:
		goto loc_82DBF8FC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1868(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1868);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1844(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1844);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1820(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1820);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1728(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1728);
	// lwz r22,-1796(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1796);
loc_82DBF8B4:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82dbf93c
	goto loc_82DBF93C;
loc_82DBF8CC:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r27,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r27.u32);
	// b 0x82dbf940
	goto loc_82DBF940;
loc_82DBF8E4:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x82dbf93c
	goto loc_82DBF93C;
loc_82DBF8FC:
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82dbf920
	if (!ctx.cr6.eq) goto loc_82DBF920;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r10,4
	ctx.r10.s64 = 4;
	// b 0x82dbf93c
	goto loc_82DBF93C;
loc_82DBF920:
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bne cr6,0x82dbf940
	if (!ctx.cr6.eq) goto loc_82DBF940;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r10,5
	ctx.r10.s64 = 5;
loc_82DBF93C:
	// stw r10,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r10.u32);
loc_82DBF940:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lhz r9,194(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 194);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r9.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lwz r9,196(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,264(r11)
	PPC_STORE_U32(ctx.r11.u32 + 264, ctx.r9.u32);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lhz r9,204(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 204);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r9.u32);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBF98C:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,108(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBF99C;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfb18
	if (!ctx.cr6.eq) goto loc_82DBFB18;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// lwz r10,256(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dbfaf0
	if (ctx.cr6.eq) goto loc_82DBFAF0;
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// bgt cr6,0x82dbfaf0
	if (ctx.cr6.gt) goto loc_82DBFAF0;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,-1564
	ctx.r12.s64 = ctx.r12.s64 + -1564;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DBFA48;
	case 1:
		goto loc_82DBFA10;
	case 2:
		goto loc_82DBFA18;
	case 3:
		goto loc_82DBFA20;
	case 4:
		goto loc_82DBFA28;
	case 5:
		goto loc_82DBFA28;
	case 6:
		goto loc_82DBFA48;
	case 7:
		goto loc_82DBFA48;
	case 8:
		goto loc_82DBFA48;
	case 9:
		goto loc_82DBFA48;
	case 10:
		goto loc_82DBFA48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1464(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1464);
	// lwz r22,-1520(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1520);
	// lwz r22,-1512(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1512);
	// lwz r22,-1504(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1504);
	// lwz r22,-1496(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1496);
	// lwz r22,-1496(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1496);
	// lwz r22,-1464(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1464);
	// lwz r22,-1464(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1464);
	// lwz r22,-1464(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1464);
	// lwz r22,-1464(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1464);
	// lwz r22,-1464(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1464);
loc_82DBFA10:
	// li r10,8
	ctx.r10.s64 = 8;
	// b 0x82dbfa2c
	goto loc_82DBFA2C;
loc_82DBFA18:
	// li r10,16
	ctx.r10.s64 = 16;
	// b 0x82dbfa2c
	goto loc_82DBFA2C;
loc_82DBFA20:
	// li r10,24
	ctx.r10.s64 = 24;
	// b 0x82dbfa2c
	goto loc_82DBFA2C;
loc_82DBFA28:
	// li r10,32
	ctx.r10.s64 = 32;
loc_82DBFA2C:
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// rldicr r8,r8,3,63
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u64, 3) & 0xFFFFFFFFFFFFFFFF;
	// tdllei r10,0
	// divdu r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 / ctx.r10.u64;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dbfae0
	goto loc_82DBFAE0;
loc_82DBFA48:
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,-1440
	ctx.r12.s64 = ctx.r12.s64 + -1440;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-1316(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1316);
	// lwz r22,-1296(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1296);
	// lwz r22,-1296(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1296);
	// lwz r22,-1296(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1296);
	// lwz r22,-1296(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1296);
	// lwz r22,-1296(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1296);
	// lwz r22,-1396(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1396);
	// lwz r22,-1376(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1376);
	// lwz r22,-1344(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1344);
	// lwz r22,-1324(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1324);
	// lwz r22,-1324(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + -1324);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mulli r10,r10,14
	ctx.r10.s64 = ctx.r10.s64 * 14;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dbfae0
	goto loc_82DBFAE0;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r8,14563
	ctx.r8.s64 = 954400768;
	// rlwinm r10,r10,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
	// ori r8,r8,36409
	ctx.r8.u64 = ctx.r8.u64 | 36409;
	// mulhwu r10,r10,r8
	ctx.r10.u64 = (uint64_t(ctx.r10.u32) * uint64_t(ctx.r8.u32)) >> 32;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dbfae0
	goto loc_82DBFAE0;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mulli r10,r10,28
	ctx.r10.s64 = ctx.r10.s64 * 28;
	// rlwinm r10,r10,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dbfae0
	goto loc_82DBFAE0;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x82dbfaec
	goto loc_82DBFAEC;
	// stw r24,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r24.u32);
loc_82DBFAE0:
	// lwz r10,272(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// twllei r9,0
	// divwu r10,r10,r9
	ctx.r10.u32 = ctx.r10.u32 / ctx.r9.u32;
loc_82DBFAEC:
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
loc_82DBFAF0:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r4,r11,256
	ctx.r4.s64 = ctx.r11.s64 + 256;
	// bl 0x82da8018
	ctx.lr = 0x82DBFB0C;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBFB18:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,172(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFB28;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfc00
	if (!ctx.cr6.eq) goto loc_82DBFC00;
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,232(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dbfb88
	if (!ctx.cr6.lt) goto loc_82DBFB88;
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,256
	ctx.r5.s64 = 256;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBFB58;
	sub_82CB16F0(ctx, base);
	// lwz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// lwz r10,240(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// li r7,0
	ctx.r7.s64 = 0;
	// mulli r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 * 280;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,1
	ctx.r5.s64 = 1;
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBFB7C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBFB88:
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,244(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dbfd90
	if (!ctx.cr6.lt) goto loc_82DBFD90;
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,256
	ctx.r5.s64 = 256;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82cb16f0
	ctx.lr = 0x82DBFBB0;
	sub_82CB16F0(ctx, base);
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// lwz r10,252(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// li r7,0
	ctx.r7.s64 = 0;
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,1
	ctx.r5.s64 = 1;
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DBFBD4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfde8
	if (!ctx.cr6.eq) goto loc_82DBFDE8;
	// lwz r11,248(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// li r5,256
	ctx.r5.s64 = 256;
	// lwz r9,252(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mulli r11,r11,296
	ctx.r11.s64 = ctx.r11.s64 * 296;
	// add r4,r9,r11
	ctx.r4.u64 = ctx.r9.u64 + ctx.r11.u64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
	// bl 0x82da4468
	ctx.lr = 0x82DBFBFC;
	sub_82DA4468(ctx, base);
	// b 0x82dbfd90
	goto loc_82DBFD90;
loc_82DBFC00:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,156(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFC10;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFC28;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,120(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFC40;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,128(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFC58;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,136(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFC70;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFC88;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,152(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFCA0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,160(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFCB8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFCD0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFCE8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r16
	ctx.r4.u64 = ctx.r16.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFD00;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFD18;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFD30;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFD48;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFD60;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFD78;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfd90
	if (ctx.cr6.eq) goto loc_82DBFD90;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DBFD90;
	sub_82DA7E70(ctx, base);
loc_82DBFD90:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r8,r11,31
	ctx.r8.u64 = ctx.r11.u32 & 0x1;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
	// addi r10,r9,8
	ctx.r10.s64 = ctx.r9.s64 + 8;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// beq cr6,0x82dbfdd0
	if (ctx.cr6.eq) goto loc_82DBFDD0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
loc_82DBFDD0:
	// lwz r9,452(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dbfde4
	if (!ctx.cr6.lt) goto loc_82DBFDE4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dbe668
	if (!ctx.cr6.eq) goto loc_82DBE668;
loc_82DBFDE4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DBFDE8:
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DBFDF0"))) PPC_WEAK_FUNC(sub_82DBFDF0);
PPC_FUNC_IMPL(__imp__sub_82DBFDF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r30,0
	ctx.r30.s64 = 0;
	// li r9,6
	ctx.r9.s64 = 6;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,19872(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19872, ctx.r11.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// stw r9,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r9.u32);
	// stw r30,220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 220, ctx.r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DBFE3C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbff24
	if (!ctx.cr6.eq) goto loc_82DBFF24;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,8
	ctx.r6.s64 = 8;
	// stw r30,156(r31)
	PPC_STORE_U32(ctx.r31.u32 + 156, ctx.r30.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r30,232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 232, ctx.r30.u32);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// stw r30,244(r31)
	PPC_STORE_U32(ctx.r31.u32 + 244, ctx.r30.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DBFE68;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbff24
	if (!ctx.cr6.eq) goto loc_82DBFF24;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,7028
	ctx.r4.s64 = ctx.r11.s64 + 7028;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFE84;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dbfe94
	if (ctx.cr6.eq) goto loc_82DBFE94;
loc_82DBFE8C:
	// li r3,25
	ctx.r3.s64 = 25;
	// b 0x82dbff24
	goto loc_82DBFF24;
loc_82DBFE94:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da76a0
	ctx.lr = 0x82DBFEAC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbff24
	if (!ctx.cr6.eq) goto loc_82DBFF24;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,7796
	ctx.r4.s64 = ctx.r11.s64 + 7796;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DBFEC8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbfe8c
	if (!ctx.cr6.eq) goto loc_82DBFE8C;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r30,156(r31)
	PPC_STORE_U32(ctx.r31.u32 + 156, ctx.r30.u32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stw r30,248(r31)
	PPC_STORE_U32(ctx.r31.u32 + 248, ctx.r30.u32);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r10,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// bl 0x82dbe4b8
	ctx.lr = 0x82DBFF08;
	sub_82DBE4B8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dbff24
	if (!ctx.cr6.eq) goto loc_82DBFF24;
	// lwz r11,232(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dbfe8c
	if (!ctx.cr6.gt) goto loc_82DBFE8C;
	// lwz r11,244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
loc_82DBFF24:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DBFF3C"))) PPC_WEAK_FUNC(sub_82DBFF3C);
PPC_FUNC_IMPL(__imp__sub_82DBFF3C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DBFF40"))) PPC_WEAK_FUNC(sub_82DBFF40);
PPC_FUNC_IMPL(__imp__sub_82DBFF40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// blt cr6,0x82dc016c
	if (ctx.cr6.lt) goto loc_82DC016C;
	// lwz r11,24(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dbff78
	if (ctx.cr6.eq) goto loc_82DBFF78;
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bge cr6,0x82dc016c
	if (!ctx.cr6.lt) goto loc_82DC016C;
loc_82DBFF78:
	// lwz r31,224(r8)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + 224);
	// lwz r11,388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 388);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc0170
	if (ctx.cr6.eq) goto loc_82DC0170;
	// lwz r11,256(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 256);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dbff9c
	if (ctx.cr6.eq) goto loc_82DBFF9C;
	// stw r4,256(r8)
	PPC_STORE_U32(ctx.r8.u32 + 256, ctx.r4.u32);
loc_82DBFF9C:
	// lwz r9,256(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 256);
	// lwz r11,28(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 28);
	// mulli r7,r9,296
	ctx.r7.s64 = ctx.r9.s64 * 296;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lwz r9,256(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lwz r6,260(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bgt cr6,0x82dc0154
	if (ctx.cr6.gt) goto loc_82DC0154;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,-44
	ctx.r12.s64 = ctx.r12.s64 + -44;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82DC0040;
	case 1:
		goto loc_82DC0000;
	case 2:
		goto loc_82DC0010;
	case 3:
		goto loc_82DC0020;
	case 4:
		goto loc_82DC0030;
	case 5:
		goto loc_82DC0030;
	case 6:
		goto loc_82DC0040;
	case 7:
		goto loc_82DC0040;
	case 8:
		goto loc_82DC0040;
	case 9:
		goto loc_82DC0040;
	case 10:
		goto loc_82DC0040;
	default:
		__builtin_unreachable();
	}
	// lwz r22,64(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
	// lwz r22,0(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r22,16(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lwz r22,32(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// lwz r22,48(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 48);
	// lwz r22,48(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 48);
	// lwz r22,64(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
	// lwz r22,64(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
	// lwz r22,64(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
	// lwz r22,64(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
	// lwz r22,64(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
loc_82DC0000:
	// li r11,8
	ctx.r11.s64 = 8;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc0120
	goto loc_82DC0120;
loc_82DC0010:
	// li r11,16
	ctx.r11.s64 = 16;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc0120
	goto loc_82DC0120;
loc_82DC0020:
	// li r11,24
	ctx.r11.s64 = 24;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc0120
	goto loc_82DC0120;
loc_82DC0030:
	// li r11,32
	ctx.r11.s64 = 32;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc0120
	goto loc_82DC0120;
loc_82DC0040:
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,88
	ctx.r12.s64 = ctx.r12.s64 + 88;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,284(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 284);
	// lwz r22,340(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 340);
	// lwz r22,340(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 340);
	// lwz r22,340(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 340);
	// lwz r22,340(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 340);
	// lwz r22,340(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 340);
	// lwz r22,132(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 132);
	// lwz r22,196(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 196);
	// lwz r22,220(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 220);
	// lwz r22,292(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 292);
	// lwz r22,292(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 292);
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// addi r10,r10,13
	ctx.r10.s64 = ctx.r10.s64 + 13;
	// ori r11,r11,18725
	ctx.r11.u64 = ctx.r11.u64 | 18725;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// mulhwu r11,r10,r11
	ctx.r11.u64 = (uint64_t(ctx.r10.u32) * uint64_t(ctx.r11.u32)) >> 32;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r9
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc0120
	goto loc_82DC0120;
	// addi r11,r10,63
	ctx.r11.s64 = ctx.r10.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dc0120
	goto loc_82DC0120;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// addi r10,r10,27
	ctx.r10.s64 = ctx.r10.s64 + 27;
	// ori r11,r11,18725
	ctx.r11.u64 = ctx.r11.u64 | 18725;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// mulhwu r11,r10,r11
	ctx.r11.u64 = (uint64_t(ctx.r10.u32) * uint64_t(ctx.r11.u32)) >> 32;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r9
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dc0120
	goto loc_82DC0120;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DC0120:
	// mullw r10,r6,r11
	ctx.r10.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r11.s32);
	// lwz r11,252(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 252);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82da7e70
	ctx.lr = 0x82DC0140;
	sub_82DA7E70(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82DC0154:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82DC016C:
	// li r3,37
	ctx.r3.s64 = 37;
loc_82DC0170:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC0184"))) PPC_WEAK_FUNC(sub_82DC0184);
PPC_FUNC_IMPL(__imp__sub_82DC0184) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC0188"))) PPC_WEAK_FUNC(sub_82DC0188);
PPC_FUNC_IMPL(__imp__sub_82DC0188) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc0198
	if (!ctx.cr6.eq) goto loc_82DC0198;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC0198:
	// b 0x82dbfdf0
	sub_82DBFDF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC019C"))) PPC_WEAK_FUNC(sub_82DC019C);
PPC_FUNC_IMPL(__imp__sub_82DC019C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC01A0"))) PPC_WEAK_FUNC(sub_82DC01A0);
PPC_FUNC_IMPL(__imp__sub_82DC01A0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc01b0
	if (!ctx.cr6.eq) goto loc_82DC01B0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC01B0:
	// b 0x82dbff40
	sub_82DBFF40(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC01B4"))) PPC_WEAK_FUNC(sub_82DC01B4);
PPC_FUNC_IMPL(__imp__sub_82DC01B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC01B8"))) PPC_WEAK_FUNC(sub_82DC01B8);
PPC_FUNC_IMPL(__imp__sub_82DC01B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,28976
	ctx.r31.s64 = ctx.r11.s64 + 28976;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DC01E0;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r7,-32036
	ctx.r7.s64 = -2099511296;
	// addi r11,r11,7804
	ctx.r11.s64 = ctx.r11.s64 + 7804;
	// lis r8,-32036
	ctx.r8.s64 = -2099511296;
	// lis r9,-32036
	ctx.r9.s64 = -2099511296;
	// lis r10,-32036
	ctx.r10.s64 = -2099511296;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// addi r11,r7,392
	ctx.r11.s64 = ctx.r7.s64 + 392;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r8,-7032
	ctx.r11.s64 = ctx.r8.s64 + -7032;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r9,-7008
	ctx.r11.s64 = ctx.r9.s64 + -7008;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r10,416
	ctx.r11.s64 = ctx.r10.s64 + 416;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// li r11,6
	ctx.r11.s64 = 6;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,264
	ctx.r11.s64 = 264;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC0258"))) PPC_WEAK_FUNC(sub_82DC0258);
PPC_FUNC_IMPL(__imp__sub_82DC0258) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// beq cr6,0x82dc027c
	if (ctx.cr6.eq) goto loc_82DC027C;
	// rlwinm r10,r10,0,21,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// blr 
	return;
loc_82DC027C:
	// ori r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 2048;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC0288"))) PPC_WEAK_FUNC(sub_82DC0288);
PPC_FUNC_IMPL(__imp__sub_82DC0288) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DC0290;
	__savegprlr_14(ctx, base);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,604(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 604);
	// stw r3,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r3.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// ble cr6,0x82dc0ae0
	if (!ctx.cr6.gt) goto loc_82DC0AE0;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r30,r11,8820
	ctx.r30.s64 = ctx.r11.s64 + 8820;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r18,r11,8808
	ctx.r18.s64 = ctx.r11.s64 + 8808;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r17,r11,8796
	ctx.r17.s64 = ctx.r11.s64 + 8796;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r16,r11,8772
	ctx.r16.s64 = ctx.r11.s64 + 8772;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r15,r11,8752
	ctx.r15.s64 = ctx.r11.s64 + 8752;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r14,r11,8732
	ctx.r14.s64 = ctx.r11.s64 + 8732;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8712
	ctx.r11.s64 = ctx.r11.s64 + 8712;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8692
	ctx.r11.s64 = ctx.r11.s64 + 8692;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8668
	ctx.r11.s64 = ctx.r11.s64 + 8668;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8648
	ctx.r11.s64 = ctx.r11.s64 + 8648;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8628
	ctx.r11.s64 = ctx.r11.s64 + 8628;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8608
	ctx.r11.s64 = ctx.r11.s64 + 8608;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8588
	ctx.r11.s64 = ctx.r11.s64 + 8588;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8568
	ctx.r11.s64 = ctx.r11.s64 + 8568;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8548
	ctx.r11.s64 = ctx.r11.s64 + 8548;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8540
	ctx.r11.s64 = ctx.r11.s64 + 8540;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8528
	ctx.r11.s64 = ctx.r11.s64 + 8528;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8512
	ctx.r11.s64 = ctx.r11.s64 + 8512;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8496
	ctx.r11.s64 = ctx.r11.s64 + 8496;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,8484
	ctx.r11.s64 = ctx.r11.s64 + 8484;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r29,r11,8472
	ctx.r29.s64 = ctx.r11.s64 + 8472;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r28,r11,8460
	ctx.r28.s64 = ctx.r11.s64 + 8460;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r27,r11,8452
	ctx.r27.s64 = ctx.r11.s64 + 8452;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r26,r11,8444
	ctx.r26.s64 = ctx.r11.s64 + 8444;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r25,r11,8428
	ctx.r25.s64 = ctx.r11.s64 + 8428;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r24,r11,8420
	ctx.r24.s64 = ctx.r11.s64 + 8420;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r23,r11,8412
	ctx.r23.s64 = ctx.r11.s64 + 8412;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r22,r11,8396
	ctx.r22.s64 = ctx.r11.s64 + 8396;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r21,r11,8376
	ctx.r21.s64 = ctx.r11.s64 + 8376;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r20,r11,8368
	ctx.r20.s64 = ctx.r11.s64 + 8368;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r19,r11,8356
	ctx.r19.s64 = ctx.r11.s64 + 8356;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r31,r11,8352
	ctx.r31.s64 = ctx.r11.s64 + 8352;
	// b 0x82dc03f4
	goto loc_82DC03F4;
loc_82DC03F0:
	// lwz r3,324(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
loc_82DC03F4:
	// lwz r11,608(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 608);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,139
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 139, ctx.xer);
	// bgt cr6,0x82dc06b4
	if (ctx.cr6.gt) goto loc_82DC06B4;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,1072
	ctx.r12.s64 = ctx.r12.s64 + 1072;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC0660;
	case 1:
		goto loc_82DC0668;
	case 2:
		goto loc_82DC0670;
	case 3:
		goto loc_82DC0678;
	case 4:
		goto loc_82DC0680;
	case 5:
		goto loc_82DC0688;
	case 6:
		goto loc_82DC0690;
	case 7:
		goto loc_82DC06B4;
	case 8:
		goto loc_82DC06B4;
	case 9:
		goto loc_82DC06B4;
	case 10:
		goto loc_82DC06B4;
	case 11:
		goto loc_82DC06B4;
	case 12:
		goto loc_82DC06B4;
	case 13:
		goto loc_82DC06B4;
	case 14:
		goto loc_82DC06B4;
	case 15:
		goto loc_82DC06B4;
	case 16:
		goto loc_82DC06B4;
	case 17:
		goto loc_82DC06B4;
	case 18:
		goto loc_82DC06B4;
	case 19:
		goto loc_82DC06B4;
	case 20:
		goto loc_82DC06B4;
	case 21:
		goto loc_82DC06B4;
	case 22:
		goto loc_82DC06B4;
	case 23:
		goto loc_82DC06B4;
	case 24:
		goto loc_82DC06B4;
	case 25:
		goto loc_82DC06B4;
	case 26:
		goto loc_82DC06B4;
	case 27:
		goto loc_82DC06B4;
	case 28:
		goto loc_82DC06B4;
	case 29:
		goto loc_82DC06B4;
	case 30:
		goto loc_82DC06B4;
	case 31:
		goto loc_82DC06B4;
	case 32:
		goto loc_82DC06B4;
	case 33:
		goto loc_82DC06B4;
	case 34:
		goto loc_82DC06B4;
	case 35:
		goto loc_82DC06B4;
	case 36:
		goto loc_82DC06B4;
	case 37:
		goto loc_82DC06B4;
	case 38:
		goto loc_82DC06B4;
	case 39:
		goto loc_82DC06B4;
	case 40:
		goto loc_82DC06B4;
	case 41:
		goto loc_82DC06B4;
	case 42:
		goto loc_82DC06B4;
	case 43:
		goto loc_82DC06B4;
	case 44:
		goto loc_82DC06B4;
	case 45:
		goto loc_82DC06B4;
	case 46:
		goto loc_82DC06B4;
	case 47:
		goto loc_82DC06B4;
	case 48:
		goto loc_82DC06B4;
	case 49:
		goto loc_82DC06B4;
	case 50:
		goto loc_82DC06B4;
	case 51:
		goto loc_82DC06B4;
	case 52:
		goto loc_82DC06B4;
	case 53:
		goto loc_82DC06B4;
	case 54:
		goto loc_82DC06B4;
	case 55:
		goto loc_82DC06B4;
	case 56:
		goto loc_82DC06B4;
	case 57:
		goto loc_82DC06B4;
	case 58:
		goto loc_82DC06B4;
	case 59:
		goto loc_82DC06B4;
	case 60:
		goto loc_82DC06B4;
	case 61:
		goto loc_82DC06B4;
	case 62:
		goto loc_82DC06B4;
	case 63:
		goto loc_82DC06B4;
	case 64:
		goto loc_82DC06B4;
	case 65:
		goto loc_82DC06B4;
	case 66:
		goto loc_82DC06B4;
	case 67:
		goto loc_82DC06B4;
	case 68:
		goto loc_82DC06B4;
	case 69:
		goto loc_82DC06B4;
	case 70:
		goto loc_82DC06B4;
	case 71:
		goto loc_82DC06B4;
	case 72:
		goto loc_82DC06B4;
	case 73:
		goto loc_82DC06B4;
	case 74:
		goto loc_82DC06B4;
	case 75:
		goto loc_82DC06B4;
	case 76:
		goto loc_82DC06B4;
	case 77:
		goto loc_82DC06B4;
	case 78:
		goto loc_82DC06B4;
	case 79:
		goto loc_82DC06B4;
	case 80:
		goto loc_82DC06B4;
	case 81:
		goto loc_82DC06B4;
	case 82:
		goto loc_82DC06B4;
	case 83:
		goto loc_82DC06B4;
	case 84:
		goto loc_82DC06B4;
	case 85:
		goto loc_82DC06B4;
	case 86:
		goto loc_82DC06B4;
	case 87:
		goto loc_82DC06B4;
	case 88:
		goto loc_82DC06B4;
	case 89:
		goto loc_82DC06B4;
	case 90:
		goto loc_82DC06B4;
	case 91:
		goto loc_82DC06B4;
	case 92:
		goto loc_82DC06B4;
	case 93:
		goto loc_82DC06B4;
	case 94:
		goto loc_82DC06B4;
	case 95:
		goto loc_82DC06B4;
	case 96:
		goto loc_82DC06B4;
	case 97:
		goto loc_82DC06B4;
	case 98:
		goto loc_82DC06B4;
	case 99:
		goto loc_82DC06B4;
	case 100:
		goto loc_82DC06B4;
	case 101:
		goto loc_82DC06B4;
	case 102:
		goto loc_82DC06B4;
	case 103:
		goto loc_82DC06B4;
	case 104:
		goto loc_82DC06B4;
	case 105:
		goto loc_82DC06B4;
	case 106:
		goto loc_82DC06B4;
	case 107:
		goto loc_82DC06B4;
	case 108:
		goto loc_82DC06B4;
	case 109:
		goto loc_82DC06B4;
	case 110:
		goto loc_82DC06B4;
	case 111:
		goto loc_82DC06B4;
	case 112:
		goto loc_82DC06B4;
	case 113:
		goto loc_82DC06B4;
	case 114:
		goto loc_82DC06B4;
	case 115:
		goto loc_82DC06B4;
	case 116:
		goto loc_82DC06B4;
	case 117:
		goto loc_82DC06B4;
	case 118:
		goto loc_82DC06B4;
	case 119:
		goto loc_82DC06B4;
	case 120:
		goto loc_82DC06B4;
	case 121:
		goto loc_82DC06B4;
	case 122:
		goto loc_82DC06B4;
	case 123:
		goto loc_82DC06B4;
	case 124:
		goto loc_82DC06B4;
	case 125:
		goto loc_82DC06B4;
	case 126:
		goto loc_82DC06B4;
	case 127:
		goto loc_82DC06B4;
	case 128:
		goto loc_82DC06B4;
	case 129:
		goto loc_82DC0698;
	case 130:
		goto loc_82DC06B4;
	case 131:
		goto loc_82DC06B4;
	case 132:
		goto loc_82DC06B4;
	case 133:
		goto loc_82DC06B4;
	case 134:
		goto loc_82DC06B4;
	case 135:
		goto loc_82DC06A0;
	case 136:
		goto loc_82DC06B4;
	case 137:
		goto loc_82DC06B4;
	case 138:
		goto loc_82DC06A8;
	case 139:
		goto loc_82DC06B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1632(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1632);
	// lwz r22,1640(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1640);
	// lwz r22,1648(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1648);
	// lwz r22,1656(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1656);
	// lwz r22,1664(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1664);
	// lwz r22,1672(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1672);
	// lwz r22,1680(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1688(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1688);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1696(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1696);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1716);
	// lwz r22,1704(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1704);
	// lwz r22,1712(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1712);
loc_82DC0660:
	// mr r5,r19
	ctx.r5.u64 = ctx.r19.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0668:
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0670:
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0678:
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0680:
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0688:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0690:
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC0698:
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC06A0:
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC06A8:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// b 0x82dc06b4
	goto loc_82DC06B4;
loc_82DC06B0:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
loc_82DC06B4:
	// lhz r11,2(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 2);
	// cmplwi cr6,r11,139
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 139, ctx.xer);
	// bgt cr6,0x82dc095c
	if (ctx.cr6.gt) goto loc_82DC095C;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,1752
	ctx.r12.s64 = ctx.r12.s64 + 1752;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC0908;
	case 1:
		goto loc_82DC0910;
	case 2:
		goto loc_82DC0918;
	case 3:
		goto loc_82DC0920;
	case 4:
		goto loc_82DC0928;
	case 5:
		goto loc_82DC0930;
	case 6:
		goto loc_82DC0938;
	case 7:
		goto loc_82DC095C;
	case 8:
		goto loc_82DC095C;
	case 9:
		goto loc_82DC095C;
	case 10:
		goto loc_82DC095C;
	case 11:
		goto loc_82DC095C;
	case 12:
		goto loc_82DC095C;
	case 13:
		goto loc_82DC095C;
	case 14:
		goto loc_82DC095C;
	case 15:
		goto loc_82DC095C;
	case 16:
		goto loc_82DC095C;
	case 17:
		goto loc_82DC095C;
	case 18:
		goto loc_82DC095C;
	case 19:
		goto loc_82DC095C;
	case 20:
		goto loc_82DC095C;
	case 21:
		goto loc_82DC095C;
	case 22:
		goto loc_82DC095C;
	case 23:
		goto loc_82DC095C;
	case 24:
		goto loc_82DC095C;
	case 25:
		goto loc_82DC095C;
	case 26:
		goto loc_82DC095C;
	case 27:
		goto loc_82DC095C;
	case 28:
		goto loc_82DC095C;
	case 29:
		goto loc_82DC095C;
	case 30:
		goto loc_82DC095C;
	case 31:
		goto loc_82DC095C;
	case 32:
		goto loc_82DC095C;
	case 33:
		goto loc_82DC095C;
	case 34:
		goto loc_82DC095C;
	case 35:
		goto loc_82DC095C;
	case 36:
		goto loc_82DC095C;
	case 37:
		goto loc_82DC095C;
	case 38:
		goto loc_82DC095C;
	case 39:
		goto loc_82DC095C;
	case 40:
		goto loc_82DC095C;
	case 41:
		goto loc_82DC095C;
	case 42:
		goto loc_82DC095C;
	case 43:
		goto loc_82DC095C;
	case 44:
		goto loc_82DC095C;
	case 45:
		goto loc_82DC095C;
	case 46:
		goto loc_82DC095C;
	case 47:
		goto loc_82DC095C;
	case 48:
		goto loc_82DC095C;
	case 49:
		goto loc_82DC095C;
	case 50:
		goto loc_82DC095C;
	case 51:
		goto loc_82DC095C;
	case 52:
		goto loc_82DC095C;
	case 53:
		goto loc_82DC095C;
	case 54:
		goto loc_82DC095C;
	case 55:
		goto loc_82DC095C;
	case 56:
		goto loc_82DC095C;
	case 57:
		goto loc_82DC095C;
	case 58:
		goto loc_82DC095C;
	case 59:
		goto loc_82DC095C;
	case 60:
		goto loc_82DC095C;
	case 61:
		goto loc_82DC095C;
	case 62:
		goto loc_82DC095C;
	case 63:
		goto loc_82DC095C;
	case 64:
		goto loc_82DC095C;
	case 65:
		goto loc_82DC095C;
	case 66:
		goto loc_82DC095C;
	case 67:
		goto loc_82DC095C;
	case 68:
		goto loc_82DC095C;
	case 69:
		goto loc_82DC095C;
	case 70:
		goto loc_82DC095C;
	case 71:
		goto loc_82DC095C;
	case 72:
		goto loc_82DC095C;
	case 73:
		goto loc_82DC095C;
	case 74:
		goto loc_82DC095C;
	case 75:
		goto loc_82DC095C;
	case 76:
		goto loc_82DC095C;
	case 77:
		goto loc_82DC095C;
	case 78:
		goto loc_82DC095C;
	case 79:
		goto loc_82DC095C;
	case 80:
		goto loc_82DC095C;
	case 81:
		goto loc_82DC095C;
	case 82:
		goto loc_82DC095C;
	case 83:
		goto loc_82DC095C;
	case 84:
		goto loc_82DC095C;
	case 85:
		goto loc_82DC095C;
	case 86:
		goto loc_82DC095C;
	case 87:
		goto loc_82DC095C;
	case 88:
		goto loc_82DC095C;
	case 89:
		goto loc_82DC095C;
	case 90:
		goto loc_82DC095C;
	case 91:
		goto loc_82DC095C;
	case 92:
		goto loc_82DC095C;
	case 93:
		goto loc_82DC095C;
	case 94:
		goto loc_82DC095C;
	case 95:
		goto loc_82DC095C;
	case 96:
		goto loc_82DC095C;
	case 97:
		goto loc_82DC095C;
	case 98:
		goto loc_82DC095C;
	case 99:
		goto loc_82DC095C;
	case 100:
		goto loc_82DC095C;
	case 101:
		goto loc_82DC095C;
	case 102:
		goto loc_82DC095C;
	case 103:
		goto loc_82DC095C;
	case 104:
		goto loc_82DC095C;
	case 105:
		goto loc_82DC095C;
	case 106:
		goto loc_82DC095C;
	case 107:
		goto loc_82DC095C;
	case 108:
		goto loc_82DC095C;
	case 109:
		goto loc_82DC095C;
	case 110:
		goto loc_82DC095C;
	case 111:
		goto loc_82DC095C;
	case 112:
		goto loc_82DC095C;
	case 113:
		goto loc_82DC095C;
	case 114:
		goto loc_82DC095C;
	case 115:
		goto loc_82DC095C;
	case 116:
		goto loc_82DC095C;
	case 117:
		goto loc_82DC095C;
	case 118:
		goto loc_82DC095C;
	case 119:
		goto loc_82DC095C;
	case 120:
		goto loc_82DC095C;
	case 121:
		goto loc_82DC095C;
	case 122:
		goto loc_82DC095C;
	case 123:
		goto loc_82DC095C;
	case 124:
		goto loc_82DC095C;
	case 125:
		goto loc_82DC095C;
	case 126:
		goto loc_82DC095C;
	case 127:
		goto loc_82DC095C;
	case 128:
		goto loc_82DC095C;
	case 129:
		goto loc_82DC0940;
	case 130:
		goto loc_82DC095C;
	case 131:
		goto loc_82DC095C;
	case 132:
		goto loc_82DC095C;
	case 133:
		goto loc_82DC095C;
	case 134:
		goto loc_82DC095C;
	case 135:
		goto loc_82DC0948;
	case 136:
		goto loc_82DC095C;
	case 137:
		goto loc_82DC095C;
	case 138:
		goto loc_82DC0950;
	case 139:
		goto loc_82DC0958;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2312(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2312);
	// lwz r22,2320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2320);
	// lwz r22,2328(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2328);
	// lwz r22,2336(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2336);
	// lwz r22,2344(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2344);
	// lwz r22,2352(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2352);
	// lwz r22,2360(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2360);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2368(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2368);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2376(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2376);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2396);
	// lwz r22,2384(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2384);
	// lwz r22,2392(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2392);
loc_82DC0908:
	// mr r6,r19
	ctx.r6.u64 = ctx.r19.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0910:
	// mr r6,r20
	ctx.r6.u64 = ctx.r20.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0918:
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0920:
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0928:
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0930:
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0938:
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0940:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0948:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0950:
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// b 0x82dc095c
	goto loc_82DC095C;
loc_82DC0958:
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
loc_82DC095C:
	// lhz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,260
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 260, ctx.xer);
	// bgt cr6,0x82dc09d0
	if (ctx.cr6.gt) goto loc_82DC09D0;
	// beq cr6,0x82dc09c8
	if (ctx.cr6.eq) goto loc_82DC09C8;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82dc0a94
	if (ctx.cr6.gt) goto loc_82DC0A94;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,2444
	ctx.r12.s64 = ctx.r12.s64 + 2444;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC09A0;
	case 1:
		goto loc_82DC09A8;
	case 2:
		goto loc_82DC09B0;
	case 3:
		goto loc_82DC09B8;
	case 4:
		goto loc_82DC09C0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2464);
	// lwz r22,2472(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2472);
	// lwz r22,2480(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2480);
	// lwz r22,2488(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2488);
	// lwz r22,2496(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2496);
loc_82DC09A0:
	// lwz r7,88(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC09A8:
	// lwz r7,92(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC09B0:
	// lwz r7,96(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC09B8:
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC09C0:
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC09C8:
	// lwz r7,108(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC09D0:
	// cmpwi cr6,r11,522
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 522, ctx.xer);
	// bgt cr6,0x82dc0a38
	if (ctx.cr6.gt) goto loc_82DC0A38;
	// beq cr6,0x82dc0a30
	if (ctx.cr6.eq) goto loc_82DC0A30;
	// cmpwi cr6,r11,519
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 519, ctx.xer);
	// bgt cr6,0x82dc0a10
	if (ctx.cr6.gt) goto loc_82DC0A10;
	// beq cr6,0x82dc0a08
	if (ctx.cr6.eq) goto loc_82DC0A08;
	// cmpwi cr6,r11,261
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 261, ctx.xer);
	// beq cr6,0x82dc0a00
	if (ctx.cr6.eq) goto loc_82DC0A00;
	// cmpwi cr6,r11,518
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 518, ctx.xer);
	// bne cr6,0x82dc0a94
	if (!ctx.cr6.eq) goto loc_82DC0A94;
	// lwz r7,112(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A00:
	// lwz r7,116(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A08:
	// lwz r7,120(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A10:
	// cmpwi cr6,r11,520
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 520, ctx.xer);
	// beq cr6,0x82dc0a28
	if (ctx.cr6.eq) goto loc_82DC0A28;
	// cmpwi cr6,r11,521
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 521, ctx.xer);
	// bne cr6,0x82dc0a94
	if (!ctx.cr6.eq) goto loc_82DC0A94;
	// lwz r7,124(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A28:
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A30:
	// lwz r7,132(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A38:
	// addi r11,r11,-778
	ctx.r11.s64 = ctx.r11.s64 + -778;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82dc0a94
	if (ctx.cr6.gt) goto loc_82DC0A94;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,2652
	ctx.r12.s64 = ctx.r12.s64 + 2652;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC0A70;
	case 1:
		goto loc_82DC0A78;
	case 2:
		goto loc_82DC0A80;
	case 3:
		goto loc_82DC0A88;
	case 4:
		goto loc_82DC0A90;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2672(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2672);
	// lwz r22,2680(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2680);
	// lwz r22,2688(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2688);
	// lwz r22,2696(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2696);
	// lwz r22,2704(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2704);
loc_82DC0A70:
	// lwz r7,136(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A78:
	// lwz r7,140(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A80:
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A88:
	// mr r7,r15
	ctx.r7.u64 = ctx.r15.u64;
	// b 0x82dc0a94
	goto loc_82DC0A94;
loc_82DC0A90:
	// mr r7,r16
	ctx.r7.u64 = ctx.r16.u64;
loc_82DC0A94:
	// lhz r11,6(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 6);
	// mr r9,r17
	ctx.r9.u64 = ctx.r17.u64;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82dc0aa8
	if (ctx.cr6.eq) goto loc_82DC0AA8;
	// mr r9,r18
	ctx.r9.u64 = ctx.r18.u64;
loc_82DC0AA8:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82ccb660
	ctx.lr = 0x82DC0AB8;
	sub_82CCB660(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// lwz r10,604(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 604);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// blt cr6,0x82dc03f0
	if (ctx.cr6.lt) goto loc_82DC03F0;
loc_82DC0AE0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC0AEC"))) PPC_WEAK_FUNC(sub_82DC0AEC);
PPC_FUNC_IMPL(__imp__sub_82DC0AEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC0AF0"))) PPC_WEAK_FUNC(sub_82DC0AF0);
PPC_FUNC_IMPL(__imp__sub_82DC0AF0) {
	PPC_FUNC_PROLOGUE();
	// lwz r9,604(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 604);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82dc0b2c
	if (!ctx.cr6.gt) goto loc_82DC0B2C;
	// lwz r11,608(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 608);
loc_82DC0B04:
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmpw cr6,r8,r4
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r4.s32, ctx.xer);
	// bne cr6,0x82dc0b1c
	if (!ctx.cr6.eq) goto loc_82DC0B1C;
	// lhz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmpw cr6,r8,r5
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r5.s32, ctx.xer);
	// beq cr6,0x82dc0b34
	if (ctx.cr6.eq) goto loc_82DC0B34;
loc_82DC0B1C:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc0b04
	if (ctx.cr6.lt) goto loc_82DC0B04;
loc_82DC0B2C:
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
loc_82DC0B34:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC0B3C"))) PPC_WEAK_FUNC(sub_82DC0B3C);
PPC_FUNC_IMPL(__imp__sub_82DC0B3C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC0B40"))) PPC_WEAK_FUNC(sub_82DC0B40);
PPC_FUNC_IMPL(__imp__sub_82DC0B40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
	// stw r7,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r7.u32);
	// lwz r11,604(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 604);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc11d0
	if (!ctx.cr6.gt) goto loc_82DC11D0;
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// lfs f13,-17360(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17360);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f11.f64 = double(temp.f32);
loc_82DC0B70:
	// lwz r11,608(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 608);
	// fmr f12,f11
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f11.f64;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
	// add r10,r8,r11
	ctx.r10.u64 = ctx.r8.u64 + ctx.r11.u64;
	// lhz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 4);
	// cmpw cr6,r11,r5
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r5.s32, ctx.xer);
	// bne cr6,0x82dc11bc
	if (!ctx.cr6.eq) goto loc_82DC11BC;
	// lhz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,139
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 139, ctx.xer);
	// bgt cr6,0x82dc0e8c
	if (ctx.cr6.gt) goto loc_82DC0E8C;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,2992
	ctx.r12.s64 = ctx.r12.s64 + 2992;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC0DE0;
	case 1:
		goto loc_82DC0DF4;
	case 2:
		goto loc_82DC0DFC;
	case 3:
		goto loc_82DC0E20;
	case 4:
		goto loc_82DC0E44;
	case 5:
		goto loc_82DC0E4C;
	case 6:
		goto loc_82DC0E60;
	case 7:
		goto loc_82DC0E8C;
	case 8:
		goto loc_82DC0E8C;
	case 9:
		goto loc_82DC0E8C;
	case 10:
		goto loc_82DC0E8C;
	case 11:
		goto loc_82DC0E8C;
	case 12:
		goto loc_82DC0E8C;
	case 13:
		goto loc_82DC0E8C;
	case 14:
		goto loc_82DC0E8C;
	case 15:
		goto loc_82DC0E8C;
	case 16:
		goto loc_82DC0E8C;
	case 17:
		goto loc_82DC0E8C;
	case 18:
		goto loc_82DC0E8C;
	case 19:
		goto loc_82DC0E8C;
	case 20:
		goto loc_82DC0E8C;
	case 21:
		goto loc_82DC0E8C;
	case 22:
		goto loc_82DC0E8C;
	case 23:
		goto loc_82DC0E8C;
	case 24:
		goto loc_82DC0E8C;
	case 25:
		goto loc_82DC0E8C;
	case 26:
		goto loc_82DC0E8C;
	case 27:
		goto loc_82DC0E8C;
	case 28:
		goto loc_82DC0E8C;
	case 29:
		goto loc_82DC0E8C;
	case 30:
		goto loc_82DC0E8C;
	case 31:
		goto loc_82DC0E8C;
	case 32:
		goto loc_82DC0E8C;
	case 33:
		goto loc_82DC0E8C;
	case 34:
		goto loc_82DC0E8C;
	case 35:
		goto loc_82DC0E8C;
	case 36:
		goto loc_82DC0E8C;
	case 37:
		goto loc_82DC0E8C;
	case 38:
		goto loc_82DC0E8C;
	case 39:
		goto loc_82DC0E8C;
	case 40:
		goto loc_82DC0E8C;
	case 41:
		goto loc_82DC0E8C;
	case 42:
		goto loc_82DC0E8C;
	case 43:
		goto loc_82DC0E8C;
	case 44:
		goto loc_82DC0E8C;
	case 45:
		goto loc_82DC0E8C;
	case 46:
		goto loc_82DC0E8C;
	case 47:
		goto loc_82DC0E8C;
	case 48:
		goto loc_82DC0E8C;
	case 49:
		goto loc_82DC0E8C;
	case 50:
		goto loc_82DC0E8C;
	case 51:
		goto loc_82DC0E8C;
	case 52:
		goto loc_82DC0E8C;
	case 53:
		goto loc_82DC0E8C;
	case 54:
		goto loc_82DC0E8C;
	case 55:
		goto loc_82DC0E8C;
	case 56:
		goto loc_82DC0E8C;
	case 57:
		goto loc_82DC0E8C;
	case 58:
		goto loc_82DC0E8C;
	case 59:
		goto loc_82DC0E8C;
	case 60:
		goto loc_82DC0E8C;
	case 61:
		goto loc_82DC0E8C;
	case 62:
		goto loc_82DC0E8C;
	case 63:
		goto loc_82DC0E8C;
	case 64:
		goto loc_82DC0E8C;
	case 65:
		goto loc_82DC0E8C;
	case 66:
		goto loc_82DC0E8C;
	case 67:
		goto loc_82DC0E8C;
	case 68:
		goto loc_82DC0E8C;
	case 69:
		goto loc_82DC0E8C;
	case 70:
		goto loc_82DC0E8C;
	case 71:
		goto loc_82DC0E8C;
	case 72:
		goto loc_82DC0E8C;
	case 73:
		goto loc_82DC0E8C;
	case 74:
		goto loc_82DC0E8C;
	case 75:
		goto loc_82DC0E8C;
	case 76:
		goto loc_82DC0E8C;
	case 77:
		goto loc_82DC0E8C;
	case 78:
		goto loc_82DC0E8C;
	case 79:
		goto loc_82DC0E8C;
	case 80:
		goto loc_82DC0E8C;
	case 81:
		goto loc_82DC0E8C;
	case 82:
		goto loc_82DC0E8C;
	case 83:
		goto loc_82DC0E8C;
	case 84:
		goto loc_82DC0E8C;
	case 85:
		goto loc_82DC0E8C;
	case 86:
		goto loc_82DC0E8C;
	case 87:
		goto loc_82DC0E8C;
	case 88:
		goto loc_82DC0E8C;
	case 89:
		goto loc_82DC0E8C;
	case 90:
		goto loc_82DC0E8C;
	case 91:
		goto loc_82DC0E8C;
	case 92:
		goto loc_82DC0E8C;
	case 93:
		goto loc_82DC0E8C;
	case 94:
		goto loc_82DC0E8C;
	case 95:
		goto loc_82DC0E8C;
	case 96:
		goto loc_82DC0E8C;
	case 97:
		goto loc_82DC0E8C;
	case 98:
		goto loc_82DC0E8C;
	case 99:
		goto loc_82DC0E8C;
	case 100:
		goto loc_82DC0E8C;
	case 101:
		goto loc_82DC0E8C;
	case 102:
		goto loc_82DC0E8C;
	case 103:
		goto loc_82DC0E8C;
	case 104:
		goto loc_82DC0E8C;
	case 105:
		goto loc_82DC0E8C;
	case 106:
		goto loc_82DC0E8C;
	case 107:
		goto loc_82DC0E8C;
	case 108:
		goto loc_82DC0E8C;
	case 109:
		goto loc_82DC0E8C;
	case 110:
		goto loc_82DC0E8C;
	case 111:
		goto loc_82DC0E8C;
	case 112:
		goto loc_82DC0E8C;
	case 113:
		goto loc_82DC0E8C;
	case 114:
		goto loc_82DC0E8C;
	case 115:
		goto loc_82DC0E8C;
	case 116:
		goto loc_82DC0E8C;
	case 117:
		goto loc_82DC0E8C;
	case 118:
		goto loc_82DC0E8C;
	case 119:
		goto loc_82DC0E8C;
	case 120:
		goto loc_82DC0E8C;
	case 121:
		goto loc_82DC0E8C;
	case 122:
		goto loc_82DC0E8C;
	case 123:
		goto loc_82DC0E8C;
	case 124:
		goto loc_82DC0E8C;
	case 125:
		goto loc_82DC0E8C;
	case 126:
		goto loc_82DC0E8C;
	case 127:
		goto loc_82DC0E8C;
	case 128:
		goto loc_82DC0E8C;
	case 129:
		goto loc_82DC0E68;
	case 130:
		goto loc_82DC0E8C;
	case 131:
		goto loc_82DC0E8C;
	case 132:
		goto loc_82DC0E8C;
	case 133:
		goto loc_82DC0E8C;
	case 134:
		goto loc_82DC0E8C;
	case 135:
		goto loc_82DC0E70;
	case 136:
		goto loc_82DC0E8C;
	case 137:
		goto loc_82DC0E8C;
	case 138:
		goto loc_82DC0E78;
	case 139:
		goto loc_82DC0E80;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3552(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3552);
	// lwz r22,3572(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3572);
	// lwz r22,3580(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3580);
	// lwz r22,3616(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3616);
	// lwz r22,3652(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3652);
	// lwz r22,3660(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3660);
	// lwz r22,3680(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3680);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3688(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3688);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3696(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3696);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3724);
	// lwz r22,3704(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3704);
	// lwz r22,3712(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3712);
loc_82DC0DE0:
	// clrlwi r11,r4,31
	ctx.r11.u64 = ctx.r4.u32 & 0x1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc11bc
	if (ctx.cr6.eq) goto loc_82DC11BC;
	// fmr f12,f11
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f11.f64;
	// b 0x82dc0e8c
	goto loc_82DC0E8C;
loc_82DC0DF4:
	// rlwinm r11,r4,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x2;
	// b 0x82dc0e84
	goto loc_82DC0E84;
loc_82DC0DFC:
	// lbz r11,600(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 600);
	// rlwinm r31,r4,0,29,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// std r11,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.r11.u64);
	// lfd f12,-88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// b 0x82dc0e88
	goto loc_82DC0E88;
loc_82DC0E20:
	// lbz r11,592(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 592);
	// rlwinm r31,r4,0,28,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x8;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// std r11,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.r11.u64);
	// lfd f12,-80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// b 0x82dc0e88
	goto loc_82DC0E88;
loc_82DC0E44:
	// rlwinm r11,r4,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x10;
	// b 0x82dc0e84
	goto loc_82DC0E84;
loc_82DC0E4C:
	// rlwinm r11,r4,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x20;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc11bc
	if (ctx.cr6.eq) goto loc_82DC11BC;
	// fmr f12,f11
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f11.f64;
	// b 0x82dc0e8c
	goto loc_82DC0E8C;
loc_82DC0E60:
	// rlwinm r11,r4,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x40;
	// b 0x82dc0e84
	goto loc_82DC0E84;
loc_82DC0E68:
	// rlwinm r11,r4,0,24,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x80;
	// b 0x82dc0e84
	goto loc_82DC0E84;
loc_82DC0E70:
	// rlwinm r11,r4,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100;
	// b 0x82dc0e84
	goto loc_82DC0E84;
loc_82DC0E78:
	// rlwinm r11,r4,0,22,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x200;
	// b 0x82dc0e84
	goto loc_82DC0E84;
loc_82DC0E80:
	// rlwinm r11,r4,0,21,21
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x400;
loc_82DC0E84:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
loc_82DC0E88:
	// beq cr6,0x82dc11bc
	if (ctx.cr6.eq) goto loc_82DC11BC;
loc_82DC0E8C:
	// lhz r11,2(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 2);
	// cmplwi cr6,r11,139
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 139, ctx.xer);
	// bgt cr6,0x82dc1170
	if (ctx.cr6.gt) goto loc_82DC1170;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,3760
	ctx.r12.s64 = ctx.r12.s64 + 3760;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC10E0;
	case 1:
		goto loc_82DC10E0;
	case 2:
		goto loc_82DC10E8;
	case 3:
		goto loc_82DC10F8;
	case 4:
		goto loc_82DC1170;
	case 5:
		goto loc_82DC1170;
	case 6:
		goto loc_82DC1170;
	case 7:
		goto loc_82DC1170;
	case 8:
		goto loc_82DC1170;
	case 9:
		goto loc_82DC1170;
	case 10:
		goto loc_82DC1170;
	case 11:
		goto loc_82DC1170;
	case 12:
		goto loc_82DC1170;
	case 13:
		goto loc_82DC1170;
	case 14:
		goto loc_82DC1170;
	case 15:
		goto loc_82DC1170;
	case 16:
		goto loc_82DC1170;
	case 17:
		goto loc_82DC1170;
	case 18:
		goto loc_82DC1170;
	case 19:
		goto loc_82DC1170;
	case 20:
		goto loc_82DC1170;
	case 21:
		goto loc_82DC1170;
	case 22:
		goto loc_82DC1170;
	case 23:
		goto loc_82DC1170;
	case 24:
		goto loc_82DC1170;
	case 25:
		goto loc_82DC1170;
	case 26:
		goto loc_82DC1170;
	case 27:
		goto loc_82DC1170;
	case 28:
		goto loc_82DC1170;
	case 29:
		goto loc_82DC1170;
	case 30:
		goto loc_82DC1170;
	case 31:
		goto loc_82DC1170;
	case 32:
		goto loc_82DC1170;
	case 33:
		goto loc_82DC1170;
	case 34:
		goto loc_82DC1170;
	case 35:
		goto loc_82DC1170;
	case 36:
		goto loc_82DC1170;
	case 37:
		goto loc_82DC1170;
	case 38:
		goto loc_82DC1170;
	case 39:
		goto loc_82DC1170;
	case 40:
		goto loc_82DC1170;
	case 41:
		goto loc_82DC1170;
	case 42:
		goto loc_82DC1170;
	case 43:
		goto loc_82DC1170;
	case 44:
		goto loc_82DC1170;
	case 45:
		goto loc_82DC1170;
	case 46:
		goto loc_82DC1170;
	case 47:
		goto loc_82DC1170;
	case 48:
		goto loc_82DC1170;
	case 49:
		goto loc_82DC1170;
	case 50:
		goto loc_82DC1170;
	case 51:
		goto loc_82DC1170;
	case 52:
		goto loc_82DC1170;
	case 53:
		goto loc_82DC1170;
	case 54:
		goto loc_82DC1170;
	case 55:
		goto loc_82DC1170;
	case 56:
		goto loc_82DC1170;
	case 57:
		goto loc_82DC1170;
	case 58:
		goto loc_82DC1170;
	case 59:
		goto loc_82DC1170;
	case 60:
		goto loc_82DC1170;
	case 61:
		goto loc_82DC1170;
	case 62:
		goto loc_82DC1170;
	case 63:
		goto loc_82DC1170;
	case 64:
		goto loc_82DC1170;
	case 65:
		goto loc_82DC1170;
	case 66:
		goto loc_82DC1170;
	case 67:
		goto loc_82DC1170;
	case 68:
		goto loc_82DC1170;
	case 69:
		goto loc_82DC1170;
	case 70:
		goto loc_82DC1170;
	case 71:
		goto loc_82DC1170;
	case 72:
		goto loc_82DC1170;
	case 73:
		goto loc_82DC1170;
	case 74:
		goto loc_82DC1170;
	case 75:
		goto loc_82DC1170;
	case 76:
		goto loc_82DC1170;
	case 77:
		goto loc_82DC1170;
	case 78:
		goto loc_82DC1170;
	case 79:
		goto loc_82DC1170;
	case 80:
		goto loc_82DC1170;
	case 81:
		goto loc_82DC1170;
	case 82:
		goto loc_82DC1170;
	case 83:
		goto loc_82DC1170;
	case 84:
		goto loc_82DC1170;
	case 85:
		goto loc_82DC1170;
	case 86:
		goto loc_82DC1170;
	case 87:
		goto loc_82DC1170;
	case 88:
		goto loc_82DC1170;
	case 89:
		goto loc_82DC1170;
	case 90:
		goto loc_82DC1170;
	case 91:
		goto loc_82DC1170;
	case 92:
		goto loc_82DC1170;
	case 93:
		goto loc_82DC1170;
	case 94:
		goto loc_82DC1170;
	case 95:
		goto loc_82DC1170;
	case 96:
		goto loc_82DC1170;
	case 97:
		goto loc_82DC1170;
	case 98:
		goto loc_82DC1170;
	case 99:
		goto loc_82DC1170;
	case 100:
		goto loc_82DC1170;
	case 101:
		goto loc_82DC1170;
	case 102:
		goto loc_82DC1170;
	case 103:
		goto loc_82DC1170;
	case 104:
		goto loc_82DC1170;
	case 105:
		goto loc_82DC1170;
	case 106:
		goto loc_82DC1170;
	case 107:
		goto loc_82DC1170;
	case 108:
		goto loc_82DC1170;
	case 109:
		goto loc_82DC1170;
	case 110:
		goto loc_82DC1170;
	case 111:
		goto loc_82DC1170;
	case 112:
		goto loc_82DC1170;
	case 113:
		goto loc_82DC1170;
	case 114:
		goto loc_82DC1170;
	case 115:
		goto loc_82DC1170;
	case 116:
		goto loc_82DC1170;
	case 117:
		goto loc_82DC1170;
	case 118:
		goto loc_82DC1170;
	case 119:
		goto loc_82DC1170;
	case 120:
		goto loc_82DC1170;
	case 121:
		goto loc_82DC1170;
	case 122:
		goto loc_82DC1170;
	case 123:
		goto loc_82DC1170;
	case 124:
		goto loc_82DC1170;
	case 125:
		goto loc_82DC1170;
	case 126:
		goto loc_82DC1170;
	case 127:
		goto loc_82DC1170;
	case 128:
		goto loc_82DC1170;
	case 129:
		goto loc_82DC1108;
	case 130:
		goto loc_82DC1170;
	case 131:
		goto loc_82DC1170;
	case 132:
		goto loc_82DC1170;
	case 133:
		goto loc_82DC1170;
	case 134:
		goto loc_82DC1170;
	case 135:
		goto loc_82DC1120;
	case 136:
		goto loc_82DC1170;
	case 137:
		goto loc_82DC1170;
	case 138:
		goto loc_82DC1138;
	case 139:
		goto loc_82DC1150;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4320);
	// lwz r22,4320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4320);
	// lwz r22,4328(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4328);
	// lwz r22,4344(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4344);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4360(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4360);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4384(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4384);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4464);
	// lwz r22,4408(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4408);
	// lwz r22,4432(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4432);
loc_82DC10E0:
	// fmr f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f11.f64;
	// b 0x82dc1170
	goto loc_82DC1170;
loc_82DC10E8:
	// lbz r11,600(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 600);
	// std r11,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.r11.u64);
	// lfd f0,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x82dc1164
	goto loc_82DC1164;
loc_82DC10F8:
	// lbz r11,592(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 592);
	// std r11,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.r11.u64);
	// lfd f0,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82dc1164
	goto loc_82DC1164;
loc_82DC1108:
	// lwz r11,640(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	// lwz r11,704(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 704);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.r11.u64);
	// lfd f0,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x82dc1164
	goto loc_82DC1164;
loc_82DC1120:
	// lwz r11,640(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	// lwz r11,708(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 708);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.r11.u64);
	// lfd f0,-48(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82dc1164
	goto loc_82DC1164;
loc_82DC1138:
	// lwz r11,640(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	// lwz r11,712(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 712);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.r11.u64);
	// lfd f0,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82dc1164
	goto loc_82DC1164;
loc_82DC1150:
	// lwz r11,640(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	// lwz r11,716(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 716);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.r11.u64);
	// lfd f0,-32(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
loc_82DC1164:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
loc_82DC1170:
	// lhz r11,6(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 6);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82dc11b8
	if (ctx.cr6.eq) goto loc_82DC11B8;
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// addi r9,r1,-96
	ctx.r9.s64 = ctx.r1.s64 + -96;
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r11.u64);
	// lfd f10,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f0,f10,f0
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,-96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82DC11B8:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82DC11BC:
	// lwz r11,604(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 604);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,12
	ctx.r8.s64 = ctx.r8.s64 + 12;
	// cmpw cr6,r7,r11
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc0b70
	if (ctx.cr6.lt) goto loc_82DC0B70;
loc_82DC11D0:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,30,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// rlwinm r11,r11,0,27,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFDF;
	// addi r3,r11,37
	ctx.r3.s64 = ctx.r11.s64 + 37;
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC11F0"))) PPC_WEAK_FUNC(sub_82DC11F0);
PPC_FUNC_IMPL(__imp__sub_82DC11F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32768
	ctx.r11.s64 = -2147483648;
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82dc1208
	if (!ctx.cr6.eq) goto loc_82DC1208;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_82DC1208:
	// extsw r10,r4
	ctx.r10.s64 = ctx.r4.s32;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// std r10,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r10.u64);
	// lfs f0,8872(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8872);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,6404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6404);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f0,8868(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8868);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82dc1254
	if (!ctx.cr6.lt) goto loc_82DC1254;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// b 0x82dc126c
	goto loc_82DC126C;
loc_82DC1254:
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f13,-17348(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -17348);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x82dc126c
	if (ctx.cr6.lt) goto loc_82DC126C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,8864(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8864);
	ctx.f0.f64 = double(temp.f32);
loc_82DC126C:
	// addi r10,r1,-16
	ctx.r10.s64 = ctx.r1.s64 + -16;
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// addi r11,r11,29584
	ctx.r11.s64 = ctx.r11.s64 + 29584;
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r10,-16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f1,r10,r11
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC1290"))) PPC_WEAK_FUNC(sub_82DC1290);
PPC_FUNC_IMPL(__imp__sub_82DC1290) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e4
	ctx.lr = 0x82DC1298;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82cb6ae4
	ctx.lr = 0x82DC12A0;
	__savefpr_27(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r10,12800
	ctx.r10.s64 = 12800;
	// li r29,1
	ctx.r29.s64 = 1;
	// lfs f31,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f31.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stfs f31,460(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 460, temp.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// stfs f31,464(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 464, temp.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// stfs f31,468(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 468, temp.u32);
	// stfs f31,512(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// stb r28,624(r31)
	PPC_STORE_U8(ctx.r31.u32 + 624, ctx.r28.u8);
	// lfs f29,8896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8896);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// stfs f31,516(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 516, temp.u32);
	// stw r10,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r10.u32);
	// stfs f31,520(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 520, temp.u32);
	// stw r28,508(r31)
	PPC_STORE_U32(ctx.r31.u32 + 508, ctx.r28.u32);
	// stfs f31,472(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 472, temp.u32);
	// stb r29,524(r31)
	PPC_STORE_U8(ctx.r31.u32 + 524, ctx.r29.u8);
	// stfs f29,476(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 476, temp.u32);
	// stw r28,564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 564, ctx.r28.u32);
	// lfs f30,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f30.f64 = double(temp.f32);
	// stb r28,580(r31)
	PPC_STORE_U8(ctx.r31.u32 + 580, ctx.r28.u8);
	// stfs f31,480(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 480, temp.u32);
	// stfs f31,484(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 484, temp.u32);
	// stfs f31,488(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 488, temp.u32);
	// stfs f29,492(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 492, temp.u32);
	// stfs f31,496(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 496, temp.u32);
	// stfs f31,500(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 500, temp.u32);
	// stfs f29,504(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 504, temp.u32);
	// stfs f31,568(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// stfs f30,572(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 572, temp.u32);
	// stfs f31,576(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 576, temp.u32);
	// stfs f31,528(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 528, temp.u32);
	// stfs f31,532(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 532, temp.u32);
	// stfs f30,536(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 536, temp.u32);
	// stfs f31,540(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 540, temp.u32);
	// stfs f30,544(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 544, temp.u32);
	// stfs f31,548(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 548, temp.u32);
	// stfs f31,552(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 552, temp.u32);
	// stfs f31,556(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 556, temp.u32);
	// stfs f31,560(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 560, temp.u32);
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1360;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc13b8
	if (!ctx.cr6.eq) goto loc_82DC13B8;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// extsw r10,r11
	ctx.r10.s64 = ctx.r11.s32;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f1,-16744(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -16744);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,8892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8892);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,10764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 10764);
	ctx.f13.f64 = double(temp.f32);
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f0,612(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 612, temp.u32);
	// fmuls f2,f0,f13
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// bl 0x82cb59b0
	ctx.lr = 0x82DC13AC;
	sub_82CB59B0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// fsubs f0,f30,f0
	ctx.f0.f64 = double(float(ctx.f30.f64 - ctx.f0.f64));
	// stfs f0,612(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 612, temp.u32);
loc_82DC13B8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC13CC;
	sub_82DC0B40(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// lfs f27,6944(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6944);
	ctx.f27.f64 = double(temp.f32);
	// bne cr6,0x82dc13fc
	if (!ctx.cr6.eq) goto loc_82DC13FC;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f0,f0,f27
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// stfs f0,616(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 616, temp.u32);
loc_82DC13FC:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1410;
	sub_82DC0B40(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r27,2048
	ctx.r27.s64 = 134217728;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// lfs f28,8888(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8888);
	ctx.f28.f64 = double(temp.f32);
	// bne cr6,0x82dc1458
	if (!ctx.cr6.eq) goto loc_82DC1458;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r27
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r27.s32, ctx.xer);
	// bne cr6,0x82dc1438
	if (!ctx.cr6.eq) goto loc_82DC1438;
	// fmr f0,f29
	ctx.f0.f64 = ctx.f29.f64;
	// b 0x82dc1454
	goto loc_82DC1454;
loc_82DC1438:
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fnmsubs f0,f0,f28,f30
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// fmuls f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
loc_82DC1454:
	// stfs f0,620(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 620, temp.u32);
loc_82DC1458:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,260
	ctx.r5.s64 = 260;
	// li r4,1997
	ctx.r4.s64 = 1997;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC146C;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc14c4
	if (!ctx.cr6.eq) goto loc_82DC14C4;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// extsw r10,r11
	ctx.r10.s64 = ctx.r11.s32;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f1,-18376(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18376);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,8884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8884);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmsubs f13,f13,f27,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 - ctx.f0.f64));
	// lfs f0,8880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8880);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82cb59b0
	ctx.lr = 0x82DC14B0;
	sub_82CB59B0(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,8876(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8876);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,468(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 468, temp.u32);
loc_82DC14C4:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,261
	ctx.r5.s64 = 261;
	// li r4,1997
	ctx.r4.s64 = 1997;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC14D8;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc14f0
	if (!ctx.cr6.eq) goto loc_82DC14F0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC14EC;
	sub_82DC11F0(ctx, base);
	// stfs f1,460(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 460, temp.u32);
loc_82DC14F0:
	// lwz r30,604(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82dc1560
	if (!ctx.cr6.gt) goto loc_82DC1560;
	// lwz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 608);
loc_82DC1504:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc151c
	if (!ctx.cr6.eq) goto loc_82DC151C;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmplwi cr6,r9,518
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 518, ctx.xer);
	// beq cr6,0x82dc1534
	if (ctx.cr6.eq) goto loc_82DC1534;
loc_82DC151C:
	// lwz r9,604(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc1504
	if (ctx.cr6.lt) goto loc_82DC1504;
	// b 0x82dc1560
	goto loc_82DC1560;
loc_82DC1534:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,518
	ctx.r5.s64 = 518;
	// li r4,1997
	ctx.r4.s64 = 1997;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1548;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1560
	if (!ctx.cr6.eq) goto loc_82DC1560;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC155C;
	sub_82DC11F0(ctx, base);
	// stfs f1,472(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 472, temp.u32);
loc_82DC1560:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82dc15cc
	if (!ctx.cr6.gt) goto loc_82DC15CC;
	// lwz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 608);
loc_82DC1570:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc1588
	if (!ctx.cr6.eq) goto loc_82DC1588;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmplwi cr6,r9,519
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 519, ctx.xer);
	// beq cr6,0x82dc15a0
	if (ctx.cr6.eq) goto loc_82DC15A0;
loc_82DC1588:
	// lwz r9,604(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc1570
	if (ctx.cr6.lt) goto loc_82DC1570;
	// b 0x82dc15cc
	goto loc_82DC15CC;
loc_82DC15A0:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,519
	ctx.r5.s64 = 519;
	// li r4,1997
	ctx.r4.s64 = 1997;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC15B4;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc15cc
	if (!ctx.cr6.eq) goto loc_82DC15CC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC15C8;
	sub_82DC11F0(ctx, base);
	// stfs f1,484(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 484, temp.u32);
loc_82DC15CC:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82dc1638
	if (!ctx.cr6.gt) goto loc_82DC1638;
	// lwz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 608);
loc_82DC15DC:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc15f4
	if (!ctx.cr6.eq) goto loc_82DC15F4;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmplwi cr6,r9,521
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 521, ctx.xer);
	// beq cr6,0x82dc160c
	if (ctx.cr6.eq) goto loc_82DC160C;
loc_82DC15F4:
	// lwz r9,604(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc15dc
	if (ctx.cr6.lt) goto loc_82DC15DC;
	// b 0x82dc1638
	goto loc_82DC1638;
loc_82DC160C:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,521
	ctx.r5.s64 = 521;
	// li r4,1997
	ctx.r4.s64 = 1997;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1620;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1638
	if (!ctx.cr6.eq) goto loc_82DC1638;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC1634;
	sub_82DC11F0(ctx, base);
	// stfs f1,496(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 496, temp.u32);
loc_82DC1638:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,522
	ctx.r5.s64 = 522;
	// li r4,1997
	ctx.r4.s64 = 1997;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC164C;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1680
	if (!ctx.cr6.eq) goto loc_82DC1680;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r27
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r27.s32, ctx.xer);
	// beq cr6,0x82dc167c
	if (ctx.cr6.eq) goto loc_82DC167C;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fnmsubs f0,f0,f28,f30
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// fmuls f29,f0,f29
	ctx.f29.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
loc_82DC167C:
	// stfs f29,516(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 516, temp.u32);
loc_82DC1680:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,32
	ctx.r4.s64 = 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1694;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1848
	if (!ctx.cr6.eq) goto loc_82DC1848;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// stb r29,580(r31)
	PPC_STORE_U8(ctx.r31.u32 + 580, ctx.r29.u8);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f0,f0,f27
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// stfs f0,576(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 576, temp.u32);
	// ble cr6,0x82dc172c
	if (!ctx.cr6.gt) goto loc_82DC172C;
	// lwz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 608);
loc_82DC16D0:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc16e8
	if (!ctx.cr6.eq) goto loc_82DC16E8;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmplwi cr6,r9,778
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 778, ctx.xer);
	// beq cr6,0x82dc1700
	if (ctx.cr6.eq) goto loc_82DC1700;
loc_82DC16E8:
	// lwz r9,604(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc16d0
	if (ctx.cr6.lt) goto loc_82DC16D0;
	// b 0x82dc172c
	goto loc_82DC172C;
loc_82DC1700:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,778
	ctx.r5.s64 = 778;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1714;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc172c
	if (!ctx.cr6.eq) goto loc_82DC172C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC1728;
	sub_82DC11F0(ctx, base);
	// stfs f1,528(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 528, temp.u32);
loc_82DC172C:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82dc1798
	if (!ctx.cr6.gt) goto loc_82DC1798;
	// lwz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 608);
loc_82DC173C:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc1754
	if (!ctx.cr6.eq) goto loc_82DC1754;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmplwi cr6,r9,779
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 779, ctx.xer);
	// beq cr6,0x82dc176c
	if (ctx.cr6.eq) goto loc_82DC176C;
loc_82DC1754:
	// lwz r9,604(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc173c
	if (ctx.cr6.lt) goto loc_82DC173C;
	// b 0x82dc1798
	goto loc_82DC1798;
loc_82DC176C:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,779
	ctx.r5.s64 = 779;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1780;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1798
	if (!ctx.cr6.eq) goto loc_82DC1798;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC1794;
	sub_82DC11F0(ctx, base);
	// stfs f1,540(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 540, temp.u32);
loc_82DC1798:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82dc1804
	if (!ctx.cr6.gt) goto loc_82DC1804;
	// lwz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 608);
loc_82DC17A8:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc17c0
	if (!ctx.cr6.eq) goto loc_82DC17C0;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// cmplwi cr6,r9,781
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 781, ctx.xer);
	// beq cr6,0x82dc17d8
	if (ctx.cr6.eq) goto loc_82DC17D8;
loc_82DC17C0:
	// lwz r9,604(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc17a8
	if (ctx.cr6.lt) goto loc_82DC17A8;
	// b 0x82dc1804
	goto loc_82DC1804;
loc_82DC17D8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,781
	ctx.r5.s64 = 781;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC17EC;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1804
	if (!ctx.cr6.eq) goto loc_82DC1804;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82dc11f0
	ctx.lr = 0x82DC1800;
	sub_82DC11F0(ctx, base);
	// stfs f1,552(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 552, temp.u32);
loc_82DC1804:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,782
	ctx.r5.s64 = 782;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc0b40
	ctx.lr = 0x82DC1818;
	sub_82DC0B40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc1848
	if (!ctx.cr6.eq) goto loc_82DC1848;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r27
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r27.s32, ctx.xer);
	// beq cr6,0x82dc1844
	if (ctx.cr6.eq) goto loc_82DC1844;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f31,f0,f28
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
loc_82DC1844:
	// stfs f31,572(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 572, temp.u32);
loc_82DC1848:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,496(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	ctx.f13.f64 = double(temp.f32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f0,9904(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9904);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bge cr6,0x82dc1864
	if (!ctx.cr6.lt) goto loc_82DC1864;
	// stfs f0,496(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 496, temp.u32);
loc_82DC1864:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82cb6b30
	ctx.lr = 0x82DC1870;
	__restfpr_27(ctx, base);
	// b 0x82cb1134
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC1874"))) PPC_WEAK_FUNC(sub_82DC1874);
PPC_FUNC_IMPL(__imp__sub_82DC1874) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC1878"))) PPC_WEAK_FUNC(sub_82DC1878);
PPC_FUNC_IMPL(__imp__sub_82DC1878) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,16
	ctx.r3.s64 = ctx.r31.s64 + 16;
	// bl 0x82d9cb18
	ctx.lr = 0x82DC18BC;
	sub_82D9CB18(ctx, base);
	// li r10,-1
	ctx.r10.s64 = -1;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r30,456(r31)
	PPC_STORE_U32(ctx.r31.u32 + 456, ctx.r30.u32);
	// stb r30,624(r31)
	PPC_STORE_U8(ctx.r31.u32 + 624, ctx.r30.u8);
	// stw r10,584(r31)
	PPC_STORE_U32(ctx.r31.u32 + 584, ctx.r10.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// addi r11,r11,11944
	ctx.r11.s64 = ctx.r11.s64 + 11944;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r31.u32);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC1930"))) PPC_WEAK_FUNC(sub_82DC1930);
PPC_FUNC_IMPL(__imp__sub_82DC1930) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6adc
	ctx.lr = 0x82DC1944;
	__savefpr_25(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lfs f27,6140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lbz r10,524(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 524);
	// fmr f28,f27
	ctx.f28.f64 = ctx.f27.f64;
	// fmr f26,f27
	ctx.f26.f64 = ctx.f27.f64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lfs f25,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f25.f64 = double(temp.f32);
	// beq cr6,0x82dc1bb8
	if (ctx.cr6.eq) goto loc_82DC1BB8;
	// lbz r11,624(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 624);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f31,8908(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8908);
	ctx.f31.f64 = double(temp.f32);
	// beq cr6,0x82dc1a54
	if (ctx.cr6.eq) goto loc_82DC1A54;
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// lbz r11,700(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 700);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc1a54
	if (!ctx.cr6.eq) goto loc_82DC1A54;
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82dc1a54
	if (ctx.cr6.eq) goto loc_82DC1A54;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,512(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f0,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// lfs f11,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f11.f64 = double(temp.f32);
	// fdivs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f11.f64));
	// fmadds f0,f12,f13,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f0.f64));
	// bne cr6,0x82dc19ec
	if (!ctx.cr6.eq) goto loc_82DC19EC;
	// fnmsubs f1,f0,f31,f27
	ctx.f1.f64 = double(float(-(ctx.f0.f64 * ctx.f31.f64 - ctx.f27.f64)));
	// bl 0x82cb4f48
	ctx.lr = 0x82DC19DC;
	sub_82CB4F48(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,7984(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 7984);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82DC19EC:
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dc1a08
	if (!ctx.cr6.eq) goto loc_82DC1A08;
	// lfs f13,516(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 516);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82dc1a08
	if (!ctx.cr6.lt) goto loc_82DC1A08;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_82DC1A08:
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r31,496
	ctx.r11.s64 = ctx.r31.s64 + 496;
	// stw r10,508(r31)
	PPC_STORE_U32(ctx.r31.u32 + 508, ctx.r10.u32);
	// lfs f11,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fcmpu cr6,f13,f25
	ctx.cr6.compare(ctx.f13.f64, ctx.f25.f64);
	// beq cr6,0x82dc1a50
	if (ctx.cr6.eq) goto loc_82DC1A50;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f25
	ctx.cr6.compare(ctx.f12.f64, ctx.f25.f64);
	// beq cr6,0x82dc1a50
	if (ctx.cr6.eq) goto loc_82DC1A50;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fdivs f13,f11,f12
	ctx.f13.f64 = double(float(ctx.f11.f64 / ctx.f12.f64));
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// b 0x82dc1a54
	goto loc_82DC1A54;
loc_82DC1A50:
	// stfs f25,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
loc_82DC1A54:
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// lfs f0,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f13,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x82dc1b10
	if (ctx.cr6.lt) goto loc_82DC1B10;
loc_82DC1A78:
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82dc1b10
	if (!ctx.cr6.lt) goto loc_82DC1B10;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dc1aa8
	if (!ctx.cr6.eq) goto loc_82DC1AA8;
	// lbz r10,624(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 624);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc1af4
	if (ctx.cr6.eq) goto loc_82DC1AF4;
	// lwz r10,640(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// lbz r10,700(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 700);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc1af4
	if (!ctx.cr6.eq) goto loc_82DC1AF4;
loc_82DC1AA8:
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f13,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f13.f64 = double(temp.f32);
	// rotlwi r11,r9,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stw r9,508(r31)
	PPC_STORE_U32(ctx.r31.u32 + 508, ctx.r9.u32);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f13,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82dc1a78
	if (!ctx.cr6.lt) goto loc_82DC1A78;
	// b 0x82dc1b10
	goto loc_82DC1B10;
loc_82DC1AF4:
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f0,472(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
loc_82DC1B10:
	// lwz r10,508(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// blt cr6,0x82dc1b28
	if (ctx.cr6.lt) goto loc_82DC1B28;
loc_82DC1B1C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc1878
	ctx.lr = 0x82DC1B24;
	sub_82DC1878(ctx, base);
	// b 0x82dc1cc8
	goto loc_82DC1CC8;
loc_82DC1B28:
	// rlwinm r11,r10,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f13,472(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f25
	ctx.cr6.compare(ctx.f13.f64, ctx.f25.f64);
	// ble cr6,0x82dc1b5c
	if (!ctx.cr6.gt) goto loc_82DC1B5C;
	// lfs f12,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// lfs f11,512(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f11.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// fmadds f0,f13,f11,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + ctx.f0.f64));
loc_82DC1B5C:
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82dc1b74
	if (!ctx.cr6.eq) goto loc_82DC1B74;
	// lfs f13,516(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 516);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82dc1b74
	if (!ctx.cr6.lt) goto loc_82DC1B74;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_82DC1B74:
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc1b84
	if (!ctx.cr6.eq) goto loc_82DC1B84;
	// fnmsubs f28,f0,f31,f27
	ctx.fpscr.disableFlushMode();
	ctx.f28.f64 = double(float(-(ctx.f0.f64 * ctx.f31.f64 - ctx.f27.f64)));
	// b 0x82dc1bb8
	goto loc_82DC1BB8;
loc_82DC1B84:
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f13,-18204(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18204);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// addi r11,r11,30096
	ctx.r11.s64 = ctx.r11.s64 + 30096;
	// addi r11,r11,768
	ctx.r11.s64 = ctx.r11.s64 + 768;
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// lfs f28,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
loc_82DC1BB8:
	// lbz r10,600(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 600);
	// lfs f13,464(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// lfs f12,460(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 460);
	ctx.f12.f64 = double(temp.f32);
	// mullw r10,r10,r10
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r10.s32);
	// fcmpu cr6,f13,f12
	ctx.cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r9,708(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 708);
	// lwz r11,716(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 716);
	// mullw r11,r11,r11
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r11.s32);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// mullw r10,r9,r9
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r9.s32);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f11,f0
	ctx.f11.f64 = double(float(ctx.f0.f64));
	// lfs f0,8904(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8904);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f31,f11,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfd f10,88(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f29,f10,f0
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfd f11,80(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// fmuls f30,f11,f0
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// blt cr6,0x82dc1c78
	if (ctx.cr6.lt) goto loc_82DC1C78;
	// fsubs f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f13,468(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 468);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,8900(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8900);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82cb4860
	ctx.lr = 0x82DC1C50;
	sub_82CB4860(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// lfs f13,612(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f26,f13,f0,f27
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fcmpu cr6,f26,f25
	ctx.cr6.compare(ctx.f26.f64, ctx.f25.f64);
	// bge cr6,0x82dc1c6c
	if (!ctx.cr6.lt) goto loc_82DC1C6C;
	// fmr f26,f25
	ctx.f26.f64 = ctx.f25.f64;
	// b 0x82dc1c78
	goto loc_82DC1C78;
loc_82DC1C6C:
	// fcmpu cr6,f26,f27
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f26.f64, ctx.f27.f64);
	// ble cr6,0x82dc1c78
	if (!ctx.cr6.gt) goto loc_82DC1C78;
	// fmr f26,f27
	ctx.f26.f64 = ctx.f27.f64;
loc_82DC1C78:
	// lfs f0,636(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// fmuls f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// bne cr6,0x82dc1cac
	if (!ctx.cr6.eq) goto loc_82DC1CAC;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f13,-17356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -17356);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x82dc1b1c
	if (ctx.cr6.lt) goto loc_82DC1B1C;
loc_82DC1CAC:
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,16
	ctx.r3.s64 = ctx.r31.s64 + 16;
	// lfs f13,688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 688);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DC1CC4;
	sub_82D99380(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC1CC8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6b28
	ctx.lr = 0x82DC1CD4;
	__restfpr_25(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC1CE4"))) PPC_WEAK_FUNC(sub_82DC1CE4);
PPC_FUNC_IMPL(__imp__sub_82DC1CE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC1CE8"))) PPC_WEAK_FUNC(sub_82DC1CE8);
PPC_FUNC_IMPL(__imp__sub_82DC1CE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6ae4
	ctx.lr = 0x82DC1CFC;
	__savefpr_27(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lbz r10,580(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 580);
	// lfs f10,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f10.f64 = double(temp.f32);
	// fmr f27,f10
	ctx.f27.f64 = ctx.f10.f64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc1f10
	if (ctx.cr6.eq) goto loc_82DC1F10;
	// lbz r9,624(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 624);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc1dd8
	if (ctx.cr6.eq) goto loc_82DC1DD8;
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// lbz r11,700(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 700);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc1dd8
	if (!ctx.cr6.eq) goto loc_82DC1DD8;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 564);
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// beq cr6,0x82dc1dd8
	if (ctx.cr6.eq) goto loc_82DC1DD8;
	// addi r11,r10,44
	ctx.r11.s64 = ctx.r10.s64 + 44;
	// lfs f13,568(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 568);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fdivs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f11.f64));
	// fmadds f11,f12,f13,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f0.f64));
	// bne cr6,0x82dc1d8c
	if (!ctx.cr6.eq) goto loc_82DC1D8C;
	// lfs f0,572(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 572);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f11,f0
	ctx.cr6.compare(ctx.f11.f64, ctx.f0.f64);
	// bge cr6,0x82dc1d8c
	if (!ctx.cr6.lt) goto loc_82DC1D8C;
	// fmr f11,f0
	ctx.f11.f64 = ctx.f0.f64;
loc_82DC1D8C:
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r31,552
	ctx.r11.s64 = ctx.r31.s64 + 552;
	// stw r10,564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 564, ctx.r10.u32);
	// lfs f12,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fcmpu cr6,f0,f10
	ctx.cr6.compare(ctx.f0.f64, ctx.f10.f64);
	// beq cr6,0x82dc1dd4
	if (ctx.cr6.eq) goto loc_82DC1DD4;
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f10
	ctx.cr6.compare(ctx.f13.f64, ctx.f10.f64);
	// beq cr6,0x82dc1dd4
	if (ctx.cr6.eq) goto loc_82DC1DD4;
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// stfs f0,568(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// b 0x82dc1dd8
	goto loc_82DC1DD8;
loc_82DC1DD4:
	// stfs f10,568(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
loc_82DC1DD8:
	// lwz r11,564(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 564);
	// lfs f0,568(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 568);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r11,44
	ctx.r11.s64 = ctx.r11.s64 + 44;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r31
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x82dc1e9c
	if (ctx.cr6.lt) goto loc_82DC1E9C;
loc_82DC1DFC:
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 564);
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// bge cr6,0x82dc1e9c
	if (!ctx.cr6.lt) goto loc_82DC1E9C;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82dc1e34
	if (!ctx.cr6.eq) goto loc_82DC1E34;
	// lfs f0,572(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 572);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f10
	ctx.cr6.compare(ctx.f0.f64, ctx.f10.f64);
	// ble cr6,0x82dc1e34
	if (!ctx.cr6.gt) goto loc_82DC1E34;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc1e80
	if (ctx.cr6.eq) goto loc_82DC1E80;
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// lbz r11,700(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 700);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc1e80
	if (!ctx.cr6.eq) goto loc_82DC1E80;
loc_82DC1E34:
	// addi r11,r10,44
	ctx.r11.s64 = ctx.r10.s64 + 44;
	// lfs f0,568(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 568);
	ctx.f0.f64 = double(temp.f32);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r31
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	ctx.f13.f64 = double(temp.f32);
	// rotlwi r11,r8,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stw r8,564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 564, ctx.r8.u32);
	// addi r11,r11,44
	ctx.r11.s64 = ctx.r11.s64 + 44;
	// stfs f0,568(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r31
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82dc1dfc
	if (!ctx.cr6.lt) goto loc_82DC1DFC;
	// b 0x82dc1e9c
	goto loc_82DC1E9C;
loc_82DC1E80:
	// lwz r11,564(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 564);
	// addi r11,r11,44
	ctx.r11.s64 = ctx.r11.s64 + 44;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f0,r11,r31
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,568(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
loc_82DC1E9C:
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 564);
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82dc1eb8
	if (ctx.cr6.lt) goto loc_82DC1EB8;
	// li r11,0
	ctx.r11.s64 = 0;
	// fmr f27,f10
	ctx.fpscr.disableFlushMode();
	ctx.f27.f64 = ctx.f10.f64;
	// stb r11,580(r31)
	PPC_STORE_U8(ctx.r31.u32 + 580, ctx.r11.u8);
	// b 0x82dc1f10
	goto loc_82DC1F10;
loc_82DC1EB8:
	// addi r11,r9,44
	ctx.r11.s64 = ctx.r9.s64 + 44;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f10
	ctx.cr6.compare(ctx.f13.f64, ctx.f10.f64);
	// beq cr6,0x82dc1ef0
	if (ctx.cr6.eq) goto loc_82DC1EF0;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// lfs f11,568(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 568);
	ctx.f11.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// fmadds f0,f13,f11,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + ctx.f0.f64));
loc_82DC1EF0:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82dc1f08
	if (!ctx.cr6.eq) goto loc_82DC1F08;
	// lfs f13,572(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 572);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82dc1f08
	if (!ctx.cr6.lt) goto loc_82DC1F08;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_82DC1F08:
	// lfs f13,576(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 576);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f27,f13,f0
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82DC1F10:
	// lbz r9,592(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 592);
	// lfs f0,464(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	ctx.f0.f64 = double(temp.f32);
	// lbz r8,593(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 593);
	// lfs f13,460(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 460);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r7,596(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// std r8,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r8.u64);
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lwz r10,696(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 696);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lwz r11,692(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 692);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r7,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r7.u64);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// lfd f11,88(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// lfd f9,96(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// lfd f8,104(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// frsp f31,f8
	ctx.f31.f64 = double(float(ctx.f8.f64));
	// fmuls f11,f12,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,6148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6148);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// fmuls f30,f9,f12
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f12,-17360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -17360);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f29,f11,f12
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfd f12,112(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f11,120(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f9,f12
	ctx.f9.f64 = double(float(ctx.f12.f64));
	// lfs f12,8912(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8912);
	ctx.f12.f64 = double(temp.f32);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f12,-16020(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16020);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f28,f9,f12
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// blt cr6,0x82dc2010
	if (ctx.cr6.lt) goto loc_82DC2010;
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f13,468(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 468);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,8900(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8900);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82cb4860
	ctx.lr = 0x82DC2000;
	sub_82CB4860(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// lfs f13,616(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 616);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x82dc2014
	goto loc_82DC2014;
loc_82DC2010:
	// fmr f0,f10
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f10.f64;
loc_82DC2014:
	// fadds f13,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfd f1,-18376(r11)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18376);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fadds f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f28.f64));
	// fadds f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// fsubs f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f0,8880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8880);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82cb59b0
	ctx.lr = 0x82DC2040;
	sub_82CB59B0(ctx, base);
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// frsp f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = double(float(ctx.f1.f64));
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC2068;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r31,16
	ctx.r3.s64 = ctx.r31.s64 + 16;
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DC2078;
	sub_82D9B8E0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6b30
	ctx.lr = 0x82DC2088;
	__restfpr_27(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2098"))) PPC_WEAK_FUNC(sub_82DC2098);
PPC_FUNC_IMPL(__imp__sub_82DC2098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lwz r10,640(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r3,16
	ctx.r3.s64 = ctx.r3.s64 + 16;
	// lfs f0,-15896(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -15896);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,712(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 712);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DC20E0;
	sub_82D99540(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC20F4"))) PPC_WEAK_FUNC(sub_82DC20F4);
PPC_FUNC_IMPL(__imp__sub_82DC20F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC20F8"))) PPC_WEAK_FUNC(sub_82DC20F8);
PPC_FUNC_IMPL(__imp__sub_82DC20F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10dc
	ctx.lr = 0x82DC2100;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,11932(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 11932);
	// lwz r10,232(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 232);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82dc231c
	if (!ctx.cr6.gt) goto loc_82DC231C;
	// lwz r3,672(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r31,240(r5)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 240);
loc_82DC2134:
	// lwz r30,260(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 260);
	// cmplw cr6,r30,r3
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r3.u32, ctx.xer);
	// bne cr6,0x82dc2150
	if (!ctx.cr6.eq) goto loc_82DC2150;
	// lbz r30,676(r29)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r29.u32 + 676);
	// lwz r27,264(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// cmplw cr6,r27,r30
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82dc216c
	if (ctx.cr6.eq) goto loc_82DC216C;
loc_82DC2150:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r31,r31,280
	ctx.r31.s64 = ctx.r31.s64 + 280;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc2134
	if (ctx.cr6.lt) goto loc_82DC2134;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb112c
	__restgprlr_25(ctx, base);
	return;
loc_82DC216C:
	// stw r31,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r31.u32);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// lwz r6,256(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 256);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r27,244(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// lwz r26,236(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82dc22a4
	if (ctx.cr6.eq) goto loc_82DC22A4;
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
loc_82DC2190:
	// lhz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// cmpw cr6,r4,r3
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r3.s32, ctx.xer);
	// blt cr6,0x82dc21a8
	if (ctx.cr6.lt) goto loc_82DC21A8;
	// lhz r3,2(r10)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r10.u32 + 2);
	// cmpw cr6,r4,r3
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r3.s32, ctx.xer);
	// ble cr6,0x82dc21bc
	if (!ctx.cr6.gt) goto loc_82DC21BC;
loc_82DC21A8:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,68
	ctx.r10.s64 = ctx.r10.s64 + 68;
	// cmplw cr6,r11,r6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82dc2190
	if (ctx.cr6.lt) goto loc_82DC2190;
	// b 0x82dc22a4
	goto loc_82DC22A4;
loc_82DC21BC:
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// mulli r11,r11,68
	ctx.r11.s64 = ctx.r11.s64 * 68;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r6,12(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r30,56(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82dc2210
	if (ctx.cr6.eq) goto loc_82DC2210;
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 16);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r10,18(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 18);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// b 0x82dc2270
	goto loc_82DC2270;
loc_82DC2210:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82dc2260
	if (ctx.cr6.lt) goto loc_82DC2260;
	// lwz r10,244(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 244);
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dc2260
	if (!ctx.cr6.lt) goto loc_82DC2260;
	// lwz r6,252(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 252);
	// mulli r10,r30,296
	ctx.r10.s64 = ctx.r30.s64 * 296;
	// add r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lhz r6,264(r6)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r6.u32 + 264);
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// lwz r7,252(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 252);
	// add r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 + ctx.r7.u64;
	// lhz r7,266(r7)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + 266);
	// extsh r7,r7
	ctx.r7.s64 = ctx.r7.s16;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// lwz r8,252(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 252);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r10,268(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// b 0x82dc2270
	goto loc_82DC2270;
loc_82DC2260:
	// li r10,60
	ctx.r10.s64 = 60;
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// stw r28,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r28.u32);
	// stw r28,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r28.u32);
loc_82DC2270:
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r9,228(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lhz r10,10(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 10);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,60(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r11,64(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
loc_82DC22A4:
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,11928(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11928);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,72(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC22C8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc2320
	if (!ctx.cr6.eq) goto loc_82DC2320;
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,11936(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11936);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc22f8
	if (ctx.cr6.eq) goto loc_82DC22F8;
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc22f8
	if (!ctx.cr6.eq) goto loc_82DC22F8;
	// li r10,1
	ctx.r10.s64 = 1;
	// stbx r10,r11,r30
	PPC_STORE_U8(ctx.r11.u32 + ctx.r30.u32, ctx.r10.u8);
loc_82DC22F8:
	// lwz r11,272(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 272);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc231c
	if (ctx.cr6.eq) goto loc_82DC231C;
	// lwz r10,276(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 276);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc231c
	if (ctx.cr6.eq) goto loc_82DC231C;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// lwz r11,276(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 276);
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
loc_82DC231C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC2320:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb112c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC2328"))) PPC_WEAK_FUNC(sub_82DC2328);
PPC_FUNC_IMPL(__imp__sub_82DC2328) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DC2330;
	__savegprlr_28(ctx, base);
	// stfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r28,r29,16
	ctx.r28.s64 = ctx.r29.s64 + 16;
	// lwz r31,16(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82dc2400
	if (ctx.cr6.eq) goto loc_82DC2400;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f30,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,-15896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -15896);
	ctx.f31.f64 = double(temp.f32);
loc_82DC2360:
	// lwz r11,456(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 456);
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc23f4
	if (ctx.cr6.eq) goto loc_82DC23F4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc1930
	ctx.lr = 0x82DC2378;
	sub_82DC1930(ctx, base);
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// lfs f0,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f13,11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11924);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// bl 0x82dc1ce8
	ctx.lr = 0x82DC2398;
	sub_82DC1CE8(ctx, base);
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// lwz r10,640(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// lfs f0,568(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 568);
	ctx.f0.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r31,16
	ctx.r3.s64 = ctx.r31.s64 + 16;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f13,11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11924);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,568(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// lwz r11,712(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 712);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmsubs f1,f0,f31,f30
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 - ctx.f30.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DC23DC;
	sub_82D99540(ctx, base);
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// lfs f0,464(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f13,11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11924);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,464(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 464, temp.u32);
loc_82DC23F4:
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
	// cmplw cr6,r30,r28
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82dc2360
	if (!ctx.cr6.eq) goto loc_82DC2360;
loc_82DC2400:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC2414"))) PPC_WEAK_FUNC(sub_82DC2414);
PPC_FUNC_IMPL(__imp__sub_82DC2414) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC2418"))) PPC_WEAK_FUNC(sub_82DC2418);
PPC_FUNC_IMPL(__imp__sub_82DC2418) {
	PPC_FUNC_PROLOGUE();
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r5,12(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x82dc243c
	if (ctx.cr6.lt) goto loc_82DC243C;
loc_82DC242C:
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,22
	ctx.r3.s64 = 22;
	// stb r11,28(r9)
	PPC_STORE_U8(ctx.r9.u32 + 28, ctx.r11.u8);
	// blr 
	return;
loc_82DC243C:
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lbzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r6.u32 + ctx.r10.u32);
	// stw r11,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r11.u32);
	// rlwinm r8,r10,0,0,24
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dc248c
	if (ctx.cr6.eq) goto loc_82DC248C;
	// clrlwi r10,r10,25
	ctx.r10.u64 = ctx.r10.u32 & 0x7F;
loc_82DC245C:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x82dc242c
	if (!ctx.cr6.lt) goto loc_82DC242C;
	// lbzx r8,r11,r6
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r6.u32);
	// rlwinm r7,r10,7,0,24
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0xFFFFFF80;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// rlwinm r3,r10,0,24,24
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// clrlwi r8,r10,25
	ctx.r8.u64 = ctx.r10.u32 & 0x7F;
	// stw r11,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r11.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// add r10,r8,r7
	ctx.r10.u64 = ctx.r8.u64 + ctx.r7.u64;
	// bne cr6,0x82dc245c
	if (!ctx.cr6.eq) goto loc_82DC245C;
loc_82DC248C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2498"))) PPC_WEAK_FUNC(sub_82DC2498);
PPC_FUNC_IMPL(__imp__sub_82DC2498) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82dc24bc
	if (ctx.cr6.lt) goto loc_82DC24BC;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r3,22
	ctx.r3.s64 = 22;
	// stb r10,28(r11)
	PPC_STORE_U8(ctx.r11.u32 + 28, ctx.r10.u8);
	// blr 
	return;
loc_82DC24BC:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stb r10,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r10.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC24DC"))) PPC_WEAK_FUNC(sub_82DC24DC);
PPC_FUNC_IMPL(__imp__sub_82DC24DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC24E0"))) PPC_WEAK_FUNC(sub_82DC24E0);
PPC_FUNC_IMPL(__imp__sub_82DC24E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc2520
	if (ctx.cr6.lt) goto loc_82DC2520;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,22
	ctx.r3.s64 = 22;
	// stb r11,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r11.u8);
	// b 0x82dc2558
	goto loc_82DC2558;
loc_82DC2520:
	// add r9,r11,r30
	ctx.r9.u64 = ctx.r11.u64 + ctx.r30.u64;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82dc2530
	if (!ctx.cr6.gt) goto loc_82DC2530;
	// subf r30,r11,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82DC2530:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc2548
	if (ctx.cr6.eq) goto loc_82DC2548;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + ctx.r11.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DC2548;
	sub_82CB1160(ctx, base);
loc_82DC2548:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r3,0
	ctx.r3.s64 = 0;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
loc_82DC2558:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2570"))) PPC_WEAK_FUNC(sub_82DC2570);
PPC_FUNC_IMPL(__imp__sub_82DC2570) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DC2578;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r11,r6,24
	ctx.r11.u64 = ctx.r6.u32 & 0xFF;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc25e0
	if (!ctx.cr6.eq) goto loc_82DC25E0;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc25bc
	if (ctx.cr6.lt) goto loc_82DC25BC;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,22
	ctx.r3.s64 = 22;
	// stb r11,28(r29)
	PPC_STORE_U8(ctx.r29.u32 + 28, ctx.r11.u8);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
loc_82DC25BC:
	// add r8,r11,r30
	ctx.r8.u64 = ctx.r11.u64 + ctx.r30.u64;
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82dc25cc
	if (!ctx.cr6.gt) goto loc_82DC25CC;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82DC25CC:
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
loc_82DC25E0:
	// lis r27,-31909
	ctx.r27.s64 = -2091188224;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r28,r11,8920
	ctx.r28.s64 = ctx.r11.s64 + 8920;
	// li r6,2395
	ctx.r6.s64 = 2395;
	// lwz r11,19872(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 19872);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC2608;
	sub_82D862B0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82dc2620
	if (!ctx.cr6.eq) goto loc_82DC2620;
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
loc_82DC2620:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dc24e0
	ctx.lr = 0x82DC2630;
	sub_82DC24E0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc267c
	if (!ctx.cr6.eq) goto loc_82DC267C;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r8,3
	ctx.r8.s64 = 3;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x82de89a0
	ctx.lr = 0x82DC2658;
	sub_82DE89A0(ctx, base);
	// lwz r11,19872(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 19872);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2409
	ctx.r6.s64 = 2409;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC2678;
	sub_82D861B0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82DC267C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC2684"))) PPC_WEAK_FUNC(sub_82DC2684);
PPC_FUNC_IMPL(__imp__sub_82DC2684) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC2688"))) PPC_WEAK_FUNC(sub_82DC2688);
PPC_FUNC_IMPL(__imp__sub_82DC2688) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DC2690;
	__savegprlr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// lwz r11,11888(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11888);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f31,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f31.f64 = double(temp.f32);
	// ble cr6,0x82dc270c
	if (!ctx.cr6.gt) goto loc_82DC270C;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82DC26BC:
	// lwz r9,11912(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11912);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stw r31,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r31.u32);
	// lwz r9,11912(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11912);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stfs f31,24(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + 24, temp.u32);
	// lwz r9,11912(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11912);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stb r31,28(r9)
	PPC_STORE_U8(ctx.r9.u32 + 28, ctx.r31.u8);
	// lwz r9,11912(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11912);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stb r31,30(r9)
	PPC_STORE_U8(ctx.r9.u32 + 30, ctx.r31.u8);
	// lwz r9,11912(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11912);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// stb r31,20(r9)
	PPC_STORE_U8(ctx.r9.u32 + 20, ctx.r31.u8);
	// lwz r9,11888(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11888);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc26bc
	if (ctx.cr6.lt) goto loc_82DC26BC;
loc_82DC270C:
	// addi r11,r30,11944
	ctx.r11.s64 = ctx.r30.s64 + 11944;
	// mr r28,r31
	ctx.r28.u64 = ctx.r31.u64;
	// stw r31,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r31.u32);
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// lwz r11,244(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 244);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc2764
	if (!ctx.cr6.gt) goto loc_82DC2764;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82DC2730:
	// lwz r11,340(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 340);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// stw r31,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r31.u32);
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// lwz r11,340(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 340);
	// add r3,r11,r29
	ctx.r3.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bl 0x82dc1878
	ctx.lr = 0x82DC2750;
	sub_82DC1878(ctx, base);
	// lwz r11,244(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 244);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r29,r29,648
	ctx.r29.s64 = ctx.r29.s64 + 648;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc2730
	if (ctx.cr6.lt) goto loc_82DC2730;
loc_82DC2764:
	// lis r4,-32256
	ctx.r4.s64 = -2113929216;
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// addi r11,r30,360
	ctx.r11.s64 = ctx.r30.s64 + 360;
	// li r5,64
	ctx.r5.s64 = 64;
	// li r6,100
	ctx.r6.s64 = 100;
	// lfs f0,6140(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// li r7,127
	ctx.r7.s64 = 127;
	// li r8,512
	ctx.r8.s64 = 512;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82DC2788:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stw r31,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r31.u32);
	// stfs f0,672(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 672, temp.u32);
	// stw r31,-4(r11)
	PPC_STORE_U32(ctx.r11.u32 + -4, ctx.r31.u32);
	// cmpwi cr6,r10,16
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 16, ctx.xer);
	// stw r5,696(r11)
	PPC_STORE_U32(ctx.r11.u32 + 696, ctx.r5.u32);
	// stw r6,692(r11)
	PPC_STORE_U32(ctx.r11.u32 + 692, ctx.r6.u32);
	// stw r7,700(r11)
	PPC_STORE_U32(ctx.r11.u32 + 700, ctx.r7.u32);
	// stw r31,656(r11)
	PPC_STORE_U32(ctx.r11.u32 + 656, ctx.r31.u32);
	// stb r31,660(r11)
	PPC_STORE_U8(ctx.r11.u32 + 660, ctx.r31.u8);
	// stw r8,680(r11)
	PPC_STORE_U32(ctx.r11.u32 + 680, ctx.r8.u32);
	// stw r9,664(r11)
	PPC_STORE_U32(ctx.r11.u32 + 664, ctx.r9.u32);
	// stb r10,648(r11)
	PPC_STORE_U8(ctx.r11.u32 + 648, ctx.r10.u8);
	// addi r11,r11,720
	ctx.r11.s64 = ctx.r11.s64 + 720;
	// blt cr6,0x82dc2788
	if (ctx.cr6.lt) goto loc_82DC2788;
	// stfs f31,11920(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 11920, temp.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,11884(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11884, ctx.r31.u32);
	// stw r31,11872(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11872, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC27E8"))) PPC_WEAK_FUNC(sub_82DC27E8);
PPC_FUNC_IMPL(__imp__sub_82DC27E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DC27F0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// lis r28,-31909
	ctx.r28.s64 = -2091188224;
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r29,r11,8920
	ctx.r29.s64 = ctx.r11.s64 + 8920;
	// beq cr6,0x82dc2884
	if (ctx.cr6.eq) goto loc_82DC2884;
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// mr r27,r26
	ctx.r27.u64 = ctx.r26.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc2868
	if (!ctx.cr6.gt) goto loc_82DC2868;
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
loc_82DC2828:
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc2854
	if (ctx.cr6.eq) goto loc_82DC2854;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3338
	ctx.r6.s64 = 3338;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC2854;
	sub_82D861B0(ctx, base);
loc_82DC2854:
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r30,r30,32
	ctx.r30.s64 = ctx.r30.s64 + 32;
	// cmpw cr6,r27,r11
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc2828
	if (ctx.cr6.lt) goto loc_82DC2828;
loc_82DC2868:
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3341
	ctx.r6.s64 = 3341;
	// lwz r4,11912(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC2884;
	sub_82D861B0(ctx, base);
loc_82DC2884:
	// lwz r4,340(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 340);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc28ac
	if (ctx.cr6.eq) goto loc_82DC28AC;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3346
	ctx.r6.s64 = 3346;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC28A8;
	sub_82D861B0(ctx, base);
	// stw r26,340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 340, ctx.r26.u32);
loc_82DC28AC:
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc28d4
	if (ctx.cr6.eq) goto loc_82DC28D4;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3352
	ctx.r6.s64 = 3352;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC28D0;
	sub_82D861B0(ctx, base);
	// stw r26,340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 340, ctx.r26.u32);
loc_82DC28D4:
	// lwz r3,236(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc28e8
	if (ctx.cr6.eq) goto loc_82DC28E8;
	// bl 0x82da94d0
	ctx.lr = 0x82DC28E4;
	sub_82DA94D0(ctx, base);
	// stw r26,236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 236, ctx.r26.u32);
loc_82DC28E8:
	// lwz r4,240(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc2910
	if (ctx.cr6.eq) goto loc_82DC2910;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3363
	ctx.r6.s64 = 3363;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC290C;
	sub_82D861B0(ctx, base);
	// stw r26,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r26.u32);
loc_82DC2910:
	// lwz r3,232(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc2934
	if (ctx.cr6.eq) goto loc_82DC2934;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC2930;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r26,232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 232, ctx.r26.u32);
loc_82DC2934:
	// lwz r3,11928(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11928);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc2958
	if (ctx.cr6.eq) goto loc_82DC2958;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC2954;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r26,11928(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11928, ctx.r26.u32);
loc_82DC2958:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC2964"))) PPC_WEAK_FUNC(sub_82DC2964);
PPC_FUNC_IMPL(__imp__sub_82DC2964) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC2968"))) PPC_WEAK_FUNC(sub_82DC2968);
PPC_FUNC_IMPL(__imp__sub_82DC2968) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82dc2978
	if (!ctx.cr6.eq) goto loc_82DC2978;
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
loc_82DC2978:
	// lwz r11,244(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 244);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2988"))) PPC_WEAK_FUNC(sub_82DC2988);
PPC_FUNC_IMPL(__imp__sub_82DC2988) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmplwi cr6,r4,15
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 15, ctx.xer);
	// bgt cr6,0x82dc29c4
	if (ctx.cr6.gt) goto loc_82DC29C4;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x82dc29c4
	if (ctx.cr6.lt) goto loc_82DC29C4;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x82dc29c4
	if (ctx.cr6.gt) goto loc_82DC29C4;
	// mulli r11,r4,720
	ctx.r11.s64 = ctx.r4.s64 * 720;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stfs f1,1032(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + 1032, temp.u32);
	// blr 
	return;
loc_82DC29C4:
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC29CC"))) PPC_WEAK_FUNC(sub_82DC29CC);
PPC_FUNC_IMPL(__imp__sub_82DC29CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC29D0"))) PPC_WEAK_FUNC(sub_82DC29D0);
PPC_FUNC_IMPL(__imp__sub_82DC29D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmplwi cr6,r4,15
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 15, ctx.xer);
	// bgt cr6,0x82dc29f8
	if (ctx.cr6.gt) goto loc_82DC29F8;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82dc29f8
	if (ctx.cr6.eq) goto loc_82DC29F8;
	// mulli r11,r4,720
	ctx.r11.s64 = ctx.r4.s64 * 720;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f0,1032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1032);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
loc_82DC29F8:
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2A00"))) PPC_WEAK_FUNC(sub_82DC2A00);
PPC_FUNC_IMPL(__imp__sub_82DC2A00) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc2a10
	if (!ctx.cr6.eq) goto loc_82DC2A10;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC2A10:
	// b 0x82dc27e8
	sub_82DC27E8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC2A14"))) PPC_WEAK_FUNC(sub_82DC2A14);
PPC_FUNC_IMPL(__imp__sub_82DC2A14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC2A18"))) PPC_WEAK_FUNC(sub_82DC2A18);
PPC_FUNC_IMPL(__imp__sub_82DC2A18) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r11,r3,-24
	ctx.r11.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc2a28
	if (!ctx.cr6.eq) goto loc_82DC2A28;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DC2A28:
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82dc2a38
	if (!ctx.cr6.eq) goto loc_82DC2A38;
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
loc_82DC2A38:
	// lwz r11,244(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2A48"))) PPC_WEAK_FUNC(sub_82DC2A48);
PPC_FUNC_IMPL(__imp__sub_82DC2A48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r10,r3,-24
	ctx.r10.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc2a58
	if (!ctx.cr6.eq) goto loc_82DC2A58;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82DC2A58:
	// cmplwi cr6,r4,15
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 15, ctx.xer);
	// bgt cr6,0x82dc2a94
	if (ctx.cr6.gt) goto loc_82DC2A94;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x82dc2a94
	if (ctx.cr6.lt) goto loc_82DC2A94;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x82dc2a94
	if (ctx.cr6.gt) goto loc_82DC2A94;
	// mulli r11,r4,720
	ctx.r11.s64 = ctx.r4.s64 * 720;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stfs f1,1032(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + 1032, temp.u32);
	// blr 
	return;
loc_82DC2A94:
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2A9C"))) PPC_WEAK_FUNC(sub_82DC2A9C);
PPC_FUNC_IMPL(__imp__sub_82DC2A9C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC2AA0"))) PPC_WEAK_FUNC(sub_82DC2AA0);
PPC_FUNC_IMPL(__imp__sub_82DC2AA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r10,r3,-24
	ctx.r10.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc2ab0
	if (!ctx.cr6.eq) goto loc_82DC2AB0;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82DC2AB0:
	// cmplwi cr6,r4,15
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 15, ctx.xer);
	// bgt cr6,0x82dc2ad8
	if (ctx.cr6.gt) goto loc_82DC2AD8;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82dc2ad8
	if (ctx.cr6.eq) goto loc_82DC2AD8;
	// mulli r11,r4,720
	ctx.r11.s64 = ctx.r4.s64 * 720;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f0,1032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1032);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
loc_82DC2AD8:
	// li r3,37
	ctx.r3.s64 = 37;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC2AE0"))) PPC_WEAK_FUNC(sub_82DC2AE0);
PPC_FUNC_IMPL(__imp__sub_82DC2AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d0
	ctx.lr = 0x82DC2AE8;
	__savegprlr_22(ctx, base);
	// stfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f30.u64);
	// stfd f31,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f31.u64);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// lbz r11,664(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 664);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bne cr6,0x82dc2b20
	if (!ctx.cr6.eq) goto loc_82DC2B20;
	// lwz r10,672(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 672);
	// lis r11,-32768
	ctx.r11.s64 = -2147483648;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dc2b20
	if (ctx.cr6.eq) goto loc_82DC2B20;
	// stw r11,672(r30)
	PPC_STORE_U32(ctx.r30.u32 + 672, ctx.r11.u32);
loc_82DC2B20:
	// rlwinm r11,r4,0,24,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xF0;
	// addi r11,r11,-128
	ctx.r11.s64 = ctx.r11.s64 + -128;
	// cmplwi cr6,r11,96
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 96, ctx.xer);
	// bgt cr6,0x82dc3564
	if (ctx.cr6.gt) goto loc_82DC3564;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,11080
	ctx.r12.s64 = ctx.r12.s64 + 11080;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC2CCC;
	case 1:
		goto loc_82DC3564;
	case 2:
		goto loc_82DC3564;
	case 3:
		goto loc_82DC3564;
	case 4:
		goto loc_82DC3564;
	case 5:
		goto loc_82DC3564;
	case 6:
		goto loc_82DC3564;
	case 7:
		goto loc_82DC3564;
	case 8:
		goto loc_82DC3564;
	case 9:
		goto loc_82DC3564;
	case 10:
		goto loc_82DC3564;
	case 11:
		goto loc_82DC3564;
	case 12:
		goto loc_82DC3564;
	case 13:
		goto loc_82DC3564;
	case 14:
		goto loc_82DC3564;
	case 15:
		goto loc_82DC3564;
	case 16:
		goto loc_82DC2DB4;
	case 17:
		goto loc_82DC3564;
	case 18:
		goto loc_82DC3564;
	case 19:
		goto loc_82DC3564;
	case 20:
		goto loc_82DC3564;
	case 21:
		goto loc_82DC3564;
	case 22:
		goto loc_82DC3564;
	case 23:
		goto loc_82DC3564;
	case 24:
		goto loc_82DC3564;
	case 25:
		goto loc_82DC3564;
	case 26:
		goto loc_82DC3564;
	case 27:
		goto loc_82DC3564;
	case 28:
		goto loc_82DC3564;
	case 29:
		goto loc_82DC3564;
	case 30:
		goto loc_82DC3564;
	case 31:
		goto loc_82DC3564;
	case 32:
		goto loc_82DC31C8;
	case 33:
		goto loc_82DC3564;
	case 34:
		goto loc_82DC3564;
	case 35:
		goto loc_82DC3564;
	case 36:
		goto loc_82DC3564;
	case 37:
		goto loc_82DC3564;
	case 38:
		goto loc_82DC3564;
	case 39:
		goto loc_82DC3564;
	case 40:
		goto loc_82DC3564;
	case 41:
		goto loc_82DC3564;
	case 42:
		goto loc_82DC3564;
	case 43:
		goto loc_82DC3564;
	case 44:
		goto loc_82DC3564;
	case 45:
		goto loc_82DC3564;
	case 46:
		goto loc_82DC3564;
	case 47:
		goto loc_82DC3564;
	case 48:
		goto loc_82DC3248;
	case 49:
		goto loc_82DC3564;
	case 50:
		goto loc_82DC3564;
	case 51:
		goto loc_82DC3564;
	case 52:
		goto loc_82DC3564;
	case 53:
		goto loc_82DC3564;
	case 54:
		goto loc_82DC3564;
	case 55:
		goto loc_82DC3564;
	case 56:
		goto loc_82DC3564;
	case 57:
		goto loc_82DC3564;
	case 58:
		goto loc_82DC3564;
	case 59:
		goto loc_82DC3564;
	case 60:
		goto loc_82DC3564;
	case 61:
		goto loc_82DC3564;
	case 62:
		goto loc_82DC3564;
	case 63:
		goto loc_82DC3564;
	case 64:
		goto loc_82DC36D8;
	case 65:
		goto loc_82DC3564;
	case 66:
		goto loc_82DC3564;
	case 67:
		goto loc_82DC3564;
	case 68:
		goto loc_82DC3564;
	case 69:
		goto loc_82DC3564;
	case 70:
		goto loc_82DC3564;
	case 71:
		goto loc_82DC3564;
	case 72:
		goto loc_82DC3564;
	case 73:
		goto loc_82DC3564;
	case 74:
		goto loc_82DC3564;
	case 75:
		goto loc_82DC3564;
	case 76:
		goto loc_82DC3564;
	case 77:
		goto loc_82DC3564;
	case 78:
		goto loc_82DC3564;
	case 79:
		goto loc_82DC3564;
	case 80:
		goto loc_82DC37A4;
	case 81:
		goto loc_82DC3564;
	case 82:
		goto loc_82DC3564;
	case 83:
		goto loc_82DC3564;
	case 84:
		goto loc_82DC3564;
	case 85:
		goto loc_82DC3564;
	case 86:
		goto loc_82DC3564;
	case 87:
		goto loc_82DC3564;
	case 88:
		goto loc_82DC3564;
	case 89:
		goto loc_82DC3564;
	case 90:
		goto loc_82DC3564;
	case 91:
		goto loc_82DC3564;
	case 92:
		goto loc_82DC3564;
	case 93:
		goto loc_82DC3564;
	case 94:
		goto loc_82DC3564;
	case 95:
		goto loc_82DC3564;
	case 96:
		goto loc_82DC3808;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11468(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 11468);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,11700(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 11700);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,12744(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12744);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,12872(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12872);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,14040(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 14040);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,14244(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 14244);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,14344(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 14344);
loc_82DC2CCC:
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc2d18
	if (!ctx.cr6.eq) goto loc_82DC2D18;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82dc2d08
	if (ctx.cr6.lt) goto loc_82DC2D08;
loc_82DC2CEC:
	// li r10,1
	ctx.r10.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r10,28(r11)
	PPC_STORE_U8(ctx.r11.u32 + 28, ctx.r10.u8);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC2D08:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// lbzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
loc_82DC2D18:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// clrlwi r7,r31,24
	ctx.r7.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// lbzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r10.u32);
	// stb r10,665(r30)
	PPC_STORE_U8(ctx.r30.u32 + 665, ctx.r10.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r10,r30,16
	ctx.r10.s64 = ctx.r30.s64 + 16;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82dc3564
	if (ctx.cr6.eq) goto loc_82DC3564;
	// clrlwi r9,r9,24
	ctx.r9.u64 = ctx.r9.u32 & 0xFF;
loc_82DC2D64:
	// lwz r8,584(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 584);
	// cmpw cr6,r9,r8
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, ctx.xer);
	// beq cr6,0x82dc2d90
	if (ctx.cr6.eq) goto loc_82DC2D90;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82dc2d64
	if (!ctx.cr6.eq) goto loc_82DC2D64;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC2D90:
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,-1
	ctx.r9.s64 = -1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r10,624(r11)
	PPC_STORE_U8(ctx.r11.u32 + 624, ctx.r10.u8);
	// stw r9,584(r11)
	PPC_STORE_U32(ctx.r11.u32 + 584, ctx.r9.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC2DB4:
	// li r22,0
	ctx.r22.s64 = 0;
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r22,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r22.u32);
	// stw r22,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r22.u32);
	// stw r22,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r22.u32);
	// stw r22,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r22.u32);
	// stb r22,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, ctx.r22.u8);
	// stw r22,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r22.u32);
	// stw r22,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r22.u32);
	// stw r22,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r22.u32);
	// stw r22,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r22.u32);
	// beq cr6,0x82dc2df4
	if (ctx.cr6.eq) goto loc_82DC2DF4;
	// mr r23,r9
	ctx.r23.u64 = ctx.r9.u64;
	// b 0x82dc2e18
	goto loc_82DC2E18;
loc_82DC2DF4:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// lbzx r23,r9,r10
	ctx.r23.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
loc_82DC2E18:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r7,r1,152
	ctx.r7.s64 = ctx.r1.s64 + 152;
	// addi r6,r1,148
	ctx.r6.s64 = ctx.r1.s64 + 148;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// clrlwi r24,r23,24
	ctx.r24.u64 = ctx.r23.u32 & 0xFF;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lbzx r4,r8,r9
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// addi r8,r1,140
	ctx.r8.s64 = ctx.r1.s64 + 140;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// addi r7,r1,136
	ctx.r7.s64 = ctx.r1.s64 + 136;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// stb r4,666(r30)
	PPC_STORE_U8(ctx.r30.u32 + 666, ctx.r4.u8);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// stw r4,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r4.u32);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// bl 0x82dc20f8
	ctx.lr = 0x82DC2E84;
	sub_82DC20F8(ctx, base);
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc3564
	if (ctx.cr6.eq) goto loc_82DC3564;
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r26,r30,16
	ctx.r26.s64 = ctx.r30.s64 + 16;
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82dc2ee4
	if (ctx.cr6.eq) goto loc_82DC2EE4;
loc_82DC2EB4:
	// lwz r10,584(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 584);
	// cmpw cr6,r24,r10
	ctx.cr6.compare<int32_t>(ctx.r24.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82dc2ed0
	if (ctx.cr6.eq) goto loc_82DC2ED0;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82dc2eb4
	if (!ctx.cr6.eq) goto loc_82DC2EB4;
	// b 0x82dc2ee4
	goto loc_82DC2EE4;
loc_82DC2ED0:
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// li r29,1
	ctx.r29.s64 = 1;
	// stw r10,584(r11)
	PPC_STORE_U32(ctx.r11.u32 + 584, ctx.r10.u32);
	// stb r9,624(r11)
	PPC_STORE_U8(ctx.r11.u32 + 624, ctx.r9.u8);
loc_82DC2EE4:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc2efc
	if (ctx.cr6.eq) goto loc_82DC2EFC;
	// lbz r11,666(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 666);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc3564
	if (ctx.cr6.eq) goto loc_82DC3564;
loc_82DC2EFC:
	// lbz r11,666(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 666);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc3564
	if (ctx.cr6.eq) goto loc_82DC3564;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// lwz r25,120(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmplw cr6,r3,r26
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82dc2f40
	if (ctx.cr6.eq) goto loc_82DC2F40;
loc_82DC2F18:
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r25,0
	ctx.cr6.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq cr6,0x82dc2f34
	if (ctx.cr6.eq) goto loc_82DC2F34;
	// lwz r11,632(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// cmpw cr6,r25,r11
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82dc2f34
	if (!ctx.cr6.eq) goto loc_82DC2F34;
	// bl 0x82dc1878
	ctx.lr = 0x82DC2F34;
	sub_82DC1878(ctx, base);
loc_82DC2F34:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82dc2f18
	if (!ctx.cr6.eq) goto loc_82DC2F18;
loc_82DC2F40:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,11944
	ctx.r11.s64 = ctx.r11.s64 + 11944;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82dc2f68
	if (!ctx.cr6.eq) goto loc_82DC2F68;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x82dc2f6c
	if (ctx.cr6.eq) goto loc_82DC2F6C;
loc_82DC2F68:
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
loc_82DC2F6C:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc3024
	if (ctx.cr6.eq) goto loc_82DC3024;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// mr r28,r22
	ctx.r28.u64 = ctx.r22.u64;
	// mr r27,r22
	ctx.r27.u64 = ctx.r22.u64;
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// lfs f31,-16776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16776);
	ctx.f31.f64 = double(temp.f32);
	// fmr f30,f31
	ctx.f30.f64 = ctx.f31.f64;
loc_82DC2F90:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// addi r11,r11,360
	ctx.r11.s64 = ctx.r11.s64 + 360;
	// lwz r31,0(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dc3004
	if (ctx.cr6.eq) goto loc_82DC3004;
loc_82DC2FAC:
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// addi r3,r31,16
	ctx.r3.s64 = ctx.r31.s64 + 16;
	// bl 0x82d994d0
	ctx.lr = 0x82DC2FB8;
	sub_82D994D0(ctx, base);
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// lfs f0,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82dc2fd8
	if (!ctx.cr6.eq) goto loc_82DC2FD8;
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// bge cr6,0x82dc2fd8
	if (!ctx.cr6.lt) goto loc_82DC2FD8;
	// fmr f30,f0
	ctx.f30.f64 = ctx.f0.f64;
	// mr r28,r31
	ctx.r28.u64 = ctx.r31.u64;
loc_82DC2FD8:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bge cr6,0x82dc2fe8
	if (!ctx.cr6.lt) goto loc_82DC2FE8;
	// fmr f31,f0
	ctx.f31.f64 = ctx.f0.f64;
	// mr r27,r31
	ctx.r27.u64 = ctx.r31.u64;
loc_82DC2FE8:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// addi r11,r11,360
	ctx.r11.s64 = ctx.r11.s64 + 360;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82dc2fac
	if (!ctx.cr6.eq) goto loc_82DC2FAC;
loc_82DC3004:
	// addi r29,r29,720
	ctx.r29.s64 = ctx.r29.s64 + 720;
	// cmpwi cr6,r29,11520
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 11520, ctx.xer);
	// blt cr6,0x82dc2f90
	if (ctx.cr6.lt) goto loc_82DC2F90;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bne cr6,0x82dc3020
	if (!ctx.cr6.eq) goto loc_82DC3020;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_82DC3020:
	// bl 0x82dc1878
	ctx.lr = 0x82DC3024;
	sub_82DC1878(ctx, base);
loc_82DC3024:
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// extsw r9,r11
	ctx.r9.s64 = ctx.r11.s32;
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// std r9,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r9.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// lfd f1,-16744(r11)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -16744);
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r31,11944(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11944);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// stw r7,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r7,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r7.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r22,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r22.u32);
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// lfs f0,9020(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9020);
	ctx.f0.f64 = double(temp.f32);
	// stw r26,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r26.u32);
	// rotlwi r11,r7,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r7.u32, 0);
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r31.u32);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// stw r24,584(r31)
	PPC_STORE_U32(ctx.r31.u32 + 584, ctx.r24.u32);
	// stw r30,640(r31)
	PPC_STORE_U32(ctx.r31.u32 + 640, ctx.r30.u32);
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stb r23,592(r31)
	PPC_STORE_U8(ctx.r31.u32 + 592, ctx.r23.u8);
	// stb r10,593(r31)
	PPC_STORE_U8(ctx.r31.u32 + 593, ctx.r10.u8);
	// stw r9,596(r31)
	PPC_STORE_U32(ctx.r31.u32 + 596, ctx.r9.u32);
	// stw r11,588(r31)
	PPC_STORE_U32(ctx.r31.u32 + 588, ctx.r11.u32);
	// lbz r11,666(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 666);
	// stw r8,456(r31)
	PPC_STORE_U32(ctx.r31.u32 + 456, ctx.r8.u32);
	// stw r25,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r25.u32);
	// stb r11,600(r31)
	PPC_STORE_U8(ctx.r31.u32 + 600, ctx.r11.u8);
	// bl 0x82cb59b0
	ctx.lr = 0x82DC30D8;
	sub_82CB59B0(ctx, base);
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,636(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 636, temp.u32);
	// stw r11,604(r31)
	PPC_STORE_U32(ctx.r31.u32 + 604, ctx.r11.u32);
	// stw r10,608(r31)
	PPC_STORE_U32(ctx.r31.u32 + 608, ctx.r10.u32);
	// bl 0x82dc1290
	ctx.lr = 0x82DC30F8;
	sub_82DC1290(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc3568
	if (!ctx.cr6.eq) goto loc_82DC3568;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r1,156
	ctx.r4.s64 = ctx.r1.s64 + 156;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,236(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	// bl 0x82da9590
	ctx.lr = 0x82DC3124;
	sub_82DA9590(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc31a8
	if (!ctx.cr6.eq) goto loc_82DC31A8;
	// lwz r11,156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r30,r31,16
	ctx.r30.s64 = ctx.r31.s64 + 16;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// bl 0x82d9d898
	ctx.lr = 0x82DC3150;
	sub_82D9D898(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc3568
	if (!ctx.cr6.eq) goto loc_82DC3568;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc1ce8
	ctx.lr = 0x82DC3160;
	sub_82DC1CE8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc3568
	if (!ctx.cr6.eq) goto loc_82DC3568;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc1930
	ctx.lr = 0x82DC3170;
	sub_82DC1930(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc3568
	if (!ctx.cr6.eq) goto loc_82DC3568;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2098
	ctx.lr = 0x82DC3180;
	sub_82DC2098(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc3568
	if (!ctx.cr6.eq) goto loc_82DC3568;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d99238
	ctx.lr = 0x82DC3194;
	sub_82D99238(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC31A8:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r11,8988
	ctx.r3.s64 = ctx.r11.s64 + 8988;
	// bl 0x82ccb660
	ctx.lr = 0x82DC31B4;
	sub_82CCB660(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC31C8:
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc31dc
	if (ctx.cr6.eq) goto loc_82DC31DC;
	// stb r9,667(r30)
	PPC_STORE_U8(ctx.r30.u32 + 667, ctx.r9.u8);
	// b 0x82dc3208
	goto loc_82DC3208;
loc_82DC31DC:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stb r10,667(r30)
	PPC_STORE_U8(ctx.r30.u32 + 667, ctx.r10.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82DC3208:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stb r10,668(r30)
	PPC_STORE_U8(ctx.r30.u32 + 668, ctx.r10.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC3248:
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc3278
	if (!ctx.cr6.eq) goto loc_82DC3278;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// lbzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
loc_82DC3278:
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82dc32a8
	if (ctx.cr6.lt) goto loc_82DC32A8;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r11,28(r10)
	PPC_STORE_U8(ctx.r10.u32 + 28, ctx.r11.u8);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC32A8:
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// clrlwi r9,r9,24
	ctx.r9.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r9,127
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 127, ctx.xer);
	// lbzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r11.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// bgt cr6,0x82dc3564
	if (ctx.cr6.gt) goto loc_82DC3564;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,13020
	ctx.r12.s64 = ctx.r12.s64 + 13020;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82DC34DC;
	case 1:
		goto loc_82DC3578;
	case 2:
		goto loc_82DC3564;
	case 3:
		goto loc_82DC3564;
	case 4:
		goto loc_82DC3564;
	case 5:
		goto loc_82DC3564;
	case 6:
		goto loc_82DC359C;
	case 7:
		goto loc_82DC35C4;
	case 8:
		goto loc_82DC3564;
	case 9:
		goto loc_82DC3564;
	case 10:
		goto loc_82DC35E0;
	case 11:
		goto loc_82DC35FC;
	case 12:
		goto loc_82DC3564;
	case 13:
		goto loc_82DC3564;
	case 14:
		goto loc_82DC3564;
	case 15:
		goto loc_82DC3564;
	case 16:
		goto loc_82DC3564;
	case 17:
		goto loc_82DC3564;
	case 18:
		goto loc_82DC3564;
	case 19:
		goto loc_82DC3564;
	case 20:
		goto loc_82DC3564;
	case 21:
		goto loc_82DC3564;
	case 22:
		goto loc_82DC3564;
	case 23:
		goto loc_82DC3564;
	case 24:
		goto loc_82DC3564;
	case 25:
		goto loc_82DC3564;
	case 26:
		goto loc_82DC3564;
	case 27:
		goto loc_82DC3564;
	case 28:
		goto loc_82DC3564;
	case 29:
		goto loc_82DC3564;
	case 30:
		goto loc_82DC3564;
	case 31:
		goto loc_82DC3564;
	case 32:
		goto loc_82DC3618;
	case 33:
		goto loc_82DC3564;
	case 34:
		goto loc_82DC3564;
	case 35:
		goto loc_82DC3564;
	case 36:
		goto loc_82DC3564;
	case 37:
		goto loc_82DC3564;
	case 38:
		goto loc_82DC3628;
	case 39:
		goto loc_82DC3564;
	case 40:
		goto loc_82DC3564;
	case 41:
		goto loc_82DC3564;
	case 42:
		goto loc_82DC3564;
	case 43:
		goto loc_82DC3564;
	case 44:
		goto loc_82DC3564;
	case 45:
		goto loc_82DC3564;
	case 46:
		goto loc_82DC3564;
	case 47:
		goto loc_82DC3564;
	case 48:
		goto loc_82DC3564;
	case 49:
		goto loc_82DC3564;
	case 50:
		goto loc_82DC3564;
	case 51:
		goto loc_82DC3564;
	case 52:
		goto loc_82DC3564;
	case 53:
		goto loc_82DC3564;
	case 54:
		goto loc_82DC3564;
	case 55:
		goto loc_82DC3564;
	case 56:
		goto loc_82DC3564;
	case 57:
		goto loc_82DC3564;
	case 58:
		goto loc_82DC3564;
	case 59:
		goto loc_82DC3564;
	case 60:
		goto loc_82DC3564;
	case 61:
		goto loc_82DC3564;
	case 62:
		goto loc_82DC3564;
	case 63:
		goto loc_82DC3564;
	case 64:
		goto loc_82DC3658;
	case 65:
		goto loc_82DC3564;
	case 66:
		goto loc_82DC3564;
	case 67:
		goto loc_82DC3564;
	case 68:
		goto loc_82DC3564;
	case 69:
		goto loc_82DC3564;
	case 70:
		goto loc_82DC3564;
	case 71:
		goto loc_82DC3564;
	case 72:
		goto loc_82DC3564;
	case 73:
		goto loc_82DC3564;
	case 74:
		goto loc_82DC3564;
	case 75:
		goto loc_82DC3564;
	case 76:
		goto loc_82DC3564;
	case 77:
		goto loc_82DC3564;
	case 78:
		goto loc_82DC3564;
	case 79:
		goto loc_82DC3564;
	case 80:
		goto loc_82DC3564;
	case 81:
		goto loc_82DC3564;
	case 82:
		goto loc_82DC3564;
	case 83:
		goto loc_82DC3564;
	case 84:
		goto loc_82DC3564;
	case 85:
		goto loc_82DC3564;
	case 86:
		goto loc_82DC3564;
	case 87:
		goto loc_82DC3564;
	case 88:
		goto loc_82DC3564;
	case 89:
		goto loc_82DC3564;
	case 90:
		goto loc_82DC3564;
	case 91:
		goto loc_82DC3564;
	case 92:
		goto loc_82DC3564;
	case 93:
		goto loc_82DC3564;
	case 94:
		goto loc_82DC3564;
	case 95:
		goto loc_82DC3564;
	case 96:
		goto loc_82DC3564;
	case 97:
		goto loc_82DC3564;
	case 98:
		goto loc_82DC3564;
	case 99:
		goto loc_82DC3564;
	case 100:
		goto loc_82DC3698;
	case 101:
		goto loc_82DC36BC;
	case 102:
		goto loc_82DC3564;
	case 103:
		goto loc_82DC3564;
	case 104:
		goto loc_82DC3564;
	case 105:
		goto loc_82DC3564;
	case 106:
		goto loc_82DC3564;
	case 107:
		goto loc_82DC3564;
	case 108:
		goto loc_82DC3564;
	case 109:
		goto loc_82DC3564;
	case 110:
		goto loc_82DC3564;
	case 111:
		goto loc_82DC3564;
	case 112:
		goto loc_82DC3564;
	case 113:
		goto loc_82DC3564;
	case 114:
		goto loc_82DC3564;
	case 115:
		goto loc_82DC3564;
	case 116:
		goto loc_82DC3564;
	case 117:
		goto loc_82DC3564;
	case 118:
		goto loc_82DC3564;
	case 119:
		goto loc_82DC3564;
	case 120:
		goto loc_82DC3564;
	case 121:
		goto loc_82DC3564;
	case 122:
		goto loc_82DC3564;
	case 123:
		goto loc_82DC3564;
	case 124:
		goto loc_82DC3564;
	case 125:
		goto loc_82DC3564;
	case 126:
		goto loc_82DC3564;
	case 127:
		goto loc_82DC3564;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13532(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13532);
	// lwz r22,13688(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13688);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13724);
	// lwz r22,13764(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13764);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13792(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13792);
	// lwz r22,13820(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13820);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13848(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13848);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13864(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13864);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13912(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13912);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13976(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13976);
	// lwz r22,14012(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 14012);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
	// lwz r22,13668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13668);
loc_82DC34DC:
	// lbz r10,664(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 664);
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// beq cr6,0x82dc34f0
	if (ctx.cr6.eq) goto loc_82DC34F0;
	// rlwinm r11,r11,8,16,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFF00;
loc_82DC34EC:
	// stw r11,672(r30)
	PPC_STORE_U32(ctx.r30.u32 + 672, ctx.r11.u32);
loc_82DC34F0:
	// lwz r8,672(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 672);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dc3564
	if (ctx.cr6.eq) goto loc_82DC3564;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r22,0
	ctx.r22.s64 = 0;
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,11932(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11932);
	// lwz r10,232(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82dc3554
	if (!ctx.cr6.gt) goto loc_82DC3554;
	// lwz r11,240(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	// addi r11,r11,264
	ctx.r11.s64 = ctx.r11.s64 + 264;
loc_82DC3524:
	// lwz r7,-4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// cmplw cr6,r7,r8
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82dc3544
	if (!ctx.cr6.eq) goto loc_82DC3544;
	// lbz r7,676(r30)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r30.u32 + 676);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r6,r7
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82dc3544
	if (!ctx.cr6.eq) goto loc_82DC3544;
	// li r9,1
	ctx.r9.s64 = 1;
loc_82DC3544:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 + 280;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc3524
	if (!ctx.cr6.eq) goto loc_82DC3524;
loc_82DC3554:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// stw r22,672(r30)
	PPC_STORE_U32(ctx.r30.u32 + 672, ctx.r22.u32);
loc_82DC3564:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC3568:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC3578:
	// lwz r10,704(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 704);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,704(r30)
	PPC_STORE_U32(ctx.r30.u32 + 704, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC359C:
	// lwz r10,680(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 680);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// rlwinm r11,r11,8,16,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFF00;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,696(r30)
	PPC_STORE_U32(ctx.r30.u32 + 696, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC35C4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,708(r30)
	PPC_STORE_U32(ctx.r30.u32 + 708, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC35E0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,712(r30)
	PPC_STORE_U32(ctx.r30.u32 + 712, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC35FC:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,716(r30)
	PPC_STORE_U32(ctx.r30.u32 + 716, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC3618:
	// lwz r10,672(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 672);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// b 0x82dc34ec
	goto loc_82DC34EC;
loc_82DC3628:
	// lwz r10,680(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 680);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// lwz r10,696(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 696);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,696(r30)
	PPC_STORE_U32(ctx.r30.u32 + 696, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC3658:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc367c
	if (!ctx.cr6.eq) goto loc_82DC367C;
	// stb r11,700(r30)
	PPC_STORE_U8(ctx.r30.u32 + 700, ctx.r11.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC367C:
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r11,700(r30)
	PPC_STORE_U8(ctx.r30.u32 + 700, ctx.r11.u8);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC3698:
	// lwz r10,680(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 680);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,680(r30)
	PPC_STORE_U32(ctx.r30.u32 + 680, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC36BC:
	// rlwinm r11,r11,8,16,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFF00;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,680(r30)
	PPC_STORE_U32(ctx.r30.u32 + 680, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC36D8:
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc36ec
	if (ctx.cr6.eq) goto loc_82DC36EC;
	// stb r9,676(r30)
	PPC_STORE_U8(ctx.r30.u32 + 676, ctx.r9.u8);
	// b 0x82dc3718
	goto loc_82DC3718;
loc_82DC36EC:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stb r10,676(r30)
	PPC_STORE_U8(ctx.r30.u32 + 676, ctx.r10.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82DC3718:
	// lbz r11,664(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 664);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r22,0
	ctx.r22.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,11932(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11932);
	// lwz r10,232(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82dc3780
	if (!ctx.cr6.gt) goto loc_82DC3780;
	// lwz r11,240(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	// lwz r9,672(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 672);
	// addi r11,r11,264
	ctx.r11.s64 = ctx.r11.s64 + 264;
loc_82DC3750:
	// lwz r7,-4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// cmplw cr6,r7,r9
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82dc3770
	if (!ctx.cr6.eq) goto loc_82DC3770;
	// lbz r7,676(r30)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r30.u32 + 676);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r6,r7
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82dc3770
	if (!ctx.cr6.eq) goto loc_82DC3770;
	// li r8,1
	ctx.r8.s64 = 1;
loc_82DC3770:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,280
	ctx.r11.s64 = ctx.r11.s64 + 280;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc3750
	if (!ctx.cr6.eq) goto loc_82DC3750;
loc_82DC3780:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc3564
	if (!ctx.cr6.eq) goto loc_82DC3564;
	// stb r22,676(r30)
	PPC_STORE_U8(ctx.r30.u32 + 676, ctx.r22.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC37A4:
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc37c8
	if (ctx.cr6.eq) goto loc_82DC37C8;
	// stb r9,684(r30)
	PPC_STORE_U8(ctx.r30.u32 + 684, ctx.r9.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC37C8:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stb r10,684(r30)
	PPC_STORE_U8(ctx.r30.u32 + 684, ctx.r10.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
loc_82DC3808:
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc3838
	if (!ctx.cr6.eq) goto loc_82DC3838;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// lbzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
loc_82DC3838:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bge cr6,0x82dc2cec
	if (!ctx.cr6.lt) goto loc_82DC2CEC;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// clrlwi r9,r9,24
	ctx.r9.u64 = ctx.r9.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// lbzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r10.u32);
	// stw r7,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r7.u32);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// rlwinm r11,r11,7,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 7) & 0xFFFFFF80;
	// or r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
	// stw r11,692(r30)
	PPC_STORE_U32(ctx.r30.u32 + 692, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82cb1120
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC3888"))) PPC_WEAK_FUNC(sub_82DC3888);
PPC_FUNC_IMPL(__imp__sub_82DC3888) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b4
	ctx.lr = 0x82DC3890;
	__savegprlr_15(ctx, base);
	// stfd f29,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, ctx.f29.u64);
	// stfd f30,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f30.u64);
	// stfd f31,-152(r1)
	PPC_STORE_U64(ctx.r1.u32 + -152, ctx.f31.u64);
	// stwu r1,-576(r1)
	ea = -576 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc41f8
	if (ctx.cr6.eq) goto loc_82DC41F8;
	// lbz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 28);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc41f8
	if (!ctx.cr6.eq) goto loc_82DC41F8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lfs f0,24(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,11920(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11920);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bgt cr6,0x82dc41f8
	if (ctx.cr6.gt) goto loc_82DC41F8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r8,-32222
	ctx.r8.s64 = -2111700992;
	// addi r26,r11,9124
	ctx.r26.s64 = ctx.r11.s64 + 9124;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r25,r11,9112
	ctx.r25.s64 = ctx.r11.s64 + 9112;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f29,-15884(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -15884);
	ctx.f29.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r24,r11,9100
	ctx.r24.s64 = ctx.r11.s64 + 9100;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f30,6140(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6140);
	ctx.f30.f64 = double(temp.f32);
	// li r16,0
	ctx.r16.s64 = 0;
	// addi r23,r11,9088
	ctx.r23.s64 = ctx.r11.s64 + 9088;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f31,6480(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6480);
	ctx.f31.f64 = double(temp.f32);
	// li r28,1
	ctx.r28.s64 = 1;
	// addi r22,r11,9080
	ctx.r22.s64 = ctx.r11.s64 + 9080;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r15,512
	ctx.r15.s64 = 512;
	// addi r21,r11,9072
	ctx.r21.s64 = ctx.r11.s64 + 9072;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r20,r11,9060
	ctx.r20.s64 = ctx.r11.s64 + 9060;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r19,r11,9044
	ctx.r19.s64 = ctx.r11.s64 + 9044;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r18,r11,9032
	ctx.r18.s64 = ctx.r11.s64 + 9032;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r17,r11,9024
	ctx.r17.s64 = ctx.r11.s64 + 9024;
loc_82DC3948:
	// lbz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc398c
	if (!ctx.cr6.eq) goto loc_82DC398C;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2418
	ctx.lr = 0x82DC3960;
	sub_82DC2418(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc41fc
	if (!ctx.cr6.eq) goto loc_82DC41FC;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lfs f0,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// stb r16,20(r31)
	PPC_STORE_U8(ctx.r31.u32 + 20, ctx.r16.u8);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,24(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
loc_82DC398C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lfs f0,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,11920(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 11920);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bgt cr6,0x82dc422c
	if (ctx.cr6.gt) goto loc_82DC422C;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stb r16,20(r31)
	PPC_STORE_U8(ctx.r31.u32 + 20, ctx.r16.u8);
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// bge cr6,0x82dc4210
	if (!ctx.cr6.lt) goto loc_82DC4210;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lbzx r29,r11,r9
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// blt cr6,0x82dc4190
	if (ctx.cr6.lt) goto loc_82DC4190;
	// cmpwi cr6,r11,240
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 240, ctx.xer);
	// beq cr6,0x82dc4168
	if (ctx.cr6.eq) goto loc_82DC4168;
	// cmpwi cr6,r11,247
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 247, ctx.xer);
	// beq cr6,0x82dc4158
	if (ctx.cr6.eq) goto loc_82DC4158;
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// bne cr6,0x82dc41d4
	if (!ctx.cr6.eq) goto loc_82DC41D4;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82dc39f8
	if (ctx.cr6.lt) goto loc_82DC39F8;
loc_82DC39F0:
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC39F8:
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lbzx r30,r10,r9
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82dc2418
	ctx.lr = 0x82DC3A10;
	sub_82DC2418(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc41d4
	if (!ctx.cr6.eq) goto loc_82DC41D4;
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,127
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 127, ctx.xer);
	// bgt cr6,0x82dc4144
	if (ctx.cr6.gt) goto loc_82DC4144;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,14908
	ctx.r12.s64 = ctx.r12.s64 + 14908;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC3C3C;
	case 1:
		goto loc_82DC3CAC;
	case 2:
		goto loc_82DC3CC4;
	case 3:
		goto loc_82DC3CDC;
	case 4:
		goto loc_82DC3D04;
	case 5:
		goto loc_82DC3D1C;
	case 6:
		goto loc_82DC3D34;
	case 7:
		goto loc_82DC3D4C;
	case 8:
		goto loc_82DC3D64;
	case 9:
		goto loc_82DC3D7C;
	case 10:
		goto loc_82DC4144;
	case 11:
		goto loc_82DC4144;
	case 12:
		goto loc_82DC4144;
	case 13:
		goto loc_82DC4144;
	case 14:
		goto loc_82DC4144;
	case 15:
		goto loc_82DC4144;
	case 16:
		goto loc_82DC4144;
	case 17:
		goto loc_82DC4144;
	case 18:
		goto loc_82DC4144;
	case 19:
		goto loc_82DC4144;
	case 20:
		goto loc_82DC4144;
	case 21:
		goto loc_82DC4144;
	case 22:
		goto loc_82DC4144;
	case 23:
		goto loc_82DC4144;
	case 24:
		goto loc_82DC4144;
	case 25:
		goto loc_82DC4144;
	case 26:
		goto loc_82DC4144;
	case 27:
		goto loc_82DC4144;
	case 28:
		goto loc_82DC4144;
	case 29:
		goto loc_82DC4144;
	case 30:
		goto loc_82DC4144;
	case 31:
		goto loc_82DC4144;
	case 32:
		goto loc_82DC3D94;
	case 33:
		goto loc_82DC3DAC;
	case 34:
		goto loc_82DC4144;
	case 35:
		goto loc_82DC4144;
	case 36:
		goto loc_82DC4144;
	case 37:
		goto loc_82DC4144;
	case 38:
		goto loc_82DC4144;
	case 39:
		goto loc_82DC4144;
	case 40:
		goto loc_82DC4144;
	case 41:
		goto loc_82DC4144;
	case 42:
		goto loc_82DC4144;
	case 43:
		goto loc_82DC4144;
	case 44:
		goto loc_82DC4144;
	case 45:
		goto loc_82DC4144;
	case 46:
		goto loc_82DC4144;
	case 47:
		goto loc_82DC39F0;
	case 48:
		goto loc_82DC4144;
	case 49:
		goto loc_82DC4144;
	case 50:
		goto loc_82DC4144;
	case 51:
		goto loc_82DC4144;
	case 52:
		goto loc_82DC4144;
	case 53:
		goto loc_82DC4144;
	case 54:
		goto loc_82DC4144;
	case 55:
		goto loc_82DC4144;
	case 56:
		goto loc_82DC4144;
	case 57:
		goto loc_82DC4144;
	case 58:
		goto loc_82DC4144;
	case 59:
		goto loc_82DC4144;
	case 60:
		goto loc_82DC4144;
	case 61:
		goto loc_82DC4144;
	case 62:
		goto loc_82DC4144;
	case 63:
		goto loc_82DC4144;
	case 64:
		goto loc_82DC4144;
	case 65:
		goto loc_82DC4144;
	case 66:
		goto loc_82DC4144;
	case 67:
		goto loc_82DC4144;
	case 68:
		goto loc_82DC4144;
	case 69:
		goto loc_82DC4144;
	case 70:
		goto loc_82DC4144;
	case 71:
		goto loc_82DC4144;
	case 72:
		goto loc_82DC4144;
	case 73:
		goto loc_82DC4144;
	case 74:
		goto loc_82DC4144;
	case 75:
		goto loc_82DC4144;
	case 76:
		goto loc_82DC4144;
	case 77:
		goto loc_82DC4144;
	case 78:
		goto loc_82DC4144;
	case 79:
		goto loc_82DC4144;
	case 80:
		goto loc_82DC4144;
	case 81:
		goto loc_82DC3DDC;
	case 82:
		goto loc_82DC4144;
	case 83:
		goto loc_82DC4144;
	case 84:
		goto loc_82DC3F04;
	case 85:
		goto loc_82DC4144;
	case 86:
		goto loc_82DC4144;
	case 87:
		goto loc_82DC4144;
	case 88:
		goto loc_82DC3FFC;
	case 89:
		goto loc_82DC40C4;
	case 90:
		goto loc_82DC4144;
	case 91:
		goto loc_82DC4144;
	case 92:
		goto loc_82DC4144;
	case 93:
		goto loc_82DC4144;
	case 94:
		goto loc_82DC4144;
	case 95:
		goto loc_82DC4144;
	case 96:
		goto loc_82DC4144;
	case 97:
		goto loc_82DC4144;
	case 98:
		goto loc_82DC4144;
	case 99:
		goto loc_82DC4144;
	case 100:
		goto loc_82DC4144;
	case 101:
		goto loc_82DC4144;
	case 102:
		goto loc_82DC4144;
	case 103:
		goto loc_82DC4144;
	case 104:
		goto loc_82DC4144;
	case 105:
		goto loc_82DC4144;
	case 106:
		goto loc_82DC4144;
	case 107:
		goto loc_82DC4144;
	case 108:
		goto loc_82DC4144;
	case 109:
		goto loc_82DC4144;
	case 110:
		goto loc_82DC4144;
	case 111:
		goto loc_82DC4144;
	case 112:
		goto loc_82DC4144;
	case 113:
		goto loc_82DC4144;
	case 114:
		goto loc_82DC4144;
	case 115:
		goto loc_82DC4144;
	case 116:
		goto loc_82DC4144;
	case 117:
		goto loc_82DC4144;
	case 118:
		goto loc_82DC4144;
	case 119:
		goto loc_82DC4144;
	case 120:
		goto loc_82DC4144;
	case 121:
		goto loc_82DC4144;
	case 122:
		goto loc_82DC4144;
	case 123:
		goto loc_82DC4144;
	case 124:
		goto loc_82DC4144;
	case 125:
		goto loc_82DC4144;
	case 126:
		goto loc_82DC4144;
	case 127:
		goto loc_82DC412C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,15420(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15420);
	// lwz r22,15532(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15532);
	// lwz r22,15556(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15556);
	// lwz r22,15580(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15580);
	// lwz r22,15620(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15620);
	// lwz r22,15644(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15644);
	// lwz r22,15668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15668);
	// lwz r22,15692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15692);
	// lwz r22,15716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15716);
	// lwz r22,15740(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15740);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,15764(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15764);
	// lwz r22,15788(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15788);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,14832(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 14832);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,15836(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 15836);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16132(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16132);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16380(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16380);
	// lwz r22,16580(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16580);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16708);
	// lwz r22,16684(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16684);
loc_82DC3C3C:
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82dc3c58
	if (!ctx.cr6.eq) goto loc_82DC3C58;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// stw r10,11868(r11)
	PPC_STORE_U32(ctx.r11.u32 + 11868, ctx.r10.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3C58:
	// cmplwi cr6,r5,4
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 4, ctx.xer);
	// ble cr6,0x82dc3c98
	if (!ctx.cr6.gt) goto loc_82DC3C98;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc3c7c
	if (ctx.cr6.lt) goto loc_82DC3C7C;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3C7C:
	// add r8,r11,r5
	ctx.r8.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82dc3c8c
	if (!ctx.cr6.gt) goto loc_82DC3C8C;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82DC3C8C:
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3C98:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,11868
	ctx.r4.s64 = ctx.r11.s64 + 11868;
	// bl 0x82dc24e0
	ctx.lr = 0x82DC3CA8;
	sub_82DC24E0(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3CAC:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3CC0;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3CC4:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3CD8;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3CDC:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// bl 0x82cb61f0
	ctx.lr = 0x82DC3CEC;
	sub_82CB61F0(ctx, base);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D00;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D04:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D18;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D1C:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D30;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D34:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D48;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D4C:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D60;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D64:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D78;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D7C:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC3D90;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3D94:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc3ff0
	if (ctx.cr6.lt) goto loc_82DC3FF0;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3DAC:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc3dc4
	if (ctx.cr6.lt) goto loc_82DC3DC4;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3DC4:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stw r9,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r9.u32);
	// stb r11,29(r31)
	PPC_STORE_U8(ctx.r31.u32 + 29, ctx.r11.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3DDC:
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc24e0
	ctx.lr = 0x82DC3DEC;
	sub_82DC24E0(ctx, base);
	// lbz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rotlwi r10,r10,16
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 16);
	// lbz r9,85(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 85);
	// lbz r8,86(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 86);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// stw r10,11916(r11)
	PPC_STORE_U32(ctx.r11.u32 + 11916, ctx.r10.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,11916(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11916);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,11916(r11)
	PPC_STORE_U32(ctx.r11.u32 + 11916, ctx.r10.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,11916(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11916);
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// stw r10,11916(r11)
	PPC_STORE_U32(ctx.r11.u32 + 11916, ctx.r10.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r9,11896(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11896);
	// lwz r10,11916(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11916);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// std r10,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r10.u64);
	// std r9,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r9.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f0,11924(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 11924, temp.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// lfs f0,11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11924);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r11,11876
	ctx.r11.s64 = ctx.r11.s64 + 11876;
	// lwz r10,264(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stfs f30,11880(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 11880, temp.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,11876(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 11876);
	// cmplwi cr6,r10,512
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 512, ctx.xer);
	// bge cr6,0x82dc41d4
	if (!ctx.cr6.lt) goto loc_82DC41D4;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// lfs f0,11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11924);
	ctx.f0.f64 = double(temp.f32);
	// lwz r10,264(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// lfd f13,128(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fdivs f0,f29,f0
	ctx.f0.f64 = double(float(ctx.f29.f64 / ctx.f0.f64));
	// stfs f0,11880(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 11880, temp.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r15,11876(r11)
	PPC_STORE_U32(ctx.r11.u32 + 11876, ctx.r15.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lfs f0,11880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11880);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11924);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,11924(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 11924, temp.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3F04:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc3f1c
	if (ctx.cr6.lt) goto loc_82DC3F1C;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3F1C:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11900(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11900, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc3f4c
	if (ctx.cr6.lt) goto loc_82DC3F4C;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3F4C:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11901(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11901, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc3f7c
	if (ctx.cr6.lt) goto loc_82DC3F7C;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3F7C:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11902(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11902, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc3fac
	if (ctx.cr6.lt) goto loc_82DC3FAC;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3FAC:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11903(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11903, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc3fdc
	if (ctx.cr6.lt) goto loc_82DC3FDC;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3FDC:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11904(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11904, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
loc_82DC3FF0:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC3FFC:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc4014
	if (ctx.cr6.lt) goto loc_82DC4014;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4014:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11905(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11905, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc4044
	if (ctx.cr6.lt) goto loc_82DC4044;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4044:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11906(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11906, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc4074
	if (ctx.cr6.lt) goto loc_82DC4074;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4074:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11907(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11907, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc40a4
	if (ctx.cr6.lt) goto loc_82DC40A4;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC40A4:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11908(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11908, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC40C4:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc40dc
	if (ctx.cr6.lt) goto loc_82DC40DC;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC40DC:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11909(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11909, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// blt cr6,0x82dc410c
	if (ctx.cr6.lt) goto loc_82DC410C;
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC410C:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// stb r11,11910(r9)
	PPC_STORE_U8(ctx.r9.u32 + 11910, ctx.r11.u8);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC412C:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2570
	ctx.lr = 0x82DC4140;
	sub_82DC2570(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4144:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4158:
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2418
	ctx.lr = 0x82DC4164;
	sub_82DC2418(ctx, base);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4168:
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2418
	ctx.lr = 0x82DC4174;
	sub_82DC2418(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc41d4
	if (!ctx.cr6.eq) goto loc_82DC41D4;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82dc41d4
	goto loc_82DC41D4;
loc_82DC4190:
	// mr r6,r16
	ctx.r6.u64 = ctx.r16.u64;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// cmplwi cr6,r11,128
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 128, ctx.xer);
	// bge cr6,0x82dc41ac
	if (!ctx.cr6.lt) goto loc_82DC41AC;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lbz r29,30(r31)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r31.u32 + 30);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
loc_82DC41AC:
	// clrlwi r11,r29,28
	ctx.r11.u64 = ctx.r29.u32 & 0xF;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mulli r11,r11,720
	ctx.r11.s64 = ctx.r11.s64 * 720;
	// add r10,r11,r3
	ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r31,356(r10)
	PPC_STORE_U32(ctx.r10.u32 + 356, ctx.r31.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r3,r11,344
	ctx.r3.s64 = ctx.r11.s64 + 344;
	// bl 0x82dc2ae0
	ctx.lr = 0x82DC41D4;
	sub_82DC2AE0(ctx, base);
loc_82DC41D4:
	// lbz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 28);
	// stb r29,30(r31)
	PPC_STORE_U8(ctx.r31.u32 + 30, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc41f8
	if (!ctx.cr6.eq) goto loc_82DC41F8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lfs f0,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,11920(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11920);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// ble cr6,0x82dc3948
	if (!ctx.cr6.gt) goto loc_82DC3948;
loc_82DC41F8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC41FC:
	// addi r1,r1,576
	ctx.r1.s64 = ctx.r1.s64 + 576;
	// lfd f29,-168(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f30,-160(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// lfd f31,-152(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// b 0x82cb1104
	__restgprlr_15(ctx, base);
	return;
loc_82DC4210:
	// stb r28,28(r31)
	PPC_STORE_U8(ctx.r31.u32 + 28, ctx.r28.u8);
	// li r3,22
	ctx.r3.s64 = 22;
	// addi r1,r1,576
	ctx.r1.s64 = ctx.r1.s64 + 576;
	// lfd f29,-168(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f30,-160(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// lfd f31,-152(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// b 0x82cb1104
	__restgprlr_15(ctx, base);
	return;
loc_82DC422C:
	// stb r28,20(r31)
	PPC_STORE_U8(ctx.r31.u32 + 20, ctx.r28.u8);
	// b 0x82dc41f8
	goto loc_82DC41F8;
}

__attribute__((alias("__imp__sub_82DC4234"))) PPC_WEAK_FUNC(sub_82DC4234);
PPC_FUNC_IMPL(__imp__sub_82DC4234) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC4238"))) PPC_WEAK_FUNC(sub_82DC4238);
PPC_FUNC_IMPL(__imp__sub_82DC4238) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DC4240;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc4280
	if (!ctx.cr6.gt) goto loc_82DC4280;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82DC425C:
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// li r4,0
	ctx.r4.s64 = 0;
	// add r3,r30,r11
	ctx.r3.u64 = ctx.r30.u64 + ctx.r11.u64;
	// bl 0x82dc3888
	ctx.lr = 0x82DC426C;
	sub_82DC3888(ctx, base);
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,32
	ctx.r30.s64 = ctx.r30.s64 + 32;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc425c
	if (ctx.cr6.lt) goto loc_82DC425C;
loc_82DC4280:
	// addi r29,r31,344
	ctx.r29.s64 = ctx.r31.s64 + 344;
	// li r30,16
	ctx.r30.s64 = 16;
loc_82DC4288:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dc2328
	ctx.lr = 0x82DC4290;
	sub_82DC2328(ctx, base);
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r29,r29,720
	ctx.r29.s64 = ctx.r29.s64 + 720;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dc4288
	if (!ctx.cr6.eq) goto loc_82DC4288;
	// lwz r10,11884(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11884);
	// lfs f0,11920(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 11920);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,11876(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11876);
	// lfs f13,11880(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 11880);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// li r3,0
	ctx.r3.s64 = 0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stfs f0,11920(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 11920, temp.u32);
	// stw r11,11884(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11884, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC42CC"))) PPC_WEAK_FUNC(sub_82DC42CC);
PPC_FUNC_IMPL(__imp__sub_82DC42CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC42D0"))) PPC_WEAK_FUNC(sub_82DC42D0);
PPC_FUNC_IMPL(__imp__sub_82DC42D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DC42D8;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// mr r22,r5
	ctx.r22.u64 = ctx.r5.u64;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// mr r20,r6
	ctx.r20.u64 = ctx.r6.u64;
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lwz r31,260(r10)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 260);
	// lwz r21,4408(r11)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4408);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// bl 0x82cb16f0
	ctx.lr = 0x82DC430C;
	sub_82CB16F0(ctx, base);
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// beq cr6,0x82dc444c
	if (ctx.cr6.eq) goto loc_82DC444C;
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dc444c
	if (ctx.cr6.gt) goto loc_82DC444C;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,17212
	ctx.r12.s64 = ctx.r12.s64 + 17212;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC43A8;
	case 1:
		goto loc_82DC4368;
	case 2:
		goto loc_82DC4370;
	case 3:
		goto loc_82DC4378;
	case 4:
		goto loc_82DC4380;
	case 5:
		goto loc_82DC4380;
	case 6:
		goto loc_82DC43A8;
	case 7:
		goto loc_82DC43A8;
	case 8:
		goto loc_82DC43A8;
	case 9:
		goto loc_82DC43A8;
	case 10:
		goto loc_82DC43A8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17320);
	// lwz r22,17256(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17256);
	// lwz r22,17264(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17264);
	// lwz r22,17272(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17272);
	// lwz r22,17280(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17280);
	// lwz r22,17280(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17280);
	// lwz r22,17320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17320);
	// lwz r22,17320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17320);
	// lwz r22,17320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17320);
	// lwz r22,17320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17320);
	// lwz r22,17320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17320);
loc_82DC4368:
	// li r11,8
	ctx.r11.s64 = 8;
	// b 0x82dc4384
	goto loc_82DC4384;
loc_82DC4370:
	// li r11,16
	ctx.r11.s64 = 16;
	// b 0x82dc4384
	goto loc_82DC4384;
loc_82DC4378:
	// li r11,24
	ctx.r11.s64 = 24;
	// b 0x82dc4384
	goto loc_82DC4384;
loc_82DC4380:
	// li r11,32
	ctx.r11.s64 = 32;
loc_82DC4384:
	// li r10,0
	ctx.r10.s64 = 0;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// rldimi r10,r22,3,29
	ctx.r10.u64 = (__builtin_rotateleft64(ctx.r22.u64, 3) & 0x7FFFFFFF8) | (ctx.r10.u64 & 0xFFFFFFF800000007);
	// tdllei r11,0
	// divdu r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 / ctx.r11.u64;
	// twllei r31,0
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// divwu r24,r11,r31
	ctx.r24.u32 = ctx.r11.u32 / ctx.r31.u32;
	// b 0x82dc4450
	goto loc_82DC4450;
loc_82DC43A8:
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,17344
	ctx.r12.s64 = ctx.r12.s64 + 17344;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,17468(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17468);
	// lwz r22,17484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17484);
	// lwz r22,17484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17484);
	// lwz r22,17484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17484);
	// lwz r22,17484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17484);
	// lwz r22,17484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17484);
	// lwz r22,17388(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17388);
	// lwz r22,17408(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17408);
	// lwz r22,17440(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17440);
	// lwz r22,17460(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17460);
	// lwz r22,17460(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17460);
	// mulli r11,r22,14
	ctx.r11.s64 = ctx.r22.s64 * 14;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// twllei r31,0
	// divwu r24,r11,r31
	ctx.r24.u32 = ctx.r11.u32 / ctx.r31.u32;
	// b 0x82dc4450
	goto loc_82DC4450;
	// lis r10,14563
	ctx.r10.s64 = 954400768;
	// rlwinm r11,r22,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 6) & 0xFFFFFFC0;
	// ori r10,r10,36409
	ctx.r10.u64 = ctx.r10.u64 | 36409;
	// twllei r31,0
	// mulhwu r11,r11,r10
	ctx.r11.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r10.u32)) >> 32;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// divwu r24,r11,r31
	ctx.r24.u32 = ctx.r11.u32 / ctx.r31.u32;
	// b 0x82dc4450
	goto loc_82DC4450;
	// mulli r11,r22,28
	ctx.r11.s64 = ctx.r22.s64 * 28;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// twllei r31,0
	// divwu r24,r11,r31
	ctx.r24.u32 = ctx.r11.u32 / ctx.r31.u32;
	// b 0x82dc4450
	goto loc_82DC4450;
	// mr r24,r22
	ctx.r24.u64 = ctx.r22.u64;
	// b 0x82dc4450
	goto loc_82DC4450;
	// li r11,0
	ctx.r11.s64 = 0;
	// twllei r31,0
	// divwu r24,r11,r31
	ctx.r24.u32 = ctx.r11.u32 / ctx.r31.u32;
	// b 0x82dc4450
	goto loc_82DC4450;
loc_82DC444C:
	// lwz r24,88(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DC4450:
	// lwz r26,11872(r28)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r28.u32 + 11872);
	// li r27,0
	ctx.r27.s64 = 0;
	// mr r25,r23
	ctx.r25.u64 = ctx.r23.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82dc46c0
	if (ctx.cr6.eq) goto loc_82DC46C0;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// lwz r29,88(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// ori r30,r11,18725
	ctx.r30.u64 = ctx.r11.u64 | 18725;
loc_82DC4470:
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// bne cr6,0x82dc449c
	if (!ctx.cr6.eq) goto loc_82DC449C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82dc4238
	ctx.lr = 0x82DC4488;
	sub_82DC4238(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc46d4
	if (!ctx.cr6.eq) goto loc_82DC46D4;
	// lwz r11,11876(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 11876);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// b 0x82dc44a0
	goto loc_82DC44A0;
loc_82DC449C:
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82DC44A0:
	// add r10,r11,r27
	ctx.r10.u64 = ctx.r11.u64 + ctx.r27.u64;
	// cmplw cr6,r10,r24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r24.u32, ctx.xer);
	// ble cr6,0x82dc44b0
	if (!ctx.cr6.gt) goto loc_82DC44B0;
	// subf r11,r27,r24
	ctx.r11.s64 = ctx.r24.s64 - ctx.r27.s64;
loc_82DC44B0:
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DC44C0;
	sub_82D8B3E0(ctx, base);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82da41c0
	ctx.lr = 0x82DC44C8;
	sub_82DA41C0(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dc4510
	if (ctx.cr6.eq) goto loc_82DC4510;
	// lwz r3,232(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 232);
	// li r9,2
	ctx.r9.s64 = 2;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC44FC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x82dc46dc
	if (!ctx.cr6.eq) goto loc_82DC46DC;
	// lwz r3,232(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 232);
	// bl 0x82d938a0
	ctx.lr = 0x82DC4510;
	sub_82D938A0(ctx, base);
loc_82DC4510:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DC4518;
	sub_82DA4200(ctx, base);
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dc4688
	if (ctx.cr6.gt) goto loc_82DC4688;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,17732
	ctx.r12.s64 = ctx.r12.s64 + 17732;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC45B0;
	case 1:
		goto loc_82DC4570;
	case 2:
		goto loc_82DC4580;
	case 3:
		goto loc_82DC4590;
	case 4:
		goto loc_82DC45A0;
	case 5:
		goto loc_82DC45A0;
	case 6:
		goto loc_82DC45B0;
	case 7:
		goto loc_82DC45B0;
	case 8:
		goto loc_82DC45B0;
	case 9:
		goto loc_82DC45B0;
	case 10:
		goto loc_82DC45B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17840);
	// lwz r22,17776(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17776);
	// lwz r22,17792(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17792);
	// lwz r22,17808(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17808);
	// lwz r22,17824(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17824);
	// lwz r22,17824(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17824);
	// lwz r22,17840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17840);
	// lwz r22,17840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17840);
	// lwz r22,17840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17840);
	// lwz r22,17840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17840);
	// lwz r22,17840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17840);
loc_82DC4570:
	// li r11,8
	ctx.r11.s64 = 8;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc4680
	goto loc_82DC4680;
loc_82DC4580:
	// li r11,16
	ctx.r11.s64 = 16;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc4680
	goto loc_82DC4680;
loc_82DC4590:
	// li r11,24
	ctx.r11.s64 = 24;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc4680
	goto loc_82DC4680;
loc_82DC45A0:
	// li r11,32
	ctx.r11.s64 = 32;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc4680
	goto loc_82DC4680;
loc_82DC45B0:
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,17864
	ctx.r12.s64 = ctx.r12.s64 + 17864;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,18044(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18044);
	// lwz r22,18056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18056);
	// lwz r22,18056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18056);
	// lwz r22,18056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18056);
	// lwz r22,18056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18056);
	// lwz r22,18056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18056);
	// lwz r22,17908(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17908);
	// lwz r22,17960(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17960);
	// lwz r22,17984(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 17984);
	// lwz r22,18036(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18036);
	// lwz r22,18036(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 18036);
	// addi r11,r9,13
	ctx.r11.s64 = ctx.r9.s64 + 13;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dc4680
	goto loc_82DC4680;
	// addi r11,r9,63
	ctx.r11.s64 = ctx.r9.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dc4680
	goto loc_82DC4680;
	// addi r11,r9,27
	ctx.r11.s64 = ctx.r9.s64 + 27;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dc4680
	goto loc_82DC4680;
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// b 0x82dc4688
	goto loc_82DC4688;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DC4680:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mullw r29,r11,r10
	ctx.r29.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82DC4688:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r25,r4
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82dc46ac
	if (ctx.cr6.eq) goto loc_82DC46AC;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dc46ac
	if (ctx.cr6.eq) goto loc_82DC46AC;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DC46A8;
	sub_82CB1160(ctx, base);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DC46AC:
	// add r27,r9,r27
	ctx.r27.u64 = ctx.r9.u64 + ctx.r27.u64;
	// add r25,r29,r25
	ctx.r25.u64 = ctx.r29.u64 + ctx.r25.u64;
	// subf r26,r9,r26
	ctx.r26.s64 = ctx.r26.s64 - ctx.r9.s64;
	// cmplw cr6,r27,r24
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82dc4470
	if (ctx.cr6.lt) goto loc_82DC4470;
loc_82DC46C0:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// stw r26,11872(r28)
	PPC_STORE_U32(ctx.r28.u32 + 11872, ctx.r26.u32);
	// beq cr6,0x82dc46d0
	if (ctx.cr6.eq) goto loc_82DC46D0;
	// stw r22,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r22.u32);
loc_82DC46D0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC46D4:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DC46DC:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DC46E4;
	sub_82DA4200(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC46F0"))) PPC_WEAK_FUNC(sub_82DC46F0);
PPC_FUNC_IMPL(__imp__sub_82DC46F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,11884(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11884);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dc4744
	if (ctx.cr6.eq) goto loc_82DC4744;
	// bge cr6,0x82dc4720
	if (!ctx.cr6.lt) goto loc_82DC4720;
	// bl 0x82dc2688
	ctx.lr = 0x82DC4720;
	sub_82DC2688(ctx, base);
loc_82DC4720:
	// lwz r11,11884(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11884);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82dc4744
	if (!ctx.cr6.lt) goto loc_82DC4744;
loc_82DC472C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc4238
	ctx.lr = 0x82DC4738;
	sub_82DC4238(ctx, base);
	// lwz r11,11884(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11884);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82dc472c
	if (ctx.cr6.lt) goto loc_82DC472C;
loc_82DC4744:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC4760"))) PPC_WEAK_FUNC(sub_82DC4760);
PPC_FUNC_IMPL(__imp__sub_82DC4760) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc4770
	if (!ctx.cr6.eq) goto loc_82DC4770;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC4770:
	// b 0x82dc42d0
	sub_82DC42D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC4774"))) PPC_WEAK_FUNC(sub_82DC4774);
PPC_FUNC_IMPL(__imp__sub_82DC4774) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC4778"))) PPC_WEAK_FUNC(sub_82DC4778);
PPC_FUNC_IMPL(__imp__sub_82DC4778) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc4788
	if (!ctx.cr6.eq) goto loc_82DC4788;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC4788:
	// b 0x82dc46f0
	sub_82DC46F0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC478C"))) PPC_WEAK_FUNC(sub_82DC478C);
PPC_FUNC_IMPL(__imp__sub_82DC478C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC4790"))) PPC_WEAK_FUNC(sub_82DC4790);
PPC_FUNC_IMPL(__imp__sub_82DC4790) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DC4798;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82cb6ae8
	ctx.lr = 0x82DC47A0;
	__savefpr_28(ctx, base);
	// stwu r1,-784(r1)
	ea = -784 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r20,-31909
	ctx.r20.s64 = -2091188224;
	// li r22,0
	ctx.r22.s64 = 0;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r28,r31,248
	ctx.r28.s64 = ctx.r31.s64 + 248;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// lfs f31,6048(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6048);
	ctx.f31.f64 = double(temp.f32);
	// stw r11,19872(r20)
	PPC_STORE_U32(ctx.r20.u32 + 19872, ctx.r11.u32);
	// li r11,11
	ctx.r11.s64 = 11;
	// stw r22,220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 220, ctx.r22.u32);
	// stw r22,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r22.u32);
	// stw r22,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r22.u32);
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f28,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f28.f64 = double(temp.f32);
	// beq cr6,0x82dc482c
	if (ctx.cr6.eq) goto loc_82DC482C;
	// addi r11,r28,36
	ctx.r11.s64 = ctx.r28.s64 + 36;
	// stw r28,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r28.u32);
	// stw r28,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r28.u32);
	// stw r22,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r22.u32);
	// stw r22,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r22.u32);
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stfs f28,60(r28)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + 60, temp.u32);
	// stfs f28,56(r28)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + 56, temp.u32);
	// stfs f28,84(r28)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + 84, temp.u32);
	// stfs f28,80(r28)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + 80, temp.u32);
	// stfs f31,68(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 68, temp.u32);
	// stfs f31,64(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 64, temp.u32);
	// stfs f28,76(r28)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + 76, temp.u32);
	// stfs f28,72(r28)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + 72, temp.u32);
loc_82DC482C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82da7e70
	ctx.lr = 0x82DC483C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC485C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,14
	ctx.r6.s64 = 14;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// bl 0x82da76a0
	ctx.lr = 0x82DC487C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,9196
	ctx.r4.s64 = ctx.r11.s64 + 9196;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82da45e8
	ctx.lr = 0x82DC4898;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dc48b4
	if (ctx.cr6.eq) goto loc_82DC48B4;
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82cb6b34
	ctx.lr = 0x82DC48B0;
	__restfpr_28(ctx, base);
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DC48B4:
	// lhz r10,114(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 114);
	// lis r8,7
	ctx.r8.s64 = 458752;
	// lhz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 116);
	// stfs f28,11880(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 11880, temp.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lhz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 112);
	// ori r8,r8,41248
	ctx.r8.u64 = ctx.r8.u64 | 41248;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// stw r11,11896(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11896, ctx.r11.u32);
	// stw r10,11888(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11888, ctx.r10.u32);
	// extsw r10,r11
	ctx.r10.s64 = ctx.r11.s32;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r9,11892(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11892, ctx.r9.u32);
	// stw r8,11916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11916, ctx.r8.u32);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,-15700(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -15700);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f29,6480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6480);
	ctx.f29.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fmuls f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// stfs f0,11924(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 11924, temp.u32);
	// beq cr6,0x82dc4924
	if (ctx.cr6.eq) goto loc_82DC4924;
	// lwz r11,64(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 64);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc4928
	if (!ctx.cr6.eq) goto loc_82DC4928;
loc_82DC4924:
	// li r11,32
	ctx.r11.s64 = 32;
loc_82DC4928:
	// stw r11,244(r31)
	PPC_STORE_U32(ctx.r31.u32 + 244, ctx.r11.u32);
	// li r11,-1
	ctx.r11.s64 = -1;
	// li r5,256
	ctx.r5.s64 = 256;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,384
	ctx.r3.s64 = ctx.r1.s64 + 384;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82cb16f0
	ctx.lr = 0x82DC4944;
	sub_82CB16F0(ctx, base);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82dc4964
	if (ctx.cr6.eq) goto loc_82DC4964;
	// lwz r4,56(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 56);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc4964
	if (ctx.cr6.eq) goto loc_82DC4964;
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r3,r1,384
	ctx.r3.s64 = ctx.r1.s64 + 384;
	// bl 0x82cb2ea0
	ctx.lr = 0x82DC4964;
	sub_82CB2EA0(ctx, base);
loc_82DC4964:
	// addi r11,r1,272
	ctx.r11.s64 = ctx.r1.s64 + 272;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// li r9,13
	ctx.r9.s64 = 13;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DC4974:
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dc4974
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DC4974;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// li r11,108
	ctx.r11.s64 = 108;
	// li r25,1
	ctx.r25.s64 = 1;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r21,r31,11928
	ctx.r21.s64 = ctx.r31.s64 + 11928;
	// addi r6,r1,272
	ctx.r6.s64 = ctx.r1.s64 + 272;
	// li r5,8
	ctx.r5.s64 = 8;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,384
	ctx.r4.s64 = ctx.r1.s64 + 384;
	// stw r25,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r25.u32);
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// stw r11,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r11.u32);
	// bl 0x82d910a0
	ctx.lr = 0x82DC49B8;
	sub_82D910A0(ctx, base);
	// cmpwi cr6,r3,23
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 23, ctx.xer);
	// bne cr6,0x82dc49d4
	if (!ctx.cr6.eq) goto loc_82DC49D4;
	// li r3,67
	ctx.r3.s64 = 67;
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82cb6b34
	ctx.lr = 0x82DC49D0;
	__restfpr_28(ctx, base);
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DC49D4:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r23,r11,8920
	ctx.r23.s64 = ctx.r11.s64 + 8920;
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// li r6,3021
	ctx.r6.s64 = 3021;
	// rlwinm r4,r11,5,0,26
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// lwz r11,60(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// stw r11,11932(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11932, ctx.r11.u32);
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC4A10;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,11912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11912, ctx.r3.u32);
	// bne cr6,0x82dc4a30
	if (!ctx.cr6.eq) goto loc_82DC4A30;
loc_82DC4A1C:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82cb6b34
	ctx.lr = 0x82DC4A2C;
	__restfpr_28(ctx, base);
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DC4A30:
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,244(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// li r6,3027
	ctx.r6.s64 = 3027;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mulli r4,r10,648
	ctx.r4.s64 = ctx.r10.s64 * 648;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC4A50;
	sub_82D862B0(ctx, base);
	// stw r3,340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 340, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc4a1c
	if (ctx.cr6.eq) goto loc_82DC4A1C;
	// lwz r11,244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc4ac0
	if (!ctx.cr6.gt) goto loc_82DC4AC0;
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
loc_82DC4A70:
	// lwz r11,340(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 340);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r22,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r22.u32);
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// lwz r11,340(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 340);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82d98af8
	ctx.lr = 0x82DC4A94;
	sub_82D98AF8(ctx, base);
	// lwz r11,340(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 340);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r31,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r31.u32);
	// lwz r11,340(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 340);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r30,r30,648
	ctx.r30.s64 = ctx.r30.s64 + 648;
	// stw r28,156(r11)
	PPC_STORE_U32(ctx.r11.u32 + 156, ctx.r28.u32);
	// lwz r11,244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc4a70
	if (ctx.cr6.lt) goto loc_82DC4A70;
loc_82DC4AC0:
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3041
	ctx.r6.s64 = 3041;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// li r4,296
	ctx.r4.s64 = 296;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC4ADC;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r3.u32);
	// beq cr6,0x82dc4a1c
	if (ctx.cr6.eq) goto loc_82DC4A1C;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r28,r22
	ctx.r28.u64 = ctx.r22.u64;
	// stw r3,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r3.u32);
	// li r29,6
	ctx.r29.s64 = 6;
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
	// stw r11,268(r3)
	PPC_STORE_U32(ctx.r3.u32 + 268, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r27,r11,9188
	ctx.r27.s64 = ctx.r11.s64 + 9188;
loc_82DC4B08:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r29,8
	ctx.r4.s64 = ctx.r29.s64 + 8;
	// bl 0x82da7e70
	ctx.lr = 0x82DC4B18;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da76a0
	ctx.lr = 0x82DC4B38;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82da45e8
	ctx.lr = 0x82DC4B50;
	sub_82DA45E8(ctx, base);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc4bf8
	if (!ctx.cr6.eq) goto loc_82DC4BF8;
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3085
	ctx.r6.s64 = 3085;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC4B74;
	sub_82D862B0(ctx, base);
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r3,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r3.u32);
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc4a1c
	if (ctx.cr6.eq) goto loc_82DC4A1C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da76a0
	ctx.lr = 0x82DC4BA8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dc4bb8
	if (ctx.cr6.eq) goto loc_82DC4BB8;
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
loc_82DC4BB8:
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r10,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r10.u32);
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r22,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r22.u32);
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// stwx r31,r30,r11
	PPC_STORE_U32(ctx.r30.u32 + ctx.r11.u32, ctx.r31.u32);
	// addi r30,r30,32
	ctx.r30.s64 = ctx.r30.s64 + 32;
	// b 0x82dc4c04
	goto loc_82DC4C04;
loc_82DC4BF8:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DC4C04;
	sub_82DA7E70(ctx, base);
loc_82DC4C04:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// addi r29,r11,8
	ctx.r29.s64 = ctx.r11.s64 + 8;
	// lwz r11,268(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82dc4c2c
	if (!ctx.cr6.lt) goto loc_82DC4C2C;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82dc4b08
	if (!ctx.cr6.eq) goto loc_82DC4B08;
loc_82DC4C2C:
	// li r10,2
	ctx.r10.s64 = 2;
	// li r27,5
	ctx.r27.s64 = 5;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82dc4c54
	if (ctx.cr6.eq) goto loc_82DC4C54;
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc4c54
	if (ctx.cr6.eq) goto loc_82DC4C54;
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r11,256(r9)
	PPC_STORE_U32(ctx.r9.u32 + 256, ctx.r11.u32);
	// b 0x82dc4c70
	goto loc_82DC4C70;
loc_82DC4C54:
	// rlwinm r11,r24,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// beq cr6,0x82dc4c6c
	if (ctx.cr6.eq) goto loc_82DC4C6C;
	// stw r27,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r27.u32);
	// b 0x82dc4c70
	goto loc_82DC4C70;
loc_82DC4C6C:
	// stw r10,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r10.u32);
loc_82DC4C70:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r10,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r10.u32);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r11,r11,264
	ctx.r11.s64 = ctx.r11.s64 + 264;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc4c94
	if (ctx.cr6.eq) goto loc_82DC4C94;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r10,1244(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1244);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
loc_82DC4C94:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,256(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lwz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// bgt cr6,0x82dc4dac
	if (ctx.cr6.gt) goto loc_82DC4DAC;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,19648
	ctx.r12.s64 = ctx.r12.s64 + 19648;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC4D2C;
	case 1:
		goto loc_82DC4CEC;
	case 2:
		goto loc_82DC4CFC;
	case 3:
		goto loc_82DC4D0C;
	case 4:
		goto loc_82DC4D1C;
	case 5:
		goto loc_82DC4D1C;
	case 6:
		goto loc_82DC4D2C;
	case 7:
		goto loc_82DC4D2C;
	case 8:
		goto loc_82DC4D2C;
	case 9:
		goto loc_82DC4D2C;
	case 10:
		goto loc_82DC4D2C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,19756(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19756);
	// lwz r22,19692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19692);
	// lwz r22,19708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19708);
	// lwz r22,19724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19724);
	// lwz r22,19740(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19740);
	// lwz r22,19740(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19740);
	// lwz r22,19756(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19756);
	// lwz r22,19756(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19756);
	// lwz r22,19756(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19756);
	// lwz r22,19756(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19756);
	// lwz r22,19756(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19756);
loc_82DC4CEC:
	// li r10,8
	ctx.r10.s64 = 8;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
loc_82DC4CFC:
	// li r10,16
	ctx.r10.s64 = 16;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
loc_82DC4D0C:
	// li r10,24
	ctx.r10.s64 = 24;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
loc_82DC4D1C:
	// li r10,32
	ctx.r10.s64 = 32;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
loc_82DC4D2C:
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,19780
	ctx.r12.s64 = ctx.r12.s64 + 19780;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,19868(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19868);
	// lwz r22,19884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19884);
	// lwz r22,19884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19884);
	// lwz r22,19884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19884);
	// lwz r22,19884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19884);
	// lwz r22,19884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19884);
	// lwz r22,19824(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19824);
	// lwz r22,19836(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19836);
	// lwz r22,19848(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19848);
	// lwz r22,19860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19860);
	// lwz r22,19860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19860);
	// li r10,8
	ctx.r10.s64 = 8;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
	// li r10,36
	ctx.r10.s64 = 36;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
	// li r10,16
	ctx.r10.s64 = 16;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dc4da0
	goto loc_82DC4DA0;
	// stw r25,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r25.u32);
	// b 0x82dc4dac
	goto loc_82DC4DAC;
	// stw r22,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r22.u32);
loc_82DC4DA0:
	// lwz r10,276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// mullw r10,r9,r10
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
loc_82DC4DAC:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,11924(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 11924);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f13.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,512
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 512, ctx.xer);
	// stw r11,11876(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11876, ctx.r11.u32);
	// bge cr6,0x82dc4e24
	if (!ctx.cr6.lt) goto loc_82DC4E24;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// li r10,512
	ctx.r10.s64 = 512;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// stw r10,11876(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11876, ctx.r10.u32);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,-15884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -15884);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// stfs f13,11880(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 11880, temp.u32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,11924(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 11924, temp.u32);
loc_82DC4E24:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2688
	ctx.lr = 0x82DC4E2C;
	sub_82DC2688(ctx, base);
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3164
	ctx.r6.s64 = 3164;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// lwz r4,136(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC4E4C;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,11936(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11936, ctx.r3.u32);
	// beq cr6,0x82dc4a1c
	if (ctx.cr6.eq) goto loc_82DC4A1C;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r22,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r22.u32);
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc4f24
	if (ctx.cr6.eq) goto loc_82DC4F24;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f30,6404(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6404);
	ctx.f30.f64 = double(temp.f32);
loc_82DC4E74:
	// lwz r11,11888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// mr r28,r22
	ctx.r28.u64 = ctx.r22.u64;
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc4ed4
	if (!ctx.cr6.gt) goto loc_82DC4ED4;
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
loc_82DC4E90:
	// li r4,1
	ctx.r4.s64 = 1;
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
	// bl 0x82dc3888
	ctx.lr = 0x82DC4E9C;
	sub_82DC3888(ctx, base);
	// lwz r11,11912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11912);
	// add r10,r11,r30
	ctx.r10.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r9,28(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 28);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc4ebc
	if (!ctx.cr6.eq) goto loc_82DC4EBC;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc4ec0
	if (!ctx.cr6.eq) goto loc_82DC4EC0;
loc_82DC4EBC:
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
loc_82DC4EC0:
	// lwz r10,11888(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,32
	ctx.r30.s64 = ctx.r30.s64 + 32;
	// cmpw cr6,r29,r10
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc4e90
	if (ctx.cr6.lt) goto loc_82DC4E90;
loc_82DC4ED4:
	// lwz r10,11896(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11896);
	// lfs f0,11920(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 11920);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,11916(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11916);
	// fadds f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f30.f64));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// stfs f0,11920(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 11920, temp.u32);
	// lwz r9,11888(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11888);
	// cmpw cr6,r28,r9
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r9.s32, ctx.xer);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fmuls f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmadds f31,f0,f30,f31
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 + ctx.f31.f64));
	// bne cr6,0x82dc4e74
	if (!ctx.cr6.eq) goto loc_82DC4E74;
loc_82DC4F24:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// fmuls f0,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f29.f64));
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// addi r9,r31,356
	ctx.r9.s64 = ctx.r31.s64 + 356;
	// li r10,16
	ctx.r10.s64 = 16;
	// lwz r7,264(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// addi r11,r11,272
	ctx.r11.s64 = ctx.r11.s64 + 272;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// std r7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r7.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
loc_82DC4F64:
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc4f74
	if (ctx.cr6.eq) goto loc_82DC4F74;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_82DC4F74:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r9,r9,720
	ctx.r9.s64 = ctx.r9.s64 + 720;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc4f64
	if (!ctx.cr6.eq) goto loc_82DC4F64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r5,r11,9168
	ctx.r5.s64 = ctx.r11.s64 + 9168;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DC4FAC;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// lwz r11,0(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
	// lwz r11,136(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc5004
	if (!ctx.cr6.gt) goto loc_82DC5004;
loc_82DC4FC8:
	// lwz r11,11936(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11936);
	// lbzx r11,r11,r30
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r30.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc4ff0
	if (ctx.cr6.eq) goto loc_82DC4FF0;
	// li r5,72
	ctx.r5.s64 = 72;
	// lwz r3,0(r21)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82da3988
	ctx.lr = 0x82DC4FE8;
	sub_82DA3988(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
loc_82DC4FF0:
	// lwz r11,0(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r11,136(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc4fc8
	if (ctx.cr6.lt) goto loc_82DC4FC8;
loc_82DC5004:
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3238
	ctx.r6.s64 = 3238;
	// lwz r4,11936(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11936);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC5020;
	sub_82D861B0(ctx, base);
	// addi r11,r1,220
	ctx.r11.s64 = ctx.r1.s64 + 220;
	// stw r22,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r22.u32);
	// stw r22,11936(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11936, ctx.r22.u32);
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// li r10,17
	ctx.r10.s64 = 17;
	// stw r11,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r11.u32);
	// addi r11,r1,220
	ctx.r11.s64 = ctx.r1.s64 + 220;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r11.u32);
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DC5048:
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dc5048
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DC5048;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r11,9144
	ctx.r4.s64 = ctx.r11.s64 + 9144;
	// bl 0x82da4448
	ctx.lr = 0x82DC5064;
	sub_82DA4448(ctx, base);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r28,r31,232
	ctx.r28.s64 = ctx.r31.s64 + 232;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// stw r27,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r27.u32);
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, ctx.r11.u32);
	// bl 0x82d8ced0
	ctx.lr = 0x82DC50A0;
	sub_82D8CED0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r6,3276
	ctx.r6.s64 = 3276;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 220, temp.u32);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// stfs f28,304(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 304, temp.u32);
	// stw r11,264(r31)
	PPC_STORE_U32(ctx.r31.u32 + 264, ctx.r11.u32);
	// stw r11,268(r31)
	PPC_STORE_U32(ctx.r31.u32 + 268, ctx.r11.u32);
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC50F8;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc5108
	if (ctx.cr6.eq) goto loc_82DC5108;
	// bl 0x82da9430
	ctx.lr = 0x82DC5104;
	sub_82DA9430(ctx, base);
	// b 0x82dc510c
	goto loc_82DC510C;
loc_82DC5108:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
loc_82DC510C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 236, ctx.r3.u32);
	// beq cr6,0x82dc4a1c
	if (ctx.cr6.eq) goto loc_82DC4A1C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,244(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// bl 0x82da9450
	ctx.lr = 0x82DC5128;
	sub_82DA9450(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc51d4
	if (!ctx.cr6.eq) goto loc_82DC51D4;
	// lwz r11,19872(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,244(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// li r6,3288
	ctx.r6.s64 = 3288;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mulli r4,r10,760
	ctx.r4.s64 = ctx.r10.s64 * 760;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DC5150;
	sub_82D862B0(ctx, base);
	// stw r3,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc4a1c
	if (ctx.cr6.eq) goto loc_82DC4A1C;
	// lwz r11,244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc51c4
	if (!ctx.cr6.gt) goto loc_82DC51C4;
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
loc_82DC5170:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// add r3,r30,r11
	ctx.r3.u64 = ctx.r30.u64 + ctx.r11.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc5184
	if (ctx.cr6.eq) goto loc_82DC5184;
	// bl 0x82e01520
	ctx.lr = 0x82DC5184;
	sub_82E01520(ctx, base);
loc_82DC5184:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,0(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// add r5,r30,r11
	ctx.r5.u64 = ctx.r30.u64 + ctx.r11.u64;
	// lwz r3,236(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 236);
	// bl 0x82da9828
	ctx.lr = 0x82DC519C;
	sub_82DA9828(ctx, base);
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r30,r30,760
	ctx.r30.s64 = ctx.r30.s64 + 760;
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// ori r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 2048;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// lwz r11,244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc5170
	if (ctx.cr6.lt) goto loc_82DC5170;
loc_82DC51C4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc2688
	ctx.lr = 0x82DC51CC;
	sub_82DC2688(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r22,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r22.u32);
loc_82DC51D4:
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82cb6b34
	ctx.lr = 0x82DC51E0;
	__restfpr_28(ctx, base);
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC51E4"))) PPC_WEAK_FUNC(sub_82DC51E4);
PPC_FUNC_IMPL(__imp__sub_82DC51E4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC51E8"))) PPC_WEAK_FUNC(sub_82DC51E8);
PPC_FUNC_IMPL(__imp__sub_82DC51E8) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc51f8
	if (!ctx.cr6.eq) goto loc_82DC51F8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC51F8:
	// b 0x82dc4790
	sub_82DC4790(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC51FC"))) PPC_WEAK_FUNC(sub_82DC51FC);
PPC_FUNC_IMPL(__imp__sub_82DC51FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC5200"))) PPC_WEAK_FUNC(sub_82DC5200);
PPC_FUNC_IMPL(__imp__sub_82DC5200) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,30872
	ctx.r31.s64 = ctx.r11.s64 + 30872;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DC5228;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r4,-32036
	ctx.r4.s64 = -2099511296;
	// addi r11,r11,9204
	ctx.r11.s64 = ctx.r11.s64 + 9204;
	// lis r5,-32036
	ctx.r5.s64 = -2099511296;
	// lis r6,-32036
	ctx.r6.s64 = -2099511296;
	// lis r7,-32036
	ctx.r7.s64 = -2099511296;
	// lis r8,-32036
	ctx.r8.s64 = -2099511296;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// lis r9,-32036
	ctx.r9.s64 = -2099511296;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// lis r10,-32036
	ctx.r10.s64 = -2099511296;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r4,20968
	ctx.r11.s64 = ctx.r4.s64 + 20968;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r5,10752
	ctx.r11.s64 = ctx.r5.s64 + 10752;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r6,18272
	ctx.r11.s64 = ctx.r6.s64 + 18272;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r7,18296
	ctx.r11.s64 = ctx.r7.s64 + 18296;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// addi r11,r8,10776
	ctx.r11.s64 = ctx.r8.s64 + 10776;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// addi r11,r9,10824
	ctx.r11.s64 = ctx.r9.s64 + 10824;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// addi r11,r10,10912
	ctx.r11.s64 = ctx.r10.s64 + 10912;
	// stw r11,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r11.u32);
	// li r11,11
	ctx.r11.s64 = 11;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,12592
	ctx.r11.s64 = 12592;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC52CC"))) PPC_WEAK_FUNC(sub_82DC52CC);
PPC_FUNC_IMPL(__imp__sub_82DC52CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC52D0"))) PPC_WEAK_FUNC(sub_82DC52D0);
PPC_FUNC_IMPL(__imp__sub_82DC52D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,218
	ctx.r11.s64 = 14286848;
	// twllei r4,0
	// ori r11,r11,30208
	ctx.r11.u64 = ctx.r11.u64 | 30208;
	// divw r3,r11,r4
	ctx.r3.s32 = ctx.r11.s32 / ctx.r4.s32;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC52E4"))) PPC_WEAK_FUNC(sub_82DC52E4);
PPC_FUNC_IMPL(__imp__sub_82DC52E4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC52E8"))) PPC_WEAK_FUNC(sub_82DC52E8);
PPC_FUNC_IMPL(__imp__sub_82DC52E8) {
	PPC_FUNC_PROLOGUE();
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// lbz r7,14380(r3)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r3.u32 + 14380);
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// bgt cr6,0x82dc5368
	if (ctx.cr6.gt) goto loc_82DC5368;
	// li r11,1
	ctx.r11.s64 = 1;
	// lwz r9,14376(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 14376);
	// slw r11,r11,r10
	ctx.r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r10.u8 & 0x3F));
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwimi r7,r11,16,16,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r7.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r6,r11,16,0,15
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r6.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r7,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xFFFF;
	// rlwinm r7,r6,8,0,15
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 | ctx.r7.u64;
	// and r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 & ctx.r11.u64;
	// srw r11,r11,r10
	ctx.r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 >> (ctx.r10.u8 & 0x3F));
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwimi r7,r11,16,16,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r7.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r6,r11,16,0,15
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r6.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r7,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xFFFF;
	// rlwinm r7,r6,8,0,15
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 | ctx.r7.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// lbz r11,14380(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 14380);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stb r11,14380(r3)
	PPC_STORE_U8(ctx.r3.u32 + 14380, ctx.r11.u8);
	// b 0x82dc53fc
	goto loc_82DC53FC;
loc_82DC5368:
	// lwz r11,14376(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 14376);
	// subf r8,r7,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r7.s64;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r9,r11,4
	ctx.r9.s64 = ctx.r11.s64 + 4;
	// subfic r4,r8,32
	ctx.xer.ca = ctx.r8.u32 <= 32;
	ctx.r4.s64 = 32 - ctx.r8.s64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// stw r9,14376(r3)
	PPC_STORE_U32(ctx.r3.u32 + 14376, ctx.r9.u32);
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// rlwimi r31,r10,16,16,31
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF) | (ctx.r31.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r30,r10,16,0,15
	ctx.r30.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r30.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r31,24,16,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 24) & 0xFFFF;
	// rlwinm r31,r30,8,0,15
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 8) & 0xFFFF0000;
	// mr r30,r9
	ctx.r30.u64 = ctx.r9.u64;
	// or r31,r10,r31
	ctx.r31.u64 = ctx.r10.u64 | ctx.r31.u64;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// rlwimi r30,r9,16,0,15
	ctx.r30.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0xFFFF0000) | (ctx.r30.u64 & 0xFFFFFFFF0000FFFF);
	// rlwimi r10,r9,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// slw r6,r6,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r8.u8 & 0x3F));
	// rlwinm r10,r10,24,16,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r9,r30,8,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 8) & 0xFFFF0000;
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// and r9,r6,r10
	ctx.r9.u64 = ctx.r6.u64 & ctx.r10.u64;
	// srw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r8.u8 & 0x3F));
	// slw r9,r9,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r7.u8 & 0x3F));
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// or r8,r31,r9
	ctx.r8.u64 = ctx.r31.u64 | ctx.r9.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rlwimi r7,r10,16,0,15
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r7.u64 & 0xFFFFFFFF0000FFFF);
	// rlwimi r9,r10,16,16,31
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF) | (ctx.r9.u64 & 0xFFFFFFFFFFFF0000);
	// rlwinm r10,r9,24,16,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFF;
	// rlwinm r9,r7,8,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// stb r4,14380(r3)
	PPC_STORE_U8(ctx.r3.u32 + 14380, ctx.r4.u8);
loc_82DC53FC:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq cr6,0x82dc540c
	if (ctx.cr6.eq) goto loc_82DC540C;
	// stw r8,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r8.u32);
loc_82DC540C:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC5418"))) PPC_WEAK_FUNC(sub_82DC5418);
PPC_FUNC_IMPL(__imp__sub_82DC5418) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DC5420;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r5,r10,9224
	ctx.r5.s64 = ctx.r10.s64 + 9224;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r6,229
	ctx.r6.s64 = 229;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r9,r11,2
	ctx.r9.s64 = ctx.r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// extsb r4,r11
	ctx.r4.s64 = ctx.r11.s8;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// rlwimi r4,r10,8,0,23
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0xFFFFFF00) | (ctx.r4.u64 & 0xFFFFFFFF000000FF);
	// clrlwi r29,r4,16
	ctx.r29.u64 = ctx.r4.u32 & 0xFFFF;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// rlwinm r4,r29,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d85f40
	ctx.lr = 0x82DC5478;
	sub_82D85F40(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,14372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 14372, ctx.r3.u32);
	// bne cr6,0x82dc5490
	if (!ctx.cr6.eq) goto loc_82DC5490;
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DC5490:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82cb1160
	ctx.lr = 0x82DC549C;
	sub_82CB1160(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,32
	ctx.r10.s64 = 32;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lwz r11,14372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14372);
	// stb r10,14380(r30)
	PPC_STORE_U8(ctx.r30.u32 + 14380, ctx.r10.u8);
	// stw r11,14376(r30)
	PPC_STORE_U32(ctx.r30.u32 + 14376, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC54C4"))) PPC_WEAK_FUNC(sub_82DC54C4);
PPC_FUNC_IMPL(__imp__sub_82DC54C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC54C8"))) PPC_WEAK_FUNC(sub_82DC54C8);
PPC_FUNC_IMPL(__imp__sub_82DC54C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r4,14372(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14372);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc5510
	if (ctx.cr6.eq) goto loc_82DC5510;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r11,9224
	ctx.r5.s64 = ctx.r11.s64 + 9224;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r6,262
	ctx.r6.s64 = 262;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC5508;
	sub_82D861B0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,14372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14372, ctx.r11.u32);
loc_82DC5510:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC5528"))) PPC_WEAK_FUNC(sub_82DC5528);
PPC_FUNC_IMPL(__imp__sub_82DC5528) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DC5530;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r14,r4
	ctx.r14.u64 = ctx.r4.u64;
	// mr r17,r6
	ctx.r17.u64 = ctx.r6.u64;
	// mr r23,r7
	ctx.r23.u64 = ctx.r7.u64;
	// mr r18,r8
	ctx.r18.u64 = ctx.r8.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82dc577c
	if (ctx.cr6.eq) goto loc_82DC577C;
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82dc577c
	if (ctx.cr6.eq) goto loc_82DC577C;
	// lwz r11,0(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc577c
	if (ctx.cr6.eq) goto loc_82DC577C;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// beq cr6,0x82dc573c
	if (ctx.cr6.eq) goto loc_82DC573C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r19,-31909
	ctx.r19.s64 = -2091188224;
	// addi r20,r11,9224
	ctx.r20.s64 = ctx.r11.s64 + 9224;
	// lis r11,0
	ctx.r11.s64 = 0;
	// li r21,0
	ctx.r21.s64 = 0;
	// ori r15,r11,32768
	ctx.r15.u64 = ctx.r11.u64 | 32768;
	// li r16,1
	ctx.r16.s64 = 1;
	// li r22,255
	ctx.r22.s64 = 255;
loc_82DC5590:
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dc5418
	ctx.lr = 0x82DC559C;
	sub_82DC5418(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc5780
	if (!ctx.cr6.eq) goto loc_82DC5780;
	// cmpw cr6,r17,r15
	ctx.cr6.compare<int32_t>(ctx.r17.s32, ctx.r15.s32, ctx.xer);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// blt cr6,0x82dc55b4
	if (ctx.cr6.lt) goto loc_82DC55B4;
	// mr r11,r15
	ctx.r11.u64 = ctx.r15.u64;
loc_82DC55B4:
	// clrlwi r25,r11,16
	ctx.r25.u64 = ctx.r11.u32 & 0xFFFF;
	// mr r27,r21
	ctx.r27.u64 = ctx.r21.u64;
	// li r30,9
	ctx.r30.s64 = 9;
	// mr r28,r21
	ctx.r28.u64 = ctx.r21.u64;
	// mr r29,r21
	ctx.r29.u64 = ctx.r21.u64;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82dc5708
	if (ctx.cr6.eq) goto loc_82DC5708;
loc_82DC55D0:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dc52e8
	ctx.lr = 0x82DC55E0;
	sub_82DC52E8(ctx, base);
	// clrlwi r31,r30,24
	ctx.r31.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r31,7
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 7, ctx.xer);
	// bge cr6,0x82dc5630
	if (!ctx.cr6.lt) goto loc_82DC5630;
	// addi r11,r31,-1
	ctx.r11.s64 = ctx.r31.s64 + -1;
	// slw r10,r16,r11
	ctx.r10.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r16.u32 << (ctx.r11.u8 & 0x3F));
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82dc569c
	if (!ctx.cr6.eq) goto loc_82DC569C;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dc52e8
	ctx.lr = 0x82DC5610;
	sub_82DC52E8(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// blt cr6,0x82dc5628
	if (ctx.cr6.lt) goto loc_82DC5628;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82DC5628:
	// clrlwi r30,r11,24
	ctx.r30.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc56fc
	goto loc_82DC56FC;
loc_82DC5630:
	// cmplwi cr6,r31,9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 9, ctx.xer);
	// bge cr6,0x82dc567c
	if (!ctx.cr6.lt) goto loc_82DC567C;
	// subfic r11,r31,9
	ctx.xer.ca = ctx.r31.u32 <= 9;
	ctx.r11.s64 = 9 - ctx.r31.s64;
	// sraw r11,r22,r11
	temp.u32 = ctx.r11.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r22.s32 < 0) & (((ctx.r22.s32 >> temp.u32) << temp.u32) != ctx.r22.s32);
	ctx.r11.s64 = ctx.r22.s32 >> temp.u32;
	// addi r11,r11,252
	ctx.r11.s64 = ctx.r11.s64 + 252;
	// clrlwi r10,r11,24
	ctx.r10.u64 = ctx.r11.u32 & 0xFF;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82dc569c
	if (!ctx.cr6.gt) goto loc_82DC569C;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bgt cr6,0x82dc569c
	if (ctx.cr6.gt) goto loc_82DC569C;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// blt cr6,0x82dc5628
	if (ctx.cr6.lt) goto loc_82DC5628;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r30,r11,24
	ctx.r30.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc56fc
	goto loc_82DC56FC;
loc_82DC567C:
	// bne cr6,0x82dc5748
	if (!ctx.cr6.eq) goto loc_82DC5748;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r11,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc569c
	if (ctx.cr6.eq) goto loc_82DC569C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r30,r11,24
	ctx.r30.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc56fc
	goto loc_82DC56FC;
loc_82DC569C:
	// cmplwi cr6,r31,8
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 8, ctx.xer);
	// bge cr6,0x82dc56c0
	if (!ctx.cr6.lt) goto loc_82DC56C0;
	// extsb r10,r30
	ctx.r10.s64 = ctx.r30.s8;
	// subfic r10,r10,8
	ctx.xer.ca = ctx.r10.u32 <= 8;
	ctx.r10.s64 = 8 - ctx.r10.s64;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// slw r11,r11,r10
	ctx.r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r10.u8 & 0x3F));
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// sraw r11,r11,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r11.s32 < 0) & (((ctx.r11.s32 >> temp.u32) << temp.u32) != ctx.r11.s32);
	ctx.r11.s64 = ctx.r11.s32 >> temp.u32;
	// b 0x82dc56c4
	goto loc_82DC56C4;
loc_82DC56C0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DC56C4:
	// add r10,r11,r29
	ctx.r10.u64 = ctx.r11.u64 + ctx.r29.u64;
	// clrlwi r9,r23,24
	ctx.r9.u64 = ctx.r23.u32 & 0xFF;
	// extsb r29,r10
	ctx.r29.s64 = ctx.r10.s8;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// add r11,r28,r29
	ctx.r11.u64 = ctx.r28.u64 + ctx.r29.u64;
	// extsb r28,r11
	ctx.r28.s64 = ctx.r11.s8;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// bne cr6,0x82dc56e8
	if (!ctx.cr6.eq) goto loc_82DC56E8;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
loc_82DC56E8:
	// clrlwi r11,r27,16
	ctx.r11.u64 = ctx.r27.u32 & 0xFFFF;
	// add r24,r24,r18
	ctx.r24.u64 = ctx.r24.u64 + ctx.r18.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r27,r11,16
	ctx.r27.u64 = ctx.r11.u32 & 0xFFFF;
	// stb r10,0(r24)
	PPC_STORE_U8(ctx.r24.u32 + 0, ctx.r10.u8);
loc_82DC56FC:
	// clrlwi r11,r27,16
	ctx.r11.u64 = ctx.r27.u32 & 0xFFFF;
	// cmplw cr6,r11,r25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r25.u32, ctx.xer);
	// blt cr6,0x82dc55d0
	if (ctx.cr6.lt) goto loc_82DC55D0;
loc_82DC5708:
	// lwz r4,14372(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 14372);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc5730
	if (ctx.cr6.eq) goto loc_82DC5730;
	// lwz r11,19872(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,262
	ctx.r6.s64 = 262;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC572C;
	sub_82D861B0(ctx, base);
	// stw r21,14372(r26)
	PPC_STORE_U32(ctx.r26.u32 + 14372, ctx.r21.u32);
loc_82DC5730:
	// subf r17,r25,r17
	ctx.r17.s64 = ctx.r17.s64 - ctx.r25.s64;
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne cr6,0x82dc5590
	if (!ctx.cr6.eq) goto loc_82DC5590;
loc_82DC573C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DC5748:
	// lwz r4,14372(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 14372);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc5770
	if (ctx.cr6.eq) goto loc_82DC5770;
	// lwz r11,19872(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,262
	ctx.r6.s64 = 262;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC576C;
	sub_82D861B0(ctx, base);
	// stw r21,14372(r26)
	PPC_STORE_U32(ctx.r26.u32 + 14372, ctx.r21.u32);
loc_82DC5770:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DC577C:
	// li r3,37
	ctx.r3.s64 = 37;
loc_82DC5780:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC5788"))) PPC_WEAK_FUNC(sub_82DC5788);
PPC_FUNC_IMPL(__imp__sub_82DC5788) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DC5790;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r14,r4
	ctx.r14.u64 = ctx.r4.u64;
	// mr r16,r6
	ctx.r16.u64 = ctx.r6.u64;
	// mr r21,r7
	ctx.r21.u64 = ctx.r7.u64;
	// mr r19,r8
	ctx.r19.u64 = ctx.r8.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82dc59e4
	if (ctx.cr6.eq) goto loc_82DC59E4;
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82dc59e4
	if (ctx.cr6.eq) goto loc_82DC59E4;
	// lwz r11,0(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc59e4
	if (ctx.cr6.eq) goto loc_82DC59E4;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq cr6,0x82dc59a4
	if (ctx.cr6.eq) goto loc_82DC59A4;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r17,-31909
	ctx.r17.s64 = -2091188224;
	// addi r18,r11,9224
	ctx.r18.s64 = ctx.r11.s64 + 9224;
	// lis r11,0
	ctx.r11.s64 = 0;
	// li r20,0
	ctx.r20.s64 = 0;
	// ori r22,r11,65535
	ctx.r22.u64 = ctx.r11.u64 | 65535;
	// lis r11,0
	ctx.r11.s64 = 0;
	// li r15,1
	ctx.r15.s64 = 1;
	// ori r23,r11,65528
	ctx.r23.u64 = ctx.r11.u64 | 65528;
loc_82DC57F4:
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dc5418
	ctx.lr = 0x82DC5800;
	sub_82DC5418(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc59e8
	if (!ctx.cr6.eq) goto loc_82DC59E8;
	// cmpwi cr6,r16,16384
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 16384, ctx.xer);
	// mr r11,r16
	ctx.r11.u64 = ctx.r16.u64;
	// blt cr6,0x82dc5818
	if (ctx.cr6.lt) goto loc_82DC5818;
	// li r11,16384
	ctx.r11.s64 = 16384;
loc_82DC5818:
	// clrlwi r25,r11,16
	ctx.r25.u64 = ctx.r11.u32 & 0xFFFF;
	// mr r27,r20
	ctx.r27.u64 = ctx.r20.u64;
	// li r30,17
	ctx.r30.s64 = 17;
	// mr r28,r20
	ctx.r28.u64 = ctx.r20.u64;
	// mr r29,r20
	ctx.r29.u64 = ctx.r20.u64;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82dc5970
	if (ctx.cr6.eq) goto loc_82DC5970;
loc_82DC5834:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dc52e8
	ctx.lr = 0x82DC5844;
	sub_82DC52E8(ctx, base);
	// clrlwi r31,r30,24
	ctx.r31.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r31,7
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 7, ctx.xer);
	// bge cr6,0x82dc5894
	if (!ctx.cr6.lt) goto loc_82DC5894;
	// addi r11,r31,-1
	ctx.r11.s64 = ctx.r31.s64 + -1;
	// slw r10,r15,r11
	ctx.r10.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r15.u32 << (ctx.r11.u8 & 0x3F));
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82dc5904
	if (!ctx.cr6.eq) goto loc_82DC5904;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dc52e8
	ctx.lr = 0x82DC5874;
	sub_82DC52E8(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// blt cr6,0x82dc588c
	if (ctx.cr6.lt) goto loc_82DC588C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82DC588C:
	// clrlwi r30,r11,24
	ctx.r30.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc5964
	goto loc_82DC5964;
loc_82DC5894:
	// cmplwi cr6,r31,17
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 17, ctx.xer);
	// bge cr6,0x82dc58e4
	if (!ctx.cr6.lt) goto loc_82DC58E4;
	// subfic r11,r31,17
	ctx.xer.ca = ctx.r31.u32 <= 17;
	ctx.r11.s64 = 17 - ctx.r31.s64;
	// sraw r11,r22,r11
	temp.u32 = ctx.r11.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r22.s32 < 0) & (((ctx.r22.s32 >> temp.u32) << temp.u32) != ctx.r22.s32);
	ctx.r11.s64 = ctx.r22.s32 >> temp.u32;
	// add r11,r11,r23
	ctx.r11.u64 = ctx.r11.u64 + ctx.r23.u64;
	// clrlwi r10,r11,16
	ctx.r10.u64 = ctx.r11.u32 & 0xFFFF;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82dc5904
	if (!ctx.cr6.gt) goto loc_82DC5904;
	// addi r9,r10,16
	ctx.r9.s64 = ctx.r10.s64 + 16;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bgt cr6,0x82dc5904
	if (ctx.cr6.gt) goto loc_82DC5904;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// blt cr6,0x82dc588c
	if (ctx.cr6.lt) goto loc_82DC588C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r30,r11,24
	ctx.r30.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc5964
	goto loc_82DC5964;
loc_82DC58E4:
	// bne cr6,0x82dc59b0
	if (!ctx.cr6.eq) goto loc_82DC59B0;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r11,0,15,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc5904
	if (ctx.cr6.eq) goto loc_82DC5904;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r30,r11,24
	ctx.r30.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc5964
	goto loc_82DC5964;
loc_82DC5904:
	// cmplwi cr6,r31,16
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 16, ctx.xer);
	// bge cr6,0x82dc5924
	if (!ctx.cr6.lt) goto loc_82DC5924;
	// subfic r10,r31,16
	ctx.xer.ca = ctx.r31.u32 <= 16;
	ctx.r10.s64 = 16 - ctx.r31.s64;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// slw r11,r11,r10
	ctx.r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r10.u8 & 0x3F));
	// extsh r11,r11
	ctx.r11.s64 = ctx.r11.s16;
	// sraw r11,r11,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r11.s32 < 0) & (((ctx.r11.s32 >> temp.u32) << temp.u32) != ctx.r11.s32);
	ctx.r11.s64 = ctx.r11.s32 >> temp.u32;
	// b 0x82dc5928
	goto loc_82DC5928;
loc_82DC5924:
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
loc_82DC5928:
	// add r10,r11,r29
	ctx.r10.u64 = ctx.r11.u64 + ctx.r29.u64;
	// clrlwi r9,r21,24
	ctx.r9.u64 = ctx.r21.u32 & 0xFF;
	// extsh r29,r10
	ctx.r29.s64 = ctx.r10.s16;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// add r11,r28,r29
	ctx.r11.u64 = ctx.r28.u64 + ctx.r29.u64;
	// extsh r28,r11
	ctx.r28.s64 = ctx.r11.s16;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// bne cr6,0x82dc594c
	if (!ctx.cr6.eq) goto loc_82DC594C;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82DC594C:
	// rlwinm r10,r19,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 1) & 0xFFFFFFFE;
	// clrlwi r11,r27,16
	ctx.r11.u64 = ctx.r27.u32 & 0xFFFF;
	// add r24,r10,r24
	ctx.r24.u64 = ctx.r10.u64 + ctx.r24.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r27,r11,16
	ctx.r27.u64 = ctx.r11.u32 & 0xFFFF;
	// sth r9,0(r24)
	PPC_STORE_U16(ctx.r24.u32 + 0, ctx.r9.u16);
loc_82DC5964:
	// clrlwi r11,r27,16
	ctx.r11.u64 = ctx.r27.u32 & 0xFFFF;
	// cmplw cr6,r11,r25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r25.u32, ctx.xer);
	// blt cr6,0x82dc5834
	if (ctx.cr6.lt) goto loc_82DC5834;
loc_82DC5970:
	// lwz r4,14372(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 14372);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc5998
	if (ctx.cr6.eq) goto loc_82DC5998;
	// lwz r11,19872(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,262
	ctx.r6.s64 = 262;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC5994;
	sub_82D861B0(ctx, base);
	// stw r20,14372(r26)
	PPC_STORE_U32(ctx.r26.u32 + 14372, ctx.r20.u32);
loc_82DC5998:
	// subf r16,r25,r16
	ctx.r16.s64 = ctx.r16.s64 - ctx.r25.s64;
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// bne cr6,0x82dc57f4
	if (!ctx.cr6.eq) goto loc_82DC57F4;
loc_82DC59A4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DC59B0:
	// lwz r4,14372(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 14372);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc59d8
	if (ctx.cr6.eq) goto loc_82DC59D8;
	// lwz r11,19872(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,262
	ctx.r6.s64 = 262;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC59D4;
	sub_82D861B0(ctx, base);
	// stw r20,14372(r26)
	PPC_STORE_U32(ctx.r26.u32 + 14372, ctx.r20.u32);
loc_82DC59D8:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DC59E4:
	// li r3,37
	ctx.r3.s64 = 37;
loc_82DC59E8:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC59F0"))) PPC_WEAK_FUNC(sub_82DC59F0);
PPC_FUNC_IMPL(__imp__sub_82DC59F0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,649(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 649);
	// lwz r7,0(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r8,r11,28
	ctx.r8.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82dc5a14
	if (!ctx.cr6.eq) goto loc_82DC5A14;
	// lwz r9,620(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 620);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,620(r3)
	PPC_STORE_U32(ctx.r3.u32 + 620, ctx.r10.u32);
loc_82DC5A14:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc5a2c
	if (!ctx.cr6.eq) goto loc_82DC5A2C;
	// lwz r11,620(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 620);
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
	// stw r11,620(r3)
	PPC_STORE_U32(ctx.r3.u32 + 620, ctx.r11.u32);
loc_82DC5A2C:
	// lwz r11,620(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 620);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dc5a40
	if (!ctx.cr6.gt) goto loc_82DC5A40;
	// li r11,64
	ctx.r11.s64 = 64;
	// stw r11,620(r3)
	PPC_STORE_U32(ctx.r3.u32 + 620, ctx.r11.u32);
loc_82DC5A40:
	// lwz r11,620(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 620);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc5a54
	if (!ctx.cr6.lt) goto loc_82DC5A54;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,620(r3)
	PPC_STORE_U32(ctx.r3.u32 + 620, ctx.r11.u32);
loc_82DC5A54:
	// lbz r11,476(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r7)
	PPC_STORE_U8(ctx.r7.u32 + 476, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC5A68"))) PPC_WEAK_FUNC(sub_82DC5A68);
PPC_FUNC_IMPL(__imp__sub_82DC5A68) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,661(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 661);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r8,704(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 704);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc5b1c
	if (!ctx.cr6.eq) goto loc_82DC5B1C;
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dc5ac8
	if (!ctx.cr6.lt) goto loc_82DC5AC8;
	// lhz r9,2034(r8)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r8.u32 + 2034);
	// rlwinm r9,r9,0,26,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc5aa4
	if (ctx.cr6.eq) goto loc_82DC5AA4;
	// lbz r9,660(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// b 0x82dc5aa8
	goto loc_82DC5AA8;
loc_82DC5AA4:
	// lbz r9,644(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 644);
loc_82DC5AA8:
	// rotlwi r9,r9,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 2);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r10,656(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc5b10
	if (ctx.cr6.lt) goto loc_82DC5B10;
	// b 0x82dc5b04
	goto loc_82DC5B04;
loc_82DC5AC8:
	// ble cr6,0x82dc5b10
	if (!ctx.cr6.gt) goto loc_82DC5B10;
	// lhz r9,2034(r8)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r8.u32 + 2034);
	// rlwinm r9,r9,0,26,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc5ae4
	if (ctx.cr6.eq) goto loc_82DC5AE4;
	// lbz r9,660(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// b 0x82dc5ae8
	goto loc_82DC5AE8;
loc_82DC5AE4:
	// lbz r9,644(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 644);
loc_82DC5AE8:
	// rotlwi r9,r9,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 2);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r10,656(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dc5b10
	if (!ctx.cr6.lt) goto loc_82DC5B10;
loc_82DC5B04:
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// stb r9,661(r3)
	PPC_STORE_U8(ctx.r3.u32 + 661, ctx.r9.u8);
loc_82DC5B10:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC5B1C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC5B24"))) PPC_WEAK_FUNC(sub_82DC5B24);
PPC_FUNC_IMPL(__imp__sub_82DC5B24) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC5B28"))) PPC_WEAK_FUNC(sub_82DC5B28);
PPC_FUNC_IMPL(__imp__sub_82DC5B28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DC5B30;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r10,695(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 695);
	// lwz r29,0(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// lwz r30,704(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 704);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dc5bcc
	if (ctx.cr6.gt) goto loc_82DC5BCC;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,23404
	ctx.r12.s64 = ctx.r12.s64 + 23404;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC5B7C;
	case 1:
		goto loc_82DC5B90;
	case 2:
		goto loc_82DC5BB8;
	case 3:
		goto loc_82DC5BC0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23420(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23420);
	// lwz r22,23440(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23440);
	// lwz r22,23480(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23480);
	// lwz r22,23488(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23488);
loc_82DC5B7C:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dc5bd0
	goto loc_82DC5BD0;
loc_82DC5B90:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dc5bb0
	if (!ctx.cr6.lt) goto loc_82DC5BB0;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DC5BB0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc5bd0
	goto loc_82DC5BD0;
loc_82DC5BB8:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dc5bd0
	goto loc_82DC5BD0;
loc_82DC5BC0:
	// bl 0x82cb2308
	ctx.lr = 0x82DC5BC4;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dc5bd0
	goto loc_82DC5BD0;
loc_82DC5BCC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DC5BD0:
	// lbz r10,664(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 664);
	// lhz r9,2034(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2034);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// rlwinm r10,r9,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	// srawi r11,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 6;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// rlwinm r9,r11,0,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// beq cr6,0x82dc5bf4
	if (ctx.cr6.eq) goto loc_82DC5BF4;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DC5BF4:
	// lbz r10,662(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r8,663(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 663);
	// add r11,r8,r10
	ctx.r11.u64 = ctx.r8.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dc5c1c
	if (!ctx.cr6.gt) goto loc_82DC5C1C;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
loc_82DC5C1C:
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// cmplwi cr6,r11,128
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 128, ctx.xer);
	// lwz r11,496(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 496);
	// bge cr6,0x82dc5c34
	if (!ctx.cr6.lt) goto loc_82DC5C34;
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// b 0x82dc5c38
	goto loc_82DC5C38;
loc_82DC5C34:
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
loc_82DC5C38:
	// stw r11,496(r29)
	PPC_STORE_U32(ctx.r29.u32 + 496, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbz r11,476(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 476);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r29)
	PPC_STORE_U8(ctx.r29.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC5C54"))) PPC_WEAK_FUNC(sub_82DC5C54);
PPC_FUNC_IMPL(__imp__sub_82DC5C54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC5C58"))) PPC_WEAK_FUNC(sub_82DC5C58);
PPC_FUNC_IMPL(__imp__sub_82DC5C58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DC5C60;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r10,695(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 695);
	// lwz r29,0(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// lwz r30,704(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 704);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dc5cfc
	if (ctx.cr6.gt) goto loc_82DC5CFC;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,23708
	ctx.r12.s64 = ctx.r12.s64 + 23708;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC5CAC;
	case 1:
		goto loc_82DC5CC0;
	case 2:
		goto loc_82DC5CE8;
	case 3:
		goto loc_82DC5CF0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23724);
	// lwz r22,23744(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23744);
	// lwz r22,23784(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23784);
	// lwz r22,23792(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 23792);
loc_82DC5CAC:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dc5d00
	goto loc_82DC5D00;
loc_82DC5CC0:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dc5ce0
	if (!ctx.cr6.lt) goto loc_82DC5CE0;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DC5CE0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc5d00
	goto loc_82DC5D00;
loc_82DC5CE8:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dc5d00
	goto loc_82DC5D00;
loc_82DC5CF0:
	// bl 0x82cb2308
	ctx.lr = 0x82DC5CF4;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dc5d00
	goto loc_82DC5D00;
loc_82DC5CFC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DC5D00:
	// lbz r10,664(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 664);
	// lhz r9,2034(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2034);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// rlwinm r10,r9,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	// srawi r11,r11,7
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 7;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc5d20
	if (ctx.cr6.eq) goto loc_82DC5D20;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DC5D20:
	// lbz r10,662(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// cmplwi cr6,r10,128
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 128, ctx.xer);
	// lwz r10,496(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 496);
	// bge cr6,0x82dc5d38
	if (!ctx.cr6.lt) goto loc_82DC5D38;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dc5d3c
	goto loc_82DC5D3C;
loc_82DC5D38:
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82DC5D3C:
	// stw r11,496(r29)
	PPC_STORE_U32(ctx.r29.u32 + 496, ctx.r11.u32);
	// lbz r10,662(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r9,663(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dc5d68
	if (!ctx.cr6.gt) goto loc_82DC5D68;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
loc_82DC5D68:
	// lbz r11,476(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r29)
	PPC_STORE_U8(ctx.r29.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC5D80"))) PPC_WEAK_FUNC(sub_82DC5D80);
PPC_FUNC_IMPL(__imp__sub_82DC5D80) {
	PPC_FUNC_PROLOGUE();
	// lbz r9,666(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 666);
	// lbz r10,696(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 696);
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r11,r9,27
	ctx.r11.u64 = ctx.r9.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dc5e04
	if (ctx.cr6.gt) goto loc_82DC5E04;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,23984
	ctx.r12.s64 = ctx.r12.s64 + 23984;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC5DF0;
	case 1:
		goto loc_82DC5DC0;
	case 2:
		goto loc_82DC5DE8;
	case 3:
		goto loc_82DC5DF0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,24048(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24048);
	// lwz r22,24000(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24000);
	// lwz r22,24040(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24040);
	// lwz r22,24048(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24048);
loc_82DC5DC0:
	// rlwinm r11,r11,3,21,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0x7F8;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dc5de0
	if (!ctx.cr6.lt) goto loc_82DC5DE0;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DC5DE0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dc5e00
	goto loc_82DC5E00;
loc_82DC5DE8:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dc5e00
	goto loc_82DC5E00;
loc_82DC5DF0:
	// lis r10,-31908
	ctx.r10.s64 = -2091122688;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r10,r10,-19352
	ctx.r10.s64 = ctx.r10.s64 + -19352;
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
loc_82DC5E00:
	// stw r11,628(r3)
	PPC_STORE_U32(ctx.r3.u32 + 628, ctx.r11.u32);
loc_82DC5E04:
	// lwz r11,628(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 628);
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// lbz r10,668(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 668);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// lwz r10,620(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 620);
	// srawi r11,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 6;
	// stw r11,628(r3)
	PPC_STORE_U32(ctx.r3.u32 + 628, ctx.r11.u32);
	// blt cr6,0x82dc5e3c
	if (ctx.cr6.lt) goto loc_82DC5E3C;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dc5e5c
	if (!ctx.cr6.gt) goto loc_82DC5E5C;
	// subfic r11,r10,64
	ctx.xer.ca = ctx.r10.u32 <= 64;
	ctx.r11.s64 = 64 - ctx.r10.s64;
	// b 0x82dc5e58
	goto loc_82DC5E58;
loc_82DC5E3C:
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// extsh r11,r11
	ctx.r11.s64 = ctx.r11.s16;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc5e50
	if (!ctx.cr6.lt) goto loc_82DC5E50;
	// stw r10,628(r3)
	PPC_STORE_U32(ctx.r3.u32 + 628, ctx.r10.u32);
loc_82DC5E50:
	// lwz r11,628(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 628);
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DC5E58:
	// stw r11,628(r3)
	PPC_STORE_U32(ctx.r3.u32 + 628, ctx.r11.u32);
loc_82DC5E5C:
	// lbz r11,667(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 667);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r11.u8);
	// ble cr6,0x82dc5e80
	if (!ctx.cr6.gt) goto loc_82DC5E80;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r11.u8);
loc_82DC5E80:
	// lbz r11,476(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r8)
	PPC_STORE_U8(ctx.r8.u32 + 476, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC5E94"))) PPC_WEAK_FUNC(sub_82DC5E94);
PPC_FUNC_IMPL(__imp__sub_82DC5E94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC5E98"))) PPC_WEAK_FUNC(sub_82DC5E98);
PPC_FUNC_IMPL(__imp__sub_82DC5E98) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,697(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 697);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dc5f14
	if (ctx.cr6.gt) goto loc_82DC5F14;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,24256
	ctx.r12.s64 = ctx.r12.s64 + 24256;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC5EFC;
	case 1:
		goto loc_82DC5ED0;
	case 2:
		goto loc_82DC5EE0;
	case 3:
		goto loc_82DC5EFC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,24316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24316);
	// lwz r22,24272(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24272);
	// lwz r22,24288(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24288);
	// lwz r22,24316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24316);
loc_82DC5ED0:
	// lwz r10,672(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 672);
	// subfic r10,r10,128
	ctx.xer.ca = ctx.r10.u32 <= 128;
	ctx.r10.s64 = 128 - ctx.r10.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// b 0x82dc5f10
	goto loc_82DC5F10;
loc_82DC5EE0:
	// lwz r10,672(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 672);
	// cmpwi cr6,r10,128
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 128, ctx.xer);
	// bge cr6,0x82dc5ef4
	if (!ctx.cr6.lt) goto loc_82DC5EF4;
	// li r10,64
	ctx.r10.s64 = 64;
	// b 0x82dc5f10
	goto loc_82DC5F10;
loc_82DC5EF4:
	// li r10,-64
	ctx.r10.s64 = -64;
	// b 0x82dc5f10
	goto loc_82DC5F10;
loc_82DC5EFC:
	// lis r10,-31908
	ctx.r10.s64 = -2091122688;
	// lwz r9,672(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 672);
	// addi r10,r10,-19320
	ctx.r10.s64 = ctx.r10.s64 + -19320;
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
loc_82DC5F10:
	// stw r10,500(r11)
	PPC_STORE_U32(ctx.r11.u32 + 500, ctx.r10.u32);
loc_82DC5F14:
	// lwz r9,500(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	// lbz r10,677(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 677);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// srawi r10,r10,5
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 5;
	// stw r10,500(r11)
	PPC_STORE_U32(ctx.r11.u32 + 500, ctx.r10.u32);
	// lwz r9,672(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 672);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lwz r9,488(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// blt cr6,0x82dc5f4c
	if (ctx.cr6.lt) goto loc_82DC5F4C;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dc5f6c
	if (!ctx.cr6.gt) goto loc_82DC5F6C;
	// subfic r10,r9,64
	ctx.xer.ca = ctx.r9.u32 <= 64;
	ctx.r10.s64 = 64 - ctx.r9.s64;
	// b 0x82dc5f68
	goto loc_82DC5F68;
loc_82DC5F4C:
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dc5f60
	if (!ctx.cr6.lt) goto loc_82DC5F60;
	// stw r9,500(r11)
	PPC_STORE_U32(ctx.r11.u32 + 500, ctx.r9.u32);
loc_82DC5F60:
	// lwz r10,500(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	// neg r10,r10
	ctx.r10.s64 = -ctx.r10.s64;
loc_82DC5F68:
	// stw r10,500(r11)
	PPC_STORE_U32(ctx.r11.u32 + 500, ctx.r10.u32);
loc_82DC5F6C:
	// lwz r9,672(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 672);
	// lbz r10,676(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 676);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// stw r10,672(r3)
	PPC_STORE_U32(ctx.r3.u32 + 672, ctx.r10.u32);
	// ble cr6,0x82dc5f8c
	if (!ctx.cr6.gt) goto loc_82DC5F8C;
	// addi r10,r10,-256
	ctx.r10.s64 = ctx.r10.s64 + -256;
	// stw r10,672(r3)
	PPC_STORE_U32(ctx.r3.u32 + 672, ctx.r10.u32);
loc_82DC5F8C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC5FA0"))) PPC_WEAK_FUNC(sub_82DC5FA0);
PPC_FUNC_IMPL(__imp__sub_82DC5FA0) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d8
	ctx.lr = 0x82DC5FA8;
	__savegprlr_24(ctx, base);
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpw cr6,r11,r6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82dc5ff4
	if (!ctx.cr6.lt) goto loc_82DC5FF4;
	// rlwinm r3,r11,1,0,30
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r31,0(r4)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lhz r11,1(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// cmpw cr6,r31,r11
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dc6024
	if (ctx.cr6.eq) goto loc_82DC6024;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// add. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// bge 0x82dc5ff4
	if (!ctx.cr0.lt) goto loc_82DC5FF4;
	// cmpwi cr6,r8,2
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 2, ctx.xer);
	// bne cr6,0x82dc5ff4
	if (!ctx.cr6.eq) goto loc_82DC5FF4;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
loc_82DC5FF4:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// lhz r9,8(r4)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r4.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r10,103(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 103);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// stw r9,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r9.u32);
	// lbz r11,476(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 476);
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stb r11,476(r5)
	PPC_STORE_U8(ctx.r5.u32 + 476, ctx.r11.u8);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC6024:
	// lwz r26,92(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r25,0
	ctx.r25.s64 = 0;
	// lwz r27,84(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DC6030:
	// lwz r31,4(r4)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpw cr6,r31,r6
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82dc5ff4
	if (!ctx.cr6.lt) goto loc_82DC5FF4;
	// rlwinm r28,r8,0,30,30
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x2;
loc_82DC6040:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// rlwinm r30,r31,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r3,r11,1,0,30
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r30,r31,r30
	ctx.r30.u64 = ctx.r31.u64 + ctx.r30.u64;
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r11,r30,r7
	ctx.r11.u64 = ctx.r30.u64 + ctx.r7.u64;
	// add r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 + ctx.r7.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lbz r30,0(r11)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r29,0(r3)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r24,r30
	ctx.r24.s64 = ctx.r30.s8;
	// lhz r30,1(r11)
	ctx.r30.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// extsb r29,r29
	ctx.r29.s64 = ctx.r29.s8;
	// lhz r3,1(r3)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + 1);
	// rlwinm r11,r24,16,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 16) & 0xFFFF0000;
	// rlwinm r29,r29,16,0,15
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 16) & 0xFFFF0000;
	// beq cr6,0x82dc60c4
	if (ctx.cr6.eq) goto loc_82DC60C4;
	// cmpw cr6,r31,r26
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r26.s32, ctx.xer);
	// blt cr6,0x82dc60c4
	if (ctx.cr6.lt) goto loc_82DC60C4;
	// lbz r24,600(r5)
	ctx.r24.u64 = PPC_LOAD_U8(ctx.r5.u32 + 600);
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// bne cr6,0x82dc60c4
	if (!ctx.cr6.eq) goto loc_82DC60C4;
	// cmpw cr6,r26,r27
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r27.s32, ctx.xer);
	// beq cr6,0x82dc6178
	if (ctx.cr6.eq) goto loc_82DC6178;
	// rlwinm r11,r27,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r27,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r27.u32);
	// mr r31,r27
	ctx.r31.u64 = ctx.r27.u64;
	// add r11,r27,r11
	ctx.r11.u64 = ctx.r27.u64 + ctx.r11.u64;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lhz r11,1(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// b 0x82dc6040
	goto loc_82DC6040;
loc_82DC60C4:
	// rlwinm r24,r8,0,29,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r24,0
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// beq cr6,0x82dc6104
	if (ctx.cr6.eq) goto loc_82DC6104;
	// cmpw cr6,r31,r10
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc6104
	if (ctx.cr6.lt) goto loc_82DC6104;
	// rlwinm r11,r9,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// ble cr6,0x82dc6180
	if (!ctx.cr6.gt) goto loc_82DC6180;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// mr r31,r9
	ctx.r31.u64 = ctx.r9.u64;
	// lhz r11,1(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// b 0x82dc6040
	goto loc_82DC6040;
loc_82DC6104:
	// lwz r28,4(r4)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// addi r24,r6,-1
	ctx.r24.s64 = ctx.r6.s64 + -1;
	// cmpw cr6,r28,r24
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r24.s32, ctx.xer);
	// beq cr6,0x82dc6194
	if (ctx.cr6.eq) goto loc_82DC6194;
	// subf r3,r30,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r30.s64;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dc6144
	if (ctx.cr6.eq) goto loc_82DC6144;
	// subf r30,r11,r29
	ctx.r30.s64 = ctx.r29.s64 - ctx.r11.s64;
	// twllei r3,0
	// rotlwi r31,r30,1
	ctx.r31.u64 = __builtin_rotateleft32(ctx.r30.u32, 1);
	// divw r30,r30,r3
	ctx.r30.s32 = ctx.r30.s32 / ctx.r3.s32;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// andc r3,r3,r31
	ctx.r3.u64 = ctx.r3.u64 & ~ctx.r31.u64;
	// twlgei r3,-1
	// stw r30,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r30.u32);
	// b 0x82dc6148
	goto loc_82DC6148;
loc_82DC6144:
	// stw r25,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r25.u32);
loc_82DC6148:
	// addi r3,r28,1
	ctx.r3.s64 = ctx.r28.s64 + 1;
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r3.u32);
	// rlwinm r3,r11,1,0,30
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r31,0(r4)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lhz r11,1(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// cmpw cr6,r31,r11
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dc6030
	if (ctx.cr6.eq) goto loc_82DC6030;
	// b 0x82dc5ff4
	goto loc_82DC5FF4;
loc_82DC6178:
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
loc_82DC6180:
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC6194:
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// li r10,1
	ctx.r10.s64 = 1;
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// stb r10,20(r4)
	PPC_STORE_U8(ctx.r4.u32 + 20, ctx.r10.u8);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC61B8"))) PPC_WEAK_FUNC(sub_82DC61B8);
PPC_FUNC_IMPL(__imp__sub_82DC61B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d8
	ctx.lr = 0x82DC61C0;
	__savegprlr_24(ctx, base);
	// lwz r11,568(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 568);
	// lbz r10,1072(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1072);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dc6200
	if (!ctx.cr6.lt) goto loc_82DC6200;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r9,564(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 564);
	// addi r28,r5,1074
	ctx.r28.s64 = ctx.r5.s64 + 1074;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lhz r11,1(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dc623c
	if (ctx.cr6.eq) goto loc_82DC623C;
	// lwz r10,572(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 572);
	// lwz r11,580(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 580);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,572(r4)
	PPC_STORE_U32(ctx.r4.u32 + 572, ctx.r11.u32);
loc_82DC6200:
	// lbz r11,1071(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1071);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc621c
	if (!ctx.cr6.eq) goto loc_82DC621C;
	// lbz r11,476(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 476);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r4)
	PPC_STORE_U8(ctx.r4.u32 + 476, ctx.r11.u8);
loc_82DC621C:
	// lwz r11,564(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 564);
	// li r3,0
	ctx.r3.s64 = 0;
	// lhz r10,572(r4)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 572);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// stw r11,564(r4)
	PPC_STORE_U32(ctx.r4.u32 + 564, ctx.r11.u32);
	// stw r10,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r10.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC623C:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r8,r11,-18528
	ctx.r8.s64 = ctx.r11.s64 + -18528;
loc_82DC6248:
	// lwz r29,568(r4)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r4.u32 + 568);
loc_82DC624C:
	// lhz r10,2034(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2034);
	// addi r11,r29,1
	ctx.r11.s64 = ctx.r29.s64 + 1;
	// rlwinm r9,r29,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// add r9,r29,r9
	ctx.r9.u64 = ctx.r29.u64 + ctx.r9.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r11,r9,r28
	ctx.r11.u64 = ctx.r9.u64 + ctx.r28.u64;
	// add r30,r10,r28
	ctx.r30.u64 = ctx.r10.u64 + ctx.r28.u64;
	// lhz r27,1(r11)
	ctx.r27.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// lhz r26,1(r30)
	ctx.r26.u64 = PPC_LOAD_U16(ctx.r30.u32 + 1);
	// bne cr6,0x82dc63d0
	if (!ctx.cr6.eq) goto loc_82DC63D0;
	// lbz r10,1071(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1071);
	// rlwinm r10,r10,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc63d0
	if (!ctx.cr6.eq) goto loc_82DC63D0;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dc6300
	if (ctx.cr6.eq) goto loc_82DC6300;
	// lwz r10,464(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// addi r31,r8,4
	ctx.r31.s64 = ctx.r8.s64 + 4;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// add r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 + ctx.r6.u64;
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mulli r10,r10,8363
	ctx.r10.s64 = ctx.r10.s64 * 8363;
	// lwzx r31,r7,r31
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// mulli r31,r31,8363
	ctx.r31.s64 = ctx.r31.s64 * 8363;
	// mulli r24,r7,8363
	ctx.r24.s64 = ctx.r7.s64 * 8363;
	// divwu r7,r31,r9
	ctx.r7.u32 = ctx.r31.u32 / ctx.r9.u32;
	// divwu r31,r24,r9
	ctx.r31.u32 = ctx.r24.u32 / ctx.r9.u32;
	// twllei r9,0
	// add r7,r7,r31
	ctx.r7.u64 = ctx.r7.u64 + ctx.r31.u64;
	// srawi r7,r7,1
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x1) != 0);
	ctx.r7.s64 = ctx.r7.s32 >> 1;
	// addze r7,r7
	temp.s64 = ctx.r7.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r7.s64 = temp.s64;
	// b 0x82dc6330
	goto loc_82DC6330;
loc_82DC6300:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,464(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// add r7,r10,r6
	ctx.r7.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r10,r9,8363
	ctx.r10.s64 = ctx.r9.s64 * 8363;
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r7,r9,8363
	ctx.r7.s64 = ctx.r9.s64 * 8363;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// divwu r7,r7,r9
	ctx.r7.u32 = ctx.r7.u32 / ctx.r9.u32;
loc_82DC6330:
	// twllei r9,0
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// twllei r9,0
	// divwu r9,r10,r9
	ctx.r9.u32 = ctx.r10.u32 / ctx.r9.u32;
	// twllei r11,0
	// subf r7,r7,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r7.s64;
	// lbz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// twllei r11,0
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// clrlwi r31,r9,31
	ctx.r31.u64 = ctx.r9.u32 & 0x1;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq cr6,0x82dc63ac
	if (ctx.cr6.eq) goto loc_82DC63AC;
	// lbz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// addi r31,r8,4
	ctx.r31.s64 = ctx.r8.s64 + 4;
	// divwu r30,r10,r11
	ctx.r30.u32 = ctx.r10.u32 / ctx.r11.u32;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// twllei r11,0
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r10,r10,8363
	ctx.r10.s64 = ctx.r10.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r10,r10,r11
	ctx.r10.u32 = ctx.r10.u32 / ctx.r11.u32;
	// divwu r11,r9,r11
	ctx.r11.u32 = ctx.r9.u32 / ctx.r11.u32;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// subf r11,r11,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r11.s64;
	// b 0x82dc63e8
	goto loc_82DC63E8;
loc_82DC63AC:
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r9,r9,r11
	ctx.r9.u32 = ctx.r9.u32 / ctx.r11.u32;
	// divwu r11,r10,r11
	ctx.r11.u32 = ctx.r10.u32 / ctx.r11.u32;
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// b 0x82dc63e8
	goto loc_82DC63E8;
loc_82DC63D0:
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// rlwinm r7,r11,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r11,r10,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
loc_82DC63E8:
	// lbz r10,1071(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1071);
	// rlwinm r31,r11,16,0,15
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0xFFFF0000;
	// rlwinm r7,r7,16,0,15
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 16) & 0xFFFF0000;
	// rlwinm r11,r10,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6448
	if (ctx.cr6.eq) goto loc_82DC6448;
	// lbz r9,1158(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1158);
	// cmpw cr6,r29,r9
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc6448
	if (ctx.cr6.lt) goto loc_82DC6448;
	// lbz r11,600(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 600);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6448
	if (!ctx.cr6.eq) goto loc_82DC6448;
	// lbz r11,1157(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1157);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dc650c
	if (ctx.cr6.eq) goto loc_82DC650C;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r11,568(r4)
	PPC_STORE_U32(ctx.r4.u32 + 568, ctx.r11.u32);
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + ctx.r28.u64;
	// lhz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 1);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,564(r4)
	PPC_STORE_U32(ctx.r4.u32 + 564, ctx.r11.u32);
	// b 0x82dc624c
	goto loc_82DC624C;
loc_82DC6448:
	// rlwinm r11,r10,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6490
	if (ctx.cr6.eq) goto loc_82DC6490;
	// lbz r10,1156(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1156);
	// cmpw cr6,r29,r10
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc6490
	if (ctx.cr6.lt) goto loc_82DC6490;
	// lbz r11,1155(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1155);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82dc6620
	if (!ctx.cr6.gt) goto loc_82DC6620;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r11,568(r4)
	PPC_STORE_U32(ctx.r4.u32 + 568, ctx.r11.u32);
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + ctx.r28.u64;
	// lhz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 1);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,564(r4)
	PPC_STORE_U32(ctx.r4.u32 + 564, ctx.r11.u32);
	// b 0x82dc624c
	goto loc_82DC624C;
loc_82DC6490:
	// lbz r11,1072(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1072);
	// lwz r10,568(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 568);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dc6738
	if (ctx.cr6.eq) goto loc_82DC6738;
	// subf r11,r27,r26
	ctx.r11.s64 = ctx.r26.s64 - ctx.r27.s64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc64d4
	if (ctx.cr6.eq) goto loc_82DC64D4;
	// subf r9,r7,r31
	ctx.r9.s64 = ctx.r31.s64 - ctx.r7.s64;
	// twllei r11,0
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r9,r9,r11
	ctx.r9.s32 = ctx.r9.s32 / ctx.r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// twlgei r11,-1
	// stw r9,580(r4)
	PPC_STORE_U32(ctx.r4.u32 + 580, ctx.r9.u32);
	// b 0x82dc64d8
	goto loc_82DC64D8;
loc_82DC64D4:
	// stw r25,580(r4)
	PPC_STORE_U32(ctx.r4.u32 + 580, ctx.r25.u32);
loc_82DC64D8:
	// lwz r11,568(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 568);
	// stw r7,572(r4)
	PPC_STORE_U32(ctx.r4.u32 + 572, ctx.r7.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,568(r4)
	PPC_STORE_U32(ctx.r4.u32 + 568, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r9,564(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 564);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lhz r11,1(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 1);
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82dc6248
	if (ctx.cr6.eq) goto loc_82DC6248;
	// b 0x82dc6200
	goto loc_82DC6200;
loc_82DC650C:
	// lhz r11,2034(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2034);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6600
	if (!ctx.cr6.eq) goto loc_82DC6600;
	// lbz r11,1071(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1071);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6600
	if (!ctx.cr6.eq) goto loc_82DC6600;
	// rlwinm r11,r29,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lbzx r10,r11,r28
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dc65b8
	if (ctx.cr6.eq) goto loc_82DC65B8;
	// lbzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// addi r7,r8,4
	ctx.r7.s64 = ctx.r8.s64 + 4;
	// lwz r10,464(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// li r3,0
	ctx.r3.s64 = 0;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// add r9,r11,r6
	ctx.r9.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r11,0
	// twllei r11,0
	// twllei r11,0
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// mulli r8,r7,8363
	ctx.r8.s64 = ctx.r7.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// mulli r7,r10,8363
	ctx.r7.s64 = ctx.r10.s64 * 8363;
	// divwu r9,r9,r11
	ctx.r9.u32 = ctx.r9.u32 / ctx.r11.u32;
	// divwu r10,r8,r11
	ctx.r10.u32 = ctx.r8.u32 / ctx.r11.u32;
	// divwu r11,r7,r11
	ctx.r11.u32 = ctx.r7.u32 / ctx.r11.u32;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC65B8:
	// lwz r9,464(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// srawi r11,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r10.s32 >> 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// add r10,r11,r6
	ctx.r10.u64 = ctx.r11.u64 + ctx.r6.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r11,0
	// twllei r11,0
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r10,r10,8363
	ctx.r10.s64 = ctx.r10.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r10,r10,r11
	ctx.r10.u32 = ctx.r10.u32 / ctx.r11.u32;
	// divwu r11,r9,r11
	ctx.r11.u32 = ctx.r9.u32 / ctx.r11.u32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC6600:
	// rlwinm r11,r29,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// li r3,0
	ctx.r3.s64 = 0;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lbzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC6620:
	// lhz r11,2034(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2034);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6714
	if (!ctx.cr6.eq) goto loc_82DC6714;
	// lbz r11,1071(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1071);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6714
	if (!ctx.cr6.eq) goto loc_82DC6714;
	// rlwinm r11,r29,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lbzx r10,r11,r28
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dc66cc
	if (ctx.cr6.eq) goto loc_82DC66CC;
	// lbzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// addi r7,r8,4
	ctx.r7.s64 = ctx.r8.s64 + 4;
	// lwz r10,464(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// li r3,0
	ctx.r3.s64 = 0;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// add r9,r11,r6
	ctx.r9.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r11,0
	// twllei r11,0
	// twllei r11,0
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// mulli r8,r7,8363
	ctx.r8.s64 = ctx.r7.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// mulli r7,r10,8363
	ctx.r7.s64 = ctx.r10.s64 * 8363;
	// divwu r9,r9,r11
	ctx.r9.u32 = ctx.r9.u32 / ctx.r11.u32;
	// divwu r10,r8,r11
	ctx.r10.u32 = ctx.r8.u32 / ctx.r11.u32;
	// divwu r11,r7,r11
	ctx.r11.u32 = ctx.r7.u32 / ctx.r11.u32;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC66CC:
	// lwz r9,464(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// srawi r11,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r10.s32 >> 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// add r10,r11,r6
	ctx.r10.u64 = ctx.r11.u64 + ctx.r6.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r11,0
	// twllei r11,0
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r10,r10,8363
	ctx.r10.s64 = ctx.r10.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r10,r10,r11
	ctx.r10.u32 = ctx.r10.u32 / ctx.r11.u32;
	// divwu r11,r9,r11
	ctx.r11.u32 = ctx.r9.u32 / ctx.r11.u32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC6714:
	// lbz r11,1155(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1155);
	// li r3,0
	ctx.r3.s64 = 0;
	// rotlwi r10,r11,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC6738:
	// lhz r11,2034(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2034);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc683c
	if (!ctx.cr6.eq) goto loc_82DC683C;
	// lbz r11,1071(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1071);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc683c
	if (!ctx.cr6.eq) goto loc_82DC683C;
	// rlwinm r11,r29,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lbzx r10,r11,r28
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dc67ec
	if (ctx.cr6.eq) goto loc_82DC67EC;
	// lbzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// addi r7,r8,4
	ctx.r7.s64 = ctx.r8.s64 + 4;
	// lwz r10,464(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// li r3,0
	ctx.r3.s64 = 0;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// add r9,r11,r6
	ctx.r9.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r11,0
	// twllei r11,0
	// twllei r11,0
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// mulli r8,r7,8363
	ctx.r8.s64 = ctx.r7.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// mulli r7,r10,8363
	ctx.r7.s64 = ctx.r10.s64 * 8363;
	// divwu r9,r9,r11
	ctx.r9.u32 = ctx.r9.u32 / ctx.r11.u32;
	// divwu r10,r8,r11
	ctx.r10.u32 = ctx.r8.u32 / ctx.r11.u32;
	// divwu r11,r7,r11
	ctx.r11.u32 = ctx.r7.u32 / ctx.r11.u32;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,584(r4)
	PPC_STORE_U8(ctx.r4.u32 + 584, ctx.r11.u8);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC67EC:
	// lwz r9,464(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// srawi r11,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r10.s32 >> 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// add r10,r11,r6
	ctx.r10.u64 = ctx.r11.u64 + ctx.r6.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r11,0
	// twllei r11,0
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// mulli r10,r10,8363
	ctx.r10.s64 = ctx.r10.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r10,r10,r11
	ctx.r10.u32 = ctx.r10.u32 / ctx.r11.u32;
	// divwu r11,r9,r11
	ctx.r11.u32 = ctx.r9.u32 / ctx.r11.u32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,584(r4)
	PPC_STORE_U8(ctx.r4.u32 + 584, ctx.r11.u8);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
loc_82DC683C:
	// rlwinm r11,r29,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// li r3,0
	ctx.r3.s64 = 0;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lbzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r28.u32);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r11,576(r4)
	PPC_STORE_U32(ctx.r4.u32 + 576, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,584(r4)
	PPC_STORE_U8(ctx.r4.u32 + 584, ctx.r11.u8);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC6864"))) PPC_WEAK_FUNC(sub_82DC6864);
PPC_FUNC_IMPL(__imp__sub_82DC6864) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC6868"))) PPC_WEAK_FUNC(sub_82DC6868);
PPC_FUNC_IMPL(__imp__sub_82DC6868) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lwz r9,464(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 464);
	// li r11,0
	ctx.r11.s64 = 0;
	// lbz r10,46(r9)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + 46);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dc68f8
	if (ctx.cr6.gt) goto loc_82DC68F8;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,26772
	ctx.r12.s64 = ctx.r12.s64 + 26772;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC68E4;
	case 1:
		goto loc_82DC68A4;
	case 2:
		goto loc_82DC68C8;
	case 3:
		goto loc_82DC68E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26852(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26852);
	// lwz r22,26788(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26788);
	// lwz r22,26824(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26824);
	// lwz r22,26852(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26852);
loc_82DC68A4:
	// lwz r11,592(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 592);
	// addi r11,r11,128
	ctx.r11.s64 = ctx.r11.s64 + 128;
	// srawi r10,r11,8
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xFF) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 8;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// subfic r11,r11,128
	ctx.xer.ca = ctx.r11.u32 <= 128;
	ctx.r11.s64 = 128 - ctx.r11.s64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// b 0x82dc68f8
	goto loc_82DC68F8;
loc_82DC68C8:
	// lwz r11,592(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 592);
	// cmpwi cr6,r11,128
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 128, ctx.xer);
	// bge cr6,0x82dc68dc
	if (!ctx.cr6.lt) goto loc_82DC68DC;
	// li r11,64
	ctx.r11.s64 = 64;
	// b 0x82dc68f8
	goto loc_82DC68F8;
loc_82DC68DC:
	// li r11,-64
	ctx.r11.s64 = -64;
	// b 0x82dc68f8
	goto loc_82DC68F8;
loc_82DC68E4:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lwz r10,592(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 592);
	// addi r11,r11,-19320
	ctx.r11.s64 = ctx.r11.s64 + -19320;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
loc_82DC68F8:
	// lwz r10,596(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 596);
	// lis r8,1
	ctx.r8.s64 = 65536;
	// lbz r7,45(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 45);
	// lwz r6,496(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 496);
	// mullw r7,r7,r10
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r10.s32);
	// mullw r11,r7,r11
	ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r11.s32);
	// srawi r11,r11,23
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7FFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 23;
	// subf r11,r11,r6
	ctx.r11.s64 = ctx.r6.s64 - ctx.r11.s64;
	// stw r11,496(r4)
	PPC_STORE_U32(ctx.r4.u32 + 496, ctx.r11.u32);
	// lbz r11,47(r9)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 47);
	// rotlwi r11,r11,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// stw r11,596(r4)
	PPC_STORE_U32(ctx.r4.u32 + 596, ctx.r11.u32);
	// ble cr6,0x82dc6938
	if (!ctx.cr6.gt) goto loc_82DC6938;
	// stw r8,596(r4)
	PPC_STORE_U32(ctx.r4.u32 + 596, ctx.r8.u32);
loc_82DC6938:
	// lbz r11,44(r9)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 44);
	// lwz r10,592(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 592);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// stw r11,592(r4)
	PPC_STORE_U32(ctx.r4.u32 + 592, ctx.r11.u32);
	// ble cr6,0x82dc6958
	if (!ctx.cr6.gt) goto loc_82DC6958;
	// addi r11,r11,-256
	ctx.r11.s64 = ctx.r11.s64 + -256;
	// stw r11,592(r4)
	PPC_STORE_U32(ctx.r4.u32 + 592, ctx.r11.u32);
loc_82DC6958:
	// lbz r11,476(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r4)
	PPC_STORE_U8(ctx.r4.u32 + 476, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC696C"))) PPC_WEAK_FUNC(sub_82DC696C);
PPC_FUNC_IMPL(__imp__sub_82DC696C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC6970"))) PPC_WEAK_FUNC(sub_82DC6970);
PPC_FUNC_IMPL(__imp__sub_82DC6970) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DC6978;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// clrlwi r5,r5,24
	ctx.r5.u64 = ctx.r5.u32 & 0xFF;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// li r3,64
	ctx.r3.s64 = 64;
	// clrlwi r8,r11,24
	ctx.r8.u64 = ctx.r11.u32 & 0xFF;
	// lwz r31,0(r7)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r30,704(r7)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r7.u32 + 704);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82dc6a5c
	if (ctx.cr6.eq) goto loc_82DC6A5C;
	// clrlwi r9,r8,24
	ctx.r9.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r9,64
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 64, ctx.xer);
	// bgt cr6,0x82dc69b8
	if (ctx.cr6.gt) goto loc_82DC69B8;
	// stw r9,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r9.u32);
loc_82DC69B8:
	// cmplwi cr6,r9,65
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 65, ctx.xer);
	// blt cr6,0x82dc69f8
	if (ctx.cr6.lt) goto loc_82DC69F8;
	// cmplwi cr6,r9,74
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 74, ctx.xer);
	// bgt cr6,0x82dc69f8
	if (ctx.cr6.gt) goto loc_82DC69F8;
	// addi r11,r9,191
	ctx.r11.s64 = ctx.r9.s64 + 191;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc69dc
	if (ctx.cr6.eq) goto loc_82DC69DC;
	// stb r11,703(r7)
	PPC_STORE_U8(ctx.r7.u32 + 703, ctx.r11.u8);
loc_82DC69DC:
	// lwz r10,620(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 620);
	// lbz r11,703(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 703);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r11.u32);
	// ble cr6,0x82dc69f8
	if (!ctx.cr6.gt) goto loc_82DC69F8;
	// stw r3,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r3.u32);
loc_82DC69F8:
	// cmplwi cr6,r9,75
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 75, ctx.xer);
	// blt cr6,0x82dc6a34
	if (ctx.cr6.lt) goto loc_82DC6A34;
	// cmplwi cr6,r9,84
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 84, ctx.xer);
	// bgt cr6,0x82dc6a34
	if (ctx.cr6.gt) goto loc_82DC6A34;
	// addi r11,r9,181
	ctx.r11.s64 = ctx.r9.s64 + 181;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6a1c
	if (ctx.cr6.eq) goto loc_82DC6A1C;
	// stb r11,703(r7)
	PPC_STORE_U8(ctx.r7.u32 + 703, ctx.r11.u8);
loc_82DC6A1C:
	// lwz r11,620(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 620);
	// lbz r10,703(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 703);
	// subf. r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r11.u32);
	// bge 0x82dc6a34
	if (!ctx.cr0.lt) goto loc_82DC6A34;
	// stw r29,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r29.u32);
loc_82DC6A34:
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// blt cr6,0x82dc6a5c
	if (ctx.cr6.lt) goto loc_82DC6A5C;
	// cmplwi cr6,r9,192
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 192, ctx.xer);
	// bgt cr6,0x82dc6a5c
	if (ctx.cr6.gt) goto loc_82DC6A5C;
	// addi r11,r9,-128
	ctx.r11.s64 = ctx.r9.s64 + -128;
	// stw r11,624(r7)
	PPC_STORE_U32(ctx.r7.u32 + 624, ctx.r11.u32);
	// lbz r10,476(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// ori r11,r10,4
	ctx.r11.u64 = ctx.r10.u64 | 4;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DC6A5C:
	// clrlwi r6,r8,24
	ctx.r6.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r6,85
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 85, ctx.xer);
	// blt cr6,0x82dc6aa8
	if (ctx.cr6.lt) goto loc_82DC6AA8;
	// cmplwi cr6,r6,94
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 94, ctx.xer);
	// bgt cr6,0x82dc6aa8
	if (ctx.cr6.gt) goto loc_82DC6AA8;
	// addi r11,r6,171
	ctx.r11.s64 = ctx.r6.s64 + 171;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6a84
	if (ctx.cr6.eq) goto loc_82DC6A84;
	// stb r11,703(r7)
	PPC_STORE_U8(ctx.r7.u32 + 703, ctx.r11.u8);
loc_82DC6A84:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82dc6aa8
	if (!ctx.cr6.eq) goto loc_82DC6AA8;
	// lwz r10,620(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 620);
	// lbz r11,703(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 703);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r11.u32);
	// ble cr6,0x82dc6aa8
	if (!ctx.cr6.gt) goto loc_82DC6AA8;
	// stw r3,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r3.u32);
loc_82DC6AA8:
	// cmplwi cr6,r6,95
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 95, ctx.xer);
	// blt cr6,0x82dc6aec
	if (ctx.cr6.lt) goto loc_82DC6AEC;
	// cmplwi cr6,r6,104
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 104, ctx.xer);
	// bgt cr6,0x82dc6aec
	if (ctx.cr6.gt) goto loc_82DC6AEC;
	// addi r11,r6,161
	ctx.r11.s64 = ctx.r6.s64 + 161;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6acc
	if (ctx.cr6.eq) goto loc_82DC6ACC;
	// stb r11,703(r7)
	PPC_STORE_U8(ctx.r7.u32 + 703, ctx.r11.u8);
loc_82DC6ACC:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82dc6aec
	if (!ctx.cr6.eq) goto loc_82DC6AEC;
	// lwz r11,620(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 620);
	// lbz r10,703(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 703);
	// subf. r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r11.u32);
	// bge 0x82dc6aec
	if (!ctx.cr0.lt) goto loc_82DC6AEC;
	// stw r29,620(r7)
	PPC_STORE_U32(ctx.r7.u32 + 620, ctx.r29.u32);
loc_82DC6AEC:
	// cmplwi cr6,r6,105
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 105, ctx.xer);
	// blt cr6,0x82dc6b24
	if (ctx.cr6.lt) goto loc_82DC6B24;
	// cmplwi cr6,r6,114
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 114, ctx.xer);
	// bgt cr6,0x82dc6b24
	if (ctx.cr6.gt) goto loc_82DC6B24;
	// addi r11,r6,151
	ctx.r11.s64 = ctx.r6.s64 + 151;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6b10
	if (ctx.cr6.eq) goto loc_82DC6B10;
	// stb r11,644(r7)
	PPC_STORE_U8(ctx.r7.u32 + 644, ctx.r11.u8);
loc_82DC6B10:
	// lbz r11,644(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 644);
	// lwz r10,480(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// rotlwi r11,r11,4
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 4);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r11.u32);
loc_82DC6B24:
	// cmplwi cr6,r6,115
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 115, ctx.xer);
	// blt cr6,0x82dc6b78
	if (ctx.cr6.lt) goto loc_82DC6B78;
	// cmplwi cr6,r6,124
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 124, ctx.xer);
	// bgt cr6,0x82dc6b78
	if (ctx.cr6.gt) goto loc_82DC6B78;
	// addi r11,r6,141
	ctx.r11.s64 = ctx.r6.s64 + 141;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6b48
	if (ctx.cr6.eq) goto loc_82DC6B48;
	// stb r11,644(r7)
	PPC_STORE_U8(ctx.r7.u32 + 644, ctx.r11.u8);
loc_82DC6B48:
	// lbz r11,644(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 644);
	// lwz r10,480(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// rotlwi r11,r11,4
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 4);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// stw r11,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r11.u32);
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// bge cr6,0x82dc6b70
	if (!ctx.cr6.lt) goto loc_82DC6B70;
	// ori r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 | 32;
	// b 0x82dc6b74
	goto loc_82DC6B74;
loc_82DC6B70:
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
loc_82DC6B74:
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DC6B78:
	// cmplwi cr6,r6,193
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 193, ctx.xer);
	// blt cr6,0x82dc6bec
	if (ctx.cr6.lt) goto loc_82DC6BEC;
	// cmplwi cr6,r6,202
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 202, ctx.xer);
	// bgt cr6,0x82dc6bec
	if (ctx.cr6.gt) goto loc_82DC6BEC;
	// lwz r11,2040(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2040);
	// addi r10,r6,63
	ctx.r10.s64 = ctx.r6.s64 + 63;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// bne cr6,0x82dc6be4
	if (!ctx.cr6.eq) goto loc_82DC6BE4;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6bc8
	if (ctx.cr6.eq) goto loc_82DC6BC8;
	// lhz r10,2034(r30)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2034);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc6bc4
	if (ctx.cr6.eq) goto loc_82DC6BC4;
	// stb r11,660(r7)
	PPC_STORE_U8(ctx.r7.u32 + 660, ctx.r11.u8);
	// b 0x82dc6bc8
	goto loc_82DC6BC8;
loc_82DC6BC4:
	// stb r11,644(r7)
	PPC_STORE_U8(ctx.r7.u32 + 644, ctx.r11.u8);
loc_82DC6BC8:
	// lwz r11,612(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 612);
	// stw r11,656(r7)
	PPC_STORE_U32(ctx.r7.u32 + 656, ctx.r11.u32);
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc6bec
	if (ctx.cr6.eq) goto loc_82DC6BEC;
	// stb r29,661(r7)
	PPC_STORE_U8(ctx.r7.u32 + 661, ctx.r29.u8);
	// b 0x82dc6bec
	goto loc_82DC6BEC;
loc_82DC6BE4:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82dc5a68
	ctx.lr = 0x82DC6BEC;
	sub_82DC5A68(ctx, base);
loc_82DC6BEC:
	// cmplwi cr6,r6,203
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 203, ctx.xer);
	// blt cr6,0x82dc6c94
	if (ctx.cr6.lt) goto loc_82DC6C94;
	// cmplwi cr6,r6,212
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 212, ctx.xer);
	// bgt cr6,0x82dc6c94
	if (ctx.cr6.gt) goto loc_82DC6C94;
	// lwz r11,2040(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2040);
	// addi r10,r6,53
	ctx.r10.s64 = ctx.r6.s64 + 53;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// bne cr6,0x82dc6c64
	if (!ctx.cr6.eq) goto loc_82DC6C64;
	// clrlwi r10,r11,24
	ctx.r10.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc6c28
	if (ctx.cr6.eq) goto loc_82DC6C28;
	// stb r11,664(r7)
	PPC_STORE_U8(ctx.r7.u32 + 664, ctx.r11.u8);
	// li r11,8
	ctx.r11.s64 = 8;
	// stb r11,665(r7)
	PPC_STORE_U8(ctx.r7.u32 + 665, ctx.r11.u8);
loc_82DC6C28:
	// lbz r11,475(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6c94
	if (!ctx.cr6.eq) goto loc_82DC6C94;
	// lhz r11,2034(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2034);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6c94
	if (!ctx.cr6.eq) goto loc_82DC6C94;
	// lbz r11,665(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 665);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc6c90
	if (!ctx.cr6.eq) goto loc_82DC6C90;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC6C58;
	sub_82DC5C58(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DC6C64:
	// lbz r11,475(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6c94
	if (!ctx.cr6.eq) goto loc_82DC6C94;
	// lbz r11,665(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 665);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc6c90
	if (!ctx.cr6.eq) goto loc_82DC6C90;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC6C84;
	sub_82DC5C58(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DC6C90:
	// bl 0x82dc5b28
	ctx.lr = 0x82DC6C94;
	sub_82DC5B28(ctx, base);
loc_82DC6C94:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC6CA0"))) PPC_WEAK_FUNC(sub_82DC6CA0);
PPC_FUNC_IMPL(__imp__sub_82DC6CA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,14368(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc6cd8
	if (!ctx.cr6.eq) goto loc_82DC6CD8;
	// li r3,33
	ctx.r3.s64 = 33;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82DC6CD8:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,1692
	ctx.r3.s64 = ctx.r31.s64 + 1692;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DC6CF0;
	sub_82CB16F0(ctx, base);
loc_82DC6CF0:
	// lwz r11,14368(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// stw r8,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r8.u32);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82dc6e90
	if (ctx.cr6.eq) goto loc_82DC6E90;
	// rlwinm r10,r6,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x80;
	// addi r11,r6,-1
	ctx.r11.s64 = ctx.r6.s64 + -1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// clrlwi r10,r11,26
	ctx.r10.u64 = ctx.r11.u32 & 0x3F;
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r11,r11,1692
	ctx.r11.s64 = ctx.r11.s64 + 1692;
	// beq cr6,0x82dc6d44
	if (ctx.cr6.eq) goto loc_82DC6D44;
	// lbz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stw r8,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r8.u32);
	// stb r9,1628(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1628, ctx.r9.u8);
	// b 0x82dc6d48
	goto loc_82DC6D48;
loc_82DC6D44:
	// lbz r9,1628(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1628);
loc_82DC6D48:
	// clrlwi r7,r9,24
	ctx.r7.u64 = ctx.r9.u32 & 0xFF;
	// clrlwi r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6d8c
	if (ctx.cr6.eq) goto loc_82DC6D8C;
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r9.u32);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// cmplwi cr6,r9,254
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 254, ctx.xer);
	// blt cr6,0x82dc6d7c
	if (ctx.cr6.lt) goto loc_82DC6D7C;
	// stb r8,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r8.u8);
	// b 0x82dc6d84
	goto loc_82DC6D84;
loc_82DC6D7C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
loc_82DC6D84:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// stb r9,1308(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1308, ctx.r9.u8);
loc_82DC6D8C:
	// rlwinm r9,r7,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6db8
	if (ctx.cr6.eq) goto loc_82DC6DB8;
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// lbz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r9,1(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1, ctx.r9.u8);
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r9.u32);
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// stb r9,1372(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1372, ctx.r9.u8);
loc_82DC6DB8:
	// rlwinm r9,r7,0,29,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6de8
	if (ctx.cr6.eq) goto loc_82DC6DE8;
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// lbz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stb r9,2(r11)
	PPC_STORE_U8(ctx.r11.u32 + 2, ctx.r9.u8);
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r9.u32);
	// lbz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// stb r9,1436(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1436, ctx.r9.u8);
loc_82DC6DE8:
	// rlwinm r9,r7,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6e30
	if (ctx.cr6.eq) goto loc_82DC6E30;
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// lbz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r9,3(r11)
	PPC_STORE_U8(ctx.r11.u32 + 3, ctx.r9.u8);
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r9.u32);
	// lbz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r9,4(r11)
	PPC_STORE_U8(ctx.r11.u32 + 4, ctx.r9.u8);
	// lwz r9,14368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14368);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r9.u32);
	// lbz r9,3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// stb r9,1500(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1500, ctx.r9.u8);
	// lbz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 4);
	// stb r9,1564(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1564, ctx.r9.u8);
loc_82DC6E30:
	// rlwinm r9,r7,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6e44
	if (ctx.cr6.eq) goto loc_82DC6E44;
	// lbz r9,1308(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1308);
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
loc_82DC6E44:
	// rlwinm r9,r7,0,26,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6e58
	if (ctx.cr6.eq) goto loc_82DC6E58;
	// lbz r9,1372(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1372);
	// stb r9,1(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1, ctx.r9.u8);
loc_82DC6E58:
	// rlwinm r9,r7,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6e6c
	if (ctx.cr6.eq) goto loc_82DC6E6C;
	// lbz r9,1436(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1436);
	// stb r9,2(r11)
	PPC_STORE_U8(ctx.r11.u32 + 2, ctx.r9.u8);
loc_82DC6E6C:
	// rlwinm r9,r7,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6e88
	if (ctx.cr6.eq) goto loc_82DC6E88;
	// lbz r9,1500(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1500);
	// stb r9,3(r11)
	PPC_STORE_U8(ctx.r11.u32 + 3, ctx.r9.u8);
	// lbz r10,1564(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1564);
	// stb r10,4(r11)
	PPC_STORE_U8(ctx.r11.u32 + 4, ctx.r10.u8);
loc_82DC6E88:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x82dc6cf0
	if (!ctx.cr6.eq) goto loc_82DC6CF0;
loc_82DC6E90:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC6EA8"))) PPC_WEAK_FUNC(sub_82DC6EA8);
PPC_FUNC_IMPL(__imp__sub_82DC6EA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DC6EB0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6ab4
	ctx.lr = 0x82DC6EB8;
	__savefpr_15(ctx, base);
	// stwu r1,-560(r1)
	ea = -560 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	ctx.r19.u64 = ctx.r3.u64;
	// stb r4,591(r1)
	PPC_STORE_U8(ctx.r1.u32 + 591, ctx.r4.u8);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r11,2056(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2056);
	// lwz r9,488(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 488);
	// add r10,r11,r19
	ctx.r10.u64 = ctx.r11.u64 + ctx.r19.u64;
	// stb r6,120(r1)
	PPC_STORE_U8(ctx.r1.u32 + 120, ctx.r6.u8);
	// lbz r10,500(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 500);
	// rotlwi r10,r10,3
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 3);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// beq cr6,0x82dc94f4
	if (ctx.cr6.eq) goto loc_82DC94F4;
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// li r5,1
	ctx.r5.s64 = 1;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc6f44
	if (!ctx.cr6.eq) goto loc_82DC6F44;
	// lwz r10,496(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 496);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc6f44
	if (ctx.cr6.eq) goto loc_82DC6F44;
	// lwz r9,2052(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2052);
	// rlwinm r11,r11,8,0,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFFFFFF00;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc6f40
	if (ctx.cr6.eq) goto loc_82DC6F40;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r11,2037(r19)
	PPC_STORE_U8(ctx.r19.u32 + 2037, ctx.r11.u8);
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b00
	ctx.lr = 0x82DC6F3C;
	__restfpr_15(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DC6F40:
	// stbx r5,r11,r10
	PPC_STORE_U8(ctx.r11.u32 + ctx.r10.u32, ctx.r5.u8);
loc_82DC6F44:
	// lwz r11,756(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 756);
	// mr r22,r6
	ctx.r22.u64 = ctx.r6.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc8ca4
	if (!ctx.cr6.gt) goto loc_82DC8CA4;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r8,-32222
	ctx.r8.s64 = -2111700992;
	// addi r24,r11,-18528
	ctx.r24.s64 = ctx.r11.s64 + -18528;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// addi r21,r11,-17952
	ctx.r21.s64 = ctx.r11.s64 + -17952;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lfs f29,-15760(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -15760);
	ctx.f29.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// addi r23,r11,-17904
	ctx.r23.s64 = ctx.r11.s64 + -17904;
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f30,9332(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 9332);
	ctx.f30.f64 = double(temp.f32);
	// li r18,64
	ctx.r18.s64 = 64;
	// ori r17,r11,8323
	ctx.r17.u64 = ctx.r11.u64 | 8323;
	// lis r11,21845
	ctx.r11.s64 = 1431633920;
	// lfs f31,9328(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 9328);
	ctx.f31.f64 = double(temp.f32);
	// li r14,8
	ctx.r14.s64 = 8;
	// ori r20,r11,21846
	ctx.r20.u64 = ctx.r11.u64 | 21846;
	// li r15,21
	ctx.r15.s64 = 21;
	// li r16,128
	ctx.r16.s64 = 128;
loc_82DC6FA4:
	// rlwinm r11,r22,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r6,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r6.u32);
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// add r11,r22,r11
	ctx.r11.u64 = ctx.r22.u64 + ctx.r11.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// add r11,r11,r19
	ctx.r11.u64 = ctx.r11.u64 + ctx.r19.u64;
	// addi r28,r11,1692
	ctx.r28.s64 = ctx.r11.s64 + 1692;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// lbz r10,3(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// rlwinm r26,r11,28,4,31
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r25,r11,28
	ctx.r25.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,19
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 19, ctx.xer);
	// bne cr6,0x82dc7004
	if (!ctx.cr6.eq) goto loc_82DC7004;
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,13
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 13, ctx.xer);
	// bne cr6,0x82dc7004
	if (!ctx.cr6.eq) goto loc_82DC7004;
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// clrlwi r9,r25,24
	ctx.r9.u64 = ctx.r25.u32 & 0xFF;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc8c94
	if (ctx.cr6.lt) goto loc_82DC8C94;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc7010
	if (!ctx.cr6.eq) goto loc_82DC7010;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
loc_82DC7004:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc7040
	if (ctx.cr6.eq) goto loc_82DC7040;
loc_82DC7010:
	// cmplwi cr6,r10,19
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 19, ctx.xer);
	// bne cr6,0x82dc7044
	if (!ctx.cr6.eq) goto loc_82DC7044;
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r10,13
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 13, ctx.xer);
	// bne cr6,0x82dc7044
	if (!ctx.cr6.eq) goto loc_82DC7044;
	// clrlwi r10,r25,24
	ctx.r10.u64 = ctx.r25.u32 & 0xFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82dc7040
	if (ctx.cr6.eq) goto loc_82DC7040;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dc7044
	if (!ctx.cr6.eq) goto loc_82DC7044;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc7044
	if (!ctx.cr6.eq) goto loc_82DC7044;
loc_82DC7040:
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
loc_82DC7044:
	// addi r11,r22,190
	ctx.r11.s64 = ctx.r22.s64 + 190;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r19
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r19.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dc706c
	if (!ctx.cr6.eq) goto loc_82DC706C;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// beq cr6,0x82dc7070
	if (ctx.cr6.eq) goto loc_82DC7070;
loc_82DC706C:
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
loc_82DC7070:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7088
	if (ctx.cr6.eq) goto loc_82DC7088;
	// stw r23,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r23.u32);
	// stw r21,464(r23)
	PPC_STORE_U32(ctx.r23.u32 + 464, ctx.r21.u32);
	// b 0x82dc708c
	goto loc_82DC708C;
loc_82DC7088:
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
loc_82DC708C:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc78c4
	if (ctx.cr6.eq) goto loc_82DC78C4;
	// lbz r11,616(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 616);
	// cmplwi cr6,r11,18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 18, ctx.xer);
	// bne cr6,0x82dc70c0
	if (!ctx.cr6.eq) goto loc_82DC70C0;
	// lbz r11,3(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// cmplwi cr6,r11,18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 18, ctx.xer);
	// beq cr6,0x82dc70c0
	if (ctx.cr6.eq) goto loc_82DC70C0;
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r11.u32);
loc_82DC70C0:
	// lbz r11,3(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// stw r6,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r6.u32);
	// stb r11,616(r31)
	PPC_STORE_U8(ctx.r31.u32 + 616, ctx.r11.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,500(r11)
	PPC_STORE_U32(ctx.r11.u32 + 500, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r6,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r6.u8);
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7104
	if (ctx.cr6.eq) goto loc_82DC7104;
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// beq cr6,0x82dc7104
	if (ctx.cr6.eq) goto loc_82DC7104;
	// cmplwi cr6,r11,254
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 254, ctx.xer);
	// beq cr6,0x82dc7104
	if (ctx.cr6.eq) goto loc_82DC7104;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// stb r11,609(r31)
	PPC_STORE_U8(ctx.r31.u32 + 609, ctx.r11.u8);
loc_82DC7104:
	// lbz r11,1(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7128
	if (ctx.cr6.eq) goto loc_82DC7128;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,608(r31)
	PPC_STORE_U8(ctx.r31.u32 + 608, ctx.r11.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplw cr6,r11,r23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r23.u32, ctx.xer);
	// bne cr6,0x82dc7128
	if (!ctx.cr6.eq) goto loc_82DC7128;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
loc_82DC7128:
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc714c
	if (ctx.cr6.eq) goto loc_82DC714C;
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1292(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1292);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc714c
	if (ctx.cr6.lt) goto loc_82DC714C;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_82DC714C:
	// lbz r11,3(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// add r10,r22,r19
	ctx.r10.u64 = ctx.r22.u64 + ctx.r19.u64;
	// stb r11,616(r31)
	PPC_STORE_U8(ctx.r31.u32 + 616, ctx.r11.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r6,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r6.u8);
	// lbz r11,1148(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1148);
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7174
	if (ctx.cr6.eq) goto loc_82DC7174;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_82DC7174:
	// lbz r11,3(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82dc71a8
	if (ctx.cr6.eq) goto loc_82DC71A8;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// beq cr6,0x82dc71a8
	if (ctx.cr6.eq) goto loc_82DC71A8;
	// lbz r11,2(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 2);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmpwi cr6,r11,193
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 193, ctx.xer);
	// blt cr6,0x82dc71a0
	if (ctx.cr6.lt) goto loc_82DC71A0;
	// cmpwi cr6,r11,202
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 202, ctx.xer);
	// ble cr6,0x82dc71a8
	if (!ctx.cr6.gt) goto loc_82DC71A8;
loc_82DC71A0:
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// b 0x82dc71ac
	goto loc_82DC71AC;
loc_82DC71A8:
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82DC71AC:
	// clrlwi r7,r11,24
	ctx.r7.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82dc71c8
	if (ctx.cr6.eq) goto loc_82DC71C8;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplw cr6,r11,r23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r23.u32, ctx.xer);
	// bne cr6,0x82dc71c8
	if (!ctx.cr6.eq) goto loc_82DC71C8;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
loc_82DC71C8:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc789c
	if (ctx.cr6.eq) goto loc_82DC789C;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// lwz r9,1300(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// mulli r10,r11,1428
	ctx.r10.s64 = ctx.r11.s64 * 1428;
	// add r29,r10,r9
	ctx.r29.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq cr6,0x82dc7208
	if (ctx.cr6.eq) goto loc_82DC7208;
	// lbz r11,609(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// addi r11,r11,588
	ctx.r11.s64 = ctx.r11.s64 + 588;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lbzx r11,r11,r29
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r29.u32);
	// b 0x82dc720c
	goto loc_82DC720C;
loc_82DC7208:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82DC720C:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc789c
	if (ctx.cr6.eq) goto loc_82DC789C;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,610(r31)
	PPC_STORE_U8(ctx.r31.u32 + 610, ctx.r11.u8);
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc72c4
	if (ctx.cr6.eq) goto loc_82DC72C4;
	// lbz r11,1169(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1169);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc72c4
	if (ctx.cr6.eq) goto loc_82DC72C4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82dc72c4
	if (ctx.cr6.eq) goto loc_82DC72C4;
loc_82DC7244:
	// lbz r10,1169(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1169);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// beq cr6,0x82dc730c
	if (ctx.cr6.eq) goto loc_82DC730C;
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// beq cr6,0x82dc7290
	if (ctx.cr6.eq) goto loc_82DC7290;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// bne cr6,0x82dc72b8
	if (!ctx.cr6.eq) goto loc_82DC72B8;
	// lbz r10,472(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 472);
	// lbz r9,608(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82dc72b8
	if (!ctx.cr6.eq) goto loc_82DC72B8;
	// lbz r9,1170(r29)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1170);
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// blt cr6,0x82dc72ac
	if (ctx.cr6.lt) goto loc_82DC72AC;
	// beq cr6,0x82dc7344
	if (ctx.cr6.eq) goto loc_82DC7344;
	// cmplwi cr6,r9,3
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 3, ctx.xer);
	// bge cr6,0x82dc72b8
	if (!ctx.cr6.lt) goto loc_82DC72B8;
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
	// b 0x82dc72b8
	goto loc_82DC72B8;
loc_82DC7290:
	// lbz r10,474(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 474);
	// lbz r9,610(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 610);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82dc72b8
	if (!ctx.cr6.eq) goto loc_82DC72B8;
	// lbz r10,1170(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1170);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// bge cr6,0x82dc732c
	if (!ctx.cr6.lt) goto loc_82DC732C;
loc_82DC72AC:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC72B8:
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dc7244
	if (!ctx.cr6.eq) goto loc_82DC7244;
loc_82DC72C4:
	// clrlwi r30,r7,24
	ctx.r30.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dc75a4
	if (!ctx.cr6.eq) goto loc_82DC75A4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// bne cr6,0x82dc7388
	if (!ctx.cr6.eq) goto loc_82DC7388;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DC72F4;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dc74e8
	if (ctx.cr6.eq) goto loc_82DC74E8;
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// stw r21,464(r23)
	PPC_STORE_U32(ctx.r23.u32 + 464, ctx.r21.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// b 0x82dc74ec
	goto loc_82DC74EC;
loc_82DC730C:
	// lbz r10,473(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 473);
	// lbz r9,609(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82dc72b8
	if (!ctx.cr6.eq) goto loc_82DC72B8;
	// lbz r10,1170(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1170);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82dc72ac
	if (ctx.cr6.lt) goto loc_82DC72AC;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
loc_82DC732C:
	// beq cr6,0x82dc7340
	if (ctx.cr6.eq) goto loc_82DC7340;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bge cr6,0x82dc72b8
	if (!ctx.cr6.lt) goto loc_82DC72B8;
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
	// b 0x82dc72b8
	goto loc_82DC72B8;
loc_82DC7340:
	// lbz r10,472(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 472);
loc_82DC7344:
	// lwz r9,1300(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r10,r10,1428
	ctx.r10.s64 = ctx.r10.s64 * 1428;
	// stb r5,600(r11)
	PPC_STORE_U8(ctx.r11.u32 + 600, ctx.r5.u8);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r8,112(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r8,478(r8)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + 478);
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82dc7370
	if (!ctx.cr6.eq) goto loc_82DC7370;
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
	// b 0x82dc72b8
	goto loc_82DC72B8;
loc_82DC7370:
	// lbz r10,896(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 896);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc72b8
	if (ctx.cr6.eq) goto loc_82DC72B8;
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
	// b 0x82dc72b8
	goto loc_82DC72B8;
loc_82DC7388:
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc74ec
	if (ctx.cr6.eq) goto loc_82DC74EC;
	// lbz r9,472(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 472);
	// lbz r10,477(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 477);
	// lwz r8,1300(r19)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r9,r9,1428
	ctx.r9.s64 = ctx.r9.s64 * 1428;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// beq cr6,0x82dc748c
	if (ctx.cr6.eq) goto loc_82DC748C;
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// beq cr6,0x82dc7414
	if (ctx.cr6.eq) goto loc_82DC7414;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// bne cr6,0x82dc74ec
	if (!ctx.cr6.eq) goto loc_82DC74EC;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r10,475(r11)
	PPC_STORE_U8(ctx.r11.u32 + 475, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r10,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r10.u8);
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc73f0
	if (!ctx.cr6.eq) goto loc_82DC73F0;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC73F0:
	// addi r6,r1,124
	ctx.r6.s64 = ctx.r1.s64 + 124;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DC7404;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc74d4
	if (!ctx.cr6.eq) goto loc_82DC74D4;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// b 0x82dc74dc
	goto loc_82DC74DC;
loc_82DC7414:
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r10,475(r11)
	PPC_STORE_U8(ctx.r11.u32 + 475, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r10,600(r11)
	PPC_STORE_U8(ctx.r11.u32 + 600, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r8,478(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 478);
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dc7448
	if (ctx.cr6.eq) goto loc_82DC7448;
	// lbz r9,896(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 896);
	// rlwinm r9,r9,0,29,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc7450
	if (ctx.cr6.eq) goto loc_82DC7450;
loc_82DC7448:
	// stb r10,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7450:
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7468
	if (!ctx.cr6.eq) goto loc_82DC7468;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC7468:
	// addi r6,r1,124
	ctx.r6.s64 = ctx.r1.s64 + 124;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DC747C;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc74d4
	if (!ctx.cr6.eq) goto loc_82DC74D4;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// b 0x82dc74dc
	goto loc_82DC74DC;
loc_82DC748C:
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r10,475(r11)
	PPC_STORE_U8(ctx.r11.u32 + 475, ctx.r10.u8);
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc74b0
	if (!ctx.cr6.eq) goto loc_82DC74B0;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC74B0:
	// addi r6,r1,124
	ctx.r6.s64 = ctx.r1.s64 + 124;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DC74C4;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dc74d4
	if (!ctx.cr6.eq) goto loc_82DC74D4;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// b 0x82dc74dc
	goto loc_82DC74DC;
loc_82DC74D4:
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// stw r21,464(r23)
	PPC_STORE_U32(ctx.r23.u32 + 464, ctx.r21.u32);
loc_82DC74DC:
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DC74E8:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC74EC:
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7540
	if (ctx.cr6.eq) goto loc_82DC7540;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,475(r11)
	PPC_STORE_U8(ctx.r11.u32 + 475, ctx.r10.u8);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r11,1168(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1168);
	// stb r11,477(r10)
	PPC_STORE_U8(ctx.r10.u32 + 477, ctx.r11.u8);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r11,896(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 896);
	// stb r11,478(r10)
	PPC_STORE_U8(ctx.r10.u32 + 478, ctx.r11.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7540:
	// lbz r10,610(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 610);
	// stb r10,474(r11)
	PPC_STORE_U8(ctx.r11.u32 + 474, ctx.r10.u8);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r11,472(r10)
	PPC_STORE_U8(ctx.r10.u32 + 472, ctx.r11.u8);
	// lbz r11,609(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r11,473(r10)
	PPC_STORE_U8(ctx.r10.u32 + 473, ctx.r11.u8);
	// lbz r11,610(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 610);
	// lwz r10,1296(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1296);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dc7594
	if (!ctx.cr6.lt) goto loc_82DC7594;
	// lwz r10,2076(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2076);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc7594
	if (ctx.cr6.eq) goto loc_82DC7594;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rotlwi r11,r9,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// stw r11,464(r10)
	PPC_STORE_U32(ctx.r10.u32 + 464, ctx.r11.u32);
	// b 0x82dc759c
	goto loc_82DC759C;
loc_82DC7594:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r21,464(r11)
	PPC_STORE_U32(ctx.r11.u32 + 464, ctx.r21.u32);
loc_82DC759C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
loc_82DC75A4:
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lbz r11,609(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// beq cr6,0x82dc75c4
	if (ctx.cr6.eq) goto loc_82DC75C4;
	// rotlwi r11,r11,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,1175(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1175);
loc_82DC75C4:
	// stb r11,611(r31)
	PPC_STORE_U8(ctx.r31.u32 + 611, ctx.r11.u8);
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc763c
	if (ctx.cr6.eq) goto loc_82DC763C;
	// lbz r11,611(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 611);
	// subfic r11,r11,120
	ctx.xer.ca = ctx.r11.u32 <= 120;
	ctx.r11.s64 = 120 - ctx.r11.s64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r11,464(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r11.u64);
	// lfd f0,144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// bl 0x82cb4db8
	ctx.lr = 0x82DC760C;
	sub_82CB4DB8(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// lwz r10,612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// b 0x82dc7660
	goto loc_82DC7660;
loc_82DC763C:
	// lbz r11,611(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 611);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rotlwi r11,r11,2
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// lwz r10,464(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 464);
	// lwzx r11,r11,r24
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r24.u32);
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// twllei r10,0
loc_82DC7660:
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dc7774
	if (!ctx.cr6.eq) goto loc_82DC7774;
	// stb r6,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r6.u8);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// stb r6,666(r31)
	PPC_STORE_U8(ctx.r31.u32 + 666, ctx.r6.u8);
	// stw r6,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r6.u32);
	// stb r6,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r6.u8);
	// stb r6,653(r31)
	PPC_STORE_U8(ctx.r31.u32 + 653, ctx.r6.u8);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// lwz r11,624(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 624);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r5,508(r11)
	PPC_STORE_U32(ctx.r11.u32 + 508, ctx.r5.u32);
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc76e0
	if (ctx.cr6.eq) goto loc_82DC76E0;
	// lbz r11,1167(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1167);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc76e0
	if (!ctx.cr6.eq) goto loc_82DC76E0;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// mulhw r10,r11,r17
	ctx.r10.s64 = (int64_t(ctx.r11.s32) * int64_t(ctx.r17.s32)) >> 32;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r11,r11,5
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 5;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
loc_82DC76E0:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r10,464(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lbz r10,9(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 9);
	// rlwinm r9,r10,0,0,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc7704
	if (ctx.cr6.eq) goto loc_82DC7704;
	// clrlwi r10,r10,25
	ctx.r10.u64 = ctx.r10.u32 & 0x7F;
	// stw r10,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7704:
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc775c
	if (ctx.cr6.eq) goto loc_82DC775C;
	// lbz r9,609(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// lbz r10,1172(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1172);
	// lbz r8,1171(r29)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1171);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r9,488(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// mullw r10,r10,r8
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// srawi r10,r10,3
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 3;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r9,1166(r29)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1166);
	// lwz r10,464(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lbz r10,33(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 33);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// srawi r10,r10,7
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 7;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// b 0x82dc7764
	goto loc_82DC7764;
loc_82DC775C:
	// lwz r10,464(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lbz r10,33(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 33);
loc_82DC7764:
	// stw r10,512(r11)
	PPC_STORE_U32(ctx.r11.u32 + 512, ctx.r10.u32);
	// li r10,12
	ctx.r10.s64 = 12;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC7774:
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc789c
	if (ctx.cr6.eq) goto loc_82DC789C;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dc77a0
	if (ctx.cr6.eq) goto loc_82DC77A0;
	// rlwinm r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc77a0
	if (!ctx.cr6.eq) goto loc_82DC77A0;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dc789c
	if (!ctx.cr6.eq) goto loc_82DC789C;
loc_82DC77A0:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r6,600(r11)
	PPC_STORE_U8(ctx.r11.u32 + 600, ctx.r6.u8);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,896(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 896);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc77e8
	if (!ctx.cr6.eq) goto loc_82DC77E8;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r18,528(r11)
	PPC_STORE_U32(ctx.r11.u32 + 528, ctx.r18.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,520(r11)
	PPC_STORE_U32(ctx.r11.u32 + 520, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,516(r11)
	PPC_STORE_U32(ctx.r11.u32 + 516, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,532(r11)
	PPC_STORE_U32(ctx.r11.u32 + 532, ctx.r6.u32);
loc_82DC77E8:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,983(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 983);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc7828
	if (!ctx.cr6.eq) goto loc_82DC7828;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,552(r11)
	PPC_STORE_U32(ctx.r11.u32 + 552, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,544(r11)
	PPC_STORE_U32(ctx.r11.u32 + 544, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,540(r11)
	PPC_STORE_U32(ctx.r11.u32 + 540, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,556(r11)
	PPC_STORE_U32(ctx.r11.u32 + 556, ctx.r6.u32);
loc_82DC7828:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,1071(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1071);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc7868
	if (!ctx.cr6.eq) goto loc_82DC7868;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,576(r11)
	PPC_STORE_U32(ctx.r11.u32 + 576, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,568(r11)
	PPC_STORE_U32(ctx.r11.u32 + 568, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,564(r11)
	PPC_STORE_U32(ctx.r11.u32 + 564, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,580(r11)
	PPC_STORE_U32(ctx.r11.u32 + 580, ctx.r6.u32);
loc_82DC7868:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r10,1024
	ctx.r10.s64 = 1024;
	// stb r6,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r6.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r10,588(r11)
	PPC_STORE_U32(ctx.r11.u32 + 588, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r6,536(r11)
	PPC_STORE_U8(ctx.r11.u32 + 536, ctx.r6.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r6,560(r11)
	PPC_STORE_U8(ctx.r11.u32 + 560, ctx.r6.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,596(r11)
	PPC_STORE_U32(ctx.r11.u32 + 596, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r6,592(r11)
	PPC_STORE_U32(ctx.r11.u32 + 592, ctx.r6.u32);
loc_82DC789C:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r10,464(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc78c4
	if (ctx.cr6.eq) goto loc_82DC78C4;
	// lbz r10,1(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc78c4
	if (ctx.cr6.eq) goto loc_82DC78C4;
	// lwz r11,464(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lbz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 8);
	// stw r11,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r11.u32);
loc_82DC78C4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82dc78e0
	if (ctx.cr6.eq) goto loc_82DC78E0;
loc_82DC78D0:
	// stw r6,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r6.u32);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dc78d0
	if (!ctx.cr6.eq) goto loc_82DC78D0;
loc_82DC78E0:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lbz r11,2(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 2);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7924
	if (ctx.cr6.eq) goto loc_82DC7924;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc6970
	ctx.lr = 0x82DC791C;
	sub_82DC6970(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
loc_82DC7924:
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7980
	if (ctx.cr6.eq) goto loc_82DC7980;
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// lbz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r9,255
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 255, ctx.xer);
	// bne cr6,0x82dc7980
	if (!ctx.cr6.eq) goto loc_82DC7980;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r5,600(r11)
	PPC_STORE_U8(ctx.r11.u32 + 600, ctx.r5.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r9,478(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 478);
	// clrlwi r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc797c
	if (ctx.cr6.eq) goto loc_82DC797C;
	// lbz r10,896(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 896);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7984
	if (ctx.cr6.eq) goto loc_82DC7984;
loc_82DC797C:
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
loc_82DC7980:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7984:
	// lbz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r10,254
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 254, ctx.xer);
	// bne cr6,0x82dc79a0
	if (!ctx.cr6.eq) goto loc_82DC79A0;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC79A0:
	// lbz r10,3(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplwi cr6,r10,24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 24, ctx.xer);
	// bgt cr6,0x82dc8c94
	if (ctx.cr6.gt) goto loc_82DC8C94;
	// lis r12,-32036
	ctx.r12.s64 = -2099511296;
	// addi r12,r12,31176
	ctx.r12.s64 = ctx.r12.s64 + 31176;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC7A2C;
	case 1:
		goto loc_82DC7A4C;
	case 2:
		goto loc_82DC7A80;
	case 3:
		goto loc_82DC7AD8;
	case 4:
		goto loc_82DC7B78;
	case 5:
		goto loc_82DC7C18;
	case 6:
		goto loc_82DC7CE0;
	case 7:
		goto loc_82DC7D48;
	case 8:
		goto loc_82DC7DFC;
	case 9:
		goto loc_82DC7E88;
	case 10:
		goto loc_82DC7FA4;
	case 11:
		goto loc_82DC80A4;
	case 12:
		goto loc_82DC8164;
	case 13:
		goto loc_82DC8188;
	case 14:
		goto loc_82DC8254;
	case 15:
		goto loc_82DC8C94;
	case 16:
		goto loc_82DC82C8;
	case 17:
		goto loc_82DC84A0;
	case 18:
		goto loc_82DC84EC;
	case 19:
		goto loc_82DC8A24;
	case 20:
		goto loc_82DC8AB0;
	case 21:
		goto loc_82DC8B28;
	case 22:
		goto loc_82DC8B4C;
	case 23:
		goto loc_82DC8BFC;
	case 24:
		goto loc_82DC8C4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,31276(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31276);
	// lwz r22,31308(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31308);
	// lwz r22,31360(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31360);
	// lwz r22,31448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31448);
	// lwz r22,31608(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31608);
	// lwz r22,31768(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31768);
	// lwz r22,31968(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 31968);
	// lwz r22,32072(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32072);
	// lwz r22,32252(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32252);
	// lwz r22,32392(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32392);
	// lwz r22,32676(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32676);
	// lwz r22,-32604(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -32604);
	// lwz r22,-32412(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -32412);
	// lwz r22,-32376(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -32376);
	// lwz r22,-32172(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -32172);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-32056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -32056);
	// lwz r22,-31584(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31584);
	// lwz r22,-31508(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31508);
	// lwz r22,-30172(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30172);
	// lwz r22,-30032(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30032);
	// lwz r22,-29912(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29912);
	// lwz r22,-29876(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29876);
	// lwz r22,-29700(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29700);
	// lwz r22,-29620(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29620);
loc_82DC7A2C:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// stw r11,2044(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2044, ctx.r11.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7A4C:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// lwz r10,1280(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1280);
	// stw r6,2068(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2068, ctx.r6.u32);
	// stw r11,2072(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2072, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc7a78
	if (ctx.cr6.lt) goto loc_82DC7A78;
	// stw r6,2072(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2072, ctx.r6.u32);
loc_82DC7A78:
	// stb r5,120(r1)
	PPC_STORE_U8(ctx.r1.u32 + 120, ctx.r5.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7A80:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r11,2068(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2068, ctx.r11.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dc7aa8
	if (!ctx.cr6.gt) goto loc_82DC7AA8;
	// stw r6,2068(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2068, ctx.r6.u32);
loc_82DC7AA8:
	// lbz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 120);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc7ac0
	if (!ctx.cr6.eq) goto loc_82DC7AC0;
	// lwz r11,2056(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2056);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,2072(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2072, ctx.r11.u32);
loc_82DC7AC0:
	// lwz r11,2072(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2072);
	// lwz r10,1280(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1280);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc8c94
	if (ctx.cr6.lt) goto loc_82DC8C94;
	// stw r6,2072(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2072, ctx.r6.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7AD8:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7b60
	if (!ctx.cr6.eq) goto loc_82DC7B60;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7af8
	if (ctx.cr6.eq) goto loc_82DC7AF8;
	// stb r10,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7AF8:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,649(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 649);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bne cr6,0x82dc7b24
	if (!ctx.cr6.eq) goto loc_82DC7B24;
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dc7b38
	goto loc_82DC7B38;
loc_82DC7B24:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dc7b3c
	if (!ctx.cr6.eq) goto loc_82DC7B3C;
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82DC7B38:
	// stw r11,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r11.u32);
loc_82DC7B3C:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dc7b4c
	if (!ctx.cr6.gt) goto loc_82DC7B4C;
	// stw r18,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r18.u32);
loc_82DC7B4C:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc8c94
	if (!ctx.cr6.lt) goto loc_82DC8C94;
	// stw r6,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r6.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7B60:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc59f0
	ctx.lr = 0x82DC7B74;
	sub_82DC59F0(ctx, base);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7B78:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7bec
	if (!ctx.cr6.eq) goto loc_82DC7BEC;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7b98
	if (ctx.cr6.eq) goto loc_82DC7B98;
	// stb r10,644(r31)
	PPC_STORE_U8(ctx.r31.u32 + 644, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7B98:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r9,r10,0,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r9,240
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 240, ctx.xer);
	// bne cr6,0x82dc7bc8
	if (!ctx.cr6.eq) goto loc_82DC7BC8;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rlwinm r10,r10,2,26,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x3C;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7BC8:
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r9,r10,0,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r9,224
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 224, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7BEC:
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// cmplwi cr6,r10,224
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 224, ctx.xer);
	// bge cr6,0x82dc8c94
	if (!ctx.cr6.lt) goto loc_82DC8C94;
	// lbz r9,475(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7C18:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7c8c
	if (!ctx.cr6.eq) goto loc_82DC7C8C;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7c38
	if (ctx.cr6.eq) goto loc_82DC7C38;
	// stb r10,644(r31)
	PPC_STORE_U8(ctx.r31.u32 + 644, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7C38:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r9,r10,0,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r9,240
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 240, ctx.xer);
	// bne cr6,0x82dc7c68
	if (!ctx.cr6.eq) goto loc_82DC7C68;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rlwinm r10,r10,2,26,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x3C;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7C68:
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r9,r10,0,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r9,224
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 224, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7C8C:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// cmplwi cr6,r10,224
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 224, ctx.xer);
	// bge cr6,0x82dc8c94
	if (!ctx.cr6.lt) goto loc_82DC8C94;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// bge cr6,0x82dc7cd4
	if (!ctx.cr6.lt) goto loc_82DC7CD4;
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7CD4:
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7CE0:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7d30
	if (!ctx.cr6.eq) goto loc_82DC7D30;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc7d14
	if (ctx.cr6.eq) goto loc_82DC7D14;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7d10
	if (ctx.cr6.eq) goto loc_82DC7D10;
	// stb r11,660(r31)
	PPC_STORE_U8(ctx.r31.u32 + 660, ctx.r11.u8);
	// b 0x82dc7d14
	goto loc_82DC7D14;
loc_82DC7D10:
	// stb r11,644(r31)
	PPC_STORE_U8(ctx.r31.u32 + 644, ctx.r11.u8);
loc_82DC7D14:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// stb r6,661(r31)
	PPC_STORE_U8(ctx.r31.u32 + 661, ctx.r6.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7D30:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc5a68
	ctx.lr = 0x82DC7D44;
	sub_82DC5A68(ctx, base);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7D48:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7dc0
	if (!ctx.cr6.eq) goto loc_82DC7DC0;
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7d68
	if (ctx.cr6.eq) goto loc_82DC7D68;
	// stb r26,663(r31)
	PPC_STORE_U8(ctx.r31.u32 + 663, ctx.r26.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7D68:
	// clrlwi r10,r25,24
	ctx.r10.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7d84
	if (ctx.cr6.eq) goto loc_82DC7D84;
	// stb r25,664(r31)
	PPC_STORE_U8(ctx.r31.u32 + 664, ctx.r25.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r14,665(r31)
	PPC_STORE_U8(ctx.r31.u32 + 665, ctx.r14.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7D84:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,665(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 665);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc7dec
	if (!ctx.cr6.eq) goto loc_82DC7DEC;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC7DB4;
	sub_82DC5C58(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7DC0:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,665(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 665);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc7dec
	if (!ctx.cr6.eq) goto loc_82DC7DEC;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC7DE0;
	sub_82DC5C58(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7DEC:
	// bl 0x82dc5b28
	ctx.lr = 0x82DC7DF0;
	sub_82DC5B28(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7DFC:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7e28
	if (!ctx.cr6.eq) goto loc_82DC7E28;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7e28
	if (ctx.cr6.eq) goto loc_82DC7E28;
	// addi r11,r25,1
	ctx.r11.s64 = ctx.r25.s64 + 1;
	// addi r10,r26,1
	ctx.r10.s64 = ctx.r26.s64 + 1;
	// stb r11,680(r31)
	PPC_STORE_U8(ctx.r31.u32 + 680, ctx.r11.u8);
	// stb r10,679(r31)
	PPC_STORE_U8(ctx.r31.u32 + 679, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7E28:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,679(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// lbz r11,678(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dc7e50
	if (ctx.cr6.lt) goto loc_82DC7E50;
	// lwz r9,620(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// neg r9,r9
	ctx.r9.s64 = -ctx.r9.s64;
	// stw r9,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r9.u32);
loc_82DC7E50:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r9,680(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 680);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// stb r11,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r11.u8);
	// blt cr6,0x82dc7e74
	if (ctx.cr6.lt) goto loc_82DC7E74;
	// stb r6,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r6.u8);
loc_82DC7E74:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7E88:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7ea8
	if (!ctx.cr6.eq) goto loc_82DC7EA8;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7ea8
	if (ctx.cr6.eq) goto loc_82DC7EA8;
	// stb r10,681(r31)
	PPC_STORE_U8(ctx.r31.u32 + 681, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7EA8:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r9,681(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 681);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// rlwinm r7,r9,28,28,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 28) & 0xF;
	// clrlwi r6,r8,28
	ctx.r6.u64 = ctx.r8.u32 & 0xF;
	// mulhw r9,r10,r20
	ctx.r9.s64 = (int64_t(ctx.r10.s32) * int64_t(ctx.r20.s32)) >> 32;
	// rlwinm r8,r9,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r8,r9,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// beq cr6,0x82dc7f20
	if (ctx.cr6.eq) goto loc_82DC7F20;
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// bne cr6,0x82dc7f90
	if (!ctx.cr6.eq) goto loc_82DC7F90;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7f18
	if (ctx.cr6.eq) goto loc_82DC7F18;
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// rlwinm r9,r6,6,18,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0x3FC0;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// b 0x82dc7f88
	goto loc_82DC7F88;
loc_82DC7F18:
	// clrlwi r7,r6,24
	ctx.r7.u64 = ctx.r6.u32 & 0xFF;
	// b 0x82dc7f44
	goto loc_82DC7F44;
loc_82DC7F20:
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7f40
	if (ctx.cr6.eq) goto loc_82DC7F40;
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// rlwinm r9,r7,6,18,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0x3FC0;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// b 0x82dc7f88
	goto loc_82DC7F88;
loc_82DC7F40:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
loc_82DC7F44:
	// lbz r10,609(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// lwz r9,464(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// add r7,r7,r10
	ctx.r7.u64 = ctx.r7.u64 + ctx.r10.u64;
	// lwz r8,496(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwzx r10,r10,r24
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r24.u32);
	// twllei r9,0
	// lwzx r7,r7,r24
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r24.u32);
	// twllei r9,0
	// mulli r10,r10,8363
	ctx.r10.s64 = ctx.r10.s64 * 8363;
	// mulli r7,r7,8363
	ctx.r7.s64 = ctx.r7.s64 * 8363;
	// divwu r10,r10,r9
	ctx.r10.u32 = ctx.r10.u32 / ctx.r9.u32;
	// divwu r7,r7,r9
	ctx.r7.u32 = ctx.r7.u32 / ctx.r9.u32;
	// subf r10,r10,r7
	ctx.r10.s64 = ctx.r7.s64 - ctx.r10.s64;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
loc_82DC7F88:
	// stw r10,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7F90:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC7FA4:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8058
	if (!ctx.cr6.eq) goto loc_82DC8058;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc7fc4
	if (ctx.cr6.eq) goto loc_82DC7FC4;
	// stb r10,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC7FC4:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,649(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 649);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bne cr6,0x82dc7ff0
	if (!ctx.cr6.eq) goto loc_82DC7FF0;
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dc8004
	goto loc_82DC8004;
loc_82DC7FF0:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dc8008
	if (!ctx.cr6.eq) goto loc_82DC8008;
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82DC8004:
	// stw r11,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r11.u32);
loc_82DC8008:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dc8018
	if (!ctx.cr6.gt) goto loc_82DC8018;
	// stw r18,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r18.u32);
loc_82DC8018:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc8028
	if (!ctx.cr6.lt) goto loc_82DC8028;
	// stw r6,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r6.u32);
loc_82DC8028:
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,665(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 665);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc7dec
	if (!ctx.cr6.eq) goto loc_82DC7DEC;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC804C;
	sub_82DC5C58(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8058:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,665(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 665);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc808c
	if (!ctx.cr6.eq) goto loc_82DC808C;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC8078;
	sub_82DC5C58(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc59f0
	ctx.lr = 0x82DC8080;
	sub_82DC59F0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC808C:
	// bl 0x82dc5b28
	ctx.lr = 0x82DC8090;
	sub_82DC5B28(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc59f0
	ctx.lr = 0x82DC8098;
	sub_82DC59F0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC80A4:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8144
	if (!ctx.cr6.eq) goto loc_82DC8144;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc80c0
	if (ctx.cr6.eq) goto loc_82DC80C0;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
loc_82DC80C0:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc80d8
	if (ctx.cr6.eq) goto loc_82DC80D8;
	// stb r6,661(r31)
	PPC_STORE_U8(ctx.r31.u32 + 661, ctx.r6.u8);
loc_82DC80D8:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,649(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 649);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bne cr6,0x82dc8108
	if (!ctx.cr6.eq) goto loc_82DC8108;
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dc811c
	goto loc_82DC811C;
loc_82DC8108:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dc8120
	if (!ctx.cr6.eq) goto loc_82DC8120;
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82DC811C:
	// stw r11,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r11.u32);
loc_82DC8120:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dc8130
	if (!ctx.cr6.gt) goto loc_82DC8130;
	// stw r18,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r18.u32);
loc_82DC8130:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc8c94
	if (!ctx.cr6.lt) goto loc_82DC8C94;
	// stw r6,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r6.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8144:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc5a68
	ctx.lr = 0x82DC8158;
	sub_82DC5A68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc59f0
	ctx.lr = 0x82DC8160;
	sub_82DC59F0(ctx, base);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8164:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r11.u32);
	// ble cr6,0x82dc8c94
	if (!ctx.cr6.gt) goto loc_82DC8C94;
	// stw r18,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r18.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8188:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc81ec
	if (!ctx.cr6.eq) goto loc_82DC81EC;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc81a8
	if (ctx.cr6.eq) goto loc_82DC81A8;
	// stb r10,692(r31)
	PPC_STORE_U8(ctx.r31.u32 + 692, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC81A8:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 692);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bne cr6,0x82dc81d4
	if (!ctx.cr6.eq) goto loc_82DC81D4;
	// lwz r10,636(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dc822c
	goto loc_82DC822C;
loc_82DC81D4:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dc8230
	if (!ctx.cr6.eq) goto loc_82DC8230;
	// lwz r11,636(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82dc822c
	goto loc_82DC822C;
loc_82DC81EC:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 692);
	// clrlwi r8,r11,28
	ctx.r8.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82dc8218
	if (!ctx.cr6.eq) goto loc_82DC8218;
	// lwz r9,636(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r10.u32);
loc_82DC8218:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8230
	if (!ctx.cr6.eq) goto loc_82DC8230;
	// lwz r11,636(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
loc_82DC822C:
	// stw r11,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r11.u32);
loc_82DC8230:
	// lwz r11,636(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dc8240
	if (!ctx.cr6.gt) goto loc_82DC8240;
	// stw r18,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r18.u32);
loc_82DC8240:
	// lwz r11,636(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc8c94
	if (!ctx.cr6.lt) goto loc_82DC8C94;
	// stw r6,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r6.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8254:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r10,464(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8280
	if (ctx.cr6.eq) goto loc_82DC8280;
	// stw r10,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r10.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8280:
	// lbz r10,702(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 702);
	// lwz r9,464(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lwz r8,632(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r8,16(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82dc82c0
	if (ctx.cr6.lt) goto loc_82DC82C0;
	// lwz r10,464(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
loc_82DC82C0:
	// stw r10,504(r11)
	PPC_STORE_U32(ctx.r11.u32 + 504, ctx.r10.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC82C8:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc82ec
	if (!ctx.cr6.eq) goto loc_82DC82EC;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc82ec
	if (ctx.cr6.eq) goto loc_82DC82EC;
	// stb r26,651(r31)
	PPC_STORE_U8(ctx.r31.u32 + 651, ctx.r26.u8);
	// stb r25,652(r31)
	PPC_STORE_U8(ctx.r31.u32 + 652, ctx.r25.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC82EC:
	// lbz r9,653(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 653);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc8490
	if (ctx.cr6.eq) goto loc_82DC8490;
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,652(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 652);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// rotlwi r8,r9,1
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r7,r9,r10
	ctx.r7.s32 = ctx.r9.s32 / ctx.r10.s32;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// mullw r7,r7,r10
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r10.s32);
	// twllei r10,0
	// andc r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r8.u64;
	// subf. r9,r7,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// twlgei r10,-1
	// bne 0x82dc8490
	if (!ctx.cr0.eq) goto loc_82DC8490;
	// lbz r10,651(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 651);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8474
	if (ctx.cr6.eq) goto loc_82DC8474;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplwi cr6,r10,14
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 14, ctx.xer);
	// bgt cr6,0x82dc843c
	if (ctx.cr6.gt) goto loc_82DC843C;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-31900
	ctx.r12.s64 = ctx.r12.s64 + -31900;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC83A0;
	case 1:
		goto loc_82DC83AC;
	case 2:
		goto loc_82DC83B8;
	case 3:
		goto loc_82DC83C4;
	case 4:
		goto loc_82DC83D0;
	case 5:
		goto loc_82DC83DC;
	case 6:
		goto loc_82DC83E4;
	case 7:
		goto loc_82DC843C;
	case 8:
		goto loc_82DC83F0;
	case 9:
		goto loc_82DC83FC;
	case 10:
		goto loc_82DC8408;
	case 11:
		goto loc_82DC8414;
	case 12:
		goto loc_82DC8420;
	case 13:
		goto loc_82DC843C;
	case 14:
		goto loc_82DC842C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-31840(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31840);
	// lwz r22,-31828(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31828);
	// lwz r22,-31816(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31816);
	// lwz r22,-31804(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31804);
	// lwz r22,-31792(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31792);
	// lwz r22,-31780(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31780);
	// lwz r22,-31772(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31772);
	// lwz r22,-31684(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31684);
	// lwz r22,-31760(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31760);
	// lwz r22,-31748(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31748);
	// lwz r22,-31736(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31736);
	// lwz r22,-31724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31724);
	// lwz r22,-31712(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31712);
	// lwz r22,-31684(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31684);
	// lwz r22,-31700(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31700);
loc_82DC83A0:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83AC:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83B8:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83C4:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83D0:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83DC:
	// stw r6,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r6.u32);
	// b 0x82dc8438
	goto loc_82DC8438;
loc_82DC83E4:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83F0:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC83FC:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC8408:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC8414:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC8420:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// b 0x82dc8434
	goto loc_82DC8434;
loc_82DC842C:
	// lwz r11,620(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DC8434:
	// stw r11,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r11.u32);
loc_82DC8438:
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC843C:
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dc8450
	if (!ctx.cr6.gt) goto loc_82DC8450;
	// stw r18,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r18.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8450:
	// lwz r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 620);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dc8464
	if (!ctx.cr6.lt) goto loc_82DC8464;
	// stw r6,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8464:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8474:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC8490:
	// lbz r11,653(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 653);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stb r11,653(r31)
	PPC_STORE_U8(ctx.r31.u32 + 653, ctx.r11.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC84A0:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc84d4
	if (!ctx.cr6.eq) goto loc_82DC84D4;
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc84c0
	if (ctx.cr6.eq) goto loc_82DC84C0;
	// stb r26,667(r31)
	PPC_STORE_U8(ctx.r31.u32 + 667, ctx.r26.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC84C0:
	// clrlwi r10,r25,24
	ctx.r10.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc84d4
	if (ctx.cr6.eq) goto loc_82DC84D4;
	// stb r25,668(r31)
	PPC_STORE_U8(ctx.r31.u32 + 668, ctx.r25.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC84D4:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc5d80
	ctx.lr = 0x82DC84E8;
	sub_82DC5D80(ctx, base);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC84EC:
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8500
	if (ctx.cr6.eq) goto loc_82DC8500;
	// stb r10,693(r31)
	PPC_STORE_U8(ctx.r31.u32 + 693, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8500:
	// lbz r10,693(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 693);
	// rlwinm r9,r10,28,4,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// cmplwi cr6,r9,11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 11, ctx.xer);
	// bgt cr6,0x82dc8c94
	if (ctx.cr6.gt) goto loc_82DC8C94;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-31440
	ctx.r12.s64 = ctx.r12.s64 + -31440;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82DC85A0;
	case 1:
		goto loc_82DC85B8;
	case 2:
		goto loc_82DC85D0;
	case 3:
		goto loc_82DC85E8;
	case 4:
		goto loc_82DC8600;
	case 5:
		goto loc_82DC884C;
	case 6:
		goto loc_82DC8898;
	case 7:
		goto loc_82DC8958;
	case 8:
		goto loc_82DC896C;
	case 9:
		goto loc_82DC8560;
	case 10:
		goto loc_82DC8C94;
	case 11:
		goto loc_82DC8A04;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-31328(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31328);
	// lwz r22,-31304(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31304);
	// lwz r22,-31280(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31280);
	// lwz r22,-31256(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31256);
	// lwz r22,-31232(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31232);
	// lwz r22,-30644(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30644);
	// lwz r22,-30568(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30568);
	// lwz r22,-30376(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30376);
	// lwz r22,-30356(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30356);
	// lwz r22,-31392(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31392);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-30204(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30204);
loc_82DC8560:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82dc8588
	if (ctx.cr6.eq) goto loc_82DC8588;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
loc_82DC8588:
	// stw r6,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r6.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC85A0:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r11,r10,30
	ctx.r11.u64 = ctx.r10.u32 & 0x3;
	// stb r11,695(r31)
	PPC_STORE_U8(ctx.r31.u32 + 695, ctx.r11.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC85B8:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r11,r10,30
	ctx.r11.u64 = ctx.r10.u32 & 0x3;
	// stb r11,696(r31)
	PPC_STORE_U8(ctx.r31.u32 + 696, ctx.r11.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC85D0:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r11,r10,30
	ctx.r11.u64 = ctx.r10.u32 & 0x3;
	// stb r11,697(r31)
	PPC_STORE_U8(ctx.r31.u32 + 697, ctx.r11.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC85E8:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// stw r11,2064(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2064, ctx.r11.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8600:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 8, ctx.xer);
	// bgt cr6,0x82dc8c94
	if (ctx.cr6.gt) goto loc_82DC8C94;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-31196
	ctx.r12.s64 = ctx.r12.s64 + -31196;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC8648;
	case 1:
		goto loc_82DC8698;
	case 2:
		goto loc_82DC8714;
	case 3:
		goto loc_82DC875C;
	case 4:
		goto loc_82DC8780;
	case 5:
		goto loc_82DC87A4;
	case 6:
		goto loc_82DC87CC;
	case 7:
		goto loc_82DC87F4;
	case 8:
		goto loc_82DC8820;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-31160(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31160);
	// lwz r22,-31080(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -31080);
	// lwz r22,-30956(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30956);
	// lwz r22,-30884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30884);
	// lwz r22,-30848(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30848);
	// lwz r22,-30812(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30812);
	// lwz r22,-30772(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30772);
	// lwz r22,-30732(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30732);
	// lwz r22,-30688(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30688);
loc_82DC8648:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
loc_82DC8670:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8688
	if (ctx.cr6.eq) goto loc_82DC8688;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DC8688:
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dc8670
	if (!ctx.cr6.eq) goto loc_82DC8670;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8698:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
loc_82DC86C0:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8704
	if (ctx.cr6.eq) goto loc_82DC8704;
	// lbz r10,472(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 472);
	// lbz r8,478(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 478);
	// lwz r9,1300(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r10,r10,1428
	ctx.r10.s64 = ctx.r10.s64 * 1428;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// stb r5,600(r11)
	PPC_STORE_U8(ctx.r11.u32 + 600, ctx.r5.u8);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dc8700
	if (ctx.cr6.eq) goto loc_82DC8700;
	// lbz r10,896(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 896);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8704
	if (ctx.cr6.eq) goto loc_82DC8704;
loc_82DC8700:
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
loc_82DC8704:
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dc86c0
	if (!ctx.cr6.eq) goto loc_82DC86C0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8714:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
loc_82DC873C:
	// lbz r10,475(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc874c
	if (ctx.cr6.eq) goto loc_82DC874C;
	// stb r5,585(r11)
	PPC_STORE_U8(ctx.r11.u32 + 585, ctx.r5.u8);
loc_82DC874C:
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dc873c
	if (!ctx.cr6.eq) goto loc_82DC873C;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC875C:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// stb r6,477(r11)
	PPC_STORE_U8(ctx.r11.u32 + 477, ctx.r6.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8780:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// stb r5,477(r11)
	PPC_STORE_U8(ctx.r11.u32 + 477, ctx.r5.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC87A4:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// li r10,2
	ctx.r10.s64 = 2;
	// stb r10,477(r11)
	PPC_STORE_U8(ctx.r11.u32 + 477, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC87CC:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// li r10,3
	ctx.r10.s64 = 3;
	// stb r10,477(r11)
	PPC_STORE_U8(ctx.r11.u32 + 477, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC87F4:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,478(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 478);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,478(r11)
	PPC_STORE_U8(ctx.r11.u32 + 478, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8820:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r10,478(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 478);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,478(r11)
	PPC_STORE_U8(ctx.r11.u32 + 478, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC884C:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// rlwinm r11,r10,2,22,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x3FC;
	// stw r11,624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 624, ctx.r11.u32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r9,475(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 475);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8898:
	// lwz r9,2040(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r9,475(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bgt cr6,0x82dc8c94
	if (ctx.cr6.gt) goto loc_82DC8C94;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-30508
	ctx.r12.s64 = ctx.r12.s64 + -30508;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DC8C3C;
	case 1:
		goto loc_82DC8914;
	case 2:
		goto loc_82DC8C94;
	case 3:
		goto loc_82DC8C94;
	case 4:
		goto loc_82DC8C94;
	case 5:
		goto loc_82DC8C94;
	case 6:
		goto loc_82DC8C94;
	case 7:
		goto loc_82DC8C94;
	case 8:
		goto loc_82DC8C94;
	case 9:
		goto loc_82DC8C94;
	case 10:
		goto loc_82DC8C94;
	case 11:
		goto loc_82DC8C94;
	case 12:
		goto loc_82DC8C94;
	case 13:
		goto loc_82DC8C94;
	case 14:
		goto loc_82DC8924;
	case 15:
		goto loc_82DC893C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-29636(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29636);
	// lwz r22,-30444(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30444);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-29548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -29548);
	// lwz r22,-30428(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30428);
	// lwz r22,-30404(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -30404);
loc_82DC8914:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,16
	ctx.r10.u64 = ctx.r10.u64 | 16;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8924:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r5,508(r11)
	PPC_STORE_U32(ctx.r11.u32 + 508, ctx.r5.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC893C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// li r10,-1
	ctx.r10.s64 = -1;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r10,508(r11)
	PPC_STORE_U32(ctx.r11.u32 + 508, ctx.r10.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8958:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// stb r10,702(r31)
	PPC_STORE_U8(ctx.r31.u32 + 702, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC896C:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8990
	if (!ctx.cr6.eq) goto loc_82DC8990;
	// lwz r11,2052(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2052);
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8990:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc89a4
	if (!ctx.cr6.eq) goto loc_82DC89A4;
	// stw r10,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r10.u32);
	// b 0x82dc89ac
	goto loc_82DC89AC;
loc_82DC89A4:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r11.u32);
loc_82DC89AC:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,496(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 496);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,2068(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2068, ctx.r11.u32);
	// beq cr6,0x82dc8c94
	if (ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,2052(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dc8c94
	if (ctx.cr6.gt) goto loc_82DC8C94;
loc_82DC89DC:
	// lwz r10,2056(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2056);
	// lwz r9,496(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 496);
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stbx r6,r10,r9
	PPC_STORE_U8(ctx.r10.u32 + ctx.r9.u32, ctx.r6.u8);
	// lwz r10,2052(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dc89dc
	if (!ctx.cr6.gt) goto loc_82DC89DC;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8A04:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,2044(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2044);
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,2060(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2060, ctx.r11.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8A24:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8a50
	if (!ctx.cr6.eq) goto loc_82DC8A50;
	// lbz r4,4(r28)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r4,31
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 31, ctx.xer);
	// ble cr6,0x82dc8a50
	if (!ctx.cr6.gt) goto loc_82DC8A50;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82e02ae0
	ctx.lr = 0x82DC8A44;
	sub_82E02AE0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8A50:
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82dc8c94
	if (ctx.cr6.gt) goto loc_82DC8C94;
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8a88
	if (!ctx.cr6.eq) goto loc_82DC8A88;
	// lwz r11,2048(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2048);
	// clrlwi r10,r25,24
	ctx.r10.u64 = ctx.r25.u32 & 0xFF;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// subf r4,r10,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bl 0x82e02ae0
	ctx.lr = 0x82DC8A7C;
	sub_82E02AE0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8A88:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lwz r11,2048(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2048);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// bl 0x82e02ae0
	ctx.lr = 0x82DC8AA4;
	sub_82E02AE0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8AB0:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc7dc0
	if (!ctx.cr6.eq) goto loc_82DC7DC0;
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8ad0
	if (ctx.cr6.eq) goto loc_82DC8AD0;
	// stb r26,663(r31)
	PPC_STORE_U8(ctx.r31.u32 + 663, ctx.r26.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8AD0:
	// clrlwi r10,r25,24
	ctx.r10.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8aec
	if (ctx.cr6.eq) goto loc_82DC8AEC;
	// stb r25,664(r31)
	PPC_STORE_U8(ctx.r31.u32 + 664, ctx.r25.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stb r15,665(r31)
	PPC_STORE_U8(ctx.r31.u32 + 665, ctx.r15.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8AEC:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,665(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 665);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bne cr6,0x82dc7dec
	if (!ctx.cr6.eq) goto loc_82DC7DEC;
	// bl 0x82dc5c58
	ctx.lr = 0x82DC8B1C;
	sub_82DC5C58(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8B28:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmpwi cr6,r11,128
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 128, ctx.xer);
	// stw r11,2028(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2028, ctx.r11.u32);
	// ble cr6,0x82dc8c94
	if (!ctx.cr6.gt) goto loc_82DC8C94;
	// stw r16,2028(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2028, ctx.r16.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8B4C:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8ba0
	if (!ctx.cr6.eq) goto loc_82DC8BA0;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8b68
	if (ctx.cr6.eq) goto loc_82DC8B68;
	// stb r11,2032(r19)
	PPC_STORE_U8(ctx.r19.u32 + 2032, ctx.r11.u8);
loc_82DC8B68:
	// lbz r11,2032(r19)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r19.u32 + 2032);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bne cr6,0x82dc8b88
	if (!ctx.cr6.eq) goto loc_82DC8B88;
	// lwz r10,2028(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dc8bd4
	goto loc_82DC8BD4;
loc_82DC8B88:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dc8bd8
	if (!ctx.cr6.eq) goto loc_82DC8BD8;
	// lwz r11,2028(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82dc8bd4
	goto loc_82DC8BD4;
loc_82DC8BA0:
	// lbz r11,2032(r19)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r19.u32 + 2032);
	// clrlwi r8,r11,28
	ctx.r8.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82dc8bc0
	if (!ctx.cr6.eq) goto loc_82DC8BC0;
	// lwz r9,2028(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,2028(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2028, ctx.r10.u32);
loc_82DC8BC0:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8bd8
	if (!ctx.cr6.eq) goto loc_82DC8BD8;
	// lwz r11,2028(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
loc_82DC8BD4:
	// stw r11,2028(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2028, ctx.r11.u32);
loc_82DC8BD8:
	// lwz r11,2028(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// cmpwi cr6,r11,128
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 128, ctx.xer);
	// ble cr6,0x82dc8be8
	if (!ctx.cr6.gt) goto loc_82DC8BE8;
	// stw r16,2028(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2028, ctx.r16.u32);
loc_82DC8BE8:
	// lwz r11,2028(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc8c94
	if (!ctx.cr6.lt) goto loc_82DC8C94;
	// stw r6,2028(r19)
	PPC_STORE_U32(ctx.r19.u32 + 2028, ctx.r6.u32);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8BFC:
	// lwz r11,2040(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// rlwinm r11,r11,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// stw r11,624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 624, ctx.r11.u32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r9,475(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 475);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8C3C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dc8c94
	goto loc_82DC8C94;
loc_82DC8C4C:
	// lwz r10,2040(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2040);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82dc8c80
	if (!ctx.cr6.eq) goto loc_82DC8C80;
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c6c
	if (ctx.cr6.eq) goto loc_82DC8C6C;
	// stb r26,676(r31)
	PPC_STORE_U8(ctx.r31.u32 + 676, ctx.r26.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8C6C:
	// clrlwi r10,r25,24
	ctx.r10.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8c80
	if (ctx.cr6.eq) goto loc_82DC8C80;
	// stb r25,677(r31)
	PPC_STORE_U8(ctx.r31.u32 + 677, ctx.r25.u8);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DC8C80:
	// lbz r11,475(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8c94
	if (!ctx.cr6.eq) goto loc_82DC8C94;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc5e98
	ctx.lr = 0x82DC8C94;
	sub_82DC5E98(ctx, base);
loc_82DC8C94:
	// lwz r11,756(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 756);
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
	// cmpw cr6,r22,r11
	ctx.cr6.compare<int32_t>(ctx.r22.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc6fa4
	if (ctx.cr6.lt) goto loc_82DC6FA4;
loc_82DC8CA4:
	// lbz r11,591(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 591);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc94f4
	if (ctx.cr6.eq) goto loc_82DC94F4;
	// lwz r11,756(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 756);
	// mr r21,r6
	ctx.r21.u64 = ctx.r6.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc94f4
	if (!ctx.cr6.gt) goto loc_82DC94F4;
	// lis r25,-32256
	ctx.r25.s64 = -2113929216;
	// lis r26,-32256
	ctx.r26.s64 = -2113929216;
	// lis r27,-32255
	ctx.r27.s64 = -2113863680;
	// lis r28,-32255
	ctx.r28.s64 = -2113863680;
	// lis r29,-32255
	ctx.r29.s64 = -2113863680;
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lfs f19,6380(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 6380);
	ctx.f19.f64 = double(temp.f32);
	// lis r31,-32256
	ctx.r31.s64 = -2113929216;
	// lfs f20,7676(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 7676);
	ctx.f20.f64 = double(temp.f32);
	// lis r3,-32255
	ctx.r3.s64 = -2113863680;
	// lfs f21,308(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// lis r4,-32255
	ctx.r4.s64 = -2113863680;
	// lfs f25,-11792(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -11792);
	ctx.f25.f64 = double(temp.f32);
	// lis r5,-32222
	ctx.r5.s64 = -2111700992;
	// lfs f26,9324(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 9324);
	ctx.f26.f64 = double(temp.f32);
	// lis r6,-32255
	ctx.r6.s64 = -2113863680;
	// lfs f28,9320(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 9320);
	ctx.f28.f64 = double(temp.f32);
	// lis r7,-32222
	ctx.r7.s64 = -2111700992;
	// lfs f29,7616(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 7616);
	ctx.f29.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f27,9316(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 9316);
	ctx.f27.f64 = double(temp.f32);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lfs f22,9312(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 9312);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfd f30,-18376(r5)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r5.u32 + -18376);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f23,9304(r6)
	ctx.f23.u64 = PPC_LOAD_U64(ctx.r6.u32 + 9304);
	// lis r23,218
	ctx.r23.s64 = 14286848;
	// lfs f24,-15788(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -15788);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,6140(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6140);
	ctx.f15.f64 = double(temp.f32);
	// addi r22,r19,14588
	ctx.r22.s64 = ctx.r19.s64 + 14588;
	// lfs f16,9296(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 9296);
	ctx.f16.f64 = double(temp.f32);
	// addi r20,r19,1148
	ctx.r20.s64 = ctx.r19.s64 + 1148;
	// lfs f17,9292(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 9292);
	ctx.f17.f64 = double(temp.f32);
	// li r24,4
	ctx.r24.s64 = 4;
	// lfs f18,9288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9288);
	ctx.f18.f64 = double(temp.f32);
	// ori r23,r23,30208
	ctx.r23.u64 = ctx.r23.u64 | 30208;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r18,2
	ctx.r18.s64 = 2;
	// li r25,1
	ctx.r25.s64 = 1;
loc_82DC8D60:
	// lbzx r11,r20,r21
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r20.u32 + ctx.r21.u32);
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc94e0
	if (!ctx.cr6.eq) goto loc_82DC94E0;
	// lwz r28,-13828(r22)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r22.u32 + -13828);
	// lwz r31,0(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82dc94e0
	if (ctx.cr6.eq) goto loc_82DC94E0;
loc_82DC8D80:
	// lwz r11,464(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// lwz r27,0(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8da0
	if (!ctx.cr6.eq) goto loc_82DC8DA0;
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// andi. r11,r11,247
	ctx.r11.u64 = ctx.r11.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DC8DA0:
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8f04
	if (ctx.cr6.eq) goto loc_82DC8F04;
	// lbz r11,472(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 472);
	// lbz r9,478(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 478);
	// lwz r10,1300(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// clrlwi r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc8e34
	if (ctx.cr6.eq) goto loc_82DC8E34;
	// lbz r11,536(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 536);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8e18
	if (!ctx.cr6.eq) goto loc_82DC8E18;
	// lbz r11,982(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 982);
	// addi r7,r30,898
	ctx.r7.s64 = ctx.r30.s64 + 898;
	// lbz r29,981(r30)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r30.u32 + 981);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r4,r31,516
	ctx.r4.s64 = ctx.r31.s64 + 516;
	// lbz r10,980(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 980);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// lbz r9,979(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 979);
	// lbz r8,896(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 896);
	// lbz r6,897(r30)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r30.u32 + 897);
	// stb r18,103(r1)
	PPC_STORE_U8(ctx.r1.u32 + 103, ctx.r18.u8);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82dc5fa0
	ctx.lr = 0x82DC8E14;
	sub_82DC5FA0(ctx, base);
	// b 0x82dc8e34
	goto loc_82DC8E34;
loc_82DC8E18:
	// lwz r11,528(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	// stb r25,585(r31)
	PPC_STORE_U8(ctx.r31.u32 + 585, ctx.r25.u8);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc8e34
	if (!ctx.cr6.eq) goto loc_82DC8E34;
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 | 32;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DC8E34:
	// lbz r8,983(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 983);
	// clrlwi r11,r8,31
	ctx.r11.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8e84
	if (ctx.cr6.eq) goto loc_82DC8E84;
	// lbz r11,560(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 560);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8e84
	if (!ctx.cr6.eq) goto loc_82DC8E84;
	// lbz r11,1070(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1070);
	// addi r7,r30,986
	ctx.r7.s64 = ctx.r30.s64 + 986;
	// lbz r29,1069(r30)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1069);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r4,r31,540
	ctx.r4.s64 = ctx.r31.s64 + 540;
	// lbz r10,1068(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1068);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// lbz r9,1067(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1067);
	// lbz r6,984(r30)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r30.u32 + 984);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stb r24,103(r1)
	PPC_STORE_U8(ctx.r1.u32 + 103, ctx.r24.u8);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82dc5fa0
	ctx.lr = 0x82DC8E84;
	sub_82DC5FA0(ctx, base);
loc_82DC8E84:
	// lbz r11,1071(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1071);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8eb4
	if (ctx.cr6.eq) goto loc_82DC8EB4;
	// lbz r11,584(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 584);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc8eb4
	if (!ctx.cr6.eq) goto loc_82DC8EB4;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lbz r6,609(r28)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r28.u32 + 609);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82dc61b8
	ctx.lr = 0x82DC8EB4;
	sub_82DC61B8(ctx, base);
loc_82DC8EB4:
	// lbz r11,585(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 585);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8ef8
	if (ctx.cr6.eq) goto loc_82DC8EF8;
	// lhz r11,1164(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 1164);
	// lwz r10,588(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,588(r31)
	PPC_STORE_U32(ctx.r31.u32 + 588, ctx.r11.u32);
	// bge 0x82dc8ed8
	if (!ctx.cr0.lt) goto loc_82DC8ED8;
	// stw r26,588(r31)
	PPC_STORE_U32(ctx.r31.u32 + 588, ctx.r26.u32);
loc_82DC8ED8:
	// lwz r11,588(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// beq cr6,0x82dc8ef0
	if (ctx.cr6.eq) goto loc_82DC8EF0;
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// b 0x82dc8ef4
	goto loc_82DC8EF4;
loc_82DC8EF0:
	// ori r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 | 32;
loc_82DC8EF4:
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DC8EF8:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82dc6868
	ctx.lr = 0x82DC8F04;
	sub_82DC6868(ctx, base);
loc_82DC8F04:
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// lwz r10,496(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// add. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82dc8f20
	if (!ctx.cr0.eq) goto loc_82DC8F20;
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DC8F20:
	// lbz r11,475(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 475);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8f34
	if (ctx.cr6.eq) goto loc_82DC8F34;
	// mr r29,r26
	ctx.r29.u64 = ctx.r26.u64;
	// b 0x82dc8f40
	goto loc_82DC8F40;
loc_82DC8F34:
	// lwz r11,620(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 620);
	// lwz r29,628(r28)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r28.u32 + 628);
	// stw r11,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r11.u32);
loc_82DC8F40:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc901c
	if (ctx.cr6.eq) goto loc_82DC901C;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dc8fb0
	if (ctx.cr6.eq) goto loc_82DC8FB0;
	// lwz r11,1416(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1416);
	// rlwinm r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8f74
	if (ctx.cr6.eq) goto loc_82DC8F74;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
loc_82DC8F74:
	// lbz r10,1071(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1071);
	// rlwinm r10,r10,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dc8f90
	if (!ctx.cr6.eq) goto loc_82DC8F90;
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// bne cr6,0x82dc8f90
	if (!ctx.cr6.eq) goto loc_82DC8F90;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
loc_82DC8F90:
	// lbz r11,1424(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1424);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc8fb0
	if (ctx.cr6.eq) goto loc_82DC8FB0;
	// clrlwi r11,r11,25
	ctx.r11.u64 = ctx.r11.u32 & 0x7F;
	// addi r11,r11,3596
	ctx.r11.s64 = ctx.r11.s64 + 3596;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r19
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r19.u32);
loc_82DC8FB0:
	// lwz r11,0(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8fc8
	if (ctx.cr6.eq) goto loc_82DC8FC8;
	// addi r11,r11,3596
	ctx.r11.s64 = ctx.r11.s64 + 3596;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r19
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r19.u32);
loc_82DC8FC8:
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82dc8fe4
	if (ctx.cr6.eq) goto loc_82DC8FE4;
	// lwz r11,104(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 104);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc8fe4
	if (ctx.cr6.eq) goto loc_82DC8FE4;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
loc_82DC8FE4:
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwz r4,464(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82e02c60
	ctx.lr = 0x82DC8FF4;
	sub_82E02C60(ctx, base);
	// lwz r11,508(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dc901c
	if (!ctx.cr6.lt) goto loc_82DC901C;
	// lwz r11,464(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// addi r4,r11,-1
	ctx.r4.s64 = ctx.r11.s64 + -1;
	// bl 0x82d9cf10
	ctx.lr = 0x82DC901C;
	sub_82D9CF10(ctx, base);
loc_82DC901C:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc91a0
	if (ctx.cr6.eq) goto loc_82DC91A0;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// beq cr6,0x82dc9108
	if (ctx.cr6.eq) goto loc_82DC9108;
	// lwz r10,528(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	// std r11,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r11.u64);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r9,588(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// lwz r7,636(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 636);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// lwz r6,2028(r19)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// lwz r5,2024(r19)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2024);
	// lwz r8,512(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	// std r10,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r10.u64);
	// extsw r10,r6
	ctx.r10.s64 = ctx.r6.s32;
	// extsw r11,r5
	ctx.r11.s64 = ctx.r5.s32;
	// std r9,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r9.u64);
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r7,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r7.u64);
	// std r10,240(r1)
	PPC_STORE_U64(ctx.r1.u32 + 240, ctx.r10.u64);
	// std r11,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r11.u64);
	// std r8,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r8.u64);
	// lfd f11,112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// lfd f13,136(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lfd f0,144(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f12,128(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f10,192(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// lfd f9,240(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 240);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// lfd f8,176(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// frsp f8,f8
	ctx.f8.f64 = double(float(ctx.f8.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// fmuls f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// fmuls f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// fmuls f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// b 0x82dc918c
	goto loc_82DC918C;
loc_82DC9108:
	// lwz r10,512(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	// std r11,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r11.u64);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r9,636(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 636);
	// lwz r8,2028(r19)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2028);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// lwz r7,2024(r19)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2024);
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// std r10,224(r1)
	PPC_STORE_U64(ctx.r1.u32 + 224, ctx.r10.u64);
	// std r9,256(r1)
	PPC_STORE_U64(ctx.r1.u32 + 256, ctx.r9.u64);
	// std r8,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r8.u64);
	// std r7,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.r7.u64);
	// lfd f13,152(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lfd f0,224(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 224);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f12,256(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 256);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f11,208(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// lfd f10,160(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// fmuls f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
loc_82DC918C:
	// lfs f13,640(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DC91A0;
	sub_82D99380(ctx, base);
loc_82DC91A0:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9200
	if (ctx.cr6.eq) goto loc_82DC9200;
	// lhz r11,2034(r19)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc91d4
	if (ctx.cr6.eq) goto loc_82DC91D4;
	// lwz r11,552(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 552);
	// lwz r9,500(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 500);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// b 0x82dc91d8
	goto loc_82DC91D8;
loc_82DC91D4:
	// lwz r11,500(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 500);
loc_82DC91D8:
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// std r11,168(r1)
	PPC_STORE_U64(ctx.r1.u32 + 168, ctx.r11.u64);
	// lfd f0,168(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmsubs f1,f0,f16,f15
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f16.f64 - ctx.f15.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DC9200;
	sub_82D99540(ctx, base);
loc_82DC9200:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc92d4
	if (ctx.cr6.eq) goto loc_82DC92D4;
	// lhz r9,2034(r19)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// lwz r10,496(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// rlwinm r11,r9,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9244
	if (ctx.cr6.eq) goto loc_82DC9244;
	// lbz r11,1071(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1071);
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// bne cr6,0x82dc9248
	if (!ctx.cr6.eq) goto loc_82DC9248;
	// lwz r8,576(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 576);
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
	// b 0x82dc9248
	goto loc_82DC9248;
loc_82DC9244:
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
loc_82DC9248:
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r10,r9,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// beq cr6,0x82dc92a0
	if (ctx.cr6.eq) goto loc_82DC92A0;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// std r11,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, ctx.r11.u64);
	// lfd f0,184(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f24,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 - ctx.f0.f64));
	// fmul f0,f0,f23
	ctx.f0.f64 = ctx.f0.f64 * ctx.f23.f64;
	// frsp f2,f0
	ctx.f2.f64 = double(float(ctx.f0.f64));
	// bl 0x82cb59b0
	ctx.lr = 0x82DC9284;
	sub_82CB59B0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// addi r11,r1,124
	ctx.r11.s64 = ctx.r1.s64 + 124;
	// fmuls f0,f0,f22
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// b 0x82dc92a8
	goto loc_82DC92A8;
loc_82DC92A0:
	// twllei r11,0
	// divw r11,r23,r11
	ctx.r11.s32 = ctx.r23.s32 / ctx.r11.s32;
loc_82DC92A8:
	// lwz r10,508(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dc92b8
	if (!ctx.cr6.lt) goto loc_82DC92B8;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DC92B8:
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// std r11,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r11.u64);
	// lfd f0,200(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DC92D4;
	sub_82D9B8E0(ctx, base);
loc_82DC92D4:
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dc9310
	if (ctx.cr6.eq) goto loc_82DC9310;
	// lwz r10,1416(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1416);
	// rlwinm r9,r10,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dc92f4
	if (ctx.cr6.eq) goto loc_82DC92F4;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
loc_82DC92F4:
	// lbz r9,1071(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1071);
	// rlwinm r9,r9,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dc9310
	if (!ctx.cr6.eq) goto loc_82DC9310;
	// cmplwi cr6,r10,255
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 255, ctx.xer);
	// bne cr6,0x82dc9310
	if (!ctx.cr6.eq) goto loc_82DC9310;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82DC9310:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9458
	if (ctx.cr6.eq) goto loc_82DC9458;
	// lbz r10,1071(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1071);
	// li r11,256
	ctx.r11.s64 = 256;
	// rlwinm r10,r10,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc933c
	if (ctx.cr6.eq) goto loc_82DC933C;
	// lwz r11,576(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 576);
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
loc_82DC933C:
	// lhz r10,2034(r19)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r19.u32 + 2034);
	// addi r11,r11,256
	ctx.r11.s64 = ctx.r11.s64 + 256;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r10,1416(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1416);
	// clrlwi r10,r10,25
	ctx.r10.u64 = ctx.r10.u32 & 0x7F;
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// beq cr6,0x82dc937c
	if (ctx.cr6.eq) goto loc_82DC937C;
	// std r11,216(r1)
	PPC_STORE_U64(ctx.r1.u32 + 216, ctx.r11.u64);
	// lfd f0,216(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 216);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmadds f2,f0,f27,f29
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f27.f64 + ctx.f29.f64));
	// b 0x82dc9390
	goto loc_82DC9390;
loc_82DC937C:
	// std r11,232(r1)
	PPC_STORE_U64(ctx.r1.u32 + 232, ctx.r11.u64);
	// lfd f0,232(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 232);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmadds f2,f0,f26,f29
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f26.f64 + ctx.f29.f64));
loc_82DC9390:
	// bl 0x82cb59b0
	ctx.lr = 0x82DC9394;
	sub_82CB59B0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fmr f1,f0
	ctx.f1.f64 = ctx.f0.f64;
	// fcmpu cr6,f0,f25
	ctx.cr6.compare(ctx.f0.f64, ctx.f25.f64);
	// bge cr6,0x82dc93b0
	if (!ctx.cr6.lt) goto loc_82DC93B0;
	// fmr f1,f25
	ctx.f1.f64 = ctx.f25.f64;
	// b 0x82dc93bc
	goto loc_82DC93BC;
loc_82DC93B0:
	// fcmpu cr6,f0,f21
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f21.f64);
	// ble cr6,0x82dc93bc
	if (!ctx.cr6.gt) goto loc_82DC93BC;
	// fmr f1,f21
	ctx.f1.f64 = ctx.f21.f64;
loc_82DC93BC:
	// lwz r11,28(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 28);
	// fmuls f13,f1,f20
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,248(r1)
	PPC_STORE_U64(ctx.r1.u32 + 248, ctx.r11.u64);
	// lfd f0,248(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 248);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// ble cr6,0x82dc93e8
	if (!ctx.cr6.gt) goto loc_82DC93E8;
	// fmuls f1,f0,f19
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
loc_82DC93E8:
	// lis r12,-512
	ctx.r12.s64 = -33554432;
	// lwz r11,1420(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1420);
	// lwz r10,52(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// lwz r9,1032(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1032);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rldicr r12,r12,7,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 7) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// std r11,264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 264, ctx.r11.u64);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lfd f0,264(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 264);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f31,f0
	ctx.f31.f64 = double(float(ctx.f0.f64));
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9430;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// lwz r10,1032(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1032);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9458;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82DC9458:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc94c8
	if (ctx.cr6.eq) goto loc_82DC94C8;
	// lwz r11,1032(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 1032);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9490
	if (ctx.cr6.eq) goto loc_82DC9490;
	// lwz r10,52(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9490;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82DC9490:
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r26,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r26.u8);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82d9cb18
	ctx.lr = 0x82DC94B8;
	sub_82D9CB18(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r19)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r19.u32 + 16);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DC94C4;
	sub_82D8B3E0(ctx, base);
	// stw r26,504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 504, ctx.r26.u32);
loc_82DC94C8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r26,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r26.u8);
	// bl 0x82e02a30
	ctx.lr = 0x82DC94D4;
	sub_82E02A30(ctx, base);
	// mr r31,r27
	ctx.r31.u64 = ctx.r27.u64;
	// cmplw cr6,r27,r28
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82dc8d80
	if (!ctx.cr6.eq) goto loc_82DC8D80;
loc_82DC94E0:
	// lwz r11,756(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 756);
	// addi r21,r21,1
	ctx.r21.s64 = ctx.r21.s64 + 1;
	// addi r22,r22,4
	ctx.r22.s64 = ctx.r22.s64 + 4;
	// cmpw cr6,r21,r11
	ctx.cr6.compare<int32_t>(ctx.r21.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc8d60
	if (ctx.cr6.lt) goto loc_82DC8D60;
loc_82DC94F4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b00
	ctx.lr = 0x82DC9504;
	__restfpr_15(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC9508"))) PPC_WEAK_FUNC(sub_82DC9508);
PPC_FUNC_IMPL(__imp__sub_82DC9508) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DC9510;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dc96c4
	if (!ctx.cr6.eq) goto loc_82DC96C4;
	// lwz r11,2072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2072);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dc95cc
	if (ctx.cr6.lt) goto loc_82DC95CC;
	// add r10,r11,r31
	ctx.r10.u64 = ctx.r11.u64 + ctx.r31.u64;
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// lbz r11,500(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 500);
	// cmplwi cr6,r11,254
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 254, ctx.xer);
	// bne cr6,0x82dc9594
	if (!ctx.cr6.eq) goto loc_82DC9594;
loc_82DC954C:
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// lwz r10,1280(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1280);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// blt cr6,0x82dc9580
	if (ctx.cr6.lt) goto loc_82DC9580;
	// lbz r11,2038(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2038);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc9578
	if (!ctx.cr6.eq) goto loc_82DC9578;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DC9578;
	sub_82E02B60(ctx, base);
loc_82DC9578:
	// lwz r11,2012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2012);
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
loc_82DC9580:
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// lbz r11,500(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 500);
	// cmplwi cr6,r11,254
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 254, ctx.xer);
	// beq cr6,0x82dc954c
	if (ctx.cr6.eq) goto loc_82DC954C;
loc_82DC9594:
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// lbz r11,500(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 500);
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// bne cr6,0x82dc95cc
	if (!ctx.cr6.eq) goto loc_82DC95CC;
	// lwz r11,2012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2012);
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r9,r11,r31
	ctx.r9.u64 = ctx.r11.u64 + ctx.r31.u64;
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// lbz r11,500(r9)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 500);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r11,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r11.u32);
loc_82DC95CC:
	// lwz r9,2068(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// blt cr6,0x82dc95e8
	if (ctx.cr6.lt) goto loc_82DC95E8;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82dc95f4
	if (!ctx.cr6.eq) goto loc_82DC95F4;
loc_82DC95E8:
	// lwz r11,2072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2072);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dc9638
	if (ctx.cr6.lt) goto loc_82DC9638;
loc_82DC95F4:
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r11,500(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 500);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r11,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r11.u32);
	// ble cr6,0x82dc9638
	if (!ctx.cr6.gt) goto loc_82DC9638;
loc_82DC9620:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc6ca0
	ctx.lr = 0x82DC9628;
	sub_82DC6CA0(ctx, base);
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc9620
	if (ctx.cr6.lt) goto loc_82DC9620;
loc_82DC9638:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dc9650
	if (ctx.cr6.lt) goto loc_82DC9650;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
	// bl 0x82dc6ca0
	ctx.lr = 0x82DC9650;
	sub_82DC6CA0(ctx, base);
loc_82DC9650:
	// li r11,-1
	ctx.r11.s64 = -1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
	// bl 0x82dc6ea8
	ctx.lr = 0x82DC9668;
	sub_82DC6EA8(ctx, base);
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82dc96d0
	if (!ctx.cr6.eq) goto loc_82DC96D0;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// lwz r10,2056(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r9,488(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r8,r10,r31
	ctx.r8.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
	// lbz r8,500(r8)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + 500);
	// rotlwi r8,r8,3
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 3);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc96d0
	if (ctx.cr6.lt) goto loc_82DC96D0;
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lwz r10,1280(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1280);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
	// blt cr6,0x82dc96bc
	if (ctx.cr6.lt) goto loc_82DC96BC;
	// lwz r11,2012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2012);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
loc_82DC96BC:
	// stw r28,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r28.u32);
	// b 0x82dc96d0
	goto loc_82DC96D0;
loc_82DC96C4:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc6ea8
	ctx.lr = 0x82DC96D0;
	sub_82DC6EA8(ctx, base);
loc_82DC96D0:
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// lwz r10,2044(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2044);
	// lwz r8,2060(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2060);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r9,2064(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2064);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r11,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r11.u32);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dc9704
	if (ctx.cr6.lt) goto loc_82DC9704;
	// stw r28,2060(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2060, ctx.r28.u32);
	// stw r28,2064(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2064, ctx.r28.u32);
	// stw r28,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r28.u32);
loc_82DC9704:
	// lwz r10,1136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,1132(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,1136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1136, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC9720"))) PPC_WEAK_FUNC(sub_82DC9720);
PPC_FUNC_IMPL(__imp__sub_82DC9720) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e032f8
	ctx.lr = 0x82DC9738;
	sub_82E032F8(ctx, base);
	// lwz r9,1288(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1288);
loc_82DC973C:
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// add r10,r11,r31
	ctx.r10.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r10,500(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 500);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dc9774
	if (ctx.cr6.lt) goto loc_82DC9774;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r8,1280(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1280);
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// bge cr6,0x82dc976c
	if (!ctx.cr6.lt) goto loc_82DC976C;
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// blt cr6,0x82dc973c
	if (ctx.cr6.lt) goto loc_82DC973C;
loc_82DC976C:
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dc97a8
	if (!ctx.cr6.lt) goto loc_82DC97A8;
loc_82DC9774:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r11,14368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14368, ctx.r11.u32);
	// bl 0x82dc6ca0
	ctx.lr = 0x82DC9790;
	sub_82DC6CA0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82DC97A8:
	// li r11,1
	ctx.r11.s64 = 1;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r3,25
	ctx.r3.s64 = 25;
	// stb r11,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r11.u8);
	// stb r10,2036(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2036, ctx.r10.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC97D0"))) PPC_WEAK_FUNC(sub_82DC97D0);
PPC_FUNC_IMPL(__imp__sub_82DC97D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DC97D8;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DC97E4;
	sub_82E02B60(ctx, base);
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// li r28,0
	ctx.r28.s64 = 0;
	// lis r26,-31909
	ctx.r26.s64 = -2091188224;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r27,r11,9224
	ctx.r27.s64 = ctx.r11.s64 + 9224;
	// beq cr6,0x82dc9898
	if (ctx.cr6.eq) goto loc_82DC9898;
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc9878
	if (!ctx.cr6.gt) goto loc_82DC9878;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
loc_82DC9814:
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc9864
	if (ctx.cr6.eq) goto loc_82DC9864;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc9864
	if (ctx.cr6.eq) goto loc_82DC9864;
	// lwzx r11,r30,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9850;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// lwzx r11,r30,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// stw r28,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r28.u32);
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// stwx r28,r30,r11
	PPC_STORE_U32(ctx.r30.u32 + ctx.r11.u32, ctx.r28.u32);
loc_82DC9864:
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc9814
	if (ctx.cr6.lt) goto loc_82DC9814;
loc_82DC9878:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6135
	ctx.r6.s64 = 6135;
	// lwz r4,2076(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9894;
	sub_82D861B0(ctx, base);
	// stw r28,2076(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2076, ctx.r28.u32);
loc_82DC9898:
	// lwz r11,1032(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1032);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9914
	if (ctx.cr6.eq) goto loc_82DC9914;
	// lwz r11,14384(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14384);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc98f4
	if (!ctx.cr6.gt) goto loc_82DC98F4;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
loc_82DC98B8:
	// lwz r11,1032(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1032);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dc98e0
	if (ctx.cr6.eq) goto loc_82DC98E0;
	// rotlwi r3,r10,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC98E0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82DC98E0:
	// lwz r11,14384(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14384);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc98b8
	if (ctx.cr6.lt) goto loc_82DC98B8;
loc_82DC98F4:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6149
	ctx.r6.s64 = 6149;
	// lwz r4,1032(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1032);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9910;
	sub_82D861B0(ctx, base);
	// stw r28,1032(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1032, ctx.r28.u32);
loc_82DC9914:
	// lwz r4,1300(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1300);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc993c
	if (ctx.cr6.eq) goto loc_82DC993C;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6155
	ctx.r6.s64 = 6155;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9938;
	sub_82D861B0(ctx, base);
	// stw r28,1300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1300, ctx.r28.u32);
loc_82DC993C:
	// lwz r4,1020(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1020);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc9964
	if (ctx.cr6.eq) goto loc_82DC9964;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6161
	ctx.r6.s64 = 6161;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9960;
	sub_82D861B0(ctx, base);
	// stw r28,1020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1020, ctx.r28.u32);
loc_82DC9964:
	// lwz r3,1024(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1024);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc9978
	if (ctx.cr6.eq) goto loc_82DC9978;
	// bl 0x82da94d0
	ctx.lr = 0x82DC9974;
	sub_82DA94D0(ctx, base);
	// stw r28,1024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1024, ctx.r28.u32);
loc_82DC9978:
	// lwz r4,1028(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc99a0
	if (ctx.cr6.eq) goto loc_82DC99A0;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6172
	ctx.r6.s64 = 6172;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC999C;
	sub_82D861B0(ctx, base);
	// stw r28,1028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1028, ctx.r28.u32);
loc_82DC99A0:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9a2c
	if (ctx.cr6.eq) goto loc_82DC9A2C;
	// lwz r11,1288(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1288);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc9a0c
	if (!ctx.cr6.gt) goto loc_82DC9A0C;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
loc_82DC99C0:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc99f8
	if (ctx.cr6.eq) goto loc_82DC99F8;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6182
	ctx.r6.s64 = 6182;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC99EC;
	sub_82D861B0(ctx, base);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r28,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r28.u32);
loc_82DC99F8:
	// lwz r11,1288(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1288);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc99c0
	if (ctx.cr6.lt) goto loc_82DC99C0;
loc_82DC9A0C:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6187
	ctx.r6.s64 = 6187;
	// lwz r4,488(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9A28;
	sub_82D861B0(ctx, base);
	// stw r28,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r28.u32);
loc_82DC9A2C:
	// addi r30,r31,14388
	ctx.r30.s64 = ctx.r31.s64 + 14388;
	// li r29,50
	ctx.r29.s64 = 50;
loc_82DC9A34:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9a78
	if (ctx.cr6.eq) goto loc_82DC9A78;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9A5C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r6,6197
	ctx.r6.s64 = 6197;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9A78;
	sub_82D861B0(ctx, base);
loc_82DC9A78:
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82dc9a34
	if (!ctx.cr6.eq) goto loc_82DC9A34;
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dc9ad8
	if (!ctx.cr6.gt) goto loc_82DC9AD8;
	// addi r30,r31,760
	ctx.r30.s64 = ctx.r31.s64 + 760;
loc_82DC9A9C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc9ac4
	if (ctx.cr6.eq) goto loc_82DC9AC4;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6205
	ctx.r6.s64 = 6205;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9AC0;
	sub_82D861B0(ctx, base);
	// stw r28,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r28.u32);
loc_82DC9AC4:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dc9a9c
	if (ctx.cr6.lt) goto loc_82DC9A9C;
loc_82DC9AD8:
	// lwz r4,496(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dc9b00
	if (ctx.cr6.eq) goto loc_82DC9B00;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6212
	ctx.r6.s64 = 6212;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DC9AFC;
	sub_82D861B0(ctx, base);
	// stw r28,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r28.u32);
loc_82DC9B00:
	// lwz r3,14844(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14844);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc9b24
	if (ctx.cr6.eq) goto loc_82DC9B24;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9B20;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r28,14844(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14844, ctx.r28.u32);
loc_82DC9B24:
	// lwz r3,14848(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14848);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc9b48
	if (ctx.cr6.eq) goto loc_82DC9B48;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9B44;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r28,14848(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14848, ctx.r28.u32);
loc_82DC9B48:
	// lwz r3,492(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 492);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dc9b6c
	if (ctx.cr6.eq) goto loc_82DC9B6C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9B68;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r28,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r28.u32);
loc_82DC9B6C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC9B78"))) PPC_WEAK_FUNC(sub_82DC9B78);
PPC_FUNC_IMPL(__imp__sub_82DC9B78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DC9B80;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,256
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 256, ctx.xer);
	// bne cr6,0x82dc9bac
	if (!ctx.cr6.eq) goto loc_82DC9BAC;
	// bl 0x82dc9720
	ctx.lr = 0x82DC9B98;
	sub_82DC9720(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r30.u32);
	// stw r30,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DC9BAC:
	// cmplwi cr6,r6,2
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 2, ctx.xer);
	// bne cr6,0x82dc9c28
	if (!ctx.cr6.eq) goto loc_82DC9C28;
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dc9c1c
	if (ctx.cr6.eq) goto loc_82DC9C1C;
	// bge cr6,0x82dc9bd4
	if (!ctx.cr6.lt) goto loc_82DC9BD4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc9720
	ctx.lr = 0x82DC9BD0;
	sub_82DC9720(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
loc_82DC9BD4:
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82dc9bf8
	if (!ctx.cr6.lt) goto loc_82DC9BF8;
loc_82DC9BE0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc9508
	ctx.lr = 0x82DC9BEC;
	sub_82DC9508(ctx, base);
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82dc9be0
	if (ctx.cr6.lt) goto loc_82DC9BE0;
loc_82DC9BF8:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9c1c
	if (ctx.cr6.eq) goto loc_82DC9C1C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lbz r30,2036(r31)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2036);
	// lbz r29,2037(r31)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// bl 0x82e02b60
	ctx.lr = 0x82DC9C14;
	sub_82E02B60(ctx, base);
	// stb r30,2036(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2036, ctx.r30.u8);
	// stb r29,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r29.u8);
loc_82DC9C1C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DC9C28:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC9C34"))) PPC_WEAK_FUNC(sub_82DC9C34);
PPC_FUNC_IMPL(__imp__sub_82DC9C34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC9C38"))) PPC_WEAK_FUNC(sub_82DC9C38);
PPC_FUNC_IMPL(__imp__sub_82DC9C38) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc9c48
	if (!ctx.cr6.eq) goto loc_82DC9C48;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC9C48:
	// b 0x82dc97d0
	sub_82DC97D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC9C4C"))) PPC_WEAK_FUNC(sub_82DC9C4C);
PPC_FUNC_IMPL(__imp__sub_82DC9C4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC9C50"))) PPC_WEAK_FUNC(sub_82DC9C50);
PPC_FUNC_IMPL(__imp__sub_82DC9C50) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dc9c60
	if (!ctx.cr6.eq) goto loc_82DC9C60;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DC9C60:
	// b 0x82dc9b78
	sub_82DC9B78(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DC9C64"))) PPC_WEAK_FUNC(sub_82DC9C64);
PPC_FUNC_IMPL(__imp__sub_82DC9C64) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC9C68"))) PPC_WEAK_FUNC(sub_82DC9C68);
PPC_FUNC_IMPL(__imp__sub_82DC9C68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// bl 0x82dc9720
	ctx.lr = 0x82DC9C8C;
	sub_82DC9720(ctx, base);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dc9cc4
	if (!ctx.cr6.eq) goto loc_82DC9CC4;
loc_82DC9C98:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dc9508
	ctx.lr = 0x82DC9CA4;
	sub_82DC9508(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,1132(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// lwz r9,272(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dc9c98
	if (ctx.cr6.eq) goto loc_82DC9C98;
loc_82DC9CC4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DC9CCC;
	sub_82E02B60(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC9CE4"))) PPC_WEAK_FUNC(sub_82DC9CE4);
PPC_FUNC_IMPL(__imp__sub_82DC9CE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC9CE8"))) PPC_WEAK_FUNC(sub_82DC9CE8);
PPC_FUNC_IMPL(__imp__sub_82DC9CE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DC9D14;
	sub_82D9B4A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC9D2C"))) PPC_WEAK_FUNC(sub_82DC9D2C);
PPC_FUNC_IMPL(__imp__sub_82DC9D2C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC9D30"))) PPC_WEAK_FUNC(sub_82DC9D30);
PPC_FUNC_IMPL(__imp__sub_82DC9D30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DC9D5C;
	sub_82D9B4A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DC9D74"))) PPC_WEAK_FUNC(sub_82DC9D74);
PPC_FUNC_IMPL(__imp__sub_82DC9D74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DC9D78"))) PPC_WEAK_FUNC(sub_82DC9D78);
PPC_FUNC_IMPL(__imp__sub_82DC9D78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DC9D80;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r21,r5
	ctx.r21.u64 = ctx.r5.u64;
	// mr r20,r6
	ctx.r20.u64 = ctx.r6.u64;
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r22,4408(r10)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4408);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// beq cr6,0x82dc9ee4
	if (ctx.cr6.eq) goto loc_82DC9EE4;
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dc9ee4
	if (ctx.cr6.gt) goto loc_82DC9EE4;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-25132
	ctx.r12.s64 = ctx.r12.s64 + -25132;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DC9E40;
	case 1:
		goto loc_82DC9E00;
	case 2:
		goto loc_82DC9E08;
	case 3:
		goto loc_82DC9E10;
	case 4:
		goto loc_82DC9E18;
	case 5:
		goto loc_82DC9E18;
	case 6:
		goto loc_82DC9E40;
	case 7:
		goto loc_82DC9E40;
	case 8:
		goto loc_82DC9E40;
	case 9:
		goto loc_82DC9E40;
	case 10:
		goto loc_82DC9E40;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-25024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25024);
	// lwz r22,-25088(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25088);
	// lwz r22,-25080(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25080);
	// lwz r22,-25072(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25072);
	// lwz r22,-25064(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25064);
	// lwz r22,-25064(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25064);
	// lwz r22,-25024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25024);
	// lwz r22,-25024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25024);
	// lwz r22,-25024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25024);
	// lwz r22,-25024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25024);
	// lwz r22,-25024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25024);
loc_82DC9E00:
	// li r11,8
	ctx.r11.s64 = 8;
	// b 0x82dc9e1c
	goto loc_82DC9E1C;
loc_82DC9E08:
	// li r11,16
	ctx.r11.s64 = 16;
	// b 0x82dc9e1c
	goto loc_82DC9E1C;
loc_82DC9E10:
	// li r11,24
	ctx.r11.s64 = 24;
	// b 0x82dc9e1c
	goto loc_82DC9E1C;
loc_82DC9E18:
	// li r11,32
	ctx.r11.s64 = 32;
loc_82DC9E1C:
	// li r9,0
	ctx.r9.s64 = 0;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// rldimi r9,r21,3,29
	ctx.r9.u64 = (__builtin_rotateleft64(ctx.r21.u64, 3) & 0x7FFFFFFF8) | (ctx.r9.u64 & 0xFFFFFFF800000007);
	// tdllei r11,0
	// divdu r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 / ctx.r11.u64;
	// twllei r10,0
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dc9ee8
	goto loc_82DC9EE8;
loc_82DC9E40:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-25000
	ctx.r12.s64 = ctx.r12.s64 + -25000;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-24876(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24876);
	// lwz r22,-24860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24860);
	// lwz r22,-24860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24860);
	// lwz r22,-24860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24860);
	// lwz r22,-24860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24860);
	// lwz r22,-24860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24860);
	// lwz r22,-24956(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24956);
	// lwz r22,-24936(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24936);
	// lwz r22,-24904(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24904);
	// lwz r22,-24884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24884);
	// lwz r22,-24884(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24884);
	// mulli r11,r21,14
	ctx.r11.s64 = ctx.r21.s64 * 14;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dc9ee8
	goto loc_82DC9EE8;
	// lis r9,14563
	ctx.r9.s64 = 954400768;
	// rlwinm r11,r21,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 6) & 0xFFFFFFC0;
	// ori r9,r9,36409
	ctx.r9.u64 = ctx.r9.u64 | 36409;
	// twllei r10,0
	// mulhwu r11,r11,r9
	ctx.r11.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dc9ee8
	goto loc_82DC9EE8;
	// mulli r11,r21,28
	ctx.r11.s64 = ctx.r21.s64 * 28;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dc9ee8
	goto loc_82DC9EE8;
	// mr r24,r21
	ctx.r24.u64 = ctx.r21.u64;
	// b 0x82dc9ee8
	goto loc_82DC9EE8;
	// li r11,0
	ctx.r11.s64 = 0;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dc9ee8
	goto loc_82DC9EE8;
loc_82DC9EE4:
	// lwz r24,88(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DC9EE8:
	// lbz r11,2036(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dca170
	if (ctx.cr6.eq) goto loc_82DCA170;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,2016(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 2016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x82dca170
	if (ctx.cr6.eq) goto loc_82DCA170;
	// lwz r27,1128(r25)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1128);
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82dca16c
	if (ctx.cr6.eq) goto loc_82DCA16C;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// lwz r29,88(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// ori r30,r11,18725
	ctx.r30.u64 = ctx.r11.u64 | 18725;
loc_82DC9F28:
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82dc9f54
	if (!ctx.cr6.eq) goto loc_82DC9F54;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82dc9508
	ctx.lr = 0x82DC9F40;
	sub_82DC9508(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dca180
	if (!ctx.cr6.eq) goto loc_82DCA180;
	// lwz r11,1132(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1132);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// b 0x82dc9f58
	goto loc_82DC9F58;
loc_82DC9F54:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82DC9F58:
	// add r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 + ctx.r28.u64;
	// cmplw cr6,r10,r24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r24.u32, ctx.xer);
	// ble cr6,0x82dc9f68
	if (!ctx.cr6.gt) goto loc_82DC9F68;
	// subf r11,r28,r24
	ctx.r11.s64 = ctx.r24.s64 - ctx.r28.s64;
loc_82DC9F68:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82da41c0
	ctx.lr = 0x82DC9F74;
	sub_82DA41C0(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dc9fbc
	if (ctx.cr6.eq) goto loc_82DC9FBC;
	// lwz r3,14844(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 14844);
	// li r9,1000
	ctx.r9.s64 = 1000;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DC9FA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x82dca188
	if (!ctx.cr6.eq) goto loc_82DCA188;
	// lwz r3,14844(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 14844);
	// bl 0x82d938a0
	ctx.lr = 0x82DC9FBC;
	sub_82D938A0(ctx, base);
loc_82DC9FBC:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DC9FC4;
	sub_82DA4200(ctx, base);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dca134
	if (ctx.cr6.gt) goto loc_82DCA134;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-24592
	ctx.r12.s64 = ctx.r12.s64 + -24592;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCA05C;
	case 1:
		goto loc_82DCA01C;
	case 2:
		goto loc_82DCA02C;
	case 3:
		goto loc_82DCA03C;
	case 4:
		goto loc_82DCA04C;
	case 5:
		goto loc_82DCA04C;
	case 6:
		goto loc_82DCA05C;
	case 7:
		goto loc_82DCA05C;
	case 8:
		goto loc_82DCA05C;
	case 9:
		goto loc_82DCA05C;
	case 10:
		goto loc_82DCA05C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24484);
	// lwz r22,-24548(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24548);
	// lwz r22,-24532(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24532);
	// lwz r22,-24516(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24516);
	// lwz r22,-24500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24500);
	// lwz r22,-24500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24500);
	// lwz r22,-24484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24484);
	// lwz r22,-24484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24484);
	// lwz r22,-24484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24484);
	// lwz r22,-24484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24484);
	// lwz r22,-24484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24484);
loc_82DCA01C:
	// li r11,8
	ctx.r11.s64 = 8;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dca12c
	goto loc_82DCA12C;
loc_82DCA02C:
	// li r11,16
	ctx.r11.s64 = 16;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dca12c
	goto loc_82DCA12C;
loc_82DCA03C:
	// li r11,24
	ctx.r11.s64 = 24;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dca12c
	goto loc_82DCA12C;
loc_82DCA04C:
	// li r11,32
	ctx.r11.s64 = 32;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dca12c
	goto loc_82DCA12C;
loc_82DCA05C:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-24460
	ctx.r12.s64 = ctx.r12.s64 + -24460;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-24280(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24280);
	// lwz r22,-24268(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24268);
	// lwz r22,-24268(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24268);
	// lwz r22,-24268(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24268);
	// lwz r22,-24268(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24268);
	// lwz r22,-24268(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24268);
	// lwz r22,-24416(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24416);
	// lwz r22,-24364(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24364);
	// lwz r22,-24340(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24340);
	// lwz r22,-24288(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24288);
	// lwz r22,-24288(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -24288);
	// addi r11,r9,13
	ctx.r11.s64 = ctx.r9.s64 + 13;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dca12c
	goto loc_82DCA12C;
	// addi r11,r9,63
	ctx.r11.s64 = ctx.r9.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dca12c
	goto loc_82DCA12C;
	// addi r11,r9,27
	ctx.r11.s64 = ctx.r9.s64 + 27;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dca12c
	goto loc_82DCA12C;
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// b 0x82dca134
	goto loc_82DCA134;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DCA12C:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mullw r29,r11,r10
	ctx.r29.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82DCA134:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r26,r4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82dca158
	if (ctx.cr6.eq) goto loc_82DCA158;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dca158
	if (ctx.cr6.eq) goto loc_82DCA158;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DCA154;
	sub_82CB1160(ctx, base);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DCA158:
	// add r28,r9,r28
	ctx.r28.u64 = ctx.r9.u64 + ctx.r28.u64;
	// add r26,r29,r26
	ctx.r26.u64 = ctx.r29.u64 + ctx.r26.u64;
	// subf r27,r9,r27
	ctx.r27.s64 = ctx.r27.s64 - ctx.r9.s64;
	// cmplw cr6,r28,r24
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82dc9f28
	if (ctx.cr6.lt) goto loc_82DC9F28;
loc_82DCA16C:
	// stw r27,1128(r25)
	PPC_STORE_U32(ctx.r25.u32 + 1128, ctx.r27.u32);
loc_82DCA170:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82dca17c
	if (ctx.cr6.eq) goto loc_82DCA17C;
	// stw r21,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r21.u32);
loc_82DCA17C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCA180:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DCA188:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DCA190;
	sub_82DA4200(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCA19C"))) PPC_WEAK_FUNC(sub_82DCA19C);
PPC_FUNC_IMPL(__imp__sub_82DCA19C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCA1A0"))) PPC_WEAK_FUNC(sub_82DCA1A0);
PPC_FUNC_IMPL(__imp__sub_82DCA1A0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dca1b0
	if (!ctx.cr6.eq) goto loc_82DCA1B0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCA1B0:
	// b 0x82dc9d78
	sub_82DC9D78(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCA1B4"))) PPC_WEAK_FUNC(sub_82DCA1B4);
PPC_FUNC_IMPL(__imp__sub_82DCA1B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCA1B8"))) PPC_WEAK_FUNC(sub_82DCA1B8);
PPC_FUNC_IMPL(__imp__sub_82DCA1B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DCA1E4;
	sub_82D9B4A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCA1FC"))) PPC_WEAK_FUNC(sub_82DCA1FC);
PPC_FUNC_IMPL(__imp__sub_82DCA1FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCA200"))) PPC_WEAK_FUNC(sub_82DCA200);
PPC_FUNC_IMPL(__imp__sub_82DCA200) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DCA208;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6ae8
	ctx.lr = 0x82DCA210;
	__savefpr_28(ctx, base);
	// stwu r1,-2480(r1)
	ea = -2480 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// stw r4,2508(r1)
	PPC_STORE_U32(ctx.r1.u32 + 2508, ctx.r4.u32);
	// li r17,0
	ctx.r17.s64 = 0;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r15,r17
	ctx.r15.u64 = ctx.r17.u64;
	// lwz r11,224(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// sth r17,92(r1)
	PPC_STORE_U16(ctx.r1.u32 + 92, ctx.r17.u16);
	// stw r31,2516(r1)
	PPC_STORE_U32(ctx.r1.u32 + 2516, ctx.r31.u32);
	// stw r15,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r15.u32);
	// stw r17,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r17.u32);
	// lwz r11,388(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	// stb r17,94(r1)
	PPC_STORE_U8(ctx.r1.u32 + 94, ctx.r17.u8);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dca264
	if (!ctx.cr6.eq) goto loc_82DCA264;
loc_82DCA250:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCA260;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCA264:
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r23,10
	ctx.r23.s64 = 10;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,19872(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19872, ctx.r11.u32);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// stw r23,60(r30)
	PPC_STORE_U32(ctx.r30.u32 + 60, ctx.r23.u32);
	// stw r17,220(r30)
	PPC_STORE_U32(ctx.r30.u32 + 220, ctx.r17.u32);
	// stw r17,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r17.u32);
	// stw r17,28(r30)
	PPC_STORE_U32(ctx.r30.u32 + 28, ctx.r17.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DCA294;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCA2B4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82da7e70
	ctx.lr = 0x82DCA2CC;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA2EC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,9508
	ctx.r4.s64 = ctx.r11.s64 + 9508;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x82da45e8
	ctx.lr = 0x82DCA308;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dca250
	if (!ctx.cr6.eq) goto loc_82DCA250;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// addi r4,r1,156
	ctx.r4.s64 = ctx.r1.s64 + 156;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCA328;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r24,r30,760
	ctx.r24.s64 = ctx.r30.s64 + 760;
	// li r18,64
	ctx.r18.s64 = 64;
	// mr r9,r17
	ctx.r9.u64 = ctx.r17.u64;
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DCA348:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82dca348
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DCA348;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// stw r17,488(r30)
	PPC_STORE_U32(ctx.r30.u32 + 488, ctx.r17.u32);
	// li r10,6
	ctx.r10.s64 = 6;
	// stb r18,1276(r30)
	PPC_STORE_U8(ctx.r30.u32 + 1276, ctx.r18.u8);
	// addi r28,r30,1140
	ctx.r28.s64 = ctx.r30.s64 + 1140;
	// stw r17,1284(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1284, ctx.r17.u32);
	// addi r27,r30,1144
	ctx.r27.s64 = ctx.r30.s64 + 1144;
	// stw r17,2012(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2012, ctx.r17.u32);
	// addi r29,r30,1276
	ctx.r29.s64 = ctx.r30.s64 + 1276;
	// stw r17,1296(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1296, ctx.r17.u32);
	// lfs f31,6140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f31.f64 = double(temp.f32);
	// li r11,125
	ctx.r11.s64 = 125;
	// stfs f31,2016(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 2016, temp.u32);
	// stw r10,1140(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1140, ctx.r10.u32);
	// addi r26,r30,1296
	ctx.r26.s64 = ctx.r30.s64 + 1296;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r11,1144(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1144, ctx.r11.u32);
	// beq cr6,0x82dca3b0
	if (ctx.cr6.eq) goto loc_82DCA3B0;
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dca3b0
	if (ctx.cr6.eq) goto loc_82DCA3B0;
	// stw r11,756(r30)
	PPC_STORE_U32(ctx.r30.u32 + 756, ctx.r11.u32);
	// b 0x82dca3b4
	goto loc_82DCA3B4;
loc_82DCA3B0:
	// stw r18,756(r30)
	PPC_STORE_U32(ctx.r30.u32 + 756, ctx.r18.u32);
loc_82DCA3B4:
	// li r11,128
	ctx.r11.s64 = 128;
	// stw r17,14368(r30)
	PPC_STORE_U32(ctx.r30.u32 + 14368, ctx.r17.u32);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,1308
	ctx.r3.s64 = ctx.r30.s64 + 1308;
	// addi r31,r30,2024
	ctx.r31.s64 = ctx.r30.s64 + 2024;
	// stw r11,2024(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2024, ctx.r11.u32);
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA3D4;
	sub_82CB16F0(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,1372
	ctx.r3.s64 = ctx.r30.s64 + 1372;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA3E4;
	sub_82CB16F0(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,1436
	ctx.r3.s64 = ctx.r30.s64 + 1436;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA3F4;
	sub_82CB16F0(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,1500
	ctx.r3.s64 = ctx.r30.s64 + 1500;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA404;
	sub_82CB16F0(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,1564
	ctx.r3.s64 = ctx.r30.s64 + 1564;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA414;
	sub_82CB16F0(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,1628
	ctx.r3.s64 = ctx.r30.s64 + 1628;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA424;
	sub_82CB16F0(ctx, base);
	// lis r11,-31894
	ctx.r11.s64 = -2090205184;
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r3,r11,-6864
	ctx.r3.s64 = ctx.r11.s64 + -6864;
	// li r4,-1
	ctx.r4.s64 = -1;
	// stw r3,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r3.u32);
	// bl 0x82cb16f0
	ctx.lr = 0x82DCA43C;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r16,r11,9224
	ctx.r16.s64 = ctx.r11.s64 + 9224;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r6,4157
	ctx.r6.s64 = 4157;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,296
	ctx.r4.s64 = 296;
	// stw r16,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r16.u32);
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCA468;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,56(r30)
	PPC_STORE_U32(ctx.r30.u32 + 56, ctx.r3.u32);
	// bne cr6,0x82dca488
	if (!ctx.cr6.eq) goto loc_82DCA488;
loc_82DCA474:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCA484;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCA488:
	// lwz r11,160(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r3,28(r30)
	PPC_STORE_U32(ctx.r30.u32 + 28, ctx.r3.u32);
	// stw r11,268(r3)
	PPC_STORE_U32(ctx.r3.u32 + 268, ctx.r11.u32);
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// addi r11,r11,264
	ctx.r11.s64 = ctx.r11.s64 + 264;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dca4b0
	if (ctx.cr6.eq) goto loc_82DCA4B0;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r10,1244(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1244);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
loc_82DCA4B0:
	// addi r4,r30,232
	ctx.r4.s64 = ctx.r30.s64 + 232;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA4C8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82da7e70
	ctx.lr = 0x82DCA4E0;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r25,r30,1280
	ctx.r25.s64 = ctx.r30.s64 + 1280;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x82da7d80
	ctx.lr = 0x82DCA4F8;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r21,r30,1292
	ctx.r21.s64 = ctx.r30.s64 + 1292;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// bl 0x82da7d80
	ctx.lr = 0x82DCA510;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCA524;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCA538;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82da7e70
	ctx.lr = 0x82DCA550;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCA564;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r26,r30,2034
	ctx.r26.s64 = ctx.r30.s64 + 2034;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da7c90
	ctx.lr = 0x82DCA57C;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82da7e70
	ctx.lr = 0x82DCA594;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCA5A8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DCA5BC;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DCA5D0;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7b50
	ctx.lr = 0x82DCA5E4;
	sub_82DA7B50(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCA5F8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCA60C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCA620;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7e20
	ctx.lr = 0x82DCA634;
	sub_82DA7E20(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7dd0
	ctx.lr = 0x82DCA648;
	sub_82DA7DD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,64
	ctx.r6.s64 = 64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r30,1148
	ctx.r4.s64 = ctx.r30.s64 + 1148;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA668;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,64
	ctx.r6.s64 = 64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r30,1212
	ctx.r4.s64 = ctx.r30.s64 + 1212;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA688;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r31,r30,500
	ctx.r31.s64 = ctx.r30.s64 + 500;
	// lwz r6,0(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA6AC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r9,0(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// mr r10,r17
	ctx.r10.u64 = ctx.r17.u64;
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82dca6f0
	if (!ctx.cr6.gt) goto loc_82DCA6F0;
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
loc_82DCA6CC:
	// lbzx r8,r31,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r11.u32);
	// cmplwi cr6,r8,255
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 255, ctx.xer);
	// beq cr6,0x82dca6e4
	if (ctx.cr6.eq) goto loc_82DCA6E4;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dca6e4
	if (!ctx.cr6.gt) goto loc_82DCA6E4;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82DCA6E4:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dca6cc
	if (ctx.cr6.lt) goto loc_82DCA6CC;
loc_82DCA6F0:
	// lis r11,-31894
	ctx.r11.s64 = -2090205184;
	// lwz r6,0(r21)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// addi r25,r11,-7888
	ctx.r25.s64 = ctx.r11.s64 + -7888;
	// addi r11,r30,1280
	ctx.r11.s64 = ctx.r30.s64 + 1280;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DCA71C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-31894
	ctx.r11.s64 = -2090205184;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r22,r11,-8912
	ctx.r22.s64 = ctx.r11.s64 + -8912;
	// addi r11,r30,1296
	ctx.r11.s64 = ctx.r30.s64 + 1296;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r22,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r22.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82da76a0
	ctx.lr = 0x82DCA74C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-31894
	ctx.r11.s64 = -2090205184;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// lhz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// addi r19,r11,-9936
	ctx.r19.s64 = ctx.r11.s64 + -9936;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// stw r19,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r19.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DCA778;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCA78C;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82da7e70
	ctx.lr = 0x82DCA7A8;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DCA7BC;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dca7dc
	if (ctx.cr6.eq) goto loc_82DCA7DC;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca830
	if (!ctx.cr6.lt) goto loc_82DCA830;
loc_82DCA7DC:
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dca7f0
	if (ctx.cr6.eq) goto loc_82DCA7F0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca830
	if (!ctx.cr6.lt) goto loc_82DCA830;
loc_82DCA7F0:
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca830
	if (!ctx.cr6.lt) goto loc_82DCA830;
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca830
	if (!ctx.cr6.lt) goto loc_82DCA830;
	// lhz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r26.u32 + 0);
	// rlwinm r11,r11,0,24,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dca830
	if (ctx.cr6.eq) goto loc_82DCA830;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,4896
	ctx.r4.s64 = 4896;
	// bl 0x82da7e70
	ctx.lr = 0x82DCA828;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
loc_82DCA830:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DCA83C;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r11,r1,752
	ctx.r11.s64 = ctx.r1.s64 + 752;
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r17,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r17.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// beq cr6,0x82dca864
	if (ctx.cr6.eq) goto loc_82DCA864;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca91c
	if (!ctx.cr6.lt) goto loc_82DCA91C;
loc_82DCA864:
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dca878
	if (ctx.cr6.eq) goto loc_82DCA878;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca91c
	if (!ctx.cr6.lt) goto loc_82DCA91C;
loc_82DCA878:
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca91c
	if (!ctx.cr6.lt) goto loc_82DCA91C;
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dca91c
	if (!ctx.cr6.lt) goto loc_82DCA91C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA8A8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,9500
	ctx.r4.s64 = ctx.r11.s64 + 9500;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x82da45e8
	ctx.lr = 0x82DCA8C4;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bne cr6,0x82dca908
	if (!ctx.cr6.eq) goto loc_82DCA908;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da7dd0
	ctx.lr = 0x82DCA8D8;
	sub_82DA7DD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82da7e70
	ctx.lr = 0x82DCA8F0;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dca91c
	if (ctx.cr6.eq) goto loc_82DCA91C;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCA904;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCA908:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bl 0x82da7e70
	ctx.lr = 0x82DCA914;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
loc_82DCA91C:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DCA928;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dca948
	if (ctx.cr6.eq) goto loc_82DCA948;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcaa20
	if (!ctx.cr6.lt) goto loc_82DCAA20;
loc_82DCA948:
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dca95c
	if (ctx.cr6.eq) goto loc_82DCA95C;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcaa20
	if (!ctx.cr6.lt) goto loc_82DCAA20;
loc_82DCA95C:
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcaa20
	if (!ctx.cr6.lt) goto loc_82DCAA20;
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcaa20
	if (!ctx.cr6.lt) goto loc_82DCAA20;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA98C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r11,9492
	ctx.r4.s64 = ctx.r11.s64 + 9492;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x82da45e8
	ctx.lr = 0x82DCA9A8;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bne cr6,0x82dcaa0c
	if (!ctx.cr6.eq) goto loc_82DCAA0C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da7dd0
	ctx.lr = 0x82DCA9BC;
	sub_82DA7DD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82da7e70
	ctx.lr = 0x82DCA9D4;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// bl 0x82da76a0
	ctx.lr = 0x82DCA9F4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dcaa20
	if (ctx.cr6.eq) goto loc_82DCAA20;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCAA08;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCAA0C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bl 0x82da7e70
	ctx.lr = 0x82DCAA18;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
loc_82DCAA20:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da8018
	ctx.lr = 0x82DCAA2C;
	sub_82DA8018(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r8,-32255
	ctx.r8.s64 = -2113863680;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f28,9488(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 9488);
	ctx.f28.f64 = double(temp.f32);
	// addi r27,r11,9480
	ctx.r27.s64 = ctx.r11.s64 + 9480;
	// lfs f29,6148(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6148);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,6048(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6048);
	ctx.f30.f64 = double(temp.f32);
loc_82DCAA54:
	// lwz r4,120(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82dcaa6c
	if (ctx.cr6.eq) goto loc_82DCAA6C;
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x82dcb048
	if (!ctx.cr6.lt) goto loc_82DCB048;
loc_82DCAA6C:
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dcaa80
	if (ctx.cr6.eq) goto loc_82DCAA80;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcb048
	if (!ctx.cr6.lt) goto loc_82DCB048;
loc_82DCAA80:
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcb048
	if (!ctx.cr6.lt) goto loc_82DCB048;
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82dcb048
	if (!ctx.cr6.lt) goto loc_82DCB048;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// bl 0x82da76a0
	ctx.lr = 0x82DCAAB0;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7dd0
	ctx.lr = 0x82DCAAC4;
	sub_82DA7DD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 88);
	// lbz r8,91(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 91);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// lbz r10,90(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 90);
	// lbz r9,89(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 89);
	// cmpwi cr6,r11,67
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 67, ctx.xer);
	// bne cr6,0x82dcab48
	if (!ctx.cr6.eq) goto loc_82DCAB48;
	// extsb r7,r9
	ctx.r7.s64 = ctx.r9.s8;
	// cmpwi cr6,r7,72
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 72, ctx.xer);
	// bne cr6,0x82dcab48
	if (!ctx.cr6.eq) goto loc_82DCAB48;
	// extsb r7,r10
	ctx.r7.s64 = ctx.r10.s8;
	// cmpwi cr6,r7,70
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 70, ctx.xer);
	// bne cr6,0x82dcab48
	if (!ctx.cr6.eq) goto loc_82DCAB48;
	// extsb r7,r8
	ctx.r7.s64 = ctx.r8.s8;
	// cmpwi cr6,r7,88
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 88, ctx.xer);
	// bne cr6,0x82dcab48
	if (!ctx.cr6.eq) goto loc_82DCAB48;
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
	// addi r29,r30,14588
	ctx.r29.s64 = ctx.r30.s64 + 14588;
loc_82DCAB14:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r31,r11
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r11.s32, ctx.xer);
	// bge cr6,0x82dcab34
	if (!ctx.cr6.lt) goto loc_82DCAB34;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7dd0
	ctx.lr = 0x82DCAB2C;
	sub_82DA7DD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
loc_82DCAB34:
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmpwi cr6,r31,256
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 256, ctx.xer);
	// blt cr6,0x82dcab14
	if (ctx.cr6.lt) goto loc_82DCAB14;
	// b 0x82dcaa54
	goto loc_82DCAA54;
loc_82DCAB48:
	// cmpwi cr6,r11,69
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 69, ctx.xer);
	// bne cr6,0x82dcab9c
	if (!ctx.cr6.eq) goto loc_82DCAB9C;
	// extsb r7,r9
	ctx.r7.s64 = ctx.r9.s8;
	// cmpwi cr6,r7,81
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 81, ctx.xer);
	// bne cr6,0x82dcab9c
	if (!ctx.cr6.eq) goto loc_82DCAB9C;
	// extsb r7,r10
	ctx.r7.s64 = ctx.r10.s8;
	// cmpwi cr6,r7,70
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 70, ctx.xer);
	// bne cr6,0x82dcab9c
	if (!ctx.cr6.eq) goto loc_82DCAB9C;
	// extsb r7,r8
	ctx.r7.s64 = ctx.r8.s8;
	// cmpwi cr6,r7,88
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 88, ctx.xer);
	// bne cr6,0x82dcab9c
	if (!ctx.cr6.eq) goto loc_82DCAB9C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DCAB84;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dcaa54
	if (ctx.cr6.eq) goto loc_82DCAA54;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCAB98;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCAB9C:
	// cmpwi cr6,r11,70
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 70, ctx.xer);
	// bne cr6,0x82dcb044
	if (!ctx.cr6.eq) goto loc_82DCB044;
	// extsb r11,r9
	ctx.r11.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,88
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 88, ctx.xer);
	// bne cr6,0x82dcb044
	if (!ctx.cr6.eq) goto loc_82DCB044;
	// extsb r11,r10
	ctx.r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,48
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 48, ctx.xer);
	// blt cr6,0x82dcb044
	if (ctx.cr6.lt) goto loc_82DCB044;
	// extsb r9,r8
	ctx.r9.s64 = ctx.r8.s8;
	// cmpwi cr6,r9,48
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 48, ctx.xer);
	// blt cr6,0x82dcb044
	if (ctx.cr6.lt) goto loc_82DCB044;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r29,r11,-528
	ctx.r29.s64 = ctx.r11.s64 + -528;
	// cmpwi cr6,r29,50
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 50, ctx.xer);
	// bge cr6,0x82dcb00c
	if (!ctx.cr6.lt) goto loc_82DCB00C;
	// cmplwi cr6,r4,132
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 132, ctx.xer);
	// blt cr6,0x82dcb00c
	if (ctx.cr6.lt) goto loc_82DCB00C;
	// lis r26,-31909
	ctx.r26.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4525
	ctx.r6.s64 = 4525;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCAC0C;
	sub_82D862B0(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82dcb030
	if (ctx.cr6.eq) goto loc_82DCB030;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCAC30;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,128(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 128);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r10,24,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// addi r3,r28,64
	ctx.r3.s64 = ctx.r28.s64 + 64;
	// or r31,r11,r10
	ctx.r31.u64 = ctx.r11.u64 | ctx.r10.u64;
	// bl 0x82da45e8
	ctx.lr = 0x82DCAC68;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dcafec
	if (!ctx.cr6.eq) goto loc_82DCAFEC;
	// cmplwi cr6,r31,24
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 24, ctx.xer);
	// bne cr6,0x82dcafec
	if (!ctx.cr6.eq) goto loc_82DCAFEC;
	// addi r11,r29,3597
	ctx.r11.s64 = ctx.r29.s64 + 3597;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r29,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82dcacb4
	if (!ctx.cr6.eq) goto loc_82DCACB4;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4549
	ctx.r6.s64 = 4549;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,224
	ctx.r4.s64 = 224;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCACA8;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stwx r3,r29,r30
	PPC_STORE_U32(ctx.r29.u32 + ctx.r30.u32, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
loc_82DCACB4:
	// addi r11,r3,36
	ctx.r11.s64 = ctx.r3.s64 + 36;
	// stw r3,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r3.u32);
	// stw r3,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r3.u32);
	// li r5,128
	ctx.r5.s64 = 128;
	// stw r17,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r17.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r17,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r17.u32);
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stfs f31,60(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 60, temp.u32);
	// stfs f31,56(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 56, temp.u32);
	// stfs f31,84(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 84, temp.u32);
	// stfs f31,80(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 80, temp.u32);
	// stfs f30,68(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 68, temp.u32);
	// stfs f30,64(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 64, temp.u32);
	// stfs f31,76(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 76, temp.u32);
	// stfs f31,72(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 72, temp.u32);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// addi r3,r11,96
	ctx.r3.s64 = ctx.r11.s64 + 96;
	// bl 0x82cb1160
	ctx.lr = 0x82DCAD04;
	sub_82CB1160(ctx, base);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// lbz r9,104(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 104);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	// lbz r9,108(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 108);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,108(r11)
	PPC_STORE_U32(ctx.r11.u32 + 108, ctx.r10.u32);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// lwz r10,96(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// lbz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 96);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,96(r11)
	PPC_STORE_U32(ctx.r11.u32 + 96, ctx.r10.u32);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// lwz r10,100(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// lbz r9,100(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 100);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// rlwinm r7,r10,24,16,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF00;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r10,r8,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFF0000;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,100(r11)
	PPC_STORE_U32(ctx.r11.u32 + 100, ctx.r10.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,-132
	ctx.r11.s64 = ctx.r11.s64 + -132;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// blt cr6,0x82dcafec
	if (ctx.cr6.lt) goto loc_82DCAFEC;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4572
	ctx.r6.s64 = 4572;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,24
	ctx.r4.s64 = 24;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCADD0;
	sub_82D862B0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// li r5,24
	ctx.r5.s64 = 24;
	// addi r4,r28,132
	ctx.r4.s64 = ctx.r28.s64 + 132;
	// bl 0x82cb1160
	ctx.lr = 0x82DCADE8;
	sub_82CB1160(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lbz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 8);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r8,r11,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,8,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 | ctx.r8.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lbz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 12);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r8,r11,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,8,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 | ctx.r8.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lbz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r8,r11,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,8,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 | ctx.r8.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lbz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 16);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r8,r11,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,8,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 | ctx.r8.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lbz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r8,r11,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,8,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 | ctx.r8.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r8,r11,24,16,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF00;
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r9,8,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 | ctx.r8.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// stfs f31,56(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 56, temp.u32);
	// lwzx r11,r29,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r5,r11,16
	ctx.r5.s64 = ctx.r11.s64 + 16;
	// bl 0x82d8d030
	ctx.lr = 0x82DCAEDC;
	sub_82D8D030(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r10,r29,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r30.u32);
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// lwz r29,16(r10)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 220, temp.u32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCAF2C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lfs f0,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// li r4,1
	ctx.r4.s64 = 1;
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCAF54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// li r4,2
	ctx.r4.s64 = 2;
	// fmuls f1,f0,f28
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCAF7C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lfs f0,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// li r4,3
	ctx.r4.s64 = 3;
	// fmuls f1,f0,f28
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCAFA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lfs f1,20(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,40(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCAFC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4628
	ctx.r6.s64 = 4628;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCAFEC;
	sub_82D861B0(ctx, base);
loc_82DCAFEC:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4633
	ctx.r6.s64 = 4633;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCB008;
	sub_82D861B0(ctx, base);
	// b 0x82dcaa54
	goto loc_82DCAA54;
loc_82DCB00C:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DCB018;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dcaa54
	if (ctx.cr6.eq) goto loc_82DCAA54;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCB02C;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCB030:
	// li r3,37
	ctx.r3.s64 = 37;
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCB040;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCB044:
	// lwz r4,120(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
loc_82DCB048:
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dcb130
	if (ctx.cr6.eq) goto loc_82DCB130;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DCB060;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4659
	ctx.r6.s64 = 4659;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// bl 0x82d862b0
	ctx.lr = 0x82DCB08C;
	sub_82D862B0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCB0B0;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82dcb0e8
	if (!ctx.cr6.gt) goto loc_82DCB0E8;
loc_82DCB0C8:
	// lbzx r10,r31,r11
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r11.u32);
	// cmplwi cr6,r10,13
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 13, ctx.xer);
	// bne cr6,0x82dcb0dc
	if (!ctx.cr6.eq) goto loc_82DCB0DC;
	// stbx r23,r31,r11
	PPC_STORE_U8(ctx.r31.u32 + ctx.r11.u32, ctx.r23.u8);
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
loc_82DCB0DC:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82dcb0c8
	if (ctx.cr6.lt) goto loc_82DCB0C8;
loc_82DCB0E8:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r5,r11,9464
	ctx.r5.s64 = ctx.r11.s64 + 9464;
	// li r8,3
	ctx.r8.s64 = 3;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DCB108;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4685
	ctx.r6.s64 = 4685;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCB130;
	sub_82D861B0(ctx, base);
loc_82DCB130:
	// addi r27,r30,756
	ctx.r27.s64 = ctx.r30.s64 + 756;
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcb1b4
	if (!ctx.cr6.gt) goto loc_82DCB1B4;
	// mr r28,r24
	ctx.r28.u64 = ctx.r24.u64;
loc_82DCB148:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4695
	ctx.r6.s64 = 4695;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,712
	ctx.r4.s64 = 712;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCB168;
	sub_82D862B0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dcb18c
	if (ctx.cr6.eq) goto loc_82DCB18C;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r17,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r17.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DCB188;
	sub_82D9B4A8(ctx, base);
	// b 0x82dcb190
	goto loc_82DCB190;
loc_82DCB18C:
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
loc_82DCB190:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r31,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// stw r30,704(r31)
	PPC_STORE_U32(ctx.r31.u32 + 704, ctx.r30.u32);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcb148
	if (ctx.cr6.lt) goto loc_82DCB148;
loc_82DCB1B4:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r5,r11,9168
	ctx.r5.s64 = ctx.r11.s64 + 9168;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DCB1D8;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4717
	ctx.r6.s64 = 4717;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mulli r4,r10,1428
	ctx.r4.s64 = ctx.r10.s64 * 1428;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCB204;
	sub_82D862B0(ctx, base);
	// stw r3,1300(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1300, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lwz r11,0(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// mr r23,r17
	ctx.r23.u64 = ctx.r17.u64;
	// li r20,1
	ctx.r20.s64 = 1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcb8c4
	if (!ctx.cr6.gt) goto loc_82DCB8C4;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r24,r17
	ctx.r24.u64 = ctx.r17.u64;
	// addi r22,r11,9456
	ctx.r22.s64 = ctx.r11.s64 + 9456;
loc_82DCB230:
	// lwz r11,1300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1300);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r25)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// add r31,r24,r11
	ctx.r31.u64 = ctx.r24.u64 + ctx.r11.u64;
	// bl 0x82da7e70
	ctx.lr = 0x82DCB248;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// bl 0x82da76a0
	ctx.lr = 0x82DCB268;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x82da45e8
	ctx.lr = 0x82DCB280;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dca250
	if (!ctx.cr6.eq) goto loc_82DCA250;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,12
	ctx.r4.s64 = 12;
	// bl 0x82da7e70
	ctx.lr = 0x82DCB298;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB2AC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1168
	ctx.r4.s64 = ctx.r31.s64 + 1168;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB2C0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1169
	ctx.r4.s64 = ctx.r31.s64 + 1169;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB2D4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1170
	ctx.r4.s64 = ctx.r31.s64 + 1170;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB2E8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1164
	ctx.r4.s64 = ctx.r31.s64 + 1164;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCB2FC;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1171
	ctx.r4.s64 = ctx.r31.s64 + 1171;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB310;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1172
	ctx.r4.s64 = ctx.r31.s64 + 1172;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB324;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1166
	ctx.r4.s64 = ctx.r31.s64 + 1166;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB338;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1167
	ctx.r4.s64 = ctx.r31.s64 + 1167;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB34C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1173
	ctx.r4.s64 = ctx.r31.s64 + 1173;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB360;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1174
	ctx.r4.s64 = ctx.r31.s64 + 1174;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB374;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82da7e70
	ctx.lr = 0x82DCB38C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,28
	ctx.r4.s64 = ctx.r31.s64 + 28;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DCB3A0;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB3B4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCB3D4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r29,r31,1416
	ctx.r29.s64 = ctx.r31.s64 + 1416;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82da7b50
	ctx.lr = 0x82DCB3EC;
	sub_82DA7B50(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// rlwinm r11,r11,0,24,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb408
	if (ctx.cr6.eq) goto loc_82DCB408;
	// stb r20,94(r1)
	PPC_STORE_U8(ctx.r1.u32 + 94, ctx.r20.u8);
loc_82DCB408:
	// addi r4,r31,1420
	ctx.r4.s64 = ctx.r31.s64 + 1420;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7b50
	ctx.lr = 0x82DCB414;
	sub_82DA7B50(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1424
	ctx.r4.s64 = ctx.r31.s64 + 1424;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB428;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB43C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82da7e70
	ctx.lr = 0x82DCB454;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,240
	ctx.r6.s64 = 240;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r31,1175
	ctx.r4.s64 = ctx.r31.s64 + 1175;
	// bl 0x82da76a0
	ctx.lr = 0x82DCB474;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stb r17,896(r31)
	PPC_STORE_U8(ctx.r31.u32 + 896, ctx.r17.u8);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB48C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb4b0
	if (ctx.cr6.eq) goto loc_82DCB4B0;
	// lbz r11,896(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 896);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,896(r31)
	PPC_STORE_U8(ctx.r31.u32 + 896, ctx.r11.u8);
loc_82DCB4B0:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb4cc
	if (ctx.cr6.eq) goto loc_82DCB4CC;
	// lbz r11,896(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 896);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,896(r31)
	PPC_STORE_U8(ctx.r31.u32 + 896, ctx.r11.u8);
loc_82DCB4CC:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb4e8
	if (ctx.cr6.eq) goto loc_82DCB4E8;
	// lbz r11,896(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 896);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,896(r31)
	PPC_STORE_U8(ctx.r31.u32 + 896, ctx.r11.u8);
loc_82DCB4E8:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb504
	if (ctx.cr6.eq) goto loc_82DCB504;
	// lbz r11,896(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 896);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// stb r11,896(r31)
	PPC_STORE_U8(ctx.r31.u32 + 896, ctx.r11.u8);
loc_82DCB504:
	// addi r26,r31,897
	ctx.r26.s64 = ctx.r31.s64 + 897;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB514;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,979
	ctx.r4.s64 = ctx.r31.s64 + 979;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB528;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,980
	ctx.r4.s64 = ctx.r31.s64 + 980;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB53C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,981
	ctx.r4.s64 = ctx.r31.s64 + 981;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB550;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,982
	ctx.r4.s64 = ctx.r31.s64 + 982;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB564;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r27,r31,898
	ctx.r27.s64 = ctx.r31.s64 + 898;
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
loc_82DCB574:
	// add r28,r29,r27
	ctx.r28.u64 = ctx.r29.u64 + ctx.r27.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82da7ba0
	ctx.lr = 0x82DCB584;
	sub_82DA7BA0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCB598;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lhz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 128);
	// addi r29,r29,3
	ctx.r29.s64 = ctx.r29.s64 + 3;
	// cmpwi cr6,r29,75
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 75, ctx.xer);
	// sth r11,1(r28)
	PPC_STORE_U16(ctx.r28.u32 + 1, ctx.r11.u16);
	// blt cr6,0x82dcb574
	if (ctx.cr6.lt) goto loc_82DCB574;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB5C0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bge cr6,0x82dcb5d8
	if (!ctx.cr6.lt) goto loc_82DCB5D8;
	// stb r17,896(r31)
	PPC_STORE_U8(ctx.r31.u32 + 896, ctx.r17.u8);
loc_82DCB5D8:
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stb r17,983(r31)
	PPC_STORE_U8(ctx.r31.u32 + 983, ctx.r17.u8);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB5E8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb60c
	if (ctx.cr6.eq) goto loc_82DCB60C;
	// lbz r11,983(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 983);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,983(r31)
	PPC_STORE_U8(ctx.r31.u32 + 983, ctx.r11.u8);
loc_82DCB60C:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb628
	if (ctx.cr6.eq) goto loc_82DCB628;
	// lbz r11,983(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 983);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,983(r31)
	PPC_STORE_U8(ctx.r31.u32 + 983, ctx.r11.u8);
loc_82DCB628:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb644
	if (ctx.cr6.eq) goto loc_82DCB644;
	// lbz r11,983(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 983);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,983(r31)
	PPC_STORE_U8(ctx.r31.u32 + 983, ctx.r11.u8);
loc_82DCB644:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb660
	if (ctx.cr6.eq) goto loc_82DCB660;
	// lbz r11,983(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 983);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// stb r11,983(r31)
	PPC_STORE_U8(ctx.r31.u32 + 983, ctx.r11.u8);
loc_82DCB660:
	// addi r26,r31,984
	ctx.r26.s64 = ctx.r31.s64 + 984;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB670;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1067
	ctx.r4.s64 = ctx.r31.s64 + 1067;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB684;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1068
	ctx.r4.s64 = ctx.r31.s64 + 1068;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB698;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1069
	ctx.r4.s64 = ctx.r31.s64 + 1069;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB6AC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1070
	ctx.r4.s64 = ctx.r31.s64 + 1070;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB6C0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r27,r31,986
	ctx.r27.s64 = ctx.r31.s64 + 986;
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
loc_82DCB6D0:
	// add r28,r29,r27
	ctx.r28.u64 = ctx.r29.u64 + ctx.r27.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82da7ba0
	ctx.lr = 0x82DCB6E0;
	sub_82DA7BA0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCB6F4;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lhz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// addi r29,r29,3
	ctx.r29.s64 = ctx.r29.s64 + 3;
	// cmpwi cr6,r29,75
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 75, ctx.xer);
	// sth r11,1(r28)
	PPC_STORE_U16(ctx.r28.u32 + 1, ctx.r11.u16);
	// blt cr6,0x82dcb6d0
	if (ctx.cr6.lt) goto loc_82DCB6D0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB71C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bge cr6,0x82dcb734
	if (!ctx.cr6.lt) goto loc_82DCB734;
	// stb r17,983(r31)
	PPC_STORE_U8(ctx.r31.u32 + 983, ctx.r17.u8);
loc_82DCB734:
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stb r17,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r17.u8);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB744;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb768
	if (ctx.cr6.eq) goto loc_82DCB768;
	// lbz r11,1071(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1071);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r11.u8);
loc_82DCB768:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb784
	if (ctx.cr6.eq) goto loc_82DCB784;
	// lbz r11,1071(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1071);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r11.u8);
loc_82DCB784:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb7a0
	if (ctx.cr6.eq) goto loc_82DCB7A0;
	// lbz r11,1071(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1071);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r11.u8);
loc_82DCB7A0:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb7bc
	if (ctx.cr6.eq) goto loc_82DCB7BC;
	// lbz r11,1071(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1071);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// stb r11,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r11.u8);
loc_82DCB7BC:
	// lbz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcb7d8
	if (ctx.cr6.eq) goto loc_82DCB7D8;
	// lbz r11,1071(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1071);
	// ori r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 16;
	// stb r11,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r11.u8);
loc_82DCB7D8:
	// addi r26,r31,1072
	ctx.r26.s64 = ctx.r31.s64 + 1072;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB7E8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1155
	ctx.r4.s64 = ctx.r31.s64 + 1155;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB7FC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1156
	ctx.r4.s64 = ctx.r31.s64 + 1156;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB810;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1157
	ctx.r4.s64 = ctx.r31.s64 + 1157;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB824;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r31,1158
	ctx.r4.s64 = ctx.r31.s64 + 1158;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB838;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r27,r31,1074
	ctx.r27.s64 = ctx.r31.s64 + 1074;
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
loc_82DCB848:
	// add r28,r29,r27
	ctx.r28.u64 = ctx.r29.u64 + ctx.r27.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82da7ba0
	ctx.lr = 0x82DCB858;
	sub_82DA7BA0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCB86C;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lhz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// addi r29,r29,3
	ctx.r29.s64 = ctx.r29.s64 + 3;
	// cmpwi cr6,r29,75
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 75, ctx.xer);
	// sth r11,1(r28)
	PPC_STORE_U16(ctx.r28.u32 + 1, ctx.r11.u16);
	// blt cr6,0x82dcb848
	if (ctx.cr6.lt) goto loc_82DCB848;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB894;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bge cr6,0x82dcb8ac
	if (!ctx.cr6.lt) goto loc_82DCB8AC;
	// stb r17,1071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1071, ctx.r17.u8);
loc_82DCB8AC:
	// lwz r11,0(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// addi r23,r23,1
	ctx.r23.s64 = ctx.r23.s64 + 1;
	// addi r24,r24,1428
	ctx.r24.s64 = ctx.r24.s64 + 1428;
	// addi r25,r25,4
	ctx.r25.s64 = ctx.r25.s64 + 4;
	// cmpw cr6,r23,r11
	ctx.cr6.compare<int32_t>(ctx.r23.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcb230
	if (ctx.cr6.lt) goto loc_82DCB230;
loc_82DCB8C4:
	// addi r31,r30,1296
	ctx.r31.s64 = ctx.r30.s64 + 1296;
	// stw r17,2076(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2076, ctx.r17.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dcb904
	if (ctx.cr6.eq) goto loc_82DCB904;
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5083
	ctx.r6.s64 = 5083;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,19872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19872);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCB8F8;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,2076(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2076, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
loc_82DCB904:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r20,r17
	ctx.r20.u64 = ctx.r17.u64;
	// li r14,2
	ctx.r14.s64 = 2;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcbeb0
	if (!ctx.cr6.gt) goto loc_82DCBEB0;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lwz r23,144(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r21,r17
	ctx.r21.u64 = ctx.r17.u64;
	// addi r17,r11,9440
	ctx.r17.s64 = ctx.r11.s64 + 9440;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r18,r30,2080
	ctx.r18.s64 = ctx.r30.s64 + 2080;
	// addi r16,r11,9432
	ctx.r16.s64 = ctx.r11.s64 + 9432;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// li r15,8363
	ctx.r15.s64 = 8363;
	// ori r25,r11,18725
	ctx.r25.u64 = ctx.r11.u64 | 18725;
	// li r19,108
	ctx.r19.s64 = 108;
loc_82DCB944:
	// lwz r11,2076(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2076);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// stwx r18,r21,r11
	PPC_STORE_U32(ctx.r21.u32 + ctx.r11.u32, ctx.r18.u32);
	// lwz r11,2076(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2076);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// lwzx r4,r21,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r10.u32);
	// lwzx r29,r21,r11
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r11.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DCB968;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// bl 0x82da76a0
	ctx.lr = 0x82DCB988;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r16
	ctx.r4.u64 = ctx.r16.u64;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x82da45e8
	ctx.lr = 0x82DCB9A0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dca250
	if (!ctx.cr6.eq) goto loc_82DCA250;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,12
	ctx.r4.s64 = 12;
	// bl 0x82da7e70
	ctx.lr = 0x82DCB9B8;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB9CC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r29,33
	ctx.r4.s64 = ctx.r29.s64 + 33;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB9E0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r31,r29,32
	ctx.r31.s64 = ctx.r29.s64 + 32;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DCB9F8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// li r24,1
	ctx.r24.s64 = 1;
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// rlwinm r9,r11,0,29,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// addi r22,r10,1
	ctx.r22.s64 = ctx.r10.s64 + 1;
	// beq cr6,0x82dcba2c
	if (ctx.cr6.eq) goto loc_82DCBA2C;
	// mr r24,r14
	ctx.r24.u64 = ctx.r14.u64;
loc_82DCBA2C:
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcba50
	if (ctx.cr6.eq) goto loc_82DCBA50;
	// rlwinm r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// addi r26,r11,74
	ctx.r26.s64 = ctx.r11.s64 + 74;
	// b 0x82dcba54
	goto loc_82DCBA54;
loc_82DCBA50:
	// li r26,73
	ctx.r26.s64 = 73;
loc_82DCBA54:
	// addi r4,r29,8
	ctx.r4.s64 = ctx.r29.s64 + 8;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBA60;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,320
	ctx.r4.s64 = ctx.r1.s64 + 320;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBA80;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// addi r3,r1,1008
	ctx.r3.s64 = ctx.r1.s64 + 1008;
	// bl 0x82cb61f0
	ctx.lr = 0x82DCBA98;
	sub_82CB61F0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,28
	ctx.r7.s64 = 28;
	// addi r6,r1,320
	ctx.r6.s64 = ctx.r1.s64 + 320;
	// addi r5,r1,1008
	ctx.r5.s64 = ctx.r1.s64 + 1008;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DCBAB8;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r11,r1,2032
	ctx.r11.s64 = ctx.r1.s64 + 2032;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// add r4,r11,r20
	ctx.r4.u64 = ctx.r11.u64 + ctx.r20.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBAD0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r29,9
	ctx.r4.s64 = ctx.r29.s64 + 9;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBAE4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBB04;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r27,r29,12
	ctx.r27.s64 = ctx.r29.s64 + 12;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBB28;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r28,r29,16
	ctx.r28.s64 = ctx.r29.s64 + 16;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBB4C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r31,r29,4
	ctx.r31.s64 = ctx.r29.s64 + 4;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBB70;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r29,36
	ctx.r4.s64 = ctx.r29.s64 + 36;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBB90;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r29,40
	ctx.r4.s64 = ctx.r29.s64 + 40;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBBB0;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r5,4
	ctx.r5.s64 = 4;
	// add r4,r21,r11
	ctx.r4.u64 = ctx.r21.u64 + ctx.r11.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCBBD4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r29,44
	ctx.r4.s64 = ctx.r29.s64 + 44;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBBE8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r29,45
	ctx.r4.s64 = ctx.r29.s64 + 45;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBBFC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r29,47
	ctx.r4.s64 = ctx.r29.s64 + 47;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBC10;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r29,46
	ctx.r4.s64 = ctx.r29.s64 + 46;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCBC24;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// bne cr6,0x82dcbc4c
	if (!ctx.cr6.eq) goto loc_82DCBC4C;
	// stw r15,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r15.u32);
loc_82DCBC4C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcbc60
	if (ctx.cr6.eq) goto loc_82DCBC60;
	// clrlwi r11,r26,31
	ctx.r11.u64 = ctx.r26.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcbc78
	if (ctx.cr6.eq) goto loc_82DCBC78;
loc_82DCBC60:
	// li r11,1
	ctx.r11.s64 = 1;
	// rlwimi r26,r11,0,29,31
	ctx.r26.u64 = (__builtin_rotateleft32(ctx.r11.u32, 0) & 0x7) | (ctx.r26.u64 & 0xFFFFFFFFFFFFFFF8);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
loc_82DCBC78:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcbe80
	if (ctx.cr6.eq) goto loc_82DCBE80;
	// cmplwi cr6,r22,10
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 10, ctx.xer);
	// bgt cr6,0x82dcbde4
	if (ctx.cr6.gt) goto loc_82DCBDE4;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-17244
	ctx.r12.s64 = ctx.r12.s64 + -17244;
	// rlwinm r0,r22,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r22.u64) {
	case 0:
		goto loc_82DCBD10;
	case 1:
		goto loc_82DCBCD0;
	case 2:
		goto loc_82DCBCE0;
	case 3:
		goto loc_82DCBCF0;
	case 4:
		goto loc_82DCBD00;
	case 5:
		goto loc_82DCBD00;
	case 6:
		goto loc_82DCBD10;
	case 7:
		goto loc_82DCBD10;
	case 8:
		goto loc_82DCBD10;
	case 9:
		goto loc_82DCBD10;
	case 10:
		goto loc_82DCBD10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17136);
	// lwz r22,-17200(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17200);
	// lwz r22,-17184(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17184);
	// lwz r22,-17168(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17168);
	// lwz r22,-17152(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17152);
	// lwz r22,-17152(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17152);
	// lwz r22,-17136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17136);
	// lwz r22,-17136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17136);
	// lwz r22,-17136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17136);
	// lwz r22,-17136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17136);
	// lwz r22,-17136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17136);
loc_82DCBCD0:
	// li r10,8
	ctx.r10.s64 = 8;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
loc_82DCBCE0:
	// li r10,16
	ctx.r10.s64 = 16;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
loc_82DCBCF0:
	// li r10,24
	ctx.r10.s64 = 24;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
loc_82DCBD00:
	// li r10,32
	ctx.r10.s64 = 32;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
loc_82DCBD10:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-17112
	ctx.r12.s64 = ctx.r12.s64 + -17112;
	// rlwinm r0,r22,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-16932(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16932);
	// lwz r22,-16924(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16924);
	// lwz r22,-16924(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16924);
	// lwz r22,-16924(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16924);
	// lwz r22,-16924(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16924);
	// lwz r22,-16924(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16924);
	// lwz r22,-17068(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17068);
	// lwz r22,-17016(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -17016);
	// lwz r22,-16992(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16992);
	// lwz r22,-16940(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16940);
	// lwz r22,-16940(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -16940);
	// addi r11,r11,13
	ctx.r11.s64 = ctx.r11.s64 + 13;
	// mulhwu r10,r11,r25
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r25.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r25
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r25.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
	// addi r11,r11,63
	ctx.r11.s64 = ctx.r11.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
	// addi r11,r11,27
	ctx.r11.s64 = ctx.r11.s64 + 27;
	// mulhwu r10,r11,r25
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r25.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r25
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r25.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dcbde0
	goto loc_82DCBDE0;
	// mr r23,r11
	ctx.r23.u64 = ctx.r11.u64;
	// b 0x82dcbde4
	goto loc_82DCBDE4;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DCBDE0:
	// mullw r23,r11,r24
	ctx.r23.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32);
loc_82DCBDE4:
	// addi r11,r1,640
	ctx.r11.s64 = ctx.r1.s64 + 640;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,13
	ctx.r9.s64 = 13;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DCBDF4:
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dcbdf4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DCBDF4;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r6,r1,640
	ctx.r6.s64 = ctx.r1.s64 + 640;
	// ori r5,r26,1024
	ctx.r5.u64 = ctx.r26.u64 | 1024;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r19,640(r1)
	PPC_STORE_U32(ctx.r1.u32 + 640, ctx.r19.u32);
	// stw r23,644(r1)
	PPC_STORE_U32(ctx.r1.u32 + 644, ctx.r23.u32);
	// stw r24,652(r1)
	PPC_STORE_U32(ctx.r1.u32 + 652, ctx.r24.u32);
	// stw r11,656(r1)
	PPC_STORE_U32(ctx.r1.u32 + 656, ctx.r11.u32);
	// stw r22,660(r1)
	PPC_STORE_U32(ctx.r1.u32 + 660, ctx.r22.u32);
	// bl 0x82d910a0
	ctx.lr = 0x82DCBE34;
	sub_82D910A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// rlwinm r11,r26,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcbe54
	if (!ctx.cr6.eq) goto loc_82DCBE54;
	// rlwinm r11,r26,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcbe80
	if (ctx.cr6.eq) goto loc_82DCBE80;
loc_82DCBE54:
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r5,2
	ctx.r5.s64 = 2;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r6,r11,-1
	ctx.r6.s64 = ctx.r11.s64 + -1;
	// lwz r11,160(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCBE80;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82DCBE80:
	// addi r11,r30,1296
	ctx.r11.s64 = ctx.r30.s64 + 1296;
	// addi r20,r20,1
	ctx.r20.s64 = ctx.r20.s64 + 1;
	// addi r18,r18,48
	ctx.r18.s64 = ctx.r18.s64 + 48;
	// addi r21,r21,4
	ctx.r21.s64 = ctx.r21.s64 + 4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r20,r11
	ctx.cr6.compare<int32_t>(ctx.r20.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcb944
	if (ctx.cr6.lt) goto loc_82DCB944;
	// lwz r15,148(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r18,64
	ctx.r18.s64 = 64;
	// lwz r16,140(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// li r17,0
	ctx.r17.s64 = 0;
	// lwz r19,136(r1)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
loc_82DCBEB0:
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// rlwinm r11,r20,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r23,100(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r8,r30,1280
	ctx.r8.s64 = ctx.r30.s64 + 1280;
	// stwx r10,r11,r23
	PPC_STORE_U32(ctx.r11.u32 + ctx.r23.u32, ctx.r10.u32);
	// lwz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r17,1284(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1284, ctx.r17.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcbf10
	if (!ctx.cr6.gt) goto loc_82DCBF10;
	// addi r11,r30,500
	ctx.r11.s64 = ctx.r30.s64 + 500;
	// subfic r9,r30,-500
	ctx.xer.ca = ctx.r30.u32 <= 4294966796;
	ctx.r9.s64 = -500 - ctx.r30.s64;
loc_82DCBEDC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,254
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 254, ctx.xer);
	// bge cr6,0x82dcbefc
	if (!ctx.cr6.lt) goto loc_82DCBEFC;
	// lwz r7,1284(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1284);
	// cmpw cr6,r10,r7
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82dcbefc
	if (ctx.cr6.lt) goto loc_82DCBEFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,1284(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1284, ctx.r10.u32);
loc_82DCBEFC:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// add r7,r9,r11
	ctx.r7.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmpw cr6,r7,r10
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dcbedc
	if (ctx.cr6.lt) goto loc_82DCBEDC;
loc_82DCBF10:
	// lwz r11,1284(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1284);
	// lhz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dcbf24
	if (ctx.cr6.gt) goto loc_82DCBF24;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82DCBF24:
	// lis r26,-31909
	ctx.r26.s64 = -2091188224;
	// stw r11,1288(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1288, ctx.r11.u32);
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5338
	ctx.r6.s64 = 5338;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCBF48;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,488(r30)
	PPC_STORE_U32(ctx.r30.u32 + 488, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lhz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// mr r27,r17
	ctx.r27.u64 = ctx.r17.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcc06c
	if (ctx.cr6.eq) goto loc_82DCC06C;
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// mr r28,r19
	ctx.r28.u64 = ctx.r19.u64;
loc_82DCBF70:
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r11,488(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 488);
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// add r31,r29,r11
	ctx.r31.u64 = ctx.r29.u64 + ctx.r11.u64;
	// bne cr6,0x82dcbfb4
	if (!ctx.cr6.eq) goto loc_82DCBFB4;
	// stw r18,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r18.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r6,5368
	ctx.r6.s64 = 5368;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,64
	ctx.r4.s64 = 64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCBFA4;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// b 0x82dcc050
	goto loc_82DCC050;
loc_82DCBFB4:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DCBFC0;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCBFD4;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCBFE8;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x82da7e70
	ctx.lr = 0x82DCC000;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lhz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5405
	ctx.r6.s64 = 5405;
	// lhz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U16(ctx.r1.u32 + 84);
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCC02C;
	sub_82D862B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lhz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r1.u32 + 84);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r4,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r4.u32);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da76a0
	ctx.lr = 0x82DCC048;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
loc_82DCC050:
	// lhz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r29,r29,8
	ctx.r29.s64 = ctx.r29.s64 + 8;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// cmpw cr6,r27,r10
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dcbf70
	if (ctx.cr6.lt) goto loc_82DCBF70;
loc_82DCC06C:
	// lwz r10,1284(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1284);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// ble cr6,0x82dcc0d4
	if (!ctx.cr6.gt) goto loc_82DCC0D4;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// cmpw cr6,r28,r10
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dcc0d4
	if (!ctx.cr6.lt) goto loc_82DCC0D4;
	// rlwinm r29,r28,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 3) & 0xFFFFFFF8;
loc_82DCC08C:
	// lwz r11,488(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 488);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5536
	ctx.r6.s64 = 5536;
	// add r31,r29,r11
	ctx.r31.u64 = ctx.r29.u64 + ctx.r11.u64;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,64
	ctx.r4.s64 = 64;
	// stw r18,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r18.u32);
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCC0B4;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lwz r11,1284(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1284);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r29,r29,8
	ctx.r29.s64 = ctx.r29.s64 + 8;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcc08c
	if (ctx.cr6.lt) goto loc_82DCC08C;
loc_82DCC0D4:
	// addi r11,r30,1296
	ctx.r11.s64 = ctx.r30.s64 + 1296;
	// mr r25,r17
	ctx.r25.u64 = ctx.r17.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcc690
	if (!ctx.cr6.gt) goto loc_82DCC690;
	// lwz r24,112(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r26,r17
	ctx.r26.u64 = ctx.r17.u64;
loc_82DCC0F0:
	// add r31,r26,r23
	ctx.r31.u64 = ctx.r26.u64 + ctx.r23.u64;
	// lwz r9,2076(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2076);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwzx r27,r26,r9
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r9.u32);
	// stw r17,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r17.u32);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dcc11c
	if (!ctx.cr6.gt) goto loc_82DCC11C;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// b 0x82dcc148
	goto loc_82DCC148;
loc_82DCC11C:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcc650
	if (ctx.cr6.eq) goto loc_82DCC650;
	// lwzx r11,r26,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r9.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCC148;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82DCC148:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcc650
	if (ctx.cr6.eq) goto loc_82DCC650;
	// lwz r11,2076(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2076);
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// mr r28,r17
	ctx.r28.u64 = ctx.r17.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lwzx r11,r26,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r11.u32);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCC180;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCC1A4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r11,r1,2032
	ctx.r11.s64 = ctx.r1.s64 + 2032;
	// lbzx r11,r11,r25
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r25.u32);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcc1bc
	if (ctx.cr6.eq) goto loc_82DCC1BC;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82DCC1BC:
	// lbz r10,32(r27)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r27.u32 + 32);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcc1ec
	if (ctx.cr6.eq) goto loc_82DCC1EC;
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r10,533
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 533, ctx.xer);
	// blt cr6,0x82dcc1e8
	if (ctx.cr6.lt) goto loc_82DCC1E8;
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// li r28,215
	ctx.r28.s64 = 215;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcc1ec
	if (!ctx.cr6.eq) goto loc_82DCC1EC;
loc_82DCC1E8:
	// li r28,214
	ctx.r28.s64 = 214;
loc_82DCC1EC:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DCC1FC;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r9,r1,136
	ctx.r9.s64 = ctx.r1.s64 + 136;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addi r7,r1,140
	ctx.r7.s64 = ctx.r1.s64 + 140;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCC230;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcc624
	if (ctx.cr6.eq) goto loc_82DCC624;
	// lwz r6,128(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82dcc624
	if (ctx.cr6.eq) goto loc_82DCC624;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82dcc4c4
	if (!ctx.cr6.eq) goto loc_82DCC4C4;
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcc4c4
	if (ctx.cr6.eq) goto loc_82DCC4C4;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r11,64(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// bne cr6,0x82dcc3a4
	if (!ctx.cr6.eq) goto loc_82DCC3A4;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dcc298
	if (!ctx.cr6.eq) goto loc_82DCC298;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// rlwinm r6,r6,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	// li r5,2
	ctx.r5.s64 = 2;
	// bl 0x82da76a0
	ctx.lr = 0x82DCC294;
	sub_82DA76A0(ctx, base);
	// b 0x82dcc398
	goto loc_82DCC398;
loc_82DCC298:
	// rlwinm r29,r6,30,2,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// mr r28,r17
	ctx.r28.u64 = ctx.r17.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82dcc314
	if (ctx.cr6.eq) goto loc_82DCC314;
loc_82DCC2A8:
	// cmplwi cr6,r29,512
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dcc2b8
	if (ctx.cr6.gt) goto loc_82DCC2B8;
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82DCC2B8:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,1008
	ctx.r4.s64 = ctx.r1.s64 + 1008;
	// bl 0x82da76a0
	ctx.lr = 0x82DCC2D0;
	sub_82DA76A0(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dcc304
	if (ctx.cr6.eq) goto loc_82DCC304;
	// rlwinm r9,r28,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,1008
	ctx.r10.s64 = ctx.r1.s64 + 1008;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82DCC2E4:
	// lhz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// sthx r8,r7,r9
	PPC_STORE_U16(ctx.r7.u32 + ctx.r9.u32, ctx.r8.u16);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne cr6,0x82dcc2e4
	if (!ctx.cr6.eq) goto loc_82DCC2E4;
loc_82DCC304:
	// subf r29,r31,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r31.s64;
	// add r28,r31,r28
	ctx.r28.u64 = ctx.r31.u64 + ctx.r28.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82dcc2a8
	if (!ctx.cr6.eq) goto loc_82DCC2A8;
loc_82DCC314:
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r28,r17
	ctx.r28.u64 = ctx.r17.u64;
	// rlwinm r29,r11,30,2,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82dcc398
	if (ctx.cr6.eq) goto loc_82DCC398;
loc_82DCC328:
	// cmplwi cr6,r29,512
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dcc338
	if (ctx.cr6.gt) goto loc_82DCC338;
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82DCC338:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,1008
	ctx.r4.s64 = ctx.r1.s64 + 1008;
	// bl 0x82da76a0
	ctx.lr = 0x82DCC350;
	sub_82DA76A0(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dcc388
	if (ctx.cr6.eq) goto loc_82DCC388;
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,1008
	ctx.r9.s64 = ctx.r1.s64 + 1008;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82DCC364:
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lhz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// sth r7,2(r8)
	PPC_STORE_U16(ctx.r8.u32 + 2, ctx.r7.u16);
	// bne cr6,0x82dcc364
	if (!ctx.cr6.eq) goto loc_82DCC364;
loc_82DCC388:
	// subf r29,r31,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r31.s64;
	// add r28,r31,r28
	ctx.r28.u64 = ctx.r31.u64 + ctx.r28.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82dcc328
	if (!ctx.cr6.eq) goto loc_82DCC328;
loc_82DCC398:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// b 0x82dcc624
	goto loc_82DCC624;
loc_82DCC3A4:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dcc3c8
	if (!ctx.cr6.eq) goto loc_82DCC3C8;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82da76a0
	ctx.lr = 0x82DCC3BC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// b 0x82dcc624
	goto loc_82DCC624;
loc_82DCC3C8:
	// rlwinm r29,r6,30,2,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// mr r28,r17
	ctx.r28.u64 = ctx.r17.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82dcc440
	if (ctx.cr6.eq) goto loc_82DCC440;
loc_82DCC3D8:
	// cmplwi cr6,r29,512
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dcc3e8
	if (ctx.cr6.gt) goto loc_82DCC3E8;
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82DCC3E8:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,1008
	ctx.r4.s64 = ctx.r1.s64 + 1008;
	// bl 0x82da76a0
	ctx.lr = 0x82DCC400;
	sub_82DA76A0(ctx, base);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dcc430
	if (ctx.cr6.eq) goto loc_82DCC430;
	// rlwinm r10,r28,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DCC410:
	// addi r9,r1,1008
	ctx.r9.s64 = ctx.r1.s64 + 1008;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lbzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stbx r9,r8,r10
	PPC_STORE_U8(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u8);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// blt cr6,0x82dcc410
	if (ctx.cr6.lt) goto loc_82DCC410;
loc_82DCC430:
	// subf r29,r31,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r31.s64;
	// add r28,r31,r28
	ctx.r28.u64 = ctx.r31.u64 + ctx.r28.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82dcc3d8
	if (!ctx.cr6.eq) goto loc_82DCC3D8;
loc_82DCC440:
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r28,r17
	ctx.r28.u64 = ctx.r17.u64;
	// rlwinm r29,r11,30,2,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82dcc624
	if (ctx.cr6.eq) goto loc_82DCC624;
loc_82DCC454:
	// cmplwi cr6,r29,512
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dcc464
	if (ctx.cr6.gt) goto loc_82DCC464;
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82DCC464:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,1008
	ctx.r4.s64 = ctx.r1.s64 + 1008;
	// bl 0x82da76a0
	ctx.lr = 0x82DCC47C;
	sub_82DA76A0(ctx, base);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dcc4b0
	if (ctx.cr6.eq) goto loc_82DCC4B0;
	// rlwinm r10,r28,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DCC48C:
	// addi r8,r1,1008
	ctx.r8.s64 = ctx.r1.s64 + 1008;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lbzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stb r8,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r8.u8);
	// blt cr6,0x82dcc48c
	if (ctx.cr6.lt) goto loc_82DCC48C;
loc_82DCC4B0:
	// subf r29,r31,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r31.s64;
	// add r28,r28,r31
	ctx.r28.u64 = ctx.r28.u64 + ctx.r31.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82dcc454
	if (!ctx.cr6.eq) goto loc_82DCC454;
	// b 0x82dcc624
	goto loc_82DCC624;
loc_82DCC4C4:
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r11,r24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r24.u32, ctx.xer);
	// ble cr6,0x82dcc52c
	if (!ctx.cr6.gt) goto loc_82DCC52C;
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// beq cr6,0x82dcc4f8
	if (ctx.cr6.eq) goto loc_82DCC4F8;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5772
	ctx.r6.s64 = 5772;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCC4F8;
	sub_82D861B0(ctx, base);
loc_82DCC4F8:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5775
	ctx.r6.s64 = 5775;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d85f40
	ctx.lr = 0x82DCC51C;
	sub_82D85F40(ctx, base);
	// mr r15,r3
	ctx.r15.u64 = ctx.r3.u64;
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lwz r24,88(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DCC52C:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCC53C;
	sub_82CB16F0(ctx, base);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// lwz r3,224(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	// bl 0x82da76a0
	ctx.lr = 0x82DCC554;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r15,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r15.u32);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r8,64(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// bne cr6,0x82dcc5c8
	if (!ctx.cr6.eq) goto loc_82DCC5C8;
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// ble cr6,0x82dcc624
	if (!ctx.cr6.gt) goto loc_82DCC624;
	// addi r11,r28,-215
	ctx.r11.s64 = ctx.r28.s64 + -215;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r29,r11,27,31,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
loc_82DCC58C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// divwu r6,r11,r8
	ctx.r6.u32 = ctx.r11.u32 / ctx.r8.u32;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// add r5,r11,r31
	ctx.r5.u64 = ctx.r11.u64 + ctx.r31.u64;
	// twllei r8,0
	// bl 0x82dc5528
	ctx.lr = 0x82DCC5B0;
	sub_82DC5528(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// lwz r8,64(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// cmpw cr6,r31,r8
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r8.s32, ctx.xer);
	// blt cr6,0x82dcc58c
	if (ctx.cr6.lt) goto loc_82DCC58C;
	// b 0x82dcc624
	goto loc_82DCC624;
loc_82DCC5C8:
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// ble cr6,0x82dcc624
	if (!ctx.cr6.gt) goto loc_82DCC624;
	// addi r11,r28,-215
	ctx.r11.s64 = ctx.r28.s64 + -215;
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r28,r11,27,31,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
loc_82DCC5E4:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// divwu r6,r11,r8
	ctx.r6.u32 = ctx.r11.u32 / ctx.r8.u32;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// twllei r8,0
	// add r5,r31,r11
	ctx.r5.u64 = ctx.r31.u64 + ctx.r11.u64;
	// bl 0x82dc5788
	ctx.lr = 0x82DCC60C;
	sub_82DC5788(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// lwz r8,64(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// cmpw cr6,r29,r8
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r8.s32, ctx.xer);
	// blt cr6,0x82dcc5e4
	if (ctx.cr6.lt) goto loc_82DCC5E4;
loc_82DCC624:
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r7,136(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r6,128(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r5,140(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCC648;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
loc_82DCC650:
	// addi r11,r30,1296
	ctx.r11.s64 = ctx.r30.s64 + 1296;
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r26,r26,4
	ctx.r26.s64 = ctx.r26.s64 + 4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r25,r11
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcc0f0
	if (ctx.cr6.lt) goto loc_82DCC0F0;
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// beq cr6,0x82dcc690
	if (ctx.cr6.eq) goto loc_82DCC690;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,5821
	ctx.r6.s64 = 5821;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCC690;
	sub_82D861B0(ctx, base);
loc_82DCC690:
	// lwz r11,2516(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 2516);
	// li r29,5
	ctx.r29.s64 = 5;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcc6bc
	if (ctx.cr6.eq) goto loc_82DCC6BC;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dcc6bc
	if (ctx.cr6.eq) goto loc_82DCC6BC;
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r24,2508(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 2508);
	// stw r11,256(r10)
	PPC_STORE_U32(ctx.r10.u32 + 256, ctx.r11.u32);
	// b 0x82dcc6dc
	goto loc_82DCC6DC;
loc_82DCC6BC:
	// lwz r24,2508(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 2508);
	// rlwinm r11,r24,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// beq cr6,0x82dcc6d8
	if (ctx.cr6.eq) goto loc_82DCC6D8;
	// stw r29,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r29.u32);
	// b 0x82dcc6dc
	goto loc_82DCC6DC;
loc_82DCC6D8:
	// stw r14,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r14.u32);
loc_82DCC6DC:
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r4,r30,232
	ctx.r4.s64 = ctx.r30.s64 + 232;
	// stw r14,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r14.u32);
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// bl 0x82da4468
	ctx.lr = 0x82DCC6F4;
	sub_82DA4468(ctx, base);
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// stw r17,156(r30)
	PPC_STORE_U32(ctx.r30.u32 + 156, ctx.r17.u32);
	// lwz r10,256(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lwz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// bgt cr6,0x82dcc810
	if (ctx.cr6.gt) goto loc_82DCC810;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-14556
	ctx.r12.s64 = ctx.r12.s64 + -14556;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DCC790;
	case 1:
		goto loc_82DCC750;
	case 2:
		goto loc_82DCC760;
	case 3:
		goto loc_82DCC770;
	case 4:
		goto loc_82DCC780;
	case 5:
		goto loc_82DCC780;
	case 6:
		goto loc_82DCC790;
	case 7:
		goto loc_82DCC790;
	case 8:
		goto loc_82DCC790;
	case 9:
		goto loc_82DCC790;
	case 10:
		goto loc_82DCC790;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14448);
	// lwz r22,-14512(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14512);
	// lwz r22,-14496(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14496);
	// lwz r22,-14480(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14480);
	// lwz r22,-14464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14464);
	// lwz r22,-14464(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14464);
	// lwz r22,-14448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14448);
	// lwz r22,-14448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14448);
	// lwz r22,-14448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14448);
	// lwz r22,-14448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14448);
	// lwz r22,-14448(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14448);
loc_82DCC750:
	// li r10,8
	ctx.r10.s64 = 8;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
loc_82DCC760:
	// li r10,16
	ctx.r10.s64 = 16;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
loc_82DCC770:
	// li r10,24
	ctx.r10.s64 = 24;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
loc_82DCC780:
	// li r10,32
	ctx.r10.s64 = 32;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
loc_82DCC790:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-14424
	ctx.r12.s64 = ctx.r12.s64 + -14424;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-14336(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14336);
	// lwz r22,-14320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14320);
	// lwz r22,-14320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14320);
	// lwz r22,-14320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14320);
	// lwz r22,-14320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14320);
	// lwz r22,-14320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14320);
	// lwz r22,-14380(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14380);
	// lwz r22,-14368(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14368);
	// lwz r22,-14356(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14356);
	// lwz r22,-14344(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14344);
	// lwz r22,-14344(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -14344);
	// li r10,8
	ctx.r10.s64 = 8;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
	// li r10,36
	ctx.r10.s64 = 36;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
	// li r10,16
	ctx.r10.s64 = 16;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dcc804
	goto loc_82DCC804;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82dcc80c
	goto loc_82DCC80C;
	// stw r17,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r17.u32);
loc_82DCC804:
	// lwz r10,276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
loc_82DCC80C:
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
loc_82DCC810:
	// addi r11,r1,268
	ctx.r11.s64 = ctx.r1.s64 + 268;
	// stw r17,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r17.u32);
	// mr r9,r17
	ctx.r9.u64 = ctx.r17.u64;
	// li r10,17
	ctx.r10.s64 = 17;
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, ctx.r11.u32);
	// addi r11,r1,268
	ctx.r11.s64 = ctx.r1.s64 + 268;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// addi r11,r1,176
	ctx.r11.s64 = ctx.r1.s64 + 176;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DCC834:
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dcc834
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DCC834;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// addi r4,r10,9404
	ctx.r4.s64 = ctx.r10.s64 + 9404;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// ori r31,r10,256
	ctx.r31.u64 = ctx.r10.u64 | 256;
	// stw r31,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r31.u32);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// stw r10,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// stw r29,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r29.u32);
	// stw r11,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r11.u32);
	// bl 0x82da4448
	ctx.lr = 0x82DCC874;
	sub_82DA4448(ctx, base);
	// addi r27,r30,14844
	ctx.r27.s64 = ctx.r30.s64 + 14844;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// bl 0x82d8ced0
	ctx.lr = 0x82DCC88C;
	sub_82D8CED0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// addi r10,r1,496
	ctx.r10.s64 = ctx.r1.s64 + 496;
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r8,r17
	ctx.r8.u64 = ctx.r17.u64;
	// li r9,17
	ctx.r9.s64 = 17;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 220, temp.u32);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r7,240(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	// ori r7,r7,2
	ctx.r7.u64 = ctx.r7.u64 | 2;
	// stw r7,240(r11)
	PPC_STORE_U32(ctx.r11.u32 + 240, ctx.r7.u32);
	// addi r11,r1,588
	ctx.r11.s64 = ctx.r1.s64 + 588;
	// stw r17,596(r1)
	PPC_STORE_U32(ctx.r1.u32 + 596, ctx.r17.u32);
	// stw r11,588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 588, ctx.r11.u32);
	// addi r11,r1,588
	ctx.r11.s64 = ctx.r1.s64 + 588;
	// stw r11,592(r1)
	PPC_STORE_U32(ctx.r1.u32 + 592, ctx.r11.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DCC8EC:
	// std r8,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r8.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x82dcc8ec
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DCC8EC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r31,528(r1)
	PPC_STORE_U32(ctx.r1.u32 + 528, ctx.r31.u32);
	// addi r3,r1,496
	ctx.r3.s64 = ctx.r1.s64 + 496;
	// stw r17,612(r1)
	PPC_STORE_U32(ctx.r1.u32 + 612, ctx.r17.u32);
	// addi r4,r11,9372
	ctx.r4.s64 = ctx.r11.s64 + 9372;
	// bl 0x82da4448
	ctx.lr = 0x82DCC910;
	sub_82DA4448(ctx, base);
	// addi r28,r30,14848
	ctx.r28.s64 = ctx.r30.s64 + 14848;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r4,r1,496
	ctx.r4.s64 = ctx.r1.s64 + 496;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// bl 0x82d8ced0
	ctx.lr = 0x82DCC928;
	sub_82D8CED0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCC94C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// addi r10,r1,352
	ctx.r10.s64 = ctx.r1.s64 + 352;
	// lwz r7,0(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r8,r17
	ctx.r8.u64 = ctx.r17.u64;
	// li r9,17
	ctx.r9.s64 = 17;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 220, temp.u32);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r7,240(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	// ori r7,r7,2
	ctx.r7.u64 = ctx.r7.u64 | 2;
	// stw r7,240(r11)
	PPC_STORE_U32(ctx.r11.u32 + 240, ctx.r7.u32);
	// addi r11,r1,444
	ctx.r11.s64 = ctx.r1.s64 + 444;
	// stw r17,452(r1)
	PPC_STORE_U32(ctx.r1.u32 + 452, ctx.r17.u32);
	// stw r11,444(r1)
	PPC_STORE_U32(ctx.r1.u32 + 444, ctx.r11.u32);
	// addi r11,r1,444
	ctx.r11.s64 = ctx.r1.s64 + 444;
	// stw r11,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, ctx.r11.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DCC9AC:
	// std r8,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r8.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x82dcc9ac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DCC9AC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stw r31,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r31.u32);
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// stw r17,468(r1)
	PPC_STORE_U32(ctx.r1.u32 + 468, ctx.r17.u32);
	// addi r4,r11,9336
	ctx.r4.s64 = ctx.r11.s64 + 9336;
	// bl 0x82da4448
	ctx.lr = 0x82DCC9D0;
	sub_82DA4448(ctx, base);
	// addi r25,r30,492
	ctx.r25.s64 = ctx.r30.s64 + 492;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// bl 0x82d8ced0
	ctx.lr = 0x82DCC9E8;
	sub_82D8CED0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r25)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCCA0C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// mr r26,r17
	ctx.r26.u64 = ctx.r17.u64;
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// addi r29,r30,14388
	ctx.r29.s64 = ctx.r30.s64 + 14388;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 220, temp.u32);
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r10,240(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,240(r11)
	PPC_STORE_U32(ctx.r11.u32 + 240, ctx.r10.u32);
loc_82DCCA50:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccb38
	if (ctx.cr6.eq) goto loc_82DCCB38;
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccb38
	if (ctx.cr6.eq) goto loc_82DCCB38;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// lwz r31,16(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// clrlwi r11,r10,31
	ctx.r11.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccae8
	if (ctx.cr6.eq) goto loc_82DCCAE8;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82d95dd0
	ctx.lr = 0x82DCCA98;
	sub_82D95DD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// bl 0x82d95348
	ctx.lr = 0x82DCCAAC;
	sub_82D95348(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCCAD0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// b 0x82dccaf4
	goto loc_82DCCAF4;
loc_82DCCAE8:
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
loc_82DCCAF4:
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// li r5,0
	ctx.r5.s64 = 0;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCCB04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,104(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccb2c
	if (ctx.cr6.eq) goto loc_82DCCB2C;
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stw r11,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r11.u32);
loc_82DCCB2C:
	// lwz r11,240(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stw r11,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r11.u32);
loc_82DCCB38:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmpwi cr6,r26,50
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 50, ctx.xer);
	// blt cr6,0x82dcca50
	if (ctx.cr6.lt) goto loc_82DCCA50;
	// addi r11,r30,756
	ctx.r11.s64 = ctx.r30.s64 + 756;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6009
	ctx.r6.s64 = 6009;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mulli r4,r11,608
	ctx.r4.s64 = ctx.r11.s64 * 608;
	// stw r11,1016(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1016, ctx.r11.u32);
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCCB74;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1020(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1020, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lwz r11,1016(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1016);
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dccbcc
	if (!ctx.cr6.gt) goto loc_82DCCBCC;
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
loc_82DCCB94:
	// lwz r11,1020(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1020);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccbb8
	if (ctx.cr6.eq) goto loc_82DCCBB8;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stw r17,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r17.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DCCBB8;
	sub_82D9B4A8(ctx, base);
loc_82DCCBB8:
	// lwz r11,1016(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1016);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,608
	ctx.r31.s64 = ctx.r31.s64 + 608;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dccb94
	if (ctx.cr6.lt) goto loc_82DCCB94;
loc_82DCCBCC:
	// lwz r11,1016(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1016);
	// lis r31,-31909
	ctx.r31.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// li r6,6026
	ctx.r6.s64 = 6026;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// stw r11,14384(r30)
	PPC_STORE_U32(ctx.r30.u32 + 14384, ctx.r11.u32);
	// lwz r11,19872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCCBF8;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dccc08
	if (ctx.cr6.eq) goto loc_82DCCC08;
	// bl 0x82da9430
	ctx.lr = 0x82DCCC04;
	sub_82DA9430(ctx, base);
	// b 0x82dccc0c
	goto loc_82DCCC0C;
loc_82DCCC08:
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
loc_82DCCC0C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1024(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1024, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,14384(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// bl 0x82da9450
	ctx.lr = 0x82DCCC28;
	sub_82DA9450(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,19872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,14384(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// li r6,6038
	ctx.r6.s64 = 6038;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mulli r4,r10,760
	ctx.r4.s64 = ctx.r10.s64 * 760;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCCC50;
	sub_82D862B0(ctx, base);
	// stw r3,1028(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1028, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lwz r11,14384(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcccc4
	if (!ctx.cr6.gt) goto loc_82DCCCC4;
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
loc_82DCCC70:
	// lwz r11,1028(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1028);
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dccc84
	if (ctx.cr6.eq) goto loc_82DCCC84;
	// bl 0x82e01520
	ctx.lr = 0x82DCCC84;
	sub_82E01520(ctx, base);
loc_82DCCC84:
	// lwz r11,1028(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1028);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,0(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// add r5,r11,r31
	ctx.r5.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r3,1024(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1024);
	// bl 0x82da9828
	ctx.lr = 0x82DCCC9C;
	sub_82DA9828(ctx, base);
	// lwz r11,1028(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1028);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r31,r31,760
	ctx.r31.s64 = ctx.r31.s64 + 760;
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// ori r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 2048;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// lwz r11,14384(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dccc70
	if (ctx.cr6.lt) goto loc_82DCCC70;
loc_82DCCCC4:
	// lbz r11,94(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 94);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccd44
	if (ctx.cr6.eq) goto loc_82DCCD44;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r10,14384(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6053
	ctx.r6.s64 = 6053;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// rlwinm r4,r10,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCCCF4;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1032(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1032, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// lwz r11,14384(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// mr r29,r17
	ctx.r29.u64 = ctx.r17.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dccd44
	if (!ctx.cr6.gt) goto loc_82DCCD44;
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
loc_82DCCD14:
	// lwz r11,1032(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1032);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// add r5,r11,r31
	ctx.r5.u64 = ctx.r11.u64 + ctx.r31.u64;
	// bl 0x82d8d030
	ctx.lr = 0x82DCCD28;
	sub_82D8D030(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dccdbc
	if (!ctx.cr6.eq) goto loc_82DCCDBC;
	// lwz r11,14384(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14384);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dccd14
	if (ctx.cr6.lt) goto loc_82DCCD14;
loc_82DCCD44:
	// rlwinm r11,r24,0,17,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dccd70
	if (!ctx.cr6.eq) goto loc_82DCCD70;
	// rlwinm r11,r24,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dccd70
	if (!ctx.cr6.eq) goto loc_82DCCD70;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r17,496(r30)
	PPC_STORE_U32(ctx.r30.u32 + 496, ctx.r17.u32);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dccdac
	goto loc_82DCCDAC;
loc_82DCCD70:
	// addi r11,r30,1280
	ctx.r11.s64 = ctx.r30.s64 + 1280;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6074
	ctx.r6.s64 = 6074;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// rlwinm r4,r10,8,0,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCCD98;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,496(r30)
	PPC_STORE_U32(ctx.r30.u32 + 496, ctx.r3.u32);
	// beq cr6,0x82dca474
	if (ctx.cr6.eq) goto loc_82DCA474;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dc9c68
	ctx.lr = 0x82DCCDAC;
	sub_82DC9C68(ctx, base);
loc_82DCCDAC:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r17,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r17.u32);
	// bl 0x82dc9720
	ctx.lr = 0x82DCCDB8;
	sub_82DC9720(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCCDBC:
	// addi r1,r1,2480
	ctx.r1.s64 = ctx.r1.s64 + 2480;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DCCDC8;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCCDCC"))) PPC_WEAK_FUNC(sub_82DCCDCC);
PPC_FUNC_IMPL(__imp__sub_82DCCDCC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCCDD0"))) PPC_WEAK_FUNC(sub_82DCCDD0);
PPC_FUNC_IMPL(__imp__sub_82DCCDD0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dccde0
	if (!ctx.cr6.eq) goto loc_82DCCDE0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCCDE0:
	// b 0x82dca200
	sub_82DCA200(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCCDE4"))) PPC_WEAK_FUNC(sub_82DCCDE4);
PPC_FUNC_IMPL(__imp__sub_82DCCDE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCCDE8"))) PPC_WEAK_FUNC(sub_82DCCDE8);
PPC_FUNC_IMPL(__imp__sub_82DCCDE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,30968
	ctx.r31.s64 = ctx.r11.s64 + 30968;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DCCE14;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r30,-32035
	ctx.r30.s64 = -2099445760;
	// addi r11,r11,9516
	ctx.r11.s64 = ctx.r11.s64 + 9516;
	// lis r3,-32035
	ctx.r3.s64 = -2099445760;
	// lis r4,-32035
	ctx.r4.s64 = -2099445760;
	// lis r5,-32032
	ctx.r5.s64 = -2099249152;
	// lis r6,-32035
	ctx.r6.s64 = -2099445760;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// lis r7,-32032
	ctx.r7.s64 = -2099249152;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// lis r8,-32032
	ctx.r8.s64 = -2099249152;
	// lis r9,-32032
	ctx.r9.s64 = -2099249152;
	// lis r10,-32032
	ctx.r10.s64 = -2099249152;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,1794
	ctx.r11.s64 = 1794;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r30,-12848
	ctx.r11.s64 = ctx.r30.s64 + -12848;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r3,-25544
	ctx.r11.s64 = ctx.r3.s64 + -25544;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r4,-24160
	ctx.r11.s64 = ctx.r4.s64 + -24160;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r5,12544
	ctx.r11.s64 = ctx.r5.s64 + 12544;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// addi r11,r6,-25520
	ctx.r11.s64 = ctx.r6.s64 + -25520;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// addi r11,r7,12656
	ctx.r11.s64 = ctx.r7.s64 + 12656;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// addi r11,r8,12752
	ctx.r11.s64 = ctx.r8.s64 + 12752;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// addi r11,r9,12800
	ctx.r11.s64 = ctx.r9.s64 + 12800;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// addi r11,r10,12904
	ctx.r11.s64 = ctx.r10.s64 + 12904;
	// stw r11,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r11.u32);
	// li r11,10
	ctx.r11.s64 = 10;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,14852
	ctx.r11.s64 = 14852;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCCED4"))) PPC_WEAK_FUNC(sub_82DCCED4);
PPC_FUNC_IMPL(__imp__sub_82DCCED4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCCED8"))) PPC_WEAK_FUNC(sub_82DCCED8);
PPC_FUNC_IMPL(__imp__sub_82DCCED8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// addi r11,r11,-17904
	ctx.r11.s64 = ctx.r11.s64 + -17904;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82dccf14
	if (!ctx.cr6.eq) goto loc_82DCCF14;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DCCF10;
	sub_82E02948(ctx, base);
	// b 0x82dccf18
	goto loc_82DCCF18;
loc_82DCCF14:
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
loc_82DCCF18:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bne cr6,0x82dccf28
	if (!ctx.cr6.eq) goto loc_82DCCF28;
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
loc_82DCCF28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCCF40"))) PPC_WEAK_FUNC(sub_82DCCF40);
PPC_FUNC_IMPL(__imp__sub_82DCCF40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DCCF48;
	__savegprlr_29(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// lwz r10,496(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// add. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82dccf78
	if (!ctx.cr0.eq) goto loc_82DCCF78;
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
loc_82DCCF78:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dccf9c
	if (ctx.cr6.eq) goto loc_82DCCF9C;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82e02c60
	ctx.lr = 0x82DCCF9C;
	sub_82E02C60(ctx, base);
loc_82DCCF9C:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcd040
	if (ctx.cr6.eq) goto loc_82DCD040;
	// lwz r10,484(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// lfs f13,640(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,492(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 492);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r8,2028(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2028);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,588(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// lwz r9,528(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// std r8,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r8.u64);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// lfd f0,96(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// lfd f10,120(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// lfd f12,104(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f11,112(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// fmuls f12,f0,f10
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f0,9540(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9540);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DCD040;
	sub_82D99380(ctx, base);
loc_82DCD040:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcd094
	if (ctx.cr6.eq) goto loc_82DCD094;
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// lfs f13,2020(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 2020);
	ctx.f13.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfd f0,120(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(ctx.f0.f64));
	// lfs f0,-17348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -17348);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,-17648(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -17648);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DCD094;
	sub_82D99540(ctx, base);
loc_82DCD094:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcd15c
	if (ctx.cr6.eq) goto loc_82DCD15C;
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// lwz r10,496(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bge cr6,0x82dcd0c4
	if (!ctx.cr6.lt) goto loc_82DCD0C4;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
loc_82DCD0C4:
	// lhz r10,2034(r29)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r29.u32 + 2034);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcd130
	if (ctx.cr6.eq) goto loc_82DCD130;
	// extsw r10,r11
	ctx.r10.s64 = ctx.r11.s32;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// std r10,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r10.u64);
	// lfd f1,-18376(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18376);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f0,120(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,9536(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9536);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f0,9532(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9532);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82cb59b0
	ctx.lr = 0x82DCD10C;
	sub_82CB59B0(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lfs f0,9312(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 9312);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// b 0x82dcd140
	goto loc_82DCD140;
loc_82DCD130:
	// lis r10,218
	ctx.r10.s64 = 14286848;
	// twllei r11,0
	// ori r10,r10,30208
	ctx.r10.u64 = ctx.r10.u64 | 30208;
	// divw r11,r10,r11
	ctx.r11.s32 = ctx.r10.s32 / ctx.r11.s32;
loc_82DCD140:
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DCD15C;
	sub_82D9B8E0(ctx, base);
loc_82DCD15C:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// rlwinm r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcd1a8
	if (ctx.cr6.eq) goto loc_82DCD1A8;
	// li r30,0
	ctx.r30.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82d9cb18
	ctx.lr = 0x82DCD198;
	sub_82D9CB18(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DCD1A4;
	sub_82D8B3E0(ctx, base);
	// stw r30,504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 504, ctx.r30.u32);
loc_82DCD1A8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCD1B4"))) PPC_WEAK_FUNC(sub_82DCD1B4);
PPC_FUNC_IMPL(__imp__sub_82DCD1B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCD1B8"))) PPC_WEAK_FUNC(sub_82DCD1B8);
PPC_FUNC_IMPL(__imp__sub_82DCD1B8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dcd1ec
	if (!ctx.cr6.lt) goto loc_82DCD1EC;
	// lbz r9,660(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// rotlwi r9,r9,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 2);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82dcd214
	if (!ctx.cr6.gt) goto loc_82DCD214;
	// b 0x82dcd210
	goto loc_82DCD210;
loc_82DCD1EC:
	// ble cr6,0x82dcd214
	if (!ctx.cr6.gt) goto loc_82DCD214;
	// lbz r10,660(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dcd214
	if (!ctx.cr6.lt) goto loc_82DCD214;
loc_82DCD210:
	// stw r9,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r9.u32);
loc_82DCD214:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCD228"))) PPC_WEAK_FUNC(sub_82DCD228);
PPC_FUNC_IMPL(__imp__sub_82DCD228) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,694(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dcd2d4
	if (ctx.cr6.gt) goto loc_82DCD2D4;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-11660
	ctx.r12.s64 = ctx.r12.s64 + -11660;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DCD284;
	case 1:
		goto loc_82DCD298;
	case 2:
		goto loc_82DCD2C0;
	case 3:
		goto loc_82DCD2C8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-11644(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11644);
	// lwz r22,-11624(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11624);
	// lwz r22,-11584(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11584);
	// lwz r22,-11576(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11576);
loc_82DCD284:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dcd2d8
	goto loc_82DCD2D8;
loc_82DCD298:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dcd2b8
	if (!ctx.cr6.lt) goto loc_82DCD2B8;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DCD2B8:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dcd2d8
	goto loc_82DCD2D8;
loc_82DCD2C0:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dcd2d8
	goto loc_82DCD2D8;
loc_82DCD2C8:
	// bl 0x82cb2308
	ctx.lr = 0x82DCD2CC;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dcd2d8
	goto loc_82DCD2D8;
loc_82DCD2D4:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DCD2D8:
	// lbz r10,664(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 664);
	// lbz r9,662(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// srawi r11,r11,5
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 5;
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// bge cr6,0x82dcd2f8
	if (!ctx.cr6.lt) goto loc_82DCD2F8;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DCD2F8:
	// stw r11,496(r30)
	PPC_STORE_U32(ctx.r30.u32 + 496, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbz r11,476(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 476);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r30)
	PPC_STORE_U8(ctx.r30.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCD324"))) PPC_WEAK_FUNC(sub_82DCD324);
PPC_FUNC_IMPL(__imp__sub_82DCD324) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCD328"))) PPC_WEAK_FUNC(sub_82DCD328);
PPC_FUNC_IMPL(__imp__sub_82DCD328) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,694(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 694);
	// lbz r9,666(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 666);
	// rlwinm r8,r11,28,30,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0x3;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r10,r9,27
	ctx.r10.u64 = ctx.r9.u32 & 0x1F;
	// cmplwi cr6,r8,3
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 3, ctx.xer);
	// bgt cr6,0x82dcd3b0
	if (ctx.cr6.gt) goto loc_82DCD3B0;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-11428
	ctx.r12.s64 = ctx.r12.s64 + -11428;
	// rlwinm r0,r8,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r8.u64) {
	case 0:
		goto loc_82DCD39C;
	case 1:
		goto loc_82DCD36C;
	case 2:
		goto loc_82DCD394;
	case 3:
		goto loc_82DCD39C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-11364(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11364);
	// lwz r22,-11412(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11412);
	// lwz r22,-11372(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11372);
	// lwz r22,-11364(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -11364);
loc_82DCD36C:
	// rlwinm r10,r10,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0x7F8;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dcd38c
	if (!ctx.cr6.lt) goto loc_82DCD38C;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// subfic r10,r10,255
	ctx.xer.ca = ctx.r10.u32 <= 255;
	ctx.r10.s64 = 255 - ctx.r10.s64;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
loc_82DCD38C:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// b 0x82dcd3ac
	goto loc_82DCD3AC;
loc_82DCD394:
	// li r10,255
	ctx.r10.s64 = 255;
	// b 0x82dcd3ac
	goto loc_82DCD3AC;
loc_82DCD39C:
	// lis r9,-31908
	ctx.r9.s64 = -2091122688;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// addi r9,r9,-19352
	ctx.r9.s64 = ctx.r9.s64 + -19352;
	// lbzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
loc_82DCD3AC:
	// stw r10,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r10.u32);
loc_82DCD3B0:
	// lwz r9,492(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	// lbz r10,668(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 668);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// srawi r10,r10,6
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 6;
	// stw r10,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r10.u32);
	// lbz r9,666(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 666);
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// bge cr6,0x82dcd3e8
	if (!ctx.cr6.lt) goto loc_82DCD3E8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dcd408
	if (!ctx.cr6.gt) goto loc_82DCD408;
	// subfic r10,r9,64
	ctx.xer.ca = ctx.r9.u32 <= 64;
	ctx.r10.s64 = 64 - ctx.r9.s64;
	// b 0x82dcd404
	goto loc_82DCD404;
loc_82DCD3E8:
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dcd3fc
	if (!ctx.cr6.lt) goto loc_82DCD3FC;
	// stw r9,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r9.u32);
loc_82DCD3FC:
	// lwz r10,492(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	// neg r10,r10
	ctx.r10.s64 = -ctx.r10.s64;
loc_82DCD404:
	// stw r10,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r10.u32);
loc_82DCD408:
	// lbz r9,666(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 666);
	// lbz r8,667(r3)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r3.u32 + 667);
	// add r10,r8,r9
	ctx.r10.u64 = ctx.r8.u64 + ctx.r9.u64;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,31
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 31, ctx.xer);
	// stb r10,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r10.u8);
	// ble cr6,0x82dcd430
	if (!ctx.cr6.gt) goto loc_82DCD430;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// addi r10,r10,-64
	ctx.r10.s64 = ctx.r10.s64 + -64;
	// stb r10,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r10.u8);
loc_82DCD430:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCD444"))) PPC_WEAK_FUNC(sub_82DCD444);
PPC_FUNC_IMPL(__imp__sub_82DCD444) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCD448"))) PPC_WEAK_FUNC(sub_82DCD448);
PPC_FUNC_IMPL(__imp__sub_82DCD448) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d4
	ctx.lr = 0x82DCD450;
	__savegprlr_23(ctx, base);
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpw cr6,r11,r6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82dcd488
	if (!ctx.cr6.lt) goto loc_82DCD488;
	// lwz r3,0(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dcd4b8
	if (ctx.cr6.eq) goto loc_82DCD4B8;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lhzx r31,r31,r7
	ctx.r31.u64 = PPC_LOAD_U16(ctx.r31.u32 + ctx.r7.u32);
	// cmpw cr6,r3,r31
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r31.s32, ctx.xer);
	// beq cr6,0x82dcd4b8
	if (ctx.cr6.eq) goto loc_82DCD4B8;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
loc_82DCD488:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lhz r9,8(r4)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r4.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// stw r9,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r9.u32);
loc_82DCD4A0:
	// lbz r11,476(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbz r10,95(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 95);
	// or r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 | ctx.r11.u64;
	// stb r11,476(r5)
	PPC_STORE_U8(ctx.r5.u32 + 476, ctx.r11.u8);
	// b 0x82cb1124
	__restgprlr_23(ctx, base);
	return;
loc_82DCD4B8:
	// lbz r26,87(r1)
	ctx.r26.u64 = PPC_LOAD_U8(ctx.r1.u32 + 87);
	// rlwinm r24,r8,0,29,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x4;
	// addi r27,r6,-1
	ctx.r27.s64 = ctx.r6.s64 + -1;
	// li r25,0
	ctx.r25.s64 = 0;
loc_82DCD4C8:
	// cmpwi cr6,r24,0
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// beq cr6,0x82dcd4ec
	if (ctx.cr6.eq) goto loc_82DCD4EC;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82dcd4ec
	if (!ctx.cr6.eq) goto loc_82DCD4EC;
	// rlwinm r3,r9,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// lhzx r3,r3,r7
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + ctx.r7.u32);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
loc_82DCD4EC:
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r11,1
	ctx.r30.s64 = ctx.r11.s64 + 1;
	// add r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 + ctx.r7.u64;
	// rlwinm r31,r30,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r11,r27
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r27.s32, ctx.xer);
	// add r31,r31,r7
	ctx.r31.u64 = ctx.r31.u64 + ctx.r7.u64;
	// lhz r28,2(r3)
	ctx.r28.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2);
	// lhz r29,0(r3)
	ctx.r29.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// rotlwi r3,r28,16
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r28.u32, 16);
	// lhz r28,2(r31)
	ctx.r28.u64 = PPC_LOAD_U16(ctx.r31.u32 + 2);
	// lhz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// rotlwi r28,r28,16
	ctx.r28.u64 = __builtin_rotateleft32(ctx.r28.u32, 16);
	// beq cr6,0x82dcd5a4
	if (ctx.cr6.eq) goto loc_82DCD5A4;
	// rlwinm r23,r8,0,30,30
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x2;
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq cr6,0x82dcd544
	if (ctx.cr6.eq) goto loc_82DCD544;
	// clrlwi r23,r26,24
	ctx.r23.u64 = ctx.r26.u32 & 0xFF;
	// cmpw cr6,r11,r23
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r23.s32, ctx.xer);
	// bne cr6,0x82dcd544
	if (!ctx.cr6.eq) goto loc_82DCD544;
	// lbz r23,600(r5)
	ctx.r23.u64 = PPC_LOAD_U8(ctx.r5.u32 + 600);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dcd5d4
	if (ctx.cr6.eq) goto loc_82DCD5D4;
loc_82DCD544:
	// subf r11,r29,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r29.s64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dcd574
	if (ctx.cr6.eq) goto loc_82DCD574;
	// subf r29,r3,r28
	ctx.r29.s64 = ctx.r28.s64 - ctx.r3.s64;
	// twllei r11,0
	// rotlwi r31,r29,1
	ctx.r31.u64 = __builtin_rotateleft32(ctx.r29.u32, 1);
	// divw r29,r29,r11
	ctx.r29.s32 = ctx.r29.s32 / ctx.r11.s32;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// andc r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r31.u64;
	// twlgei r11,-1
	// stw r29,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r29.u32);
	// b 0x82dcd578
	goto loc_82DCD578;
loc_82DCD574:
	// stw r25,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r25.u32);
loc_82DCD578:
	// rlwinm r29,r30,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r3,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r3.u32);
	// stw r30,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// lwz r31,0(r4)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lhzx r3,r29,r7
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r29.u32 + ctx.r7.u32);
	// cmpw cr6,r31,r3
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r3.s32, ctx.xer);
	// bne cr6,0x82dcd488
	if (!ctx.cr6.eq) goto loc_82DCD488;
	// cmpw cr6,r30,r6
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r6.s32, ctx.xer);
	// blt cr6,0x82dcd4c8
	if (ctx.cr6.lt) goto loc_82DCD4C8;
	// b 0x82dcd488
	goto loc_82DCD488;
loc_82DCD5A4:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lbz r9,95(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 95);
	// li r10,1
	ctx.r10.s64 = 1;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lhz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// stb r10,20(r4)
	PPC_STORE_U8(ctx.r4.u32 + 20, ctx.r10.u8);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r11.u32);
	// lbz r11,476(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 476);
	// or r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 | ctx.r11.u64;
	// stb r11,476(r5)
	PPC_STORE_U8(ctx.r5.u32 + 476, ctx.r11.u8);
	// b 0x82cb1124
	__restgprlr_23(ctx, base);
	return;
loc_82DCD5D4:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lhz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r11.u32);
	// b 0x82dcd4a0
	goto loc_82DCD4A0;
}

__attribute__((alias("__imp__sub_82DCD5E8"))) PPC_WEAK_FUNC(sub_82DCD5E8);
PPC_FUNC_IMPL(__imp__sub_82DCD5E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lbz r10,1159(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1159);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dcd69c
	if (ctx.cr6.gt) goto loc_82DCD69C;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-10736
	ctx.r12.s64 = ctx.r12.s64 + -10736;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DCD620;
	case 1:
		goto loc_82DCD638;
	case 2:
		goto loc_82DCD654;
	case 3:
		goto loc_82DCD678;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10720(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10720);
	// lwz r22,-10696(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10696);
	// lwz r22,-10668(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10668);
	// lwz r22,-10632(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10632);
loc_82DCD620:
	// lis r10,-31908
	ctx.r10.s64 = -2091122688;
	// lwz r9,592(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 592);
	// addi r10,r10,-19320
	ctx.r10.s64 = ctx.r10.s64 + -19320;
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// b 0x82dcd6a0
	goto loc_82DCD6A0;
loc_82DCD638:
	// lwz r10,592(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 592);
	// cmpwi cr6,r10,128
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 128, ctx.xer);
	// bge cr6,0x82dcd64c
	if (!ctx.cr6.lt) goto loc_82DCD64C;
	// li r10,64
	ctx.r10.s64 = 64;
	// b 0x82dcd6a0
	goto loc_82DCD6A0;
loc_82DCD64C:
	// li r10,-64
	ctx.r10.s64 = -64;
	// b 0x82dcd6a0
	goto loc_82DCD6A0;
loc_82DCD654:
	// lwz r10,592(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 592);
	// addi r10,r10,128
	ctx.r10.s64 = ctx.r10.s64 + 128;
	// srawi r9,r10,8
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFF) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 8;
	// addze r9,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r9.s64 = temp.s64;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// subfic r10,r10,128
	ctx.xer.ca = ctx.r10.u32 <= 128;
	ctx.r10.s64 = 128 - ctx.r10.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// b 0x82dcd6a0
	goto loc_82DCD6A0;
loc_82DCD678:
	// lwz r10,592(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 592);
	// subfic r10,r10,384
	ctx.xer.ca = ctx.r10.u32 <= 384;
	ctx.r10.s64 = 384 - ctx.r10.s64;
	// srawi r9,r10,8
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFF) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 8;
	// addze r9,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r9.s64 = temp.s64;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// subfic r10,r10,128
	ctx.xer.ca = ctx.r10.u32 <= 128;
	ctx.r10.s64 = 128 - ctx.r10.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// b 0x82dcd6a0
	goto loc_82DCD6A0;
loc_82DCD69C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82DCD6A0:
	// lbz r8,1160(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1160);
	// lbz r9,1161(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1161);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// beq cr6,0x82dcd6d4
	if (ctx.cr6.eq) goto loc_82DCD6D4;
	// lwz r10,596(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 596);
	// twllei r8,0
	// mullw r9,r10,r9
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r9,r9,r8
	ctx.r9.s32 = ctx.r9.s32 / ctx.r8.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 & ~ctx.r10.u64;
	// twlgei r10,-1
loc_82DCD6D4:
	// lwz r10,596(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 596);
	// srawi r9,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 6;
	// lwz r8,496(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stw r10,596(r11)
	PPC_STORE_U32(ctx.r11.u32 + 596, ctx.r10.u32);
	// stw r9,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r9.u32);
	// lbz r9,1160(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1160);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82dcd700
	if (!ctx.cr6.gt) goto loc_82DCD700;
	// stw r9,596(r11)
	PPC_STORE_U32(ctx.r11.u32 + 596, ctx.r9.u32);
loc_82DCD700:
	// lbz r10,1162(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1162);
	// lwz r9,592(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 592);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// stw r10,592(r11)
	PPC_STORE_U32(ctx.r11.u32 + 592, ctx.r10.u32);
	// ble cr6,0x82dcd720
	if (!ctx.cr6.gt) goto loc_82DCD720;
	// addi r10,r10,-256
	ctx.r10.s64 = ctx.r10.s64 + -256;
	// stw r10,592(r11)
	PPC_STORE_U32(ctx.r11.u32 + 592, ctx.r10.u32);
loc_82DCD720:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCD734"))) PPC_WEAK_FUNC(sub_82DCD734);
PPC_FUNC_IMPL(__imp__sub_82DCD734) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCD738"))) PPC_WEAK_FUNC(sub_82DCD738);
PPC_FUNC_IMPL(__imp__sub_82DCD738) {
	PPC_FUNC_PROLOGUE();
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// blt cr6,0x82dcd76c
	if (ctx.cr6.lt) goto loc_82DCD76C;
	// cmplwi cr6,r10,80
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 80, ctx.xer);
	// bgt cr6,0x82dcd76c
	if (ctx.cr6.gt) goto loc_82DCD76C;
	// lbz r9,476(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// addi r10,r10,-16
	ctx.r10.s64 = ctx.r10.s64 + -16;
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// stb r9,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r9.u8);
	// blr 
	return;
loc_82DCD76C:
	// rlwinm r9,r10,28,4,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// addi r9,r9,-6
	ctx.r9.s64 = ctx.r9.s64 + -6;
	// cmplwi cr6,r9,9
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 9, ctx.xer);
	// bgt cr6,0x82dcd8cc
	if (ctx.cr6.gt) goto loc_82DCD8CC;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-10348
	ctx.r12.s64 = ctx.r12.s64 + -10348;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82DCD7BC;
	case 1:
		goto loc_82DCD7EC;
	case 2:
		goto loc_82DCD7BC;
	case 3:
		goto loc_82DCD7EC;
	case 4:
		goto loc_82DCD820;
	case 5:
		goto loc_82DCD830;
	case 6:
		goto loc_82DCD840;
	case 7:
		goto loc_82DCD85C;
	case 8:
		goto loc_82DCD880;
	case 9:
		goto loc_82DCD8A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10308(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10308);
	// lwz r22,-10260(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10260);
	// lwz r22,-10308(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10308);
	// lwz r22,-10260(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10260);
	// lwz r22,-10208(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10208);
	// lwz r22,-10192(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10192);
	// lwz r22,-10176(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10176);
	// lwz r22,-10148(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10148);
	// lwz r22,-10112(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10112);
	// lwz r22,-10076(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -10076);
loc_82DCD7BC:
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// subf. r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// bge 0x82dcd7d8
	if (!ctx.cr0.lt) goto loc_82DCD7D8;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DCD7D8:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
loc_82DCD7EC:
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// ble cr6,0x82dcd80c
	if (!ctx.cr6.gt) goto loc_82DCD80C;
	// li r10,64
	ctx.r10.s64 = 64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DCD80C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
loc_82DCD820:
	// clrlwi r11,r10,28
	ctx.r11.u64 = ctx.r10.u32 & 0xF;
	// stb r11,663(r3)
	PPC_STORE_U8(ctx.r3.u32 + 663, ctx.r11.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82DCD830:
	// clrlwi r11,r10,28
	ctx.r11.u64 = ctx.r10.u32 & 0xF;
	// stb r11,664(r3)
	PPC_STORE_U8(ctx.r3.u32 + 664, ctx.r11.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82DCD840:
	// lbz r9,476(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,4,24,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xF0;
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r9,r9,4
	ctx.r9.u64 = ctx.r9.u64 | 4;
	// stw r10,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r10.u32);
	// stb r9,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r9.u8);
	// blr 
	return;
loc_82DCD85C:
	// lwz r9,488(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// lbz r8,476(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ori r9,r8,4
	ctx.r9.u64 = ctx.r8.u64 | 4;
	// stw r10,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r10.u32);
	// stb r9,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r9.u8);
	// blr 
	return;
loc_82DCD880:
	// lwz r9,488(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// lbz r8,476(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// ori r9,r8,4
	ctx.r9.u64 = ctx.r8.u64 | 4;
	// stw r10,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r10.u32);
	// stb r9,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r9.u8);
	// blr 
	return;
loc_82DCD8A4:
	// clrlwi r9,r10,28
	ctx.r9.u64 = ctx.r10.u32 & 0xF;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dcd8b8
	if (ctx.cr6.eq) goto loc_82DCD8B8;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// stb r10,660(r3)
	PPC_STORE_U8(ctx.r3.u32 + 660, ctx.r10.u8);
loc_82DCD8B8:
	// lwz r10,612(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 612);
	// stw r10,656(r3)
	PPC_STORE_U32(ctx.r3.u32 + 656, ctx.r10.u32);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DCD8CC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCD8D4"))) PPC_WEAK_FUNC(sub_82DCD8D4);
PPC_FUNC_IMPL(__imp__sub_82DCD8D4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCD8D8"))) PPC_WEAK_FUNC(sub_82DCD8D8);
PPC_FUNC_IMPL(__imp__sub_82DCD8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-19064
	ctx.r9.s64 = ctx.r11.s64 + -19064;
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// add r8,r10,r9
	ctx.r8.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// bge cr6,0x82dcd90c
	if (!ctx.cr6.lt) goto loc_82DCD90C;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82dcd90c
	if (ctx.cr6.eq) goto loc_82DCD90C;
	// lwz r10,-4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82dcd918
	goto loc_82DCD918;
loc_82DCD90C:
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82DCD918:
	// mullw r10,r10,r5
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// srawi r10,r10,7
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 7;
	// li r3,0
	ctx.r3.s64 = 0;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCD934"))) PPC_WEAK_FUNC(sub_82DCD934);
PPC_FUNC_IMPL(__imp__sub_82DCD934) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCD938"))) PPC_WEAK_FUNC(sub_82DCD938);
PPC_FUNC_IMPL(__imp__sub_82DCD938) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x82DCD940;
	__savegprlr_28(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// lbz r11,1(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 1);
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcd9f0
	if (ctx.cr6.eq) goto loc_82DCD9F0;
	// lbz r11,8(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 8);
	// li r10,64
	ctx.r10.s64 = 64;
	// stw r11,484(r5)
	PPC_STORE_U32(ctx.r5.u32 + 484, ctx.r11.u32);
	// li r11,32
	ctx.r11.s64 = 32;
	// lbz r9,9(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 9);
	// stw r10,528(r5)
	PPC_STORE_U32(ctx.r5.u32 + 528, ctx.r10.u32);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// stw r31,520(r5)
	PPC_STORE_U32(ctx.r5.u32 + 520, ctx.r31.u32);
	// stw r31,516(r5)
	PPC_STORE_U32(ctx.r5.u32 + 516, ctx.r31.u32);
	// stw r31,532(r5)
	PPC_STORE_U32(ctx.r5.u32 + 532, ctx.r31.u32);
	// stw r9,488(r5)
	PPC_STORE_U32(ctx.r5.u32 + 488, ctx.r9.u32);
	// stw r10,588(r5)
	PPC_STORE_U32(ctx.r5.u32 + 588, ctx.r10.u32);
	// stw r11,552(r5)
	PPC_STORE_U32(ctx.r5.u32 + 552, ctx.r11.u32);
	// stw r31,544(r5)
	PPC_STORE_U32(ctx.r5.u32 + 544, ctx.r31.u32);
	// stw r31,540(r5)
	PPC_STORE_U32(ctx.r5.u32 + 540, ctx.r31.u32);
	// stw r31,556(r5)
	PPC_STORE_U32(ctx.r5.u32 + 556, ctx.r31.u32);
	// stb r31,536(r5)
	PPC_STORE_U8(ctx.r5.u32 + 536, ctx.r31.u8);
	// stb r31,560(r5)
	PPC_STORE_U8(ctx.r5.u32 + 560, ctx.r31.u8);
	// stb r31,600(r5)
	PPC_STORE_U8(ctx.r5.u32 + 600, ctx.r31.u8);
	// stw r31,596(r5)
	PPC_STORE_U32(ctx.r5.u32 + 596, ctx.r31.u32);
	// stw r31,592(r5)
	PPC_STORE_U32(ctx.r5.u32 + 592, ctx.r31.u32);
	// lbz r11,694(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 694);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bge cr6,0x82dcd9d0
	if (!ctx.cr6.lt) goto loc_82DCD9D0;
	// stb r31,662(r3)
	PPC_STORE_U8(ctx.r3.u32 + 662, ctx.r31.u8);
loc_82DCD9D0:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// bge cr6,0x82dcd9e0
	if (!ctx.cr6.lt) goto loc_82DCD9E0;
	// stb r31,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r31.u8);
loc_82DCD9E0:
	// stb r31,678(r3)
	PPC_STORE_U8(ctx.r3.u32 + 678, ctx.r31.u8);
	// lbz r11,476(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 476);
	// ori r11,r11,6
	ctx.r11.u64 = ctx.r11.u64 | 6;
	// stb r11,476(r5)
	PPC_STORE_U8(ctx.r5.u32 + 476, ctx.r11.u8);
loc_82DCD9F0:
	// lbz r4,2(r29)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r29.u32 + 2);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcda00
	if (ctx.cr6.eq) goto loc_82DCDA00;
	// bl 0x82dcd738
	ctx.lr = 0x82DCDA00;
	sub_82DCD738(ctx, base);
loc_82DCDA00:
	// lbz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// beq cr6,0x82dcda18
	if (ctx.cr6.eq) goto loc_82DCDA18;
	// lbz r11,3(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 3);
	// cmplwi cr6,r11,20
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 20, ctx.xer);
	// bne cr6,0x82dcda20
	if (!ctx.cr6.eq) goto loc_82DCDA20;
loc_82DCDA18:
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,600(r5)
	PPC_STORE_U8(ctx.r5.u32 + 600, ctx.r11.u8);
loc_82DCDA20:
	// lbz r8,896(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 896);
	// clrlwi r11,r8,31
	ctx.r11.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcda6c
	if (ctx.cr6.eq) goto loc_82DCDA6C;
	// lbz r11,536(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 536);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcda7c
	if (!ctx.cr6.eq) goto loc_82DCDA7C;
	// lbz r11,978(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 978);
	// li r29,2
	ctx.r29.s64 = 2;
	// addi r7,r30,898
	ctx.r7.s64 = ctx.r30.s64 + 898;
	// lbz r10,980(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 980);
	// addi r4,r5,516
	ctx.r4.s64 = ctx.r5.s64 + 516;
	// lbz r9,979(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 979);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lbz r6,897(r30)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r30.u32 + 897);
	// stb r11,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r11.u8);
	// stb r29,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r29.u8);
	// bl 0x82dcd448
	ctx.lr = 0x82DCDA68;
	sub_82DCD448(ctx, base);
	// b 0x82dcda7c
	goto loc_82DCDA7C;
loc_82DCDA6C:
	// lbz r11,600(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 600);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcda7c
	if (ctx.cr6.eq) goto loc_82DCDA7C;
	// stw r31,528(r5)
	PPC_STORE_U32(ctx.r5.u32 + 528, ctx.r31.u32);
loc_82DCDA7C:
	// lbz r8,983(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 983);
	// clrlwi r11,r8,31
	ctx.r11.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdac4
	if (ctx.cr6.eq) goto loc_82DCDAC4;
	// lbz r11,560(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 560);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcdac4
	if (!ctx.cr6.eq) goto loc_82DCDAC4;
	// lbz r11,1066(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1066);
	// li r29,4
	ctx.r29.s64 = 4;
	// addi r7,r30,986
	ctx.r7.s64 = ctx.r30.s64 + 986;
	// lbz r10,1068(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1068);
	// addi r4,r5,540
	ctx.r4.s64 = ctx.r5.s64 + 540;
	// lbz r9,1067(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1067);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lbz r6,984(r30)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r30.u32 + 984);
	// stb r11,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r11.u8);
	// stb r29,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r29.u8);
	// bl 0x82dcd448
	ctx.lr = 0x82DCDAC4;
	sub_82DCD448(ctx, base);
loc_82DCDAC4:
	// lbz r11,600(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 600);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdaf4
	if (ctx.cr6.eq) goto loc_82DCDAF4;
	// lhz r11,1164(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 1164);
	// lwz r10,588(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 588);
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,588(r5)
	PPC_STORE_U32(ctx.r5.u32 + 588, ctx.r11.u32);
	// bge 0x82dcdae8
	if (!ctx.cr0.lt) goto loc_82DCDAE8;
	// stw r31,588(r5)
	PPC_STORE_U32(ctx.r5.u32 + 588, ctx.r31.u32);
loc_82DCDAE8:
	// lbz r11,476(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 476);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r5)
	PPC_STORE_U8(ctx.r5.u32 + 476, ctx.r11.u8);
loc_82DCDAF4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCDB00"))) PPC_WEAK_FUNC(sub_82DCDB00);
PPC_FUNC_IMPL(__imp__sub_82DCDB00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DCDB08;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// li r20,0
	ctx.r20.s64 = 0;
	// lwz r9,2056(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2056);
	// lwz r7,488(r24)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r24.u32 + 488);
	// add r8,r9,r24
	ctx.r8.u64 = ctx.r9.u64 + ctx.r24.u64;
	// lwz r10,2052(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2052);
	// lwz r11,756(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 756);
	// stb r20,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r20.u8);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// lbz r8,500(r8)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + 500);
	// rotlwi r8,r8,3
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 3);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// add r22,r8,r11
	ctx.r22.u64 = ctx.r8.u64 + ctx.r11.u64;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82dce6d0
	if (ctx.cr6.eq) goto loc_82DCE6D0;
	// lwz r11,496(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 496);
	// li r15,1
	ctx.r15.s64 = 1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdb90
	if (ctx.cr6.eq) goto loc_82DCDB90;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lbzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dcdb8c
	if (ctx.cr6.eq) goto loc_82DCDB8C;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r11,2037(r24)
	PPC_STORE_U8(ctx.r24.u32 + 2037, ctx.r11.u8);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCDB8C:
	// stbx r15,r11,r10
	PPC_STORE_U8(ctx.r11.u32 + ctx.r10.u32, ctx.r15.u8);
loc_82DCDB90:
	// lwz r11,756(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 756);
	// mr r19,r20
	ctx.r19.u64 = ctx.r20.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dce6d0
	if (!ctx.cr6.gt) goto loc_82DCE6D0;
	// lis r11,-31891
	ctx.r11.s64 = -2090008576;
	// li r14,64
	ctx.r14.s64 = 64;
	// addi r16,r11,26712
	ctx.r16.s64 = ctx.r11.s64 + 26712;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// addi r18,r11,-17952
	ctx.r18.s64 = ctx.r11.s64 + -17952;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// addi r17,r11,-17904
	ctx.r17.s64 = ctx.r11.s64 + -17904;
loc_82DCDBBC:
	// addi r10,r19,190
	ctx.r10.s64 = ctx.r19.s64 + 190;
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r20.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r11,28,4,31
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r26,r11,28
	ctx.r26.u64 = ctx.r11.u32 & 0xF;
	// lwzx r31,r10,r24
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r24.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dcdbf4
	if (!ctx.cr6.eq) goto loc_82DCDBF4;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// mr r10,r15
	ctx.r10.u64 = ctx.r15.u64;
	// beq cr6,0x82dcdbf8
	if (ctx.cr6.eq) goto loc_82DCDBF8;
loc_82DCDBF4:
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
loc_82DCDBF8:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcdc10
	if (ctx.cr6.eq) goto loc_82DCDC10;
	// mr r9,r17
	ctx.r9.u64 = ctx.r17.u64;
	// stw r18,464(r17)
	PPC_STORE_U32(ctx.r17.u32 + 464, ctx.r18.u32);
	// b 0x82dcdc14
	goto loc_82DCDC14;
loc_82DCDC10:
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
loc_82DCDC14:
	// lbz r11,3(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 3);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82dcdc30
	if (ctx.cr6.eq) goto loc_82DCDC30;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
	// bne cr6,0x82dcdc34
	if (!ctx.cr6.eq) goto loc_82DCDC34;
loc_82DCDC30:
	// mr r10,r15
	ctx.r10.u64 = ctx.r15.u64;
loc_82DCDC34:
	// lbz r11,1(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 1);
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdc5c
	if (ctx.cr6.eq) goto loc_82DCDC5C;
	// clrlwi r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dcdc5c
	if (!ctx.cr6.eq) goto loc_82DCDC5C;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,608(r31)
	PPC_STORE_U8(ctx.r31.u32 + 608, ctx.r11.u8);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DCDC5C:
	// lbz r11,0(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdc88
	if (ctx.cr6.eq) goto loc_82DCDC88;
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// beq cr6,0x82dcdc88
	if (ctx.cr6.eq) goto loc_82DCDC88;
	// clrlwi r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dcdc88
	if (!ctx.cr6.eq) goto loc_82DCDC88;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,609(r31)
	PPC_STORE_U8(ctx.r31.u32 + 609, ctx.r11.u8);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DCDC88:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1292(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1292);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dcdcac
	if (ctx.cr6.lt) goto loc_82DCDCAC;
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// mr r23,r16
	ctx.r23.u64 = ctx.r16.u64;
	// mr r21,r18
	ctx.r21.u64 = ctx.r18.u64;
	// stw r11,0(r18)
	PPC_STORE_U32(ctx.r18.u32 + 0, ctx.r11.u32);
	// b 0x82dcdcfc
	goto loc_82DCDCFC;
loc_82DCDCAC:
	// lwz r10,1300(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r23,r11,r10
	ctx.r23.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,609(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// add r11,r11,r23
	ctx.r11.u64 = ctx.r11.u64 + ctx.r23.u64;
	// lbz r11,800(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 800);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82dcdcd4
	if (ctx.cr6.lt) goto loc_82DCDCD4;
	// mr r21,r18
	ctx.r21.u64 = ctx.r18.u64;
	// b 0x82dcdce8
	goto loc_82DCDCE8;
loc_82DCDCD4:
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r23
	ctx.r11.u64 = ctx.r11.u64 + ctx.r23.u64;
	// addi r21,r11,32
	ctx.r21.s64 = ctx.r11.s64 + 32;
loc_82DCDCE8:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcdcfc
	if (!ctx.cr6.eq) goto loc_82DCDCFC;
	// stw r21,464(r9)
	PPC_STORE_U32(ctx.r9.u32 + 464, ctx.r21.u32);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DCDCFC:
	// lbz r11,616(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 616);
	// lwz r29,484(r9)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 484);
	// lwz r28,480(r9)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 480);
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// lwz r27,488(r9)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + 488);
	// bne cr6,0x82dcdd30
	if (!ctx.cr6.eq) goto loc_82DCDD30;
	// lbz r11,3(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 3);
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82dcdd30
	if (ctx.cr6.eq) goto loc_82DCDD30;
	// lwz r11,492(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 492);
	// rotlwi r10,r29,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r29.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,484(r9)
	PPC_STORE_U32(ctx.r9.u32 + 484, ctx.r11.u32);
loc_82DCDD30:
	// lbz r11,3(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 3);
	// stb r11,616(r31)
	PPC_STORE_U8(ctx.r31.u32 + 616, ctx.r11.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r20,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r20.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stb r20,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r20.u8);
	// lbz r11,0(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcde1c
	if (ctx.cr6.eq) goto loc_82DCDE1C;
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// beq cr6,0x82dcde1c
	if (ctx.cr6.eq) goto loc_82DCDE1C;
	// clrlwi r30,r8,24
	ctx.r30.u64 = ctx.r8.u32 & 0xFF;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dcdd74
	if (ctx.cr6.eq) goto loc_82DCDD74;
	// cmplw cr6,r5,r17
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r17.u32, ctx.xer);
	// bne cr6,0x82dcdd8c
	if (!ctx.cr6.eq) goto loc_82DCDD8C;
loc_82DCDD74:
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82dcced8
	ctx.lr = 0x82DCDD88;
	sub_82DCCED8(ctx, base);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DCDD8C:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82dcdd9c
	if (!ctx.cr6.eq) goto loc_82DCDD9C;
	// stw r17,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r17.u32);
	// stw r18,464(r17)
	PPC_STORE_U32(ctx.r17.u32 + 464, ctx.r18.u32);
loc_82DCDD9C:
	// lbz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r22.u32 + 0);
	// addi r6,r31,612
	ctx.r6.s64 = ctx.r31.s64 + 612;
	// lwz r11,20(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 20);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// stb r11,611(r31)
	PPC_STORE_U8(ctx.r31.u32 + 611, ctx.r11.u8);
	// lhz r10,2034(r24)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r24.u32 + 2034);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcddec
	if (ctx.cr6.eq) goto loc_82DCDDEC;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// lwz r10,24(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 24);
	// subfic r11,r11,120
	ctx.xer.ca = ctx.r11.u32 <= 120;
	ctx.r11.s64 = 120 - ctx.r11.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// b 0x82dcddfc
	goto loc_82DCDDFC;
loc_82DCDDEC:
	// clrlwi r4,r11,24
	ctx.r4.u64 = ctx.r11.u32 & 0xFF;
	// lwz r5,24(r21)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r21.u32 + 24);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82dcd8d8
	ctx.lr = 0x82DCDDFC;
	sub_82DCD8D8(ctx, base);
loc_82DCDDFC:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dcde10
	if (!ctx.cr6.eq) goto loc_82DCDE10;
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
loc_82DCDE10:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r10,8
	ctx.r10.s64 = 8;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DCDE1C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// stw r20,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r20.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82dcd938
	ctx.lr = 0x82DCDE60;
	sub_82DCD938(ctx, base);
	// lbz r11,3(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 3);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// bgt cr6,0x82dce69c
	if (ctx.cr6.gt) goto loc_82DCE69C;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-8568
	ctx.r12.s64 = ctx.r12.s64 + -8568;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCDF0C;
	case 1:
		goto loc_82DCDF20;
	case 2:
		goto loc_82DCDF34;
	case 3:
		goto loc_82DCDFAC;
	case 4:
		goto loc_82DCDF70;
	case 5:
		goto loc_82DCDFD8;
	case 6:
		goto loc_82DCDFF4;
	case 7:
		goto loc_82DCE018;
	case 8:
		goto loc_82DCE038;
	case 9:
		goto loc_82DCE094;
	case 10:
		goto loc_82DCE0A8;
	case 11:
		goto loc_82DCE0D4;
	case 12:
		goto loc_82DCE0F4;
	case 13:
		goto loc_82DCE14C;
	case 14:
		goto loc_82DCE3D8;
	case 15:
		goto loc_82DCE400;
	case 16:
		goto loc_82DCE428;
	case 17:
		goto loc_82DCE69C;
	case 18:
		goto loc_82DCE69C;
	case 19:
		goto loc_82DCE69C;
	case 20:
		goto loc_82DCE43C;
	case 21:
		goto loc_82DCE69C;
	case 22:
		goto loc_82DCE69C;
	case 23:
		goto loc_82DCE69C;
	case 24:
		goto loc_82DCE588;
	case 25:
		goto loc_82DCE69C;
	case 26:
		goto loc_82DCE5AC;
	case 27:
		goto loc_82DCE69C;
	case 28:
		goto loc_82DCE5C4;
	case 29:
		goto loc_82DCE69C;
	case 30:
		goto loc_82DCE69C;
	case 31:
		goto loc_82DCE69C;
	case 32:
		goto loc_82DCE640;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-8436(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8436);
	// lwz r22,-8416(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8416);
	// lwz r22,-8396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8396);
	// lwz r22,-8276(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8276);
	// lwz r22,-8336(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8336);
	// lwz r22,-8232(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8232);
	// lwz r22,-8204(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8204);
	// lwz r22,-8168(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8168);
	// lwz r22,-8136(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8136);
	// lwz r22,-8044(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8044);
	// lwz r22,-8024(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8024);
	// lwz r22,-7980(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7980);
	// lwz r22,-7948(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7948);
	// lwz r22,-7860(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7860);
	// lwz r22,-7208(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7208);
	// lwz r22,-7168(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7168);
	// lwz r22,-7128(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7128);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-7108(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7108);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6776(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6776);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6740(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6740);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6716);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-6592(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6592);
loc_82DCDF0C:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r11,646(r31)
	PPC_STORE_U8(ctx.r31.u32 + 646, ctx.r11.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCDF20:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r11,645(r31)
	PPC_STORE_U8(ctx.r31.u32 + 645, ctx.r11.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCDF34:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdf44
	if (ctx.cr6.eq) goto loc_82DCDF44;
	// stb r11,660(r31)
	PPC_STORE_U8(ctx.r31.u32 + 660, ctx.r11.u8);
loc_82DCDF44:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCDF70:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdf88
	if (ctx.cr6.eq) goto loc_82DCDF88;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
loc_82DCDF88:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCDFAC:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdfbc
	if (ctx.cr6.eq) goto loc_82DCDFBC;
	// stb r25,663(r31)
	PPC_STORE_U8(ctx.r31.u32 + 663, ctx.r25.u8);
loc_82DCDFBC:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdfcc
	if (ctx.cr6.eq) goto loc_82DCDFCC;
	// stb r26,664(r31)
	PPC_STORE_U8(ctx.r31.u32 + 664, ctx.r26.u8);
loc_82DCDFCC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcd228
	ctx.lr = 0x82DCDFD4;
	sub_82DCD228(ctx, base);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCDFD8:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcdfe8
	if (ctx.cr6.eq) goto loc_82DCDFE8;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
loc_82DCDFE8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcd228
	ctx.lr = 0x82DCDFF0;
	sub_82DCD228(ctx, base);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCDFF4:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce004
	if (ctx.cr6.eq) goto loc_82DCE004;
	// stb r25,667(r31)
	PPC_STORE_U8(ctx.r31.u32 + 667, ctx.r25.u8);
loc_82DCE004:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r26,668(r31)
	PPC_STORE_U8(ctx.r31.u32 + 668, ctx.r26.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE018:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE038:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce048
	if (ctx.cr6.eq) goto loc_82DCE048;
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
loc_82DCE048:
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,16(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 16);
	// lwz r9,12(r21)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// rlwinm r11,r11,8,0,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFFFFFF00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dce088
	if (ctx.cr6.lt) goto loc_82DCE088;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE088:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,504(r10)
	PPC_STORE_U32(ctx.r10.u32 + 504, ctx.r11.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE094:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE0A8:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// lwz r10,1280(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1280);
	// stw r20,2068(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2068, ctx.r20.u32);
	// stw r11,2072(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2072, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dce0cc
	if (ctx.cr6.lt) goto loc_82DCE0CC;
	// stw r20,2072(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2072, ctx.r20.u32);
	// stb r15,2037(r24)
	PPC_STORE_U8(ctx.r24.u32 + 2037, ctx.r15.u8);
loc_82DCE0CC:
	// stb r15,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r15.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE0D4:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE0F4:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,63
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 63, ctx.xer);
	// stw r11,2068(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2068, ctx.r11.u32);
	// ble cr6,0x82dce11c
	if (!ctx.cr6.gt) goto loc_82DCE11C;
	// stw r20,2068(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2068, ctx.r20.u32);
loc_82DCE11C:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dce134
	if (!ctx.cr6.eq) goto loc_82DCE134;
	// lwz r11,2056(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2056);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,2072(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2072, ctx.r11.u32);
loc_82DCE134:
	// lwz r11,2072(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2072);
	// lwz r10,1280(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1280);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dce69c
	if (ctx.cr6.lt) goto loc_82DCE69C;
	// stw r20,2072(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2072, ctx.r20.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE14C:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,13
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 13, ctx.xer);
	// bgt cr6,0x82dce69c
	if (ctx.cr6.gt) goto loc_82DCE69C;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-7820
	ctx.r12.s64 = ctx.r12.s64 + -7820;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCE1AC;
	case 1:
		goto loc_82DCE1D4;
	case 2:
		goto loc_82DCE69C;
	case 3:
		goto loc_82DCE1F0;
	case 4:
		goto loc_82DCE208;
	case 5:
		goto loc_82DCE214;
	case 6:
		goto loc_82DCE2A0;
	case 7:
		goto loc_82DCE2B0;
	case 8:
		goto loc_82DCE69C;
	case 9:
		goto loc_82DCE2D0;
	case 10:
		goto loc_82DCE31C;
	case 11:
		goto loc_82DCE69C;
	case 12:
		goto loc_82DCE368;
	case 13:
		goto loc_82DCE3C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-7764(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7764);
	// lwz r22,-7724(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7724);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-7696(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7696);
	// lwz r22,-7672(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7672);
	// lwz r22,-7660(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7660);
	// lwz r22,-7520(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7520);
	// lwz r22,-7504(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7504);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-7472(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7472);
	// lwz r22,-7396(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7396);
	// lwz r22,-6500(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -6500);
	// lwz r22,-7320(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7320);
	// lwz r22,-7228(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -7228);
loc_82DCE1AC:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce1bc
	if (ctx.cr6.eq) goto loc_82DCE1BC;
	// stb r26,700(r31)
	PPC_STORE_U8(ctx.r31.u32 + 700, ctx.r26.u8);
loc_82DCE1BC:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,700(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 700);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// b 0x82dce698
	goto loc_82DCE698;
loc_82DCE1D4:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce1e4
	if (ctx.cr6.eq) goto loc_82DCE1E4;
	// stb r26,701(r31)
	PPC_STORE_U8(ctx.r31.u32 + 701, ctx.r26.u8);
loc_82DCE1E4:
	// lbz r10,701(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 701);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// b 0x82dce68c
	goto loc_82DCE68C;
loc_82DCE1F0:
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stb r11,694(r31)
	PPC_STORE_U8(ctx.r31.u32 + 694, ctx.r11.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE208:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// stw r11,24(r21)
	PPC_STORE_U32(ctx.r21.u32 + 24, ctx.r11.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE214:
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dce22c
	if (!ctx.cr6.eq) goto loc_82DCE22C;
	// lwz r11,2052(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2052);
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE22C:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dce240
	if (!ctx.cr6.eq) goto loc_82DCE240;
	// stw r10,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r10.u32);
	// b 0x82dce248
	goto loc_82DCE248;
loc_82DCE240:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r11.u32);
loc_82DCE248:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,496(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 496);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,2068(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2068, ctx.r11.u32);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,2052(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dce69c
	if (ctx.cr6.gt) goto loc_82DCE69C;
loc_82DCE278:
	// lwz r10,2056(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2056);
	// lwz r9,496(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 496);
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stbx r20,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + ctx.r11.u32, ctx.r20.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,2052(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dce278
	if (!ctx.cr6.gt) goto loc_82DCE278;
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE2A0:
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// rlwimi r11,r26,4,20,27
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r26.u32, 4) & 0xFF0) | (ctx.r11.u64 & 0xFFFFFFFFFFFFF00F);
	// stb r11,694(r31)
	PPC_STORE_U8(ctx.r31.u32 + 694, ctx.r11.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE2B0:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r11,r26,4,20,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 4) & 0xFF0;
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE2D0:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce2e0
	if (ctx.cr6.eq) goto loc_82DCE2E0;
	// stb r26,699(r31)
	PPC_STORE_U8(ctx.r31.u32 + 699, ctx.r26.u8);
loc_82DCE2E0:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,699(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 699);
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dce30c
	if (!ctx.cr6.gt) goto loc_82DCE30C;
	// stw r14,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r14.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DCE30C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE31C:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce32c
	if (ctx.cr6.eq) goto loc_82DCE32C;
	// stb r26,699(r31)
	PPC_STORE_U8(ctx.r31.u32 + 699, ctx.r26.u8);
loc_82DCE32C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,699(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 699);
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dce358
	if (!ctx.cr6.lt) goto loc_82DCE358;
	// stw r20,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r20.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DCE358:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE368:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r29,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r29.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r28,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r28.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r27,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r27.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,253
	ctx.r10.u64 = ctx.r10.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,251
	ctx.r10.u64 = ctx.r10.u64 & 251;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE3C4:
	// lwz r11,2044(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2044);
	// clrlwi r10,r26,24
	ctx.r10.u64 = ctx.r26.u32 & 0xFF;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,2060(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2060, ctx.r11.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE3D8:
	// lbz r4,4(r22)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r4,32
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 32, ctx.xer);
	// bge cr6,0x82dce3f4
	if (!ctx.cr6.lt) goto loc_82DCE3F4;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stw r4,2044(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2044, ctx.r4.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE3F4:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82e02ae0
	ctx.lr = 0x82DCE3FC;
	sub_82E02AE0(ctx, base);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE400:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,2028(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2028, ctx.r11.u32);
	// ble cr6,0x82dce414
	if (!ctx.cr6.gt) goto loc_82DCE414;
	// stw r14,2028(r24)
	PPC_STORE_U32(ctx.r24.u32 + 2028, ctx.r14.u32);
loc_82DCE414:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE428:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r11,2032(r24)
	PPC_STORE_U8(ctx.r24.u32 + 2032, ctx.r11.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE43C:
	// lbz r11,896(r23)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r23.u32 + 896);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// lbz r9,4(r22)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// lhz r8,902(r23)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r23.u32 + 902);
	// addi r10,r23,902
	ctx.r10.s64 = ctx.r23.s64 + 902;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x82dce484
	if (!ctx.cr6.gt) goto loc_82DCE484;
	// lbz r8,897(r23)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r23.u32 + 897);
loc_82DCE468:
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82dce484
	if (!ctx.cr6.lt) goto loc_82DCE484;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// bgt cr6,0x82dce468
	if (ctx.cr6.gt) goto loc_82DCE468;
loc_82DCE484:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,520(r10)
	PPC_STORE_U32(ctx.r10.u32 + 520, ctx.r11.u32);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,897(r23)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r23.u32 + 897);
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// lwz r8,520(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 520);
	// cmpw cr6,r8,r7
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82dce4c0
	if (ctx.cr6.lt) goto loc_82DCE4C0;
	// addi r11,r10,224
	ctx.r11.s64 = ctx.r10.s64 + 224;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lhzx r11,r11,r23
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r23.u32);
	// stw r11,528(r9)
	PPC_STORE_U32(ctx.r9.u32 + 528, ctx.r11.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stb r15,536(r11)
	PPC_STORE_U8(ctx.r11.u32 + 536, ctx.r15.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE4C0:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stb r20,536(r9)
	PPC_STORE_U8(ctx.r9.u32 + 536, ctx.r20.u8);
	// addi r11,r11,225
	ctx.r11.s64 = ctx.r11.s64 + 225;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r10,r10,r23
	ctx.r10.u64 = ctx.r10.u64 + ctx.r23.u64;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// stw r11,516(r9)
	PPC_STORE_U32(ctx.r9.u32 + 516, ctx.r11.u32);
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lhz r9,898(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 898);
	// lwz r11,520(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 520);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lhzx r11,r8,r23
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + ctx.r23.u32);
	// rotlwi r8,r11,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r11.u32, 16);
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r23
	ctx.r11.u64 = ctx.r11.u64 + ctx.r23.u64;
	// lhz r11,898(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 898);
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dce544
	if (ctx.cr6.eq) goto loc_82DCE544;
	// addi r10,r10,225
	ctx.r10.s64 = ctx.r10.s64 + 225;
	// twllei r11,0
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lhzx r10,r10,r23
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r23.u32);
	// rotlwi r10,r10,16
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 16);
	// subf r6,r8,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r8.s64;
	// rotlwi r10,r6,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r6.u32, 1);
	// divw r6,r6,r11
	ctx.r6.s32 = ctx.r6.s32 / ctx.r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// twlgei r11,-1
	// stw r6,532(r7)
	PPC_STORE_U32(ctx.r7.u32 + 532, ctx.r6.u32);
	// b 0x82dce548
	goto loc_82DCE548;
loc_82DCE544:
	// stw r20,532(r7)
	PPC_STORE_U32(ctx.r7.u32 + 532, ctx.r20.u32);
loc_82DCE548:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,516(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 516);
	// lwz r7,532(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 532);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r10,524(r11)
	PPC_STORE_U32(ctx.r11.u32 + 524, ctx.r10.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lhz r10,524(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 524);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// stw r10,528(r11)
	PPC_STORE_U32(ctx.r11.u32 + 528, ctx.r10.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,520(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 520);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,520(r11)
	PPC_STORE_U32(ctx.r11.u32 + 520, ctx.r10.u32);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE588:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r11,650(r31)
	PPC_STORE_U8(ctx.r31.u32 + 650, ctx.r11.u8);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE5AC:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce69c
	if (ctx.cr6.eq) goto loc_82DCE69C;
	// stb r25,651(r31)
	PPC_STORE_U8(ctx.r31.u32 + 651, ctx.r25.u8);
	// stb r26,652(r31)
	PPC_STORE_U8(ctx.r31.u32 + 652, ctx.r26.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE5C4:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce5e0
	if (ctx.cr6.eq) goto loc_82DCE5E0;
	// addi r10,r25,1
	ctx.r10.s64 = ctx.r25.s64 + 1;
	// addi r11,r26,1
	ctx.r11.s64 = ctx.r26.s64 + 1;
	// stb r10,679(r31)
	PPC_STORE_U8(ctx.r31.u32 + 679, ctx.r10.u8);
	// stb r11,680(r31)
	PPC_STORE_U8(ctx.r31.u32 + 680, ctx.r11.u8);
loc_82DCE5E0:
	// lbz r11,678(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// lbz r10,679(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dce600
	if (ctx.cr6.lt) goto loc_82DCE600;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// neg r10,r10
	ctx.r10.s64 = -ctx.r10.s64;
	// stw r10,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r10.u32);
loc_82DCE600:
	// lbz r11,678(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// lbz r9,679(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r10,680(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 680);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// stb r11,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r11.u8);
	// blt cr6,0x82dce62c
	if (ctx.cr6.lt) goto loc_82DCE62C;
	// stb r20,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r20.u8);
loc_82DCE62C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dce69c
	goto loc_82DCE69C;
loc_82DCE640:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82dce670
	if (!ctx.cr6.eq) goto loc_82DCE670;
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce65c
	if (ctx.cr6.eq) goto loc_82DCE65C;
	// stb r26,648(r31)
	PPC_STORE_U8(ctx.r31.u32 + 648, ctx.r26.u8);
loc_82DCE65C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbz r10,648(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 648);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// b 0x82dce698
	goto loc_82DCE698;
loc_82DCE670:
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bne cr6,0x82dce69c
	if (!ctx.cr6.eq) goto loc_82DCE69C;
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce688
	if (ctx.cr6.eq) goto loc_82DCE688;
	// stb r26,647(r31)
	PPC_STORE_U8(ctx.r31.u32 + 647, ctx.r26.u8);
loc_82DCE688:
	// lbz r10,647(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 647);
loc_82DCE68C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82DCE698:
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
loc_82DCE69C:
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcd5e8
	ctx.lr = 0x82DCE6A8;
	sub_82DCD5E8(ctx, base);
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82dccf40
	ctx.lr = 0x82DCE6BC;
	sub_82DCCF40(ctx, base);
	// lwz r11,756(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 756);
	// addi r19,r19,1
	ctx.r19.s64 = ctx.r19.s64 + 1;
	// addi r22,r22,5
	ctx.r22.s64 = ctx.r22.s64 + 5;
	// cmpw cr6,r19,r11
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcdbbc
	if (ctx.cr6.lt) goto loc_82DCDBBC;
loc_82DCE6D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCE6DC"))) PPC_WEAK_FUNC(sub_82DCE6DC);
PPC_FUNC_IMPL(__imp__sub_82DCE6DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCE6E0"))) PPC_WEAK_FUNC(sub_82DCE6E0);
PPC_FUNC_IMPL(__imp__sub_82DCE6E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DCE6E8;
	__savegprlr_14(ctx, base);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// lwz r11,2056(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2056);
	// lwz r9,488(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 488);
	// add r11,r11,r26
	ctx.r11.u64 = ctx.r11.u64 + ctx.r26.u64;
	// lwz r8,2052(r26)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2052);
	// lwz r10,756(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 756);
	// lbz r11,500(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 500);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mullw r11,r8,r10
	ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// add r22,r9,r11
	ctx.r22.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82dcf298
	if (ctx.cr6.eq) goto loc_82DCF298;
	// li r24,0
	ctx.r24.s64 = 0;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// mr r19,r24
	ctx.r19.u64 = ctx.r24.u64;
	// ble cr6,0x82dcf298
	if (!ctx.cr6.gt) goto loc_82DCF298;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// li r14,2
	ctx.r14.s64 = 2;
	// addi r20,r11,-17952
	ctx.r20.s64 = ctx.r11.s64 + -17952;
	// lis r11,-31891
	ctx.r11.s64 = -2090008576;
	// li r15,4
	ctx.r15.s64 = 4;
	// addi r17,r11,26712
	ctx.r17.s64 = ctx.r11.s64 + 26712;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// li r18,64
	ctx.r18.s64 = 64;
	// addi r16,r11,-17904
	ctx.r16.s64 = ctx.r11.s64 + -17904;
	// lis r11,21845
	ctx.r11.s64 = 1431633920;
	// ori r21,r11,21846
	ctx.r21.u64 = ctx.r11.u64 | 21846;
loc_82DCE768:
	// addi r11,r19,190
	ctx.r11.s64 = ctx.r19.s64 + 190;
	// stw r24,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r24.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r26
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r26.u32);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82dce794
	if (!ctx.cr6.eq) goto loc_82DCE794;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq cr6,0x82dce798
	if (ctx.cr6.eq) goto loc_82DCE798;
loc_82DCE794:
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82DCE798:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// mr r9,r16
	ctx.r9.u64 = ctx.r16.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dce7ac
	if (!ctx.cr6.eq) goto loc_82DCE7AC;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
loc_82DCE7AC:
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// lbz r11,608(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// lwz r10,1292(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 1292);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dce7d0
	if (ctx.cr6.lt) goto loc_82DCE7D0;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// mr r25,r17
	ctx.r25.u64 = ctx.r17.u64;
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
	// b 0x82dce80c
	goto loc_82DCE80C;
loc_82DCE7D0:
	// lwz r10,1300(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 1300);
	// mulli r11,r11,1428
	ctx.r11.s64 = ctx.r11.s64 * 1428;
	// add r25,r11,r10
	ctx.r25.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,609(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 609);
	// add r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 + ctx.r25.u64;
	// lbz r11,800(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 800);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// bge cr6,0x82dce80c
	if (!ctx.cr6.lt) goto loc_82DCE80C;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 + ctx.r25.u64;
	// addi r23,r11,32
	ctx.r23.s64 = ctx.r11.s64 + 32;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// bne cr6,0x82dce810
	if (!ctx.cr6.eq) goto loc_82DCE810;
loc_82DCE80C:
	// mr r23,r20
	ctx.r23.u64 = ctx.r20.u64;
loc_82DCE810:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// lbz r29,3(r22)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r22.u32 + 3);
	// stw r24,492(r9)
	PPC_STORE_U32(ctx.r9.u32 + 492, ctx.r24.u32);
	// rlwinm r28,r11,28,4,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r27,r11,28
	ctx.r27.u64 = ctx.r11.u32 & 0xF;
	// stw r24,496(r10)
	PPC_STORE_U32(ctx.r10.u32 + 496, ctx.r24.u32);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r24,476(r10)
	PPC_STORE_U8(ctx.r10.u32 + 476, ctx.r24.u8);
	// lbz r8,896(r25)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r25.u32 + 896);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r11,r8,31
	ctx.r11.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce884
	if (ctx.cr6.eq) goto loc_82DCE884;
	// lbz r11,536(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 536);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dce884
	if (!ctx.cr6.eq) goto loc_82DCE884;
	// lbz r11,978(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 978);
	// addi r7,r25,898
	ctx.r7.s64 = ctx.r25.s64 + 898;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lbz r10,980(r25)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r25.u32 + 980);
	// addi r4,r31,516
	ctx.r4.s64 = ctx.r31.s64 + 516;
	// lbz r9,979(r25)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r25.u32 + 979);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lbz r6,897(r25)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r25.u32 + 897);
	// stb r14,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r14.u8);
	// stb r11,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r11.u8);
	// bl 0x82dcd448
	ctx.lr = 0x82DCE880;
	sub_82DCD448(ctx, base);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCE884:
	// lbz r8,983(r25)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r25.u32 + 983);
	// clrlwi r11,r8,31
	ctx.r11.u64 = ctx.r8.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce8d0
	if (ctx.cr6.eq) goto loc_82DCE8D0;
	// lbz r11,560(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 560);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dce8d0
	if (!ctx.cr6.eq) goto loc_82DCE8D0;
	// lbz r11,1066(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 1066);
	// addi r7,r25,986
	ctx.r7.s64 = ctx.r25.s64 + 986;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lbz r10,1068(r25)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r25.u32 + 1068);
	// addi r4,r31,540
	ctx.r4.s64 = ctx.r31.s64 + 540;
	// lbz r9,1067(r25)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r25.u32 + 1067);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lbz r6,984(r25)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r25.u32 + 984);
	// stb r15,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r15.u8);
	// stb r11,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r11.u8);
	// bl 0x82dcd448
	ctx.lr = 0x82DCE8CC;
	sub_82DCD448(ctx, base);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCE8D0:
	// lbz r11,600(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 600);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dce914
	if (ctx.cr6.eq) goto loc_82DCE914;
	// lwz r10,588(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// lhz r11,1164(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 1164);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r11,588(r31)
	PPC_STORE_U32(ctx.r31.u32 + 588, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,588(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 588);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dce904
	if (!ctx.cr6.lt) goto loc_82DCE904;
	// stw r24,588(r11)
	PPC_STORE_U32(ctx.r11.u32 + 588, ctx.r24.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCE904:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCE914:
	// lbz r11,2(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 2);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// addi r10,r10,-6
	ctx.r10.s64 = ctx.r10.s64 + -6;
	// cmplwi cr6,r10,9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 9, ctx.xer);
	// bgt cr6,0x82dcea68
	if (ctx.cr6.gt) goto loc_82DCEA68;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-5824
	ctx.r12.s64 = ctx.r12.s64 + -5824;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DCE968;
	case 1:
		goto loc_82DCE9A0;
	case 2:
		goto loc_82DCEA68;
	case 3:
		goto loc_82DCEA68;
	case 4:
		goto loc_82DCEA68;
	case 5:
		goto loc_82DCE9D8;
	case 6:
		goto loc_82DCEA68;
	case 7:
		goto loc_82DCEA14;
	case 8:
		goto loc_82DCEA38;
	case 9:
		goto loc_82DCEA5C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5784(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5784);
	// lwz r22,-5728(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5728);
	// lwz r22,-5528(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5528);
	// lwz r22,-5528(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5528);
	// lwz r22,-5528(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5528);
	// lwz r22,-5672(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5672);
	// lwz r22,-5528(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5528);
	// lwz r22,-5612(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5612);
	// lwz r22,-5576(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5576);
	// lwz r22,-5540(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5540);
loc_82DCE968:
	// lwz r10,484(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r11,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dce990
	if (!ctx.cr6.lt) goto loc_82DCE990;
	// stw r24,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r24.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCE990:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dcea64
	goto loc_82DCEA64;
loc_82DCE9A0:
	// lwz r10,484(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dce9c8
	if (!ctx.cr6.gt) goto loc_82DCE9C8;
	// stw r18,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r18.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCE9C8:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dcea64
	goto loc_82DCEA64;
loc_82DCE9D8:
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stb r11,664(r30)
	PPC_STORE_U8(ctx.r30.u32 + 664, ctx.r11.u8);
	// bl 0x82dcd228
	ctx.lr = 0x82DCE9E8;
	sub_82DCD228(ctx, base);
	// lbz r10,662(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 662);
	// lbz r9,663(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r30)
	PPC_STORE_U8(ctx.r30.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dcea64
	if (!ctx.cr6.gt) goto loc_82DCEA64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r30)
	PPC_STORE_U8(ctx.r30.u32 + 662, ctx.r11.u8);
	// b 0x82dcea64
	goto loc_82DCEA64;
loc_82DCEA14:
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dcea64
	goto loc_82DCEA64;
loc_82DCEA38:
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dcea64
	goto loc_82DCEA64;
loc_82DCEA5C:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dcd1b8
	ctx.lr = 0x82DCEA64;
	sub_82DCD1B8(ctx, base);
loc_82DCEA64:
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCEA68:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 29, ctx.xer);
	// bgt cr6,0x82dcf264
	if (ctx.cr6.gt) goto loc_82DCF264;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-5492
	ctx.r12.s64 = ctx.r12.s64 + -5492;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCEB04;
	case 1:
		goto loc_82DCEBFC;
	case 2:
		goto loc_82DCEC40;
	case 3:
		goto loc_82DCEC6C;
	case 4:
		goto loc_82DCEC7C;
	case 5:
		goto loc_82DCECB0;
	case 6:
		goto loc_82DCED30;
	case 7:
		goto loc_82DCEDA0;
	case 8:
		goto loc_82DCF264;
	case 9:
		goto loc_82DCF264;
	case 10:
		goto loc_82DCEDAC;
	case 11:
		goto loc_82DCF264;
	case 12:
		goto loc_82DCF264;
	case 13:
		goto loc_82DCF264;
	case 14:
		goto loc_82DCEE38;
	case 15:
		goto loc_82DCF264;
	case 16:
		goto loc_82DCF264;
	case 17:
		goto loc_82DCF124;
	case 18:
		goto loc_82DCF264;
	case 19:
		goto loc_82DCF264;
	case 20:
		goto loc_82DCF264;
	case 21:
		goto loc_82DCF264;
	case 22:
		goto loc_82DCF264;
	case 23:
		goto loc_82DCF264;
	case 24:
		goto loc_82DCF264;
	case 25:
		goto loc_82DCF17C;
	case 26:
		goto loc_82DCF264;
	case 27:
		goto loc_82DCEF7C;
	case 28:
		goto loc_82DCF264;
	case 29:
		goto loc_82DCF20C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5372(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5372);
	// lwz r22,-5124(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5124);
	// lwz r22,-5056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5056);
	// lwz r22,-5012(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -5012);
	// lwz r22,-4996(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4996);
	// lwz r22,-4944(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4944);
	// lwz r22,-4816(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4816);
	// lwz r22,-4704(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4704);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-4692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4692);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-4552(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4552);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3804(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3804);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3716);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-4228(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4228);
	// lwz r22,-3484(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3484);
	// lwz r22,-3572(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3572);
loc_82DCEB04:
	// lbz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r22.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf264
	if (ctx.cr6.eq) goto loc_82DCF264;
	// lwz r11,2040(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2040);
	// mulhw r10,r11,r21
	ctx.r10.s64 = (int64_t(ctx.r11.s32) * int64_t(ctx.r21.s32)) >> 32;
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82dceb90
	if (ctx.cr6.eq) goto loc_82DCEB90;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82dcebec
	if (!ctx.cr6.eq) goto loc_82DCEBEC;
	// lhz r11,2034(r26)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r26.u32 + 2034);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// beq cr6,0x82dceb5c
	if (ctx.cr6.eq) goto loc_82DCEB5C;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// b 0x82dcebe4
	goto loc_82DCEBE4;
loc_82DCEB5C:
	// lbz r7,611(r30)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r30.u32 + 611);
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r23.u32 + 24);
	// add r4,r11,r7
	ctx.r4.u64 = ctx.r11.u64 + ctx.r7.u64;
	// bl 0x82dcd8d8
	ctx.lr = 0x82DCEB74;
	sub_82DCD8D8(ctx, base);
	// addi r6,r1,104
	ctx.r6.s64 = ctx.r1.s64 + 104;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dcd8d8
	ctx.lr = 0x82DCEB84;
	sub_82DCD8D8(ctx, base);
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// b 0x82dcebe0
	goto loc_82DCEBE0;
loc_82DCEB90:
	// lhz r11,2034(r26)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r26.u32 + 2034);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// beq cr6,0x82dcebb0
	if (ctx.cr6.eq) goto loc_82DCEBB0;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// b 0x82dcebe4
	goto loc_82DCEBE4;
loc_82DCEBB0:
	// lbz r7,611(r30)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r30.u32 + 611);
	// addi r6,r1,108
	ctx.r6.s64 = ctx.r1.s64 + 108;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r23.u32 + 24);
	// add r4,r11,r7
	ctx.r4.u64 = ctx.r11.u64 + ctx.r7.u64;
	// bl 0x82dcd8d8
	ctx.lr = 0x82DCEBC8;
	sub_82DCD8D8(ctx, base);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dcd8d8
	ctx.lr = 0x82DCEBD8;
	sub_82DCD8D8(ctx, base);
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82DCEBE0:
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82DCEBE4:
	// stw r11,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCEBEC:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCEBFC:
	// stw r24,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r24.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,646(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 646);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpwi cr6,r10,56
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 56, ctx.xer);
	// bge cr6,0x82dcec34
	if (!ctx.cr6.lt) goto loc_82DCEC34;
	// li r10,56
	ctx.r10.s64 = 56;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCEC34:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// b 0x82dcf260
	goto loc_82DCF260;
loc_82DCEC40:
	// stw r24,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r24.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,645(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 645);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// b 0x82dcf260
	goto loc_82DCF260;
loc_82DCEC6C:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r24,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r24.u32);
	// bl 0x82dcd1b8
	ctx.lr = 0x82DCEC78;
	sub_82DCD1B8(ctx, base);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCEC7C:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dcd228
	ctx.lr = 0x82DCEC84;
	sub_82DCD228(ctx, base);
	// lbz r10,662(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 662);
	// lbz r9,663(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r30)
	PPC_STORE_U8(ctx.r30.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dcf264
	if (!ctx.cr6.gt) goto loc_82DCF264;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r30)
	PPC_STORE_U8(ctx.r30.u32 + 662, ctx.r11.u8);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCECB0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r24,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r24.u32);
	// bl 0x82dcd1b8
	ctx.lr = 0x82DCECBC;
	sub_82DCD1B8(ctx, base);
	// lbz r11,649(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 649);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r9,r11,28
	ctx.r9.u64 = ctx.r11.u32 & 0xF;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcecfc
	if (ctx.cr6.eq) goto loc_82DCECFC;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dcf258
	if (!ctx.cr6.gt) goto loc_82DCF258;
	// stw r18,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r18.u32);
	// b 0x82dcf254
	goto loc_82DCF254;
loc_82DCECFC:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf254
	if (ctx.cr6.eq) goto loc_82DCF254;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dcf258
	if (!ctx.cr6.lt) goto loc_82DCF258;
	// stw r24,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r24.u32);
	// b 0x82dcf254
	goto loc_82DCF254;
loc_82DCED30:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dcd228
	ctx.lr = 0x82DCED38;
	sub_82DCD228(ctx, base);
	// lbz r10,662(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 662);
	// lbz r9,663(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r30)
	PPC_STORE_U8(ctx.r30.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dced60
	if (!ctx.cr6.gt) goto loc_82DCED60;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r30)
	PPC_STORE_U8(ctx.r30.u32 + 662, ctx.r11.u8);
loc_82DCED60:
	// lbz r11,649(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 649);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r9,r11,28
	ctx.r9.u64 = ctx.r11.u32 & 0xF;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcecfc
	if (ctx.cr6.eq) goto loc_82DCECFC;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dcf258
	if (!ctx.cr6.gt) goto loc_82DCF258;
	// stw r18,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r18.u32);
	// b 0x82dcf254
	goto loc_82DCF254;
loc_82DCEDA0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dcd328
	ctx.lr = 0x82DCEDA8;
	sub_82DCD328(ctx, base);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCEDAC:
	// lbz r11,649(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 649);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r9,r11,28
	ctx.r9.u64 = ctx.r11.u32 & 0xF;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcedf8
	if (ctx.cr6.eq) goto loc_82DCEDF8;
	// lwz r10,484(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dcee28
	if (!ctx.cr6.gt) goto loc_82DCEE28;
	// stw r18,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r18.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCEDF8:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcee28
	if (ctx.cr6.eq) goto loc_82DCEE28;
	// lwz r10,484(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r11,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dcee28
	if (!ctx.cr6.lt) goto loc_82DCEE28;
	// stw r24,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r24.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCEE28:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCEE38:
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// beq cr6,0x82dcef1c
	if (ctx.cr6.eq) goto loc_82DCEF1C;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82dcef04
	if (ctx.cr6.eq) goto loc_82DCEF04;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82dcf264
	if (!ctx.cr6.eq) goto loc_82DCF264;
	// lwz r11,2040(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2040);
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82dceec8
	if (!ctx.cr6.eq) goto loc_82DCEEC8;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dcced8
	ctx.lr = 0x82DCEE7C;
	sub_82DCCED8(ctx, base);
	// lwz r11,612(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 612);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bl 0x82dcd938
	ctx.lr = 0x82DCEEC4;
	sub_82DCD938(ctx, base);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCEEC8:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// andi. r11,r11,253
	ctx.r11.u64 = ctx.r11.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,251
	ctx.r10.u64 = ctx.r10.u64 & 251;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// b 0x82dcf260
	goto loc_82DCF260;
loc_82DCEF04:
	// lwz r11,2040(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2040);
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82dcf264
	if (!ctx.cr6.eq) goto loc_82DCF264;
	// stw r24,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r24.u32);
	// b 0x82dcf254
	goto loc_82DCF254;
loc_82DCEF1C:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf264
	if (ctx.cr6.eq) goto loc_82DCF264;
	// lwz r9,2040(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2040);
	// twllei r11,0
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / ctx.r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// subf. r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// twlgei r11,-1
	// bne 0x82dcf264
	if (!ctx.cr0.eq) goto loc_82DCF264;
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// b 0x82dcf260
	goto loc_82DCF260;
loc_82DCEF7C:
	// lbz r11,652(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 652);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf264
	if (ctx.cr6.eq) goto loc_82DCF264;
	// lwz r9,2040(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2040);
	// twllei r11,0
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / ctx.r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// subf. r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// twlgei r11,-1
	// bne 0x82dcf264
	if (!ctx.cr0.eq) goto loc_82DCF264;
	// lbz r11,651(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 651);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf108
	if (ctx.cr6.eq) goto loc_82DCF108;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,14
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 14, ctx.xer);
	// bgt cr6,0x82dcf0e0
	if (ctx.cr6.gt) goto loc_82DCF0E0;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-4128
	ctx.r12.s64 = ctx.r12.s64 + -4128;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCF01C;
	case 1:
		goto loc_82DCF028;
	case 2:
		goto loc_82DCF034;
	case 3:
		goto loc_82DCF040;
	case 4:
		goto loc_82DCF04C;
	case 5:
		goto loc_82DCF058;
	case 6:
		goto loc_82DCF070;
	case 7:
		goto loc_82DCF0E0;
	case 8:
		goto loc_82DCF07C;
	case 9:
		goto loc_82DCF088;
	case 10:
		goto loc_82DCF094;
	case 11:
		goto loc_82DCF0A0;
	case 12:
		goto loc_82DCF0AC;
	case 13:
		goto loc_82DCF0B8;
	case 14:
		goto loc_82DCF0D0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-4068(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4068);
	// lwz r22,-4056(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4056);
	// lwz r22,-4044(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4044);
	// lwz r22,-4032(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4032);
	// lwz r22,-4020(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4020);
	// lwz r22,-4008(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -4008);
	// lwz r22,-3984(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3984);
	// lwz r22,-3872(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3872);
	// lwz r22,-3972(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3972);
	// lwz r22,-3960(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3960);
	// lwz r22,-3948(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3948);
	// lwz r22,-3936(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3936);
	// lwz r22,-3924(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3924);
	// lwz r22,-3912(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3912);
	// lwz r22,-3888(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -3888);
loc_82DCF01C:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF028:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF034:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF040:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF04C:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF058:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mulhw r11,r11,r21
	ctx.r11.s64 = (int64_t(ctx.r11.s32) * int64_t(ctx.r21.s32)) >> 32;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF070:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF07C:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF088:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF094:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF0A0:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF0AC:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF0B8:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// b 0x82dcf0d8
	goto loc_82DCF0D8;
loc_82DCF0D0:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DCF0D8:
	// stw r11,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCF0E0:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// ble cr6,0x82dcf0f4
	if (!ctx.cr6.gt) goto loc_82DCF0F4;
	// stw r18,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r18.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCF0F4:
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dcf108
	if (!ctx.cr6.lt) goto loc_82DCF108;
	// stw r24,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r24.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCF108:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// b 0x82dcf260
	goto loc_82DCF260;
loc_82DCF124:
	// lbz r11,2032(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 2032);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r9,r11,28
	ctx.r9.u64 = ctx.r11.u32 & 0xF;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf158
	if (ctx.cr6.eq) goto loc_82DCF158;
	// lwz r10,2028(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2028);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,2028(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2028, ctx.r11.u32);
	// ble cr6,0x82dcf264
	if (!ctx.cr6.gt) goto loc_82DCF264;
	// stw r18,2028(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2028, ctx.r18.u32);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCF158:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf264
	if (ctx.cr6.eq) goto loc_82DCF264;
	// lwz r10,2028(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2028);
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,2028(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2028, ctx.r11.u32);
	// bge 0x82dcf264
	if (!ctx.cr0.lt) goto loc_82DCF264;
	// stw r24,2028(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2028, ctx.r24.u32);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCF17C:
	// lbz r11,650(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 650);
	// rlwinm r10,r11,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r9,r11,28
	ctx.r9.u64 = ctx.r11.u32 & 0xF;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf1cc
	if (ctx.cr6.eq) goto loc_82DCF1CC;
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// ble cr6,0x82dcf1fc
	if (!ctx.cr6.gt) goto loc_82DCF1FC;
	// li r11,255
	ctx.r11.s64 = 255;
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCF1CC:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf1fc
	if (ctx.cr6.eq) goto loc_82DCF1FC;
	// lwz r10,488(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82dcf1fc
	if (!ctx.cr6.lt) goto loc_82DCF1FC;
	// stw r24,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r24.u32);
	// lwz r31,96(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCF1FC:
	// lbz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 476);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 476, ctx.r11.u8);
	// b 0x82dcf264
	goto loc_82DCF264;
loc_82DCF20C:
	// lbz r11,678(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 678);
	// lbz r10,679(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 679);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dcf228
	if (ctx.cr6.lt) goto loc_82DCF228;
	// lwz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
	// stw r11,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r11.u32);
loc_82DCF228:
	// lbz r11,678(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 678);
	// lbz r9,679(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 679);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r10,680(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 680);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// stb r11,678(r30)
	PPC_STORE_U8(ctx.r30.u32 + 678, ctx.r11.u8);
	// blt cr6,0x82dcf254
	if (ctx.cr6.lt) goto loc_82DCF254;
	// stb r24,678(r30)
	PPC_STORE_U8(ctx.r30.u32 + 678, ctx.r24.u8);
loc_82DCF254:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DCF258:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
loc_82DCF260:
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DCF264:
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82dcd5e8
	ctx.lr = 0x82DCF270;
	sub_82DCD5E8(ctx, base);
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82dccf40
	ctx.lr = 0x82DCF284;
	sub_82DCCF40(ctx, base);
	// lwz r11,756(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 756);
	// addi r19,r19,1
	ctx.r19.s64 = ctx.r19.s64 + 1;
	// addi r22,r22,5
	ctx.r22.s64 = ctx.r22.s64 + 5;
	// cmpw cr6,r19,r11
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dce768
	if (ctx.cr6.lt) goto loc_82DCE768;
loc_82DCF298:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCF2A4"))) PPC_WEAK_FUNC(sub_82DCF2A4);
PPC_FUNC_IMPL(__imp__sub_82DCF2A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCF2A8"))) PPC_WEAK_FUNC(sub_82DCF2A8);
PPC_FUNC_IMPL(__imp__sub_82DCF2A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dcf380
	if (!ctx.cr6.eq) goto loc_82DCF380;
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf2f0
	if (ctx.cr6.eq) goto loc_82DCF2F0;
	// lbz r11,2038(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2038);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcf2f0
	if (!ctx.cr6.eq) goto loc_82DCF2F0;
	// bl 0x82e02b60
	ctx.lr = 0x82DCF2EC;
	sub_82E02B60(ctx, base);
	// b 0x82dcf394
	goto loc_82DCF394;
loc_82DCF2F0:
	// lwz r11,2072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2072);
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dcf308
	if (ctx.cr6.lt) goto loc_82DCF308;
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// stw r10,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r10.u32);
loc_82DCF308:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dcf31c
	if (ctx.cr6.lt) goto loc_82DCF31C;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82DCF31C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcdb00
	ctx.lr = 0x82DCF324;
	sub_82DCDB00(ctx, base);
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82dcf394
	if (!ctx.cr6.eq) goto loc_82DCF394;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// lwz r10,2056(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r9,488(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r8,r10,r31
	ctx.r8.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
	// lbz r8,500(r8)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + 500);
	// rotlwi r8,r8,3
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 3);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82dcf394
	if (ctx.cr6.lt) goto loc_82DCF394;
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lwz r10,1280(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1280);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
	// blt cr6,0x82dcf378
	if (ctx.cr6.lt) goto loc_82DCF378;
	// lwz r11,2012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2012);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
loc_82DCF378:
	// stw r30,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r30.u32);
	// b 0x82dcf394
	goto loc_82DCF394;
loc_82DCF380:
	// clrlwi r11,r4,24
	ctx.r11.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf394
	if (ctx.cr6.eq) goto loc_82DCF394;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dce6e0
	ctx.lr = 0x82DCF394;
	sub_82DCE6E0(ctx, base);
loc_82DCF394:
	// lwz r9,2044(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2044);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dcf3c8
	if (ctx.cr6.eq) goto loc_82DCF3C8;
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// lwz r10,2060(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2060);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r11.u32);
	// blt cr6,0x82dcf3d0
	if (ctx.cr6.lt) goto loc_82DCF3D0;
	// stw r30,2060(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2060, ctx.r30.u32);
	// stw r30,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r30.u32);
	// b 0x82dcf3d0
	goto loc_82DCF3D0;
loc_82DCF3C8:
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r11.u8);
loc_82DCF3D0:
	// lwz r10,1136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,1132(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,1136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1136, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCF3FC"))) PPC_WEAK_FUNC(sub_82DCF3FC);
PPC_FUNC_IMPL(__imp__sub_82DCF3FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCF400"))) PPC_WEAK_FUNC(sub_82DCF400);
PPC_FUNC_IMPL(__imp__sub_82DCF400) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DCF408;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DCF414;
	sub_82E02B60(ctx, base);
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// li r29,0
	ctx.r29.s64 = 0;
	// lis r26,-31909
	ctx.r26.s64 = -2091188224;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r27,r11,9544
	ctx.r27.s64 = ctx.r11.s64 + 9544;
	// beq cr6,0x82dcf4c8
	if (ctx.cr6.eq) goto loc_82DCF4C8;
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// mr r28,r29
	ctx.r28.u64 = ctx.r29.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcf4a8
	if (!ctx.cr6.gt) goto loc_82DCF4A8;
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
loc_82DCF444:
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcf494
	if (ctx.cr6.eq) goto loc_82DCF494;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dcf494
	if (ctx.cr6.eq) goto loc_82DCF494;
	// lwzx r11,r30,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCF480;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// lwzx r11,r30,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// stw r29,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r29.u32);
	// lwz r11,2076(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// stwx r29,r30,r11
	PPC_STORE_U32(ctx.r30.u32 + ctx.r11.u32, ctx.r29.u32);
loc_82DCF494:
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcf444
	if (ctx.cr6.lt) goto loc_82DCF444;
loc_82DCF4A8:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3259
	ctx.r6.s64 = 3259;
	// lwz r4,2076(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF4C4;
	sub_82D861B0(ctx, base);
	// stw r29,2076(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2076, ctx.r29.u32);
loc_82DCF4C8:
	// lwz r4,1300(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1300);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcf4f0
	if (ctx.cr6.eq) goto loc_82DCF4F0;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3265
	ctx.r6.s64 = 3265;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF4EC;
	sub_82D861B0(ctx, base);
	// stw r29,1300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1300, ctx.r29.u32);
loc_82DCF4F0:
	// lwz r4,1020(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1020);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcf518
	if (ctx.cr6.eq) goto loc_82DCF518;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3271
	ctx.r6.s64 = 3271;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF514;
	sub_82D861B0(ctx, base);
	// stw r29,1020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1020, ctx.r29.u32);
loc_82DCF518:
	// lwz r3,1024(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1024);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dcf52c
	if (ctx.cr6.eq) goto loc_82DCF52C;
	// bl 0x82da94d0
	ctx.lr = 0x82DCF528;
	sub_82DA94D0(ctx, base);
	// stw r29,1024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1024, ctx.r29.u32);
loc_82DCF52C:
	// lwz r4,1028(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcf554
	if (ctx.cr6.eq) goto loc_82DCF554;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3282
	ctx.r6.s64 = 3282;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF550;
	sub_82D861B0(ctx, base);
	// stw r29,1028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1028, ctx.r29.u32);
loc_82DCF554:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf5e0
	if (ctx.cr6.eq) goto loc_82DCF5E0;
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// mr r28,r29
	ctx.r28.u64 = ctx.r29.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcf5c0
	if (!ctx.cr6.gt) goto loc_82DCF5C0;
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
loc_82DCF574:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcf5ac
	if (ctx.cr6.eq) goto loc_82DCF5AC;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3292
	ctx.r6.s64 = 3292;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF5A0;
	sub_82D861B0(ctx, base);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r29,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r29.u32);
loc_82DCF5AC:
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcf574
	if (ctx.cr6.lt) goto loc_82DCF574;
loc_82DCF5C0:
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3297
	ctx.r6.s64 = 3297;
	// lwz r4,488(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF5DC;
	sub_82D861B0(ctx, base);
	// stw r29,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r29.u32);
loc_82DCF5E0:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// mr r28,r29
	ctx.r28.u64 = ctx.r29.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dcf630
	if (!ctx.cr6.gt) goto loc_82DCF630;
	// addi r30,r31,760
	ctx.r30.s64 = ctx.r31.s64 + 760;
loc_82DCF5F4:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcf61c
	if (ctx.cr6.eq) goto loc_82DCF61C;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3305
	ctx.r6.s64 = 3305;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF618;
	sub_82D861B0(ctx, base);
	// stw r29,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r29.u32);
loc_82DCF61C:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcf5f4
	if (ctx.cr6.lt) goto loc_82DCF5F4;
loc_82DCF630:
	// lwz r4,496(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dcf658
	if (ctx.cr6.eq) goto loc_82DCF658;
	// lwz r11,19872(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3312
	ctx.r6.s64 = 3312;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DCF654;
	sub_82D861B0(ctx, base);
	// stw r29,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r29.u32);
loc_82DCF658:
	// lwz r3,492(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 492);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dcf67c
	if (ctx.cr6.eq) goto loc_82DCF67C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCF678;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r29.u32);
loc_82DCF67C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCF688"))) PPC_WEAK_FUNC(sub_82DCF688);
PPC_FUNC_IMPL(__imp__sub_82DCF688) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DCF690;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,256
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 256, ctx.xer);
	// bne cr6,0x82dcf6bc
	if (!ctx.cr6.eq) goto loc_82DCF6BC;
	// bl 0x82e032f8
	ctx.lr = 0x82DCF6A8;
	sub_82E032F8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r30.u32);
	// stw r30,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DCF6BC:
	// cmplwi cr6,r6,2
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 2, ctx.xer);
	// bne cr6,0x82dcf738
	if (!ctx.cr6.eq) goto loc_82DCF738;
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dcf72c
	if (ctx.cr6.eq) goto loc_82DCF72C;
	// bge cr6,0x82dcf6e4
	if (!ctx.cr6.lt) goto loc_82DCF6E4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e032f8
	ctx.lr = 0x82DCF6E0;
	sub_82E032F8(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
loc_82DCF6E4:
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82dcf708
	if (!ctx.cr6.lt) goto loc_82DCF708;
loc_82DCF6F0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcf2a8
	ctx.lr = 0x82DCF6FC;
	sub_82DCF2A8(ctx, base);
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82dcf6f0
	if (ctx.cr6.lt) goto loc_82DCF6F0;
loc_82DCF708:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf72c
	if (ctx.cr6.eq) goto loc_82DCF72C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lbz r30,2036(r31)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2036);
	// lbz r29,2037(r31)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// bl 0x82e02b60
	ctx.lr = 0x82DCF724;
	sub_82E02B60(ctx, base);
	// stb r30,2036(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2036, ctx.r30.u8);
	// stb r29,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r29.u8);
loc_82DCF72C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DCF738:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCF744"))) PPC_WEAK_FUNC(sub_82DCF744);
PPC_FUNC_IMPL(__imp__sub_82DCF744) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCF748"))) PPC_WEAK_FUNC(sub_82DCF748);
PPC_FUNC_IMPL(__imp__sub_82DCF748) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dcf758
	if (!ctx.cr6.eq) goto loc_82DCF758;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCF758:
	// b 0x82dcf400
	sub_82DCF400(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCF75C"))) PPC_WEAK_FUNC(sub_82DCF75C);
PPC_FUNC_IMPL(__imp__sub_82DCF75C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCF760"))) PPC_WEAK_FUNC(sub_82DCF760);
PPC_FUNC_IMPL(__imp__sub_82DCF760) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dcf770
	if (!ctx.cr6.eq) goto loc_82DCF770;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCF770:
	// b 0x82dcf688
	sub_82DCF688(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCF774"))) PPC_WEAK_FUNC(sub_82DCF774);
PPC_FUNC_IMPL(__imp__sub_82DCF774) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCF778"))) PPC_WEAK_FUNC(sub_82DCF778);
PPC_FUNC_IMPL(__imp__sub_82DCF778) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// bl 0x82e032f8
	ctx.lr = 0x82DCF79C;
	sub_82E032F8(ctx, base);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcf7d4
	if (!ctx.cr6.eq) goto loc_82DCF7D4;
loc_82DCF7A8:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcf2a8
	ctx.lr = 0x82DCF7B4;
	sub_82DCF2A8(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,1132(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// lwz r9,272(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcf7a8
	if (ctx.cr6.eq) goto loc_82DCF7A8;
loc_82DCF7D4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DCF7DC;
	sub_82E02B60(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCF7F4"))) PPC_WEAK_FUNC(sub_82DCF7F4);
PPC_FUNC_IMPL(__imp__sub_82DCF7F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCF7F8"))) PPC_WEAK_FUNC(sub_82DCF7F8);
PPC_FUNC_IMPL(__imp__sub_82DCF7F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DCF800;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r21,r5
	ctx.r21.u64 = ctx.r5.u64;
	// mr r20,r6
	ctx.r20.u64 = ctx.r6.u64;
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r22,4408(r10)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4408);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// beq cr6,0x82dcf964
	if (ctx.cr6.eq) goto loc_82DCF964;
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dcf964
	if (ctx.cr6.gt) goto loc_82DCF964;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-1964
	ctx.r12.s64 = ctx.r12.s64 + -1964;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCF8C0;
	case 1:
		goto loc_82DCF880;
	case 2:
		goto loc_82DCF888;
	case 3:
		goto loc_82DCF890;
	case 4:
		goto loc_82DCF898;
	case 5:
		goto loc_82DCF898;
	case 6:
		goto loc_82DCF8C0;
	case 7:
		goto loc_82DCF8C0;
	case 8:
		goto loc_82DCF8C0;
	case 9:
		goto loc_82DCF8C0;
	case 10:
		goto loc_82DCF8C0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1856(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1856);
	// lwz r22,-1920(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1920);
	// lwz r22,-1912(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1912);
	// lwz r22,-1904(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1904);
	// lwz r22,-1896(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1896);
	// lwz r22,-1896(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1896);
	// lwz r22,-1856(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1856);
	// lwz r22,-1856(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1856);
	// lwz r22,-1856(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1856);
	// lwz r22,-1856(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1856);
	// lwz r22,-1856(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1856);
loc_82DCF880:
	// li r11,8
	ctx.r11.s64 = 8;
	// b 0x82dcf89c
	goto loc_82DCF89C;
loc_82DCF888:
	// li r11,16
	ctx.r11.s64 = 16;
	// b 0x82dcf89c
	goto loc_82DCF89C;
loc_82DCF890:
	// li r11,24
	ctx.r11.s64 = 24;
	// b 0x82dcf89c
	goto loc_82DCF89C;
loc_82DCF898:
	// li r11,32
	ctx.r11.s64 = 32;
loc_82DCF89C:
	// li r9,0
	ctx.r9.s64 = 0;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// rldimi r9,r21,3,29
	ctx.r9.u64 = (__builtin_rotateleft64(ctx.r21.u64, 3) & 0x7FFFFFFF8) | (ctx.r9.u64 & 0xFFFFFFF800000007);
	// tdllei r11,0
	// divdu r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 / ctx.r11.u64;
	// twllei r10,0
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dcf968
	goto loc_82DCF968;
loc_82DCF8C0:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-1832
	ctx.r12.s64 = ctx.r12.s64 + -1832;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-1708(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1708);
	// lwz r22,-1692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1692);
	// lwz r22,-1692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1692);
	// lwz r22,-1692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1692);
	// lwz r22,-1692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1692);
	// lwz r22,-1692(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1692);
	// lwz r22,-1788(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1788);
	// lwz r22,-1768(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1768);
	// lwz r22,-1736(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1736);
	// lwz r22,-1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1716);
	// lwz r22,-1716(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1716);
	// mulli r11,r21,14
	ctx.r11.s64 = ctx.r21.s64 * 14;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dcf968
	goto loc_82DCF968;
	// lis r9,14563
	ctx.r9.s64 = 954400768;
	// rlwinm r11,r21,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 6) & 0xFFFFFFC0;
	// ori r9,r9,36409
	ctx.r9.u64 = ctx.r9.u64 | 36409;
	// twllei r10,0
	// mulhwu r11,r11,r9
	ctx.r11.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dcf968
	goto loc_82DCF968;
	// mulli r11,r21,28
	ctx.r11.s64 = ctx.r21.s64 * 28;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dcf968
	goto loc_82DCF968;
	// mr r24,r21
	ctx.r24.u64 = ctx.r21.u64;
	// b 0x82dcf968
	goto loc_82DCF968;
	// li r11,0
	ctx.r11.s64 = 0;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dcf968
	goto loc_82DCF968;
loc_82DCF964:
	// lwz r24,88(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DCF968:
	// lbz r11,2036(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dcfbf0
	if (ctx.cr6.eq) goto loc_82DCFBF0;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,2016(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 2016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x82dcfbf0
	if (ctx.cr6.eq) goto loc_82DCFBF0;
	// lwz r27,1128(r25)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1128);
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82dcfbec
	if (ctx.cr6.eq) goto loc_82DCFBEC;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// lwz r29,88(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// ori r30,r11,18725
	ctx.r30.u64 = ctx.r11.u64 | 18725;
loc_82DCF9A8:
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82dcf9d4
	if (!ctx.cr6.eq) goto loc_82DCF9D4;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82dcf2a8
	ctx.lr = 0x82DCF9C0;
	sub_82DCF2A8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dcfc00
	if (!ctx.cr6.eq) goto loc_82DCFC00;
	// lwz r11,1132(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1132);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// b 0x82dcf9d8
	goto loc_82DCF9D8;
loc_82DCF9D4:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82DCF9D8:
	// add r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 + ctx.r28.u64;
	// cmplw cr6,r10,r24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r24.u32, ctx.xer);
	// ble cr6,0x82dcf9e8
	if (!ctx.cr6.gt) goto loc_82DCF9E8;
	// subf r11,r28,r24
	ctx.r11.s64 = ctx.r24.s64 - ctx.r28.s64;
loc_82DCF9E8:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82da41c0
	ctx.lr = 0x82DCF9F4;
	sub_82DA41C0(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dcfa3c
	if (ctx.cr6.eq) goto loc_82DCFA3C;
	// lwz r3,492(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 492);
	// li r9,1000
	ctx.r9.s64 = 1000;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCFA28;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x82dcfc08
	if (!ctx.cr6.eq) goto loc_82DCFC08;
	// lwz r3,492(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 492);
	// bl 0x82d938a0
	ctx.lr = 0x82DCFA3C;
	sub_82D938A0(ctx, base);
loc_82DCFA3C:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DCFA44;
	sub_82DA4200(ctx, base);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dcfbb4
	if (ctx.cr6.gt) goto loc_82DCFBB4;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-1424
	ctx.r12.s64 = ctx.r12.s64 + -1424;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DCFADC;
	case 1:
		goto loc_82DCFA9C;
	case 2:
		goto loc_82DCFAAC;
	case 3:
		goto loc_82DCFABC;
	case 4:
		goto loc_82DCFACC;
	case 5:
		goto loc_82DCFACC;
	case 6:
		goto loc_82DCFADC;
	case 7:
		goto loc_82DCFADC;
	case 8:
		goto loc_82DCFADC;
	case 9:
		goto loc_82DCFADC;
	case 10:
		goto loc_82DCFADC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1316);
	// lwz r22,-1380(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1380);
	// lwz r22,-1364(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1364);
	// lwz r22,-1348(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1348);
	// lwz r22,-1332(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1332);
	// lwz r22,-1332(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1332);
	// lwz r22,-1316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1316);
	// lwz r22,-1316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1316);
	// lwz r22,-1316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1316);
	// lwz r22,-1316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1316);
	// lwz r22,-1316(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1316);
loc_82DCFA9C:
	// li r11,8
	ctx.r11.s64 = 8;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
loc_82DCFAAC:
	// li r11,16
	ctx.r11.s64 = 16;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
loc_82DCFABC:
	// li r11,24
	ctx.r11.s64 = 24;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
loc_82DCFACC:
	// li r11,32
	ctx.r11.s64 = 32;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
loc_82DCFADC:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,-1292
	ctx.r12.s64 = ctx.r12.s64 + -1292;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,-1112(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1112);
	// lwz r22,-1100(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1100);
	// lwz r22,-1100(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1100);
	// lwz r22,-1100(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1100);
	// lwz r22,-1100(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1100);
	// lwz r22,-1100(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1100);
	// lwz r22,-1248(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1248);
	// lwz r22,-1196(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1196);
	// lwz r22,-1172(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1172);
	// lwz r22,-1120(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1120);
	// lwz r22,-1120(r28)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r28.u32 + -1120);
	// addi r11,r9,13
	ctx.r11.s64 = ctx.r9.s64 + 13;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
	// addi r11,r9,63
	ctx.r11.s64 = ctx.r9.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
	// addi r11,r9,27
	ctx.r11.s64 = ctx.r9.s64 + 27;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dcfbac
	goto loc_82DCFBAC;
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// b 0x82dcfbb4
	goto loc_82DCFBB4;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DCFBAC:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mullw r29,r11,r10
	ctx.r29.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82DCFBB4:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r26,r4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82dcfbd8
	if (ctx.cr6.eq) goto loc_82DCFBD8;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dcfbd8
	if (ctx.cr6.eq) goto loc_82DCFBD8;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DCFBD4;
	sub_82CB1160(ctx, base);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DCFBD8:
	// add r28,r9,r28
	ctx.r28.u64 = ctx.r9.u64 + ctx.r28.u64;
	// add r26,r29,r26
	ctx.r26.u64 = ctx.r29.u64 + ctx.r26.u64;
	// subf r27,r9,r27
	ctx.r27.s64 = ctx.r27.s64 - ctx.r9.s64;
	// cmplw cr6,r28,r24
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82dcf9a8
	if (ctx.cr6.lt) goto loc_82DCF9A8;
loc_82DCFBEC:
	// stw r27,1128(r25)
	PPC_STORE_U32(ctx.r25.u32 + 1128, ctx.r27.u32);
loc_82DCFBF0:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82dcfbfc
	if (ctx.cr6.eq) goto loc_82DCFBFC;
	// stw r21,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r21.u32);
loc_82DCFBFC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCFC00:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DCFC08:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DCFC10;
	sub_82DA4200(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCFC1C"))) PPC_WEAK_FUNC(sub_82DCFC1C);
PPC_FUNC_IMPL(__imp__sub_82DCFC1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCFC20"))) PPC_WEAK_FUNC(sub_82DCFC20);
PPC_FUNC_IMPL(__imp__sub_82DCFC20) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dcfc30
	if (!ctx.cr6.eq) goto loc_82DCFC30;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DCFC30:
	// b 0x82dcf7f8
	sub_82DCF7F8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DCFC34"))) PPC_WEAK_FUNC(sub_82DCFC34);
PPC_FUNC_IMPL(__imp__sub_82DCFC34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCFC38"))) PPC_WEAK_FUNC(sub_82DCFC38);
PPC_FUNC_IMPL(__imp__sub_82DCFC38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DCFC64;
	sub_82D9B4A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DCFC7C"))) PPC_WEAK_FUNC(sub_82DCFC7C);
PPC_FUNC_IMPL(__imp__sub_82DCFC7C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DCFC80"))) PPC_WEAK_FUNC(sub_82DCFC80);
PPC_FUNC_IMPL(__imp__sub_82DCFC80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DCFC88;
	__savegprlr_14(ctx, base);
	// stwu r1,-1120(r1)
	ea = -1120 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r5,1156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1156, ctx.r5.u32);
	// li r21,0
	ctx.r21.s64 = 0;
	// mr r18,r4
	ctx.r18.u64 = ctx.r4.u64;
	// lwz r11,224(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// sth r21,84(r1)
	PPC_STORE_U16(ctx.r1.u32 + 84, ctx.r21.u16);
	// stw r18,1148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1148, ctx.r18.u32);
	// lwz r11,388(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dcfcc4
	if (!ctx.cr6.eq) goto loc_82DCFCC4;
loc_82DCFCB8:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,1120
	ctx.r1.s64 = ctx.r1.s64 + 1120;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DCFCC4:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r9,21
	ctx.r9.s64 = 21;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,19872(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19872, ctx.r11.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// stw r9,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r9.u32);
	// stw r21,220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 220, ctx.r21.u32);
	// stw r21,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r21.u32);
	// stw r21,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r21.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DCFCF4;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DCFD14;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82da7e70
	ctx.lr = 0x82DCFD2C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,17
	ctx.r6.s64 = 17;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,448
	ctx.r4.s64 = ctx.r1.s64 + 448;
	// bl 0x82da76a0
	ctx.lr = 0x82DCFD4C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,17
	ctx.r5.s64 = 17;
	// addi r4,r11,9636
	ctx.r4.s64 = ctx.r11.s64 + 9636;
	// addi r3,r1,448
	ctx.r3.s64 = ctx.r1.s64 + 448;
	// bl 0x82da45e8
	ctx.lr = 0x82DCFD68;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dcfcb8
	if (!ctx.cr6.eq) goto loc_82DCFCB8;
	// addi r29,r31,760
	ctx.r29.s64 = ctx.r31.s64 + 760;
	// li r23,64
	ctx.r23.s64 = 64;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DCFD88:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82dcfd88
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DCFD88;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r10,125
	ctx.r10.s64 = 125;
	// stw r21,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r21.u32);
	// addi r4,r31,232
	ctx.r4.s64 = ctx.r31.s64 + 232;
	// stb r23,1276(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1276, ctx.r23.u8);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r21,1284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1284, ctx.r21.u32);
	// li r6,20
	ctx.r6.s64 = 20;
	// stw r21,2012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2012, ctx.r21.u32);
	// lfs f0,6140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// li r11,6
	ctx.r11.s64 = 6;
	// li r5,1
	ctx.r5.s64 = 1;
	// stfs f0,2020(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2020, temp.u32);
	// stfs f0,2016(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2016, temp.u32);
	// stw r10,1144(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1144, ctx.r10.u32);
	// addi r28,r31,1140
	ctx.r28.s64 = ctx.r31.s64 + 1140;
	// stw r21,1296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1296, ctx.r21.u32);
	// addi r27,r31,1144
	ctx.r27.s64 = ctx.r31.s64 + 1144;
	// stw r11,1140(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1140, ctx.r11.u32);
	// addi r30,r31,2012
	ctx.r30.s64 = ctx.r31.s64 + 2012;
	// bl 0x82da76a0
	ctx.lr = 0x82DCFDEC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r1,86
	ctx.r4.s64 = ctx.r1.s64 + 86;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DCFE00;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,86(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 86);
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bne cr6,0x82dcfcb8
	if (!ctx.cr6.eq) goto loc_82DCFCB8;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r4,60
	ctx.r4.s64 = 60;
	// bl 0x82da7e70
	ctx.lr = 0x82DCFE24;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// bl 0x82da76a0
	ctx.lr = 0x82DCFE44;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r31,1280
	ctx.r4.s64 = ctx.r31.s64 + 1280;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCFE58;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCFE6C;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r26,r31,756
	ctx.r26.s64 = ctx.r31.s64 + 756;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da7d80
	ctx.lr = 0x82DCFE84;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCFE98;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r31,1292
	ctx.r4.s64 = ctx.r31.s64 + 1292;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCFEAC;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r31,2034
	ctx.r4.s64 = ctx.r31.s64 + 2034;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DCFEC0;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DCFED4;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ce0
	ctx.lr = 0x82DCFEE8;
	sub_82DA7CE0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r27,r31,500
	ctx.r27.s64 = ctx.r31.s64 + 500;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,256
	ctx.r6.s64 = 256;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DCFF0C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r5,r11,9168
	ctx.r5.s64 = ctx.r11.s64 + 9168;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DCFF38;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r28,r21
	ctx.r28.u64 = ctx.r21.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r20,r11,9544
	ctx.r20.s64 = ctx.r11.s64 + 9544;
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// ble cr6,0x82dcffc4
	if (!ctx.cr6.gt) goto loc_82DCFFC4;
loc_82DCFF5C:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2346
	ctx.r6.s64 = 2346;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// li r4,704
	ctx.r4.s64 = 704;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DCFF7C;
	sub_82D862B0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dcffa0
	if (ctx.cr6.eq) goto loc_82DCFFA0;
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// stw r30,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r30.u32);
	// stw r30,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r30.u32);
	// stw r21,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r21.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DCFF9C;
	sub_82D9B4A8(ctx, base);
	// b 0x82dcffa4
	goto loc_82DCFFA4;
loc_82DCFFA0:
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82DCFFA4:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// stw r30,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r30.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dcff5c
	if (ctx.cr6.lt) goto loc_82DCFF5C;
loc_82DCFFC4:
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r11,60
	ctx.r4.s64 = ctx.r11.s64 + 60;
	// bl 0x82da7e70
	ctx.lr = 0x82DCFFD8;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r8,r31,1280
	ctx.r8.s64 = ctx.r31.s64 + 1280;
	// stw r21,1284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1284, ctx.r21.u32);
	// lwz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd0028
	if (!ctx.cr6.gt) goto loc_82DD0028;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// subfic r9,r31,-500
	ctx.xer.ca = ctx.r31.u32 <= 4294966796;
	ctx.r9.s64 = -500 - ctx.r31.s64;
loc_82DCFFFC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lwz r7,1284(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// cmpw cr6,r10,r7
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82dd0014
	if (ctx.cr6.lt) goto loc_82DD0014;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,1284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1284, ctx.r10.u32);
loc_82DD0014:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// add r7,r9,r11
	ctx.r7.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmpw cr6,r7,r10
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dcfffc
	if (ctx.cr6.lt) goto loc_82DCFFFC;
loc_82DD0028:
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// lhz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dd003c
	if (ctx.cr6.gt) goto loc_82DD003C;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82DD003C:
	// stw r11,1288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1288, ctx.r11.u32);
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2377
	ctx.r6.s64 = 2377;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD0060;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lhz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 84);
	// mr r25,r21
	ctx.r25.u64 = ctx.r21.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd02e0
	if (ctx.cr6.eq) goto loc_82DD02E0;
	// mr r26,r21
	ctx.r26.u64 = ctx.r21.u64;
	// li r24,255
	ctx.r24.s64 = 255;
loc_82DD0088:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,108
	ctx.r4.s64 = ctx.r1.s64 + 108;
	// add r27,r26,r11
	ctx.r27.u64 = ctx.r26.u64 + ctx.r11.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD00A8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD00BC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD00D0;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD00E4;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// addi r22,r31,756
	ctx.r22.s64 = ctx.r31.s64 + 756;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2428
	ctx.r6.s64 = 2428;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// lwz r10,19872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19872);
	// lwz r9,0(r22)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82d862b0
	ctx.lr = 0x82DD0124;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,4(r27)
	PPC_STORE_U32(ctx.r27.u32 + 4, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lhz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd02c8
	if (ctx.cr6.eq) goto loc_82DD02C8;
	// lwz r11,0(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r28,r21
	ctx.r28.u64 = ctx.r21.u64;
	// mullw. r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble 0x82dd02c8
	if (!ctx.cr0.gt) goto loc_82DD02C8;
	// addi r30,r29,3
	ctx.r30.s64 = ctx.r29.s64 + 3;
loc_82DD0158:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0164;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// rlwinm r9,r10,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dd022c
	if (ctx.cr6.eq) goto loc_82DD022C;
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd01a4
	if (ctx.cr6.eq) goto loc_82DD01A4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0198;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
loc_82DD01A4:
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd01c8
	if (ctx.cr6.eq) goto loc_82DD01C8;
	// addi r4,r30,-2
	ctx.r4.s64 = ctx.r30.s64 + -2;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD01BC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
loc_82DD01C8:
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd01ec
	if (ctx.cr6.eq) goto loc_82DD01EC;
	// addi r4,r30,-1
	ctx.r4.s64 = ctx.r30.s64 + -1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD01E0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
loc_82DD01EC:
	// rlwinm r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd0210
	if (ctx.cr6.eq) goto loc_82DD0210;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0204;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
loc_82DD0210:
	// rlwinm r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0288
	if (ctx.cr6.eq) goto loc_82DD0288;
	// b 0x82dd0274
	goto loc_82DD0274;
loc_82DD0220:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,1120
	ctx.r1.s64 = ctx.r1.s64 + 1120;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DD022C:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd0238
	if (ctx.cr6.eq) goto loc_82DD0238;
	// stb r11,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r11.u8);
loc_82DD0238:
	// addi r4,r30,-2
	ctx.r4.s64 = ctx.r30.s64 + -2;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0244;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r30,-1
	ctx.r4.s64 = ctx.r30.s64 + -1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0258;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD026C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
loc_82DD0274:
	// addi r4,r30,1
	ctx.r4.s64 = ctx.r30.s64 + 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0280;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
loc_82DD0288:
	// lbz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,97
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 97, ctx.xer);
	// bne cr6,0x82dd0298
	if (!ctx.cr6.eq) goto loc_82DD0298;
	// stb r24,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r24.u8);
loc_82DD0298:
	// lbz r11,-2(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + -2);
	// cmplwi cr6,r11,128
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 128, ctx.xer);
	// ble cr6,0x82dd02a8
	if (!ctx.cr6.gt) goto loc_82DD02A8;
	// stb r21,-2(r30)
	PPC_STORE_U8(ctx.r30.u32 + -2, ctx.r21.u8);
loc_82DD02A8:
	// lwz r11,0(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r29,r29,5
	ctx.r29.s64 = ctx.r29.s64 + 5;
	// addi r30,r30,5
	ctx.r30.s64 = ctx.r30.s64 + 5;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd0158
	if (ctx.cr6.lt) goto loc_82DD0158;
loc_82DD02C8:
	// lhz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 84);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r26,r26,8
	ctx.r26.s64 = ctx.r26.s64 + 8;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmpw cr6,r25,r10
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd0088
	if (ctx.cr6.lt) goto loc_82DD0088;
loc_82DD02E0:
	// lwz r10,1284(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// ble cr6,0x82dd035c
	if (!ctx.cr6.gt) goto loc_82DD035C;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// cmpw cr6,r28,r10
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dd035c
	if (!ctx.cr6.lt) goto loc_82DD035C;
	// rlwinm r29,r28,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 3) & 0xFFFFFFF8;
loc_82DD0300:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// add r30,r29,r11
	ctx.r30.u64 = ctx.r29.u64 + ctx.r11.u64;
	// addi r11,r31,756
	ctx.r11.s64 = ctx.r31.s64 + 756;
	// li r6,2550
	ctx.r6.s64 = 2550;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// stw r23,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r23.u32);
	// lwz r10,19872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19872);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r4,r11,6,0,25
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x82d862b0
	ctx.lr = 0x82DD033C;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r29,r29,8
	ctx.r29.s64 = ctx.r29.s64 + 8;
	// cmpw cr6,r28,r11
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd0300
	if (ctx.cr6.lt) goto loc_82DD0300;
loc_82DD035C:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// addi r30,r31,1292
	ctx.r30.s64 = ctx.r31.s64 + 1292;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2563
	ctx.r6.s64 = 2563;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mulli r4,r10,1428
	ctx.r4.s64 = ctx.r10.s64 * 1428;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD0384;
	sub_82D862B0(ctx, base);
	// stw r3,1300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1300, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r16,r21
	ctx.r16.u64 = ctx.r21.u64;
	// li r19,1
	ctx.r19.s64 = 1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd0d24
	if (!ctx.cr6.gt) goto loc_82DD0D24;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r20,108
	ctx.r20.s64 = 108;
	// addi r14,r11,9628
	ctx.r14.s64 = ctx.r11.s64 + 9628;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r15,r11,9440
	ctx.r15.s64 = ctx.r11.s64 + 9440;
	// lis r11,0
	ctx.r11.s64 = 0;
	// ori r18,r11,44100
	ctx.r18.u64 = ctx.r11.u64 | 44100;
loc_82DD03C0:
	// lwz r10,1300(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1300);
	// mulli r11,r16,1428
	ctx.r11.s64 = ctx.r16.s64 * 1428;
	// li r21,0
	ctx.r21.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// add r23,r11,r10
	ctx.r23.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r17,r21
	ctx.r17.u64 = ctx.r21.u64;
	// bl 0x82da8018
	ctx.lr = 0x82DD03E0;
	sub_82DA8018(ctx, base);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82da76a0
	ctx.lr = 0x82DD03F8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd0d1c
	if (!ctx.cr6.eq) goto loc_82DD0D1C;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r6,22
	ctx.r6.s64 = 22;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DD0428;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD043C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD0450;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// stw r11,28(r23)
	PPC_STORE_U32(ctx.r23.u32 + 28, ctx.r11.u32);
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0cd0
	if (ctx.cr6.eq) goto loc_82DD0CD0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// bl 0x82da76a0
	ctx.lr = 0x82DD0484;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,96
	ctx.r6.s64 = 96;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r23,800
	ctx.r4.s64 = ctx.r23.s64 + 800;
	// bl 0x82da76a0
	ctx.lr = 0x82DD04A4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,24
	ctx.r6.s64 = 24;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r23,898
	ctx.r4.s64 = ctx.r23.s64 + 898;
	// bl 0x82da76a0
	ctx.lr = 0x82DD04C4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,24
	ctx.r6.s64 = 24;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r23,986
	ctx.r4.s64 = ctx.r23.s64 + 986;
	// bl 0x82da76a0
	ctx.lr = 0x82DD04E4;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r27,r23,897
	ctx.r27.s64 = ctx.r23.s64 + 897;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD04FC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r26,r23,984
	ctx.r26.s64 = ctx.r23.s64 + 984;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0514;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,978
	ctx.r4.s64 = ctx.r23.s64 + 978;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0528;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,979
	ctx.r4.s64 = ctx.r23.s64 + 979;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD053C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,980
	ctx.r4.s64 = ctx.r23.s64 + 980;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0550;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1066
	ctx.r4.s64 = ctx.r23.s64 + 1066;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0564;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1067
	ctx.r4.s64 = ctx.r23.s64 + 1067;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0578;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1068
	ctx.r4.s64 = ctx.r23.s64 + 1068;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD058C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r28,r23,896
	ctx.r28.s64 = ctx.r23.s64 + 896;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD05A4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r29,r23,983
	ctx.r29.s64 = ctx.r23.s64 + 983;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD05BC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1159
	ctx.r4.s64 = ctx.r23.s64 + 1159;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD05D0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1160
	ctx.r4.s64 = ctx.r23.s64 + 1160;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD05E4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1161
	ctx.r4.s64 = ctx.r23.s64 + 1161;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD05F8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r23,1162
	ctx.r4.s64 = ctx.r23.s64 + 1162;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD060C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r30,r23,1164
	ctx.r30.s64 = ctx.r23.s64 + 1164;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82da7c90
	ctx.lr = 0x82DD0624;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lhz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 0);
	// lbz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r27.u32 + 0);
	// rotlwi r11,r11,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// sth r11,0(r30)
	PPC_STORE_U16(ctx.r30.u32 + 0, ctx.r11.u16);
	// bge cr6,0x82dd0648
	if (!ctx.cr6.lt) goto loc_82DD0648;
	// stb r21,0(r28)
	PPC_STORE_U8(ctx.r28.u32 + 0, ctx.r21.u8);
loc_82DD0648:
	// lbz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bge cr6,0x82dd0658
	if (!ctx.cr6.lt) goto loc_82DD0658;
	// stb r21,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r21.u8);
loc_82DD0658:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// bl 0x82da7e70
	ctx.lr = 0x82DD0668;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// li r22,0
	ctx.r22.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0970
	if (ctx.cr6.eq) goto loc_82DD0970;
	// addi r29,r23,48
	ctx.r29.s64 = ctx.r23.s64 + 48;
loc_82DD0684:
	// addi r24,r29,-16
	ctx.r24.s64 = ctx.r29.s64 + -16;
	// li r5,48
	ctx.r5.s64 = 48;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DD0698;
	sub_82CB16F0(ctx, base);
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// stw r11,1296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1296, ctx.r11.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DD06BC;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r25,r29,-4
	ctx.r25.s64 = ctx.r29.s64 + -4;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD06E0;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD0700;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r28,r29,8
	ctx.r28.s64 = ctx.r29.s64 + 8;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// addi r4,r28,-16
	ctx.r4.s64 = ctx.r28.s64 + -16;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0718;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DD072C;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r27,72
	ctx.r27.s64 = 72;
	// mr r30,r19
	ctx.r30.u64 = ctx.r19.u64;
	// mr r26,r19
	ctx.r26.u64 = ctx.r19.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD074C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd0768
	if (ctx.cr6.eq) goto loc_82DD0768;
	// li r27,74
	ctx.r27.s64 = 74;
loc_82DD0768:
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd0778
	if (ctx.cr6.eq) goto loc_82DD0778;
	// rlwimi r27,r19,2,29,30
	ctx.r27.u64 = (__builtin_rotateleft32(ctx.r19.u32, 2) & 0x6) | (ctx.r27.u64 & 0xFFFFFFFFFFFFFFF9);
loc_82DD0778:
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd0788
	if (ctx.cr6.eq) goto loc_82DD0788;
	// li r26,2
	ctx.r26.s64 = 2;
loc_82DD0788:
	// rlwinm r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0798
	if (ctx.cr6.eq) goto loc_82DD0798;
	// li r30,2
	ctx.r30.s64 = 2;
loc_82DD0798:
	// rlwinm r11,r27,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x2;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd07bc
	if (!ctx.cr6.eq) goto loc_82DD07BC;
	// rlwinm r11,r27,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd07bc
	if (!ctx.cr6.eq) goto loc_82DD07BC;
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// stw r10,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r10.u32);
loc_82DD07BC:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd07d4
	if (!ctx.cr6.eq) goto loc_82DD07D4;
	// rlwimi r27,r19,0,29,31
	ctx.r27.u64 = (__builtin_rotateleft32(ctx.r19.u32, 0) & 0x7) | (ctx.r27.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// stw r10,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r10.u32);
loc_82DD07D4:
	// addi r11,r26,-1
	ctx.r11.s64 = ctx.r26.s64 + -1;
	// lwz r9,0(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r8,0(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r4,r28,-15
	ctx.r4.s64 = ctx.r28.s64 + -15;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// stw r10,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r10.u32);
	// twllei r30,0
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// twllei r30,0
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// divwu r10,r9,r11
	ctx.r10.u32 = ctx.r9.u32 / ctx.r11.u32;
	// twllei r11,0
	// twllei r11,0
	// divwu r11,r8,r11
	ctx.r11.u32 = ctx.r8.u32 / ctx.r11.u32;
	// divwu r10,r10,r30
	ctx.r10.u32 = ctx.r10.u32 / ctx.r30.u32;
	// divwu r11,r11,r30
	ctx.r11.u32 = ctx.r11.u32 / ctx.r30.u32;
	// stw r10,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r10.u32);
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0828;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// addi r4,r28,-4
	ctx.r4.s64 = ctx.r28.s64 + -4;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DD083C;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD0850;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// li r6,22
	ctx.r6.s64 = 22;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// bl 0x82da76a0
	ctx.lr = 0x82DD0870;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// addi r3,r1,704
	ctx.r3.s64 = ctx.r1.s64 + 704;
	// bl 0x82cb61f0
	ctx.lr = 0x82DD0888;
	sub_82CB61F0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,28
	ctx.r7.s64 = 28;
	// addi r6,r1,272
	ctx.r6.s64 = ctx.r1.s64 + 272;
	// addi r5,r1,704
	ctx.r5.s64 = ctx.r1.s64 + 704;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DD08A8;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lwz r8,100(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dd0954
	if (ctx.cr6.eq) goto loc_82DD0954;
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,13
	ctx.r9.s64 = 13;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DD08CC:
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dd08cc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD08CC;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// ori r5,r27,1024
	ctx.r5.u64 = ctx.r27.u64 | 1024;
	// stw r20,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r20.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r8,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r8.u32);
	// stw r19,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r19.u32);
	// stw r18,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r18.u32);
	// stw r26,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r26.u32);
	// bl 0x82d910a0
	ctx.lr = 0x82DD0908;
	sub_82D910A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// rlwinm r11,r27,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd0928
	if (!ctx.cr6.eq) goto loc_82DD0928;
	// rlwinm r11,r27,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0954
	if (ctx.cr6.eq) goto loc_82DD0954;
loc_82DD0928:
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r4,0(r25)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// li r5,2
	ctx.r5.s64 = 2;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// add r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 + ctx.r11.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r6,r11,-1
	ctx.r6.s64 = ctx.r11.s64 + -1;
	// lwz r11,160(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD0954;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82DD0954:
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
	// addi r29,r29,48
	ctx.r29.s64 = ctx.r29.s64 + 48;
	// cmplw cr6,r22,r11
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82dd0684
	if (ctx.cr6.lt) goto loc_82DD0684;
	// cmplwi cr6,r22,16
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 16, ctx.xer);
	// bge cr6,0x82dd09a0
	if (!ctx.cr6.lt) goto loc_82DD09A0;
loc_82DD0970:
	// rlwinm r10,r22,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 1) & 0xFFFFFFFE;
	// subfic r11,r22,16
	ctx.xer.ca = ctx.r22.u32 <= 16;
	ctx.r11.s64 = 16 - ctx.r22.s64;
	// add r10,r22,r10
	ctx.r10.u64 = ctx.r22.u64 + ctx.r10.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r10,r10,r23
	ctx.r10.u64 = ctx.r10.u64 + ctx.r23.u64;
	// addi r10,r10,32
	ctx.r10.s64 = ctx.r10.s64 + 32;
loc_82DD098C:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,48
	ctx.r10.s64 = ctx.r10.s64 + 48;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd098c
	if (!ctx.cr6.eq) goto loc_82DD098C;
loc_82DD09A0:
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0d04
	if (ctx.cr6.eq) goto loc_82DD0D04;
	// addi r28,r23,32
	ctx.r28.s64 = ctx.r23.s64 + 32;
loc_82DD09B4:
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c90
	if (ctx.cr6.eq) goto loc_82DD0C90;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r27,r28,12
	ctx.r27.s64 = ctx.r28.s64 + 12;
	// lwz r30,28(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r1,136
	ctx.r6.s64 = ctx.r1.s64 + 136;
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD09E8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c90
	if (ctx.cr6.eq) goto loc_82DD0C90;
	// cmplw cr6,r30,r17
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r17.u32, ctx.xer);
	// ble cr6,0x82dd0a2c
	if (!ctx.cr6.gt) goto loc_82DD0A2C;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,2923
	ctx.r7.s64 = 2923;
	// addi r5,r30,16
	ctx.r5.s64 = ctx.r30.s64 + 16;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b8
	ctx.lr = 0x82DD0A1C;
	sub_82D862B8(ctx, base);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// mr r17,r30
	ctx.r17.u64 = ctx.r30.u64;
loc_82DD0A2C:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD0A44;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dd0a54
	if (ctx.cr6.eq) goto loc_82DD0A54;
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
loc_82DD0A54:
	// addi r29,r21,4
	ctx.r29.s64 = ctx.r21.s64 + 4;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82da45e8
	ctx.lr = 0x82DD0A68;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd0b40
	if (!ctx.cr6.eq) goto loc_82DD0B40;
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,13
	ctx.r9.s64 = 13;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DD0A80:
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dd0a80
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD0A80;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r20,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r20.u32);
	// stw r30,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r30.u32);
	// lwz r11,64(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// stw r11,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r11.u32);
	// lfs f0,72(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	ctx.f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// stw r11,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r11.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r30,24(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD0AD4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// rlwimi r30,r19,11,20,21
	ctx.r30.u64 = (__builtin_rotateleft32(ctx.r19.u32, 11) & 0xC00) | (ctx.r30.u64 & 0xFFFFFFFFFFFFF3FF);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// bl 0x82d910a0
	ctx.lr = 0x82DD0AF8;
	sub_82D910A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd0c90
	if (!ctx.cr6.eq) goto loc_82DD0C90;
	// rlwinm r11,r30,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd0b18
	if (!ctx.cr6.eq) goto loc_82DD0B18;
	// rlwinm r11,r30,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c90
	if (ctx.cr6.eq) goto loc_82DD0C90;
loc_82DD0B18:
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r5,2
	ctx.r5.s64 = 2;
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// add r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 + ctx.r11.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r6,r11,-1
	ctx.r6.s64 = ctx.r11.s64 + -1;
	// lwz r11,160(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	// b 0x82dd0c80
	goto loc_82DD0C80;
loc_82DD0B40:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0b90
	if (ctx.cr6.eq) goto loc_82DD0B90;
	// rlwinm r10,r30,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd0b90
	if (ctx.cr6.eq) goto loc_82DD0B90;
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
loc_82DD0B64:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// extsh r8,r9
	ctx.r8.s64 = ctx.r9.s16;
	// rlwinm r9,r9,24,8,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFFFF;
	// rlwinm r8,r8,8,0,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFFFF00;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// extsh r8,r8
	ctx.r8.s64 = ctx.r8.s16;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// sth r9,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r9.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// bne cr6,0x82dd0b64
	if (!ctx.cr6.eq) goto loc_82DD0B64;
loc_82DD0B90:
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// addi r7,r1,108
	ctx.r7.s64 = ctx.r1.s64 + 108;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD0BBC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lwz r3,88(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c64
	if (ctx.cr6.eq) goto loc_82DD0C64;
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c64
	if (ctx.cr6.eq) goto loc_82DD0C64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DD0BE8;
	sub_82CB1160(ctx, base);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dd0c2c
	if (!ctx.cr6.eq) goto loc_82DD0C2C;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c64
	if (ctx.cr6.eq) goto loc_82DD0C64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
loc_82DD0C08:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// stb r8,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r8.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne cr6,0x82dd0c08
	if (!ctx.cr6.eq) goto loc_82DD0C08;
	// b 0x82dd0c64
	goto loc_82DD0C64;
loc_82DD0C2C:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82dd0c64
	if (!ctx.cr6.eq) goto loc_82DD0C64;
	// rlwinm r9,r30,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 31) & 0x7FFFFFFF;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dd0c64
	if (ctx.cr6.eq) goto loc_82DD0C64;
loc_82DD0C44:
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// sth r8,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r8.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// bne cr6,0x82dd0c44
	if (!ctx.cr6.eq) goto loc_82DD0C44;
loc_82DD0C64:
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r7,116(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r6,104(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82DD0C80:
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD0C88;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
loc_82DD0C90:
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r28,r28,48
	ctx.r28.s64 = ctx.r28.s64 + 48;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82dd09b4
	if (ctx.cr6.lt) goto loc_82DD09B4;
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82dd0d04
	if (ctx.cr6.eq) goto loc_82DD0D04;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3035
	ctx.r6.s64 = 3035;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD0CCC;
	sub_82D861B0(ctx, base);
	// b 0x82dd0d04
	goto loc_82DD0D04;
loc_82DD0CD0:
	// addi r10,r23,32
	ctx.r10.s64 = ctx.r23.s64 + 32;
	// li r11,16
	ctx.r11.s64 = 16;
loc_82DD0CD8:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r21,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r21.u32);
	// addi r10,r10,48
	ctx.r10.s64 = ctx.r10.s64 + 48;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd0cd8
	if (!ctx.cr6.eq) goto loc_82DD0CD8;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// bl 0x82da7e70
	ctx.lr = 0x82DD0CFC;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
loc_82DD0D04:
	// addi r11,r31,1292
	ctx.r11.s64 = ctx.r31.s64 + 1292;
	// addi r16,r16,1
	ctx.r16.s64 = ctx.r16.s64 + 1;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r16,r11
	ctx.cr6.compare<int32_t>(ctx.r16.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd03c0
	if (ctx.cr6.lt) goto loc_82DD03C0;
	// li r21,0
	ctx.r21.s64 = 0;
loc_82DD0D1C:
	// lwz r18,1148(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	// lwz r20,96(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD0D24:
	// lwz r10,1296(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// stw r21,2076(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2076, ctx.r21.u32);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82dd0d60
	if (ctx.cr6.eq) goto loc_82DD0D60;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3063
	ctx.r6.s64 = 3063;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// rlwinm r4,r10,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD0D54;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,2076(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2076, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
loc_82DD0D60:
	// addi r11,r31,1292
	ctx.r11.s64 = ctx.r31.s64 + 1292;
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd0ddc
	if (!ctx.cr6.gt) goto loc_82DD0DDC;
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
loc_82DD0D7C:
	// lwz r11,1300(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1300);
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// add r8,r11,r6
	ctx.r8.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwz r11,28(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd0dc4
	if (!ctx.cr6.gt) goto loc_82DD0DC4;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r8,32
	ctx.r11.s64 = ctx.r8.s64 + 32;
loc_82DD0D9C:
	// lwz r4,2076(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2076);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,48
	ctx.r11.s64 = ctx.r11.s64 + 48;
	// stwx r3,r4,r10
	PPC_STORE_U32(ctx.r4.u32 + ctx.r10.u32, ctx.r3.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r4,28(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 28);
	// cmpw cr6,r9,r4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r4.s32, ctx.xer);
	// blt cr6,0x82dd0d9c
	if (ctx.cr6.lt) goto loc_82DD0D9C;
loc_82DD0DC4:
	// addi r11,r31,1292
	ctx.r11.s64 = ctx.r31.s64 + 1292;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,1428
	ctx.r6.s64 = ctx.r6.s64 + 1428;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r5,r11
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd0d7c
	if (ctx.cr6.lt) goto loc_82DD0D7C;
loc_82DD0DDC:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3090
	ctx.r6.s64 = 3090;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// li r4,296
	ctx.r4.s64 = 296;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD0DFC;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r30,5
	ctx.r30.s64 = 5;
	// lwz r11,1156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	// stw r3,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r3.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,268(r3)
	PPC_STORE_U32(ctx.r3.u32 + 268, ctx.r10.u32);
	// beq cr6,0x82dd0e3c
	if (ctx.cr6.eq) goto loc_82DD0E3C;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dd0e3c
	if (ctx.cr6.eq) goto loc_82DD0E3C;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r11,256(r10)
	PPC_STORE_U32(ctx.r10.u32 + 256, ctx.r11.u32);
	// b 0x82dd0e5c
	goto loc_82DD0E5C;
loc_82DD0E3C:
	// rlwinm r11,r18,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// beq cr6,0x82dd0e54
	if (ctx.cr6.eq) goto loc_82DD0E54;
	// stw r30,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r30.u32);
	// b 0x82dd0e5c
	goto loc_82DD0E5C;
loc_82DD0E54:
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r10,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r10.u32);
loc_82DD0E5C:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r10,2
	ctx.r10.s64 = 2;
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r4,r31,232
	ctx.r4.s64 = ctx.r31.s64 + 232;
	// stw r10,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r10.u32);
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// bl 0x82da4468
	ctx.lr = 0x82DD0E78;
	sub_82DA4468(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r11,r11,264
	ctx.r11.s64 = ctx.r11.s64 + 264;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd0e94
	if (ctx.cr6.eq) goto loc_82DD0E94;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r10,1244(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1244);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
loc_82DD0E94:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r21,156(r31)
	PPC_STORE_U32(ctx.r31.u32 + 156, ctx.r21.u32);
	// lwz r10,256(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lwz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// bgt cr6,0x82dd0fb0
	if (ctx.cr6.gt) goto loc_82DD0FB0;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,3780
	ctx.r12.s64 = ctx.r12.s64 + 3780;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD0F30;
	case 1:
		goto loc_82DD0EF0;
	case 2:
		goto loc_82DD0F00;
	case 3:
		goto loc_82DD0F10;
	case 4:
		goto loc_82DD0F20;
	case 5:
		goto loc_82DD0F20;
	case 6:
		goto loc_82DD0F30;
	case 7:
		goto loc_82DD0F30;
	case 8:
		goto loc_82DD0F30;
	case 9:
		goto loc_82DD0F30;
	case 10:
		goto loc_82DD0F30;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3888(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3888);
	// lwz r22,3824(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3824);
	// lwz r22,3840(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3840);
	// lwz r22,3856(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3856);
	// lwz r22,3872(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3872);
	// lwz r22,3872(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3872);
	// lwz r22,3888(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3888);
	// lwz r22,3888(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3888);
	// lwz r22,3888(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3888);
	// lwz r22,3888(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3888);
	// lwz r22,3888(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3888);
loc_82DD0EF0:
	// li r10,8
	ctx.r10.s64 = 8;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
loc_82DD0F00:
	// li r10,16
	ctx.r10.s64 = 16;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
loc_82DD0F10:
	// li r10,24
	ctx.r10.s64 = 24;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
loc_82DD0F20:
	// li r10,32
	ctx.r10.s64 = 32;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
loc_82DD0F30:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,3912
	ctx.r12.s64 = ctx.r12.s64 + 3912;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,4000(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4000);
	// lwz r22,4016(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4016);
	// lwz r22,4016(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4016);
	// lwz r22,4016(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4016);
	// lwz r22,4016(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4016);
	// lwz r22,4016(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4016);
	// lwz r22,3956(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3956);
	// lwz r22,3968(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3968);
	// lwz r22,3980(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3980);
	// lwz r22,3992(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3992);
	// lwz r22,3992(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3992);
	// li r10,8
	ctx.r10.s64 = 8;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
	// li r10,36
	ctx.r10.s64 = 36;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
	// li r10,16
	ctx.r10.s64 = 16;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd0fa4
	goto loc_82DD0FA4;
	// stw r19,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r19.u32);
	// b 0x82dd0fb0
	goto loc_82DD0FB0;
	// stw r21,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r21.u32);
loc_82DD0FA4:
	// lwz r10,276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
loc_82DD0FB0:
	// addi r11,r1,396
	ctx.r11.s64 = ctx.r1.s64 + 396;
	// stw r21,404(r1)
	PPC_STORE_U32(ctx.r1.u32 + 404, ctx.r21.u32);
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
	// li r9,17
	ctx.r9.s64 = 17;
	// stw r11,396(r1)
	PPC_STORE_U32(ctx.r1.u32 + 396, ctx.r11.u32);
	// addi r11,r1,396
	ctx.r11.s64 = ctx.r1.s64 + 396;
	// stw r11,400(r1)
	PPC_STORE_U32(ctx.r1.u32 + 400, ctx.r11.u32);
	// addi r11,r1,304
	ctx.r11.s64 = ctx.r1.s64 + 304;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82DD0FD4:
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dd0fd4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD0FD4;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,304
	ctx.r3.s64 = ctx.r1.s64 + 304;
	// addi r4,r11,9608
	ctx.r4.s64 = ctx.r11.s64 + 9608;
	// bl 0x82da4448
	ctx.lr = 0x82DD0FF0;
	sub_82DA4448(ctx, base);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r27,r31,492
	ctx.r27.s64 = ctx.r31.s64 + 492;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,304
	ctx.r4.s64 = ctx.r1.s64 + 304;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// stw r10,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, ctx.r10.u32);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// stw r10,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// stw r30,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r30.u32);
	// stw r11,408(r1)
	PPC_STORE_U32(ctx.r1.u32 + 408, ctx.r11.u32);
	// bl 0x82d8ced0
	ctx.lr = 0x82DD102C;
	sub_82D8CED0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r6,3155
	ctx.r6.s64 = 3155;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r11.u64);
	// lfd f0,136(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// addi r11,r31,756
	ctx.r11.s64 = ctx.r31.s64 + 756;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 220, temp.u32);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mulli r4,r11,608
	ctx.r4.s64 = ctx.r11.s64 * 608;
	// stw r11,1016(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1016, ctx.r11.u32);
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD1084;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1020, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// lwz r11,1016(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1016);
	// mr r29,r21
	ctx.r29.u64 = ctx.r21.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd10dc
	if (!ctx.cr6.gt) goto loc_82DD10DC;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82DD10A4:
	// lwz r11,1020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1020);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd10c8
	if (ctx.cr6.eq) goto loc_82DD10C8;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stw r21,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r21.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DD10C8;
	sub_82D9B4A8(ctx, base);
loc_82DD10C8:
	// lwz r11,1016(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1016);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,608
	ctx.r30.s64 = ctx.r30.s64 + 608;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd10a4
	if (ctx.cr6.lt) goto loc_82DD10A4;
loc_82DD10DC:
	// lis r30,-31909
	ctx.r30.s64 = -2091188224;
	// lwz r10,1016(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1016);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3172
	ctx.r6.s64 = 3172;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r11,19872(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 19872);
	// rlwinm r28,r10,1,0,30
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD1104;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd1114
	if (ctx.cr6.eq) goto loc_82DD1114;
	// bl 0x82da9430
	ctx.lr = 0x82DD1110;
	sub_82DA9430(ctx, base);
	// b 0x82dd1118
	goto loc_82DD1118;
loc_82DD1114:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
loc_82DD1118:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1024, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82da9450
	ctx.lr = 0x82DD1134;
	sub_82DA9450(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd123c
	if (!ctx.cr6.eq) goto loc_82DD123C;
	// lwz r11,19872(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3184
	ctx.r6.s64 = 3184;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// mulli r4,r28,760
	ctx.r4.s64 = ctx.r28.s64 * 760;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD1158;
	sub_82D862B0(ctx, base);
	// stw r3,1028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1028, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// mr r29,r21
	ctx.r29.u64 = ctx.r21.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// ble cr6,0x82dd11c4
	if (!ctx.cr6.gt) goto loc_82DD11C4;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82DD1174:
	// lwz r11,1028(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd1188
	if (ctx.cr6.eq) goto loc_82DD1188;
	// bl 0x82e01520
	ctx.lr = 0x82DD1188;
	sub_82E01520(ctx, base);
loc_82DD1188:
	// lwz r11,1028(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,0(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r3,1024(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1024);
	// bl 0x82da9828
	ctx.lr = 0x82DD11A0;
	sub_82DA9828(ctx, base);
	// lwz r11,1028(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r30,r30,760
	ctx.r30.s64 = ctx.r30.s64 + 760;
	// cmpw cr6,r29,r28
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r28.s32, ctx.xer);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// ori r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 2048;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// blt cr6,0x82dd1174
	if (ctx.cr6.lt) goto loc_82DD1174;
loc_82DD11C4:
	// rlwinm r11,r18,0,17,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd11f0
	if (!ctx.cr6.eq) goto loc_82DD11F0;
	// rlwinm r11,r18,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd11f0
	if (!ctx.cr6.eq) goto loc_82DD11F0;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r21,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r21.u32);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dd122c
	goto loc_82DD122C;
loc_82DD11F0:
	// addi r11,r31,1280
	ctx.r11.s64 = ctx.r31.s64 + 1280;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3200
	ctx.r6.s64 = 3200;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// rlwinm r4,r10,8,0,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD1218;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r3.u32);
	// beq cr6,0x82dd0220
	if (ctx.cr6.eq) goto loc_82DD0220;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dcf778
	ctx.lr = 0x82DD122C;
	sub_82DCF778(ctx, base);
loc_82DD122C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r21,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r21.u32);
	// bl 0x82e032f8
	ctx.lr = 0x82DD1238;
	sub_82E032F8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD123C:
	// addi r1,r1,1120
	ctx.r1.s64 = ctx.r1.s64 + 1120;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD1244"))) PPC_WEAK_FUNC(sub_82DD1244);
PPC_FUNC_IMPL(__imp__sub_82DD1244) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD1248"))) PPC_WEAK_FUNC(sub_82DD1248);
PPC_FUNC_IMPL(__imp__sub_82DD1248) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd1258
	if (!ctx.cr6.eq) goto loc_82DD1258;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD1258:
	// b 0x82dcfc80
	sub_82DCFC80(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD125C"))) PPC_WEAK_FUNC(sub_82DD125C);
PPC_FUNC_IMPL(__imp__sub_82DD125C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD1260"))) PPC_WEAK_FUNC(sub_82DD1260);
PPC_FUNC_IMPL(__imp__sub_82DD1260) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,31064
	ctx.r31.s64 = ctx.r11.s64 + 31064;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DD128C;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r30,-32035
	ctx.r30.s64 = -2099445760;
	// addi r11,r11,9656
	ctx.r11.s64 = ctx.r11.s64 + 9656;
	// lis r3,-32035
	ctx.r3.s64 = -2099445760;
	// lis r4,-32035
	ctx.r4.s64 = -2099445760;
	// lis r5,-32032
	ctx.r5.s64 = -2099249152;
	// lis r6,-32035
	ctx.r6.s64 = -2099445760;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// lis r7,-32032
	ctx.r7.s64 = -2099249152;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// lis r8,-32032
	ctx.r8.s64 = -2099249152;
	// lis r9,-32032
	ctx.r9.s64 = -2099249152;
	// lis r10,-32032
	ctx.r10.s64 = -2099249152;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,1794
	ctx.r11.s64 = 1794;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r30,4680
	ctx.r11.s64 = ctx.r30.s64 + 4680;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r3,-2232
	ctx.r11.s64 = ctx.r3.s64 + -2232;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r4,-992
	ctx.r11.s64 = ctx.r4.s64 + -992;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r5,12544
	ctx.r11.s64 = ctx.r5.s64 + 12544;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// addi r11,r6,-2208
	ctx.r11.s64 = ctx.r6.s64 + -2208;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// addi r11,r7,12656
	ctx.r11.s64 = ctx.r7.s64 + 12656;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// addi r11,r8,12752
	ctx.r11.s64 = ctx.r8.s64 + 12752;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// addi r11,r9,12800
	ctx.r11.s64 = ctx.r9.s64 + 12800;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// addi r11,r10,12904
	ctx.r11.s64 = ctx.r10.s64 + 12904;
	// stw r11,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r11.u32);
	// li r11,21
	ctx.r11.s64 = 21;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,2080
	ctx.r11.s64 = 2080;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD134C"))) PPC_WEAK_FUNC(sub_82DD134C);
PPC_FUNC_IMPL(__imp__sub_82DD134C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD1350"))) PPC_WEAK_FUNC(sub_82DD1350);
PPC_FUNC_IMPL(__imp__sub_82DD1350) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,649(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 649);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r9,r10,28
	ctx.r9.u64 = ctx.r10.u32 & 0xF;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dd1374
	if (!ctx.cr6.eq) goto loc_82DD1374;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// rlwinm r10,r10,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD1374:
	// lbz r10,649(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 649);
	// rlwinm r9,r10,0,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82dd1394
	if (!ctx.cr6.eq) goto loc_82DD1394;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD1394:
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd13a8
	if (!ctx.cr6.gt) goto loc_82DD13A8;
	// li r10,64
	ctx.r10.s64 = 64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD13A8:
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dd13bc
	if (!ctx.cr6.lt) goto loc_82DD13BC;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD13BC:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD13D0"))) PPC_WEAK_FUNC(sub_82DD13D0);
PPC_FUNC_IMPL(__imp__sub_82DD13D0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dd1404
	if (!ctx.cr6.lt) goto loc_82DD1404;
	// lbz r9,660(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// rotlwi r9,r9,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 2);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82dd1404
	if (!ctx.cr6.gt) goto loc_82DD1404;
	// stw r9,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r9.u32);
loc_82DD1404:
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82dd1438
	if (!ctx.cr6.gt) goto loc_82DD1438;
	// lbz r10,660(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dd1438
	if (!ctx.cr6.lt) goto loc_82DD1438;
	// stw r9,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r9.u32);
loc_82DD1438:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD144C"))) PPC_WEAK_FUNC(sub_82DD144C);
PPC_FUNC_IMPL(__imp__sub_82DD144C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD1450"))) PPC_WEAK_FUNC(sub_82DD1450);
PPC_FUNC_IMPL(__imp__sub_82DD1450) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,694(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dd14fc
	if (ctx.cr6.gt) goto loc_82DD14FC;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,5276
	ctx.r12.s64 = ctx.r12.s64 + 5276;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD14AC;
	case 1:
		goto loc_82DD14C0;
	case 2:
		goto loc_82DD14E8;
	case 3:
		goto loc_82DD14F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5292(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5292);
	// lwz r22,5312(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5312);
	// lwz r22,5352(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5352);
	// lwz r22,5360(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5360);
loc_82DD14AC:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dd1500
	goto loc_82DD1500;
loc_82DD14C0:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dd14e0
	if (!ctx.cr6.lt) goto loc_82DD14E0;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DD14E0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dd1500
	goto loc_82DD1500;
loc_82DD14E8:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dd1500
	goto loc_82DD1500;
loc_82DD14F0:
	// bl 0x82cb2308
	ctx.lr = 0x82DD14F4;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dd1500
	goto loc_82DD1500;
loc_82DD14FC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD1500:
	// lbz r10,664(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 664);
	// lbz r9,662(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// srawi r11,r11,5
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 5;
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// blt cr6,0x82dd1520
	if (ctx.cr6.lt) goto loc_82DD1520;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DD1520:
	// stw r11,496(r30)
	PPC_STORE_U32(ctx.r30.u32 + 496, ctx.r11.u32);
	// lbz r10,662(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r9,663(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dd154c
	if (!ctx.cr6.gt) goto loc_82DD154C;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
loc_82DD154C:
	// lbz r11,476(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r30)
	PPC_STORE_U8(ctx.r30.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD1574"))) PPC_WEAK_FUNC(sub_82DD1574);
PPC_FUNC_IMPL(__imp__sub_82DD1574) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD1578"))) PPC_WEAK_FUNC(sub_82DD1578);
PPC_FUNC_IMPL(__imp__sub_82DD1578) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,694(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// lbz r11,666(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 666);
	// rlwinm r10,r10,28,30,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x3;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dd1624
	if (ctx.cr6.gt) goto loc_82DD1624;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,5572
	ctx.r12.s64 = ctx.r12.s64 + 5572;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD15D4;
	case 1:
		goto loc_82DD15E8;
	case 2:
		goto loc_82DD1610;
	case 3:
		goto loc_82DD1618;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5588(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5588);
	// lwz r22,5608(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5608);
	// lwz r22,5648(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5648);
	// lwz r22,5656(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5656);
loc_82DD15D4:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dd1628
	goto loc_82DD1628;
loc_82DD15E8:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dd1608
	if (!ctx.cr6.lt) goto loc_82DD1608;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DD1608:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dd1628
	goto loc_82DD1628;
loc_82DD1610:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dd1628
	goto loc_82DD1628;
loc_82DD1618:
	// bl 0x82cb2308
	ctx.lr = 0x82DD161C;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dd1628
	goto loc_82DD1628;
loc_82DD1624:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD1628:
	// lbz r10,668(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 668);
	// lbz r9,666(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 666);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// lwz r10,484(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 484);
	// srawi r11,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 6;
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// bge cr6,0x82dd1658
	if (!ctx.cr6.lt) goto loc_82DD1658;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + ctx.r11.u64;
	// cmpwi cr6,r9,64
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 64, ctx.xer);
	// ble cr6,0x82dd166c
	if (!ctx.cr6.gt) goto loc_82DD166C;
	// subfic r11,r10,64
	ctx.xer.ca = ctx.r10.u32 <= 64;
	ctx.r11.s64 = 64 - ctx.r10.s64;
	// b 0x82dd166c
	goto loc_82DD166C;
loc_82DD1658:
	// extsh r9,r10
	ctx.r9.s64 = ctx.r10.s16;
	// subf. r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge 0x82dd1668
	if (!ctx.cr0.lt) goto loc_82DD1668;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82DD1668:
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DD166C:
	// stw r11,492(r30)
	PPC_STORE_U32(ctx.r30.u32 + 492, ctx.r11.u32);
	// lbz r10,666(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 666);
	// lbz r9,668(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 668);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,666(r31)
	PPC_STORE_U8(ctx.r31.u32 + 666, ctx.r11.u8);
	// ble cr6,0x82dd1698
	if (!ctx.cr6.gt) goto loc_82DD1698;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,666(r31)
	PPC_STORE_U8(ctx.r31.u32 + 666, ctx.r11.u8);
loc_82DD1698:
	// lbz r11,476(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r30)
	PPC_STORE_U8(ctx.r30.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD16C0"))) PPC_WEAK_FUNC(sub_82DD16C0);
PPC_FUNC_IMPL(__imp__sub_82DD16C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,694(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dd176c
	if (ctx.cr6.gt) goto loc_82DD176C;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,5900
	ctx.r12.s64 = ctx.r12.s64 + 5900;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD171C;
	case 1:
		goto loc_82DD1730;
	case 2:
		goto loc_82DD1758;
	case 3:
		goto loc_82DD1760;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5916(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5916);
	// lwz r22,5936(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5936);
	// lwz r22,5976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5976);
	// lwz r22,5984(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 5984);
loc_82DD171C:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dd1770
	goto loc_82DD1770;
loc_82DD1730:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dd1750
	if (!ctx.cr6.lt) goto loc_82DD1750;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DD1750:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dd1770
	goto loc_82DD1770;
loc_82DD1758:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dd1770
	goto loc_82DD1770;
loc_82DD1760:
	// bl 0x82cb2308
	ctx.lr = 0x82DD1764;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dd1770
	goto loc_82DD1770;
loc_82DD176C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD1770:
	// lbz r10,664(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 664);
	// lbz r9,662(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// srawi r11,r11,7
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 7;
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// blt cr6,0x82dd178c
	if (ctx.cr6.lt) goto loc_82DD178C;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DD178C:
	// stw r11,496(r30)
	PPC_STORE_U32(ctx.r30.u32 + 496, ctx.r11.u32);
	// lbz r10,662(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r9,663(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dd17b8
	if (!ctx.cr6.gt) goto loc_82DD17B8;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
loc_82DD17B8:
	// lbz r11,476(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r30)
	PPC_STORE_U8(ctx.r30.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD17E0"))) PPC_WEAK_FUNC(sub_82DD17E0);
PPC_FUNC_IMPL(__imp__sub_82DD17E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DD17E8;
	__savegprlr_14(ctx, base);
	// stfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -176, ctx.f29.u64);
	// stfd f30,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, ctx.f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r16,r23
	ctx.r16.u64 = ctx.r23.u64;
	// lwz r9,2056(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2056);
	// lwz r7,488(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 488);
	// add r8,r9,r26
	ctx.r8.u64 = ctx.r9.u64 + ctx.r26.u64;
	// lwz r10,2052(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2052);
	// lwz r11,756(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 756);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// lbz r8,500(r8)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + 500);
	// rotlwi r8,r8,3
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 3);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// add r25,r8,r11
	ctx.r25.u64 = ctx.r8.u64 + ctx.r11.u64;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82dd233c
	if (ctx.cr6.eq) goto loc_82DD233C;
	// lwz r11,496(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 496);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1874
	if (ctx.cr6.eq) goto loc_82DD1874;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lbzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dd186c
	if (ctx.cr6.eq) goto loc_82DD186C;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,2037(r26)
	PPC_STORE_U8(ctx.r26.u32 + 2037, ctx.r11.u8);
	// b 0x82dd233c
	goto loc_82DD233C;
loc_82DD186C:
	// li r9,1
	ctx.r9.s64 = 1;
	// stbx r9,r11,r10
	PPC_STORE_U8(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u8);
loc_82DD1874:
	// lwz r11,756(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 756);
	// mr r22,r23
	ctx.r22.u64 = ctx.r23.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd233c
	if (!ctx.cr6.gt) goto loc_82DD233C;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r8,-32222
	ctx.r8.s64 = -2111700992;
	// addi r20,r11,-19064
	ctx.r20.s64 = ctx.r11.s64 + -19064;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r9,-32222
	ctx.r9.s64 = -2111700992;
	// addi r19,r11,-17952
	ctx.r19.s64 = ctx.r11.s64 + -17952;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lfs f30,-17360(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -17360);
	ctx.f30.f64 = double(temp.f32);
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// addi r21,r11,-17904
	ctx.r21.s64 = ctx.r11.s64 + -17904;
	// lis r11,218
	ctx.r11.s64 = 14286848;
	// lfs f31,-17348(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -17348);
	ctx.f31.f64 = double(temp.f32);
	// clrlwi r14,r4,24
	ctx.r14.u64 = ctx.r4.u32 & 0xFF;
	// li r15,8
	ctx.r15.s64 = 8;
	// lfs f29,-16020(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -16020);
	ctx.f29.f64 = double(temp.f32);
	// li r17,64
	ctx.r17.s64 = 64;
	// ori r18,r11,30208
	ctx.r18.u64 = ctx.r11.u64 | 30208;
loc_82DD18C8:
	// addi r10,r22,190
	ctx.r10.s64 = ctx.r22.s64 + 190;
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// stw r23,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r23.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r11,28,4,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r27,r11,28
	ctx.r27.u64 = ctx.r11.u32 & 0xF;
	// lwzx r31,r10,r26
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r26.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dd1900
	if (!ctx.cr6.eq) goto loc_82DD1900;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq cr6,0x82dd1904
	if (ctx.cr6.eq) goto loc_82DD1904;
loc_82DD1900:
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82DD1904:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd191c
	if (ctx.cr6.eq) goto loc_82DD191C;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// stw r19,464(r21)
	PPC_STORE_U32(ctx.r21.u32 + 464, ctx.r19.u32);
	// b 0x82dd1920
	goto loc_82DD1920;
loc_82DD191C:
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
loc_82DD1920:
	// lbz r11,1(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 1);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd193c
	if (ctx.cr6.eq) goto loc_82DD193C;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,608(r31)
	PPC_STORE_U8(ctx.r31.u32 + 608, ctx.r11.u8);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD193C:
	// lbz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd195c
	if (ctx.cr6.eq) goto loc_82DD195C;
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// beq cr6,0x82dd195c
	if (ctx.cr6.eq) goto loc_82DD195C;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,609(r31)
	PPC_STORE_U8(ctx.r31.u32 + 609, ctx.r11.u8);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD195C:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1296(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 1296);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dd1984
	if (!ctx.cr6.lt) goto loc_82DD1984;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r26
	ctx.r11.u64 = ctx.r11.u64 + ctx.r26.u64;
	// addi r24,r11,2076
	ctx.r24.s64 = ctx.r11.s64 + 2076;
	// b 0x82dd1988
	goto loc_82DD1988;
loc_82DD1984:
	// mr r24,r19
	ctx.r24.u64 = ctx.r19.u64;
loc_82DD1988:
	// lbz r11,616(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 616);
	// lwz r30,484(r9)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 484);
	// lwz r29,480(r9)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 480);
	// cmplwi cr6,r11,18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 18, ctx.xer);
	// bne cr6,0x82dd19b8
	if (!ctx.cr6.eq) goto loc_82DD19B8;
	// lbz r11,3(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 3);
	// cmplwi cr6,r11,18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 18, ctx.xer);
	// beq cr6,0x82dd19b8
	if (ctx.cr6.eq) goto loc_82DD19B8;
	// lwz r11,492(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 492);
	// rotlwi r10,r30,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r30.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,484(r9)
	PPC_STORE_U32(ctx.r9.u32 + 484, ctx.r11.u32);
loc_82DD19B8:
	// lbz r11,3(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 3);
	// stb r11,616(r31)
	PPC_STORE_U8(ctx.r31.u32 + 616, ctx.r11.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r23.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r23,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r23.u8);
	// lbz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1a80
	if (ctx.cr6.eq) goto loc_82DD1A80;
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// beq cr6,0x82dd1a80
	if (ctx.cr6.eq) goto loc_82DD1A80;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r11,r21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r21.u32, ctx.xer);
	// bne cr6,0x82dd1a14
	if (!ctx.cr6.eq) goto loc_82DD1A14;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DD1A04;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dd1a14
	if (ctx.cr6.eq) goto loc_82DD1A14;
	// stw r21,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r21.u32);
	// stw r19,464(r21)
	PPC_STORE_U32(ctx.r21.u32 + 464, ctx.r19.u32);
loc_82DD1A14:
	// lbz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 0);
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// stb r11,609(r31)
	PPC_STORE_U8(ctx.r31.u32 + 609, ctx.r11.u8);
	// rlwinm r11,r11,2,22,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FC;
	// lwz r10,4(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwzx r11,r11,r20
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r20.u32);
	// beq cr6,0x82dd1a44
	if (ctx.cr6.eq) goto loc_82DD1A44;
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// twllei r10,0
loc_82DD1A44:
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// add r11,r22,r26
	ctx.r11.u64 = ctx.r22.u64 + ctx.r26.u64;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r11,1148(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1148);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lbz r11,3(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 3);
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82dd1a78
	if (ctx.cr6.eq) goto loc_82DD1A78;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// beq cr6,0x82dd1a78
	if (ctx.cr6.eq) goto loc_82DD1A78;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
loc_82DD1A78:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r15,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r15.u8);
loc_82DD1A80:
	// lbz r11,1(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1ac0
	if (ctx.cr6.eq) goto loc_82DD1AC0;
	// lbz r11,8(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 8);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// stb r23,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r23.u8);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bge cr6,0x82dd1ab0
	if (!ctx.cr6.lt) goto loc_82DD1AB0;
	// stb r23,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r23.u8);
loc_82DD1AB0:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// bge cr6,0x82dd1ac0
	if (!ctx.cr6.lt) goto loc_82DD1AC0;
	// stb r23,666(r31)
	PPC_STORE_U8(ctx.r31.u32 + 666, ctx.r23.u8);
loc_82DD1AC0:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r23.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,7
	ctx.r10.u64 = ctx.r10.u64 | 7;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lbz r11,2(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 2);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1af0
	if (ctx.cr6.eq) goto loc_82DD1AF0;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
loc_82DD1AF0:
	// lbz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,255
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 255, ctx.xer);
	// bne cr6,0x82dd1b04
	if (!ctx.cr6.eq) goto loc_82DD1B04;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r23.u32);
loc_82DD1B04:
	// lbz r11,3(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 3);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 23, ctx.xer);
	// bgt cr6,0x82dd2194
	if (ctx.cr6.gt) goto loc_82DD2194;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,6956
	ctx.r12.s64 = ctx.r12.s64 + 6956;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD1B8C;
	case 1:
		goto loc_82DD1BA0;
	case 2:
		goto loc_82DD1BC8;
	case 3:
		goto loc_82DD1C20;
	case 4:
		goto loc_82DD1CF4;
	case 5:
		goto loc_82DD1D50;
	case 6:
		goto loc_82DD1DAC;
	case 7:
		goto loc_82DD1DE4;
	case 8:
		goto loc_82DD1E08;
	case 9:
		goto loc_82DD1ECC;
	case 10:
		goto loc_82DD1EB8;
	case 11:
		goto loc_82DD1E80;
	case 12:
		goto loc_82DD2194;
	case 13:
		goto loc_82DD2194;
	case 14:
		goto loc_82DD1EE0;
	case 15:
		goto loc_82DD2194;
	case 16:
		goto loc_82DD1F28;
	case 17:
		goto loc_82DD1F40;
	case 18:
		goto loc_82DD1F64;
	case 19:
		goto loc_82DD215C;
	case 20:
		goto loc_82DD2120;
	case 21:
		goto loc_82DD2144;
	case 22:
		goto loc_82DD2194;
	case 23:
		goto loc_82DD2174;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7052(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7052);
	// lwz r22,7072(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7072);
	// lwz r22,7112(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7112);
	// lwz r22,7200(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7200);
	// lwz r22,7412(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7412);
	// lwz r22,7504(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7504);
	// lwz r22,7596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7596);
	// lwz r22,7652(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7652);
	// lwz r22,7688(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7688);
	// lwz r22,7884(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7884);
	// lwz r22,7864(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7864);
	// lwz r22,7808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7808);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,7904(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7904);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,7976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 7976);
	// lwz r22,8000(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8000);
	// lwz r22,8036(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8036);
	// lwz r22,8540(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8540);
	// lwz r22,8480(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8480);
	// lwz r22,8516(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8516);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8564(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8564);
loc_82DD1B8C:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stw r11,2044(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2044, ctx.r11.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1BA0:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// lwz r10,1280(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 1280);
	// stw r23,2068(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2068, ctx.r23.u32);
	// stw r11,2072(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2072, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd1bc0
	if (ctx.cr6.lt) goto loc_82DD1BC0;
	// stw r23,2072(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2072, ctx.r23.u32);
loc_82DD1BC0:
	// li r16,1
	ctx.r16.s64 = 1;
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1BC8:
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,63
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 63, ctx.xer);
	// stw r11,2068(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2068, ctx.r11.u32);
	// ble cr6,0x82dd1bf0
	if (!ctx.cr6.gt) goto loc_82DD1BF0;
	// stw r23,2068(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2068, ctx.r23.u32);
loc_82DD1BF0:
	// clrlwi r11,r16,24
	ctx.r11.u64 = ctx.r16.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd1c08
	if (!ctx.cr6.eq) goto loc_82DD1C08;
	// lwz r11,2056(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2056);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,2072(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2072, ctx.r11.u32);
loc_82DD1C08:
	// lwz r11,2072(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2072);
	// lwz r10,1280(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 1280);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd2194
	if (ctx.cr6.lt) goto loc_82DD2194;
	// stw r23,2072(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2072, ctx.r23.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1C20:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1c30
	if (ctx.cr6.eq) goto loc_82DD1C30;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
loc_82DD1C30:
	// lbz r11,649(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 649);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 15, ctx.xer);
	// bne cr6,0x82dd1c58
	if (!ctx.cr6.eq) goto loc_82DD1C58;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// b 0x82dd1c74
	goto loc_82DD1C74;
loc_82DD1C58:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dd1c74
	if (!ctx.cr6.eq) goto loc_82DD1C74;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD1C74:
	// lhz r11,2034(r26)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r26.u32 + 2034);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82dd1cc8
	if (!ctx.cr6.eq) goto loc_82DD1CC8;
	// lbz r10,649(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 649);
	// clrlwi r11,r10,28
	ctx.r11.u64 = ctx.r10.u32 & 0xF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd1ca4
	if (!ctx.cr6.eq) goto loc_82DD1CA4;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r10,r10,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD1CA4:
	// lbz r11,649(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 649);
	// rlwinm r10,r11,0,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dd1cc8
	if (!ctx.cr6.eq) goto loc_82DD1CC8;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
loc_82DD1CC8:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd1ce0
	if (!ctx.cr6.gt) goto loc_82DD1CE0;
	// stw r17,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r17.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD1CE0:
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dd2194
	if (!ctx.cr6.lt) goto loc_82DD2194;
	// stw r23,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r23.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1CF4:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1d04
	if (ctx.cr6.eq) goto loc_82DD1D04;
	// stb r11,644(r31)
	PPC_STORE_U8(ctx.r31.u32 + 644, ctx.r11.u8);
loc_82DD1D04:
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r11,r10,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,240
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 240, ctx.xer);
	// bne cr6,0x82dd1d28
	if (!ctx.cr6.eq) goto loc_82DD1D28;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r10,r10,2,26,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x3C;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
loc_82DD1D28:
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r11,r10,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,224
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 224, ctx.xer);
	// bne cr6,0x82dd2194
	if (!ctx.cr6.eq) goto loc_82DD2194;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1D50:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1d60
	if (ctx.cr6.eq) goto loc_82DD1D60;
	// stb r11,644(r31)
	PPC_STORE_U8(ctx.r31.u32 + 644, ctx.r11.u8);
loc_82DD1D60:
	// lbz r11,644(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r10,r11,0,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r10,240
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 240, ctx.xer);
	// bne cr6,0x82dd1d84
	if (!ctx.cr6.eq) goto loc_82DD1D84;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r11,2,26,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3C;
	// lwz r9,480(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 480);
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
loc_82DD1D84:
	// lbz r11,644(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// rlwinm r10,r11,0,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r10,224
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 224, ctx.xer);
	// bne cr6,0x82dd2194
	if (!ctx.cr6.eq) goto loc_82DD2194;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// lwz r9,480(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 480);
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1DAC:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1dbc
	if (ctx.cr6.eq) goto loc_82DD1DBC;
	// stb r11,660(r31)
	PPC_STORE_U8(ctx.r31.u32 + 660, ctx.r11.u8);
loc_82DD1DBC:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// b 0x82dd2190
	goto loc_82DD2190;
loc_82DD1DE4:
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1df4
	if (ctx.cr6.eq) goto loc_82DD1DF4;
	// stb r28,663(r31)
	PPC_STORE_U8(ctx.r31.u32 + 663, ctx.r28.u8);
loc_82DD1DF4:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stb r27,664(r31)
	PPC_STORE_U8(ctx.r31.u32 + 664, ctx.r27.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1E08:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1e24
	if (ctx.cr6.eq) goto loc_82DD1E24;
	// addi r10,r28,1
	ctx.r10.s64 = ctx.r28.s64 + 1;
	// addi r11,r27,1
	ctx.r11.s64 = ctx.r27.s64 + 1;
	// stb r10,679(r31)
	PPC_STORE_U8(ctx.r31.u32 + 679, ctx.r10.u8);
	// stb r11,680(r31)
	PPC_STORE_U8(ctx.r31.u32 + 680, ctx.r11.u8);
loc_82DD1E24:
	// lbz r11,679(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// lbz r10,678(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82dd1e44
	if (ctx.cr6.lt) goto loc_82DD1E44;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// neg r10,r10
	ctx.r10.s64 = -ctx.r10.s64;
	// stw r10,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r10.u32);
loc_82DD1E44:
	// lbz r11,678(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// lbz r9,679(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r10,680(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 680);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// stb r11,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r11.u8);
	// blt cr6,0x82dd1e70
	if (ctx.cr6.lt) goto loc_82DD1E70;
	// stb r23,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r23.u8);
loc_82DD1E70:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// b 0x82dd2190
	goto loc_82DD2190;
loc_82DD1E80:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1e90
	if (ctx.cr6.eq) goto loc_82DD1E90;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
loc_82DD1E90:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// b 0x82dd2190
	goto loc_82DD2190;
loc_82DD1EB8:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stb r11,649(r31)
	PPC_STORE_U8(ctx.r31.u32 + 649, ctx.r11.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1ECC:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stb r11,681(r31)
	PPC_STORE_U8(ctx.r31.u32 + 681, ctx.r11.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1EE0:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// lwz r10,16(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 16);
	// lwz r9,12(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 12);
	// rotlwi r11,r11,8
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 8);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dd1f1c
	if (ctx.cr6.lt) goto loc_82DD1F1C;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// b 0x82dd2190
	goto loc_82DD2190;
loc_82DD1F1C:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,504(r10)
	PPC_STORE_U32(ctx.r10.u32 + 504, ctx.r11.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1F28:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stb r28,651(r31)
	PPC_STORE_U8(ctx.r31.u32 + 651, ctx.r28.u8);
	// stb r27,652(r31)
	PPC_STORE_U8(ctx.r31.u32 + 652, ctx.r27.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1F40:
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd1f50
	if (ctx.cr6.eq) goto loc_82DD1F50;
	// stb r28,668(r31)
	PPC_STORE_U8(ctx.r31.u32 + 668, ctx.r28.u8);
loc_82DD1F50:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stb r27,668(r31)
	PPC_STORE_U8(ctx.r31.u32 + 668, ctx.r27.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1F64:
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82dd2194
	if (ctx.cr6.gt) goto loc_82DD2194;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,8076
	ctx.r12.s64 = ctx.r12.s64 + 8076;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD1FC0;
	case 1:
		goto loc_82DD1FD4;
	case 2:
		goto loc_82DD1FEC;
	case 3:
		goto loc_82DD2194;
	case 4:
		goto loc_82DD2194;
	case 5:
		goto loc_82DD2194;
	case 6:
		goto loc_82DD1FFC;
	case 7:
		goto loc_82DD2194;
	case 8:
		goto loc_82DD2004;
	case 9:
		goto loc_82DD2030;
	case 10:
		goto loc_82DD2194;
	case 11:
		goto loc_82DD20BC;
	case 12:
		goto loc_82DD210C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8128(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8128);
	// lwz r22,8148(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8148);
	// lwz r22,8172(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8172);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8188(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8188);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8196(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8196);
	// lwz r22,8240(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8240);
	// lwz r22,8596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8596);
	// lwz r22,8380(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8380);
	// lwz r22,8460(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8460);
loc_82DD1FC0:
	// addi r5,r24,4
	ctx.r5.s64 = ctx.r24.s64 + 4;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82e02e10
	ctx.lr = 0x82DD1FD0;
	sub_82E02E10(ctx, base);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1FD4:
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stb r11,694(r31)
	PPC_STORE_U8(ctx.r31.u32 + 694, ctx.r11.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1FEC:
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// rlwimi r11,r27,4,20,27
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r27.u32, 4) & 0xFF0) | (ctx.r11.u64 & 0xFFFFFFFFFFFFF00F);
	// stb r11,694(r31)
	PPC_STORE_U8(ctx.r31.u32 + 694, ctx.r11.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD1FFC:
	// rlwinm r11,r27,4,20,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFF0;
	// b 0x82dd217c
	goto loc_82DD217C;
loc_82DD2004:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// ble cr6,0x82dd2020
	if (!ctx.cr6.gt) goto loc_82DD2020;
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// rlwinm r11,r11,4,20,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFF0;
	// b 0x82dd217c
	goto loc_82DD217C;
loc_82DD2020:
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// rlwinm r11,r11,4,20,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFF0;
	// b 0x82dd217c
	goto loc_82DD217C;
loc_82DD2030:
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dd2048
	if (!ctx.cr6.eq) goto loc_82DD2048;
	// lwz r11,2052(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2052);
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD2048:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dd205c
	if (!ctx.cr6.eq) goto loc_82DD205C;
	// stw r10,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r10.u32);
	// b 0x82dd2064
	goto loc_82DD2064;
loc_82DD205C:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r11.u32);
loc_82DD2064:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,496(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 496);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,2068(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2068, ctx.r11.u32);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,2052(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dd2194
	if (ctx.cr6.gt) goto loc_82DD2194;
loc_82DD2094:
	// lwz r10,2056(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2056);
	// lwz r9,496(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 496);
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stbx r23,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + ctx.r11.u32, ctx.r23.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,2052(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dd2094
	if (!ctx.cr6.gt) goto loc_82DD2094;
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD20BC:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r30,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r30.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r29,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r29.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,251
	ctx.r10.u64 = ctx.r10.u64 & 251;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,253
	ctx.r10.u64 = ctx.r10.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// b 0x82dd2190
	goto loc_82DD2190;
loc_82DD210C:
	// lwz r11,2044(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2044);
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,2060(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2060, ctx.r11.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD2120:
	// clrlwi r11,r28,24
	ctx.r11.u64 = ctx.r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2130
	if (ctx.cr6.eq) goto loc_82DD2130;
	// stb r28,663(r31)
	PPC_STORE_U8(ctx.r31.u32 + 663, ctx.r28.u8);
loc_82DD2130:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2194
	if (ctx.cr6.eq) goto loc_82DD2194;
	// stb r27,664(r31)
	PPC_STORE_U8(ctx.r31.u32 + 664, ctx.r27.u8);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD2144:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,2028(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2028, ctx.r11.u32);
	// ble cr6,0x82dd2194
	if (!ctx.cr6.gt) goto loc_82DD2194;
	// stw r17,2028(r26)
	PPC_STORE_U32(ctx.r26.u32 + 2028, ctx.r17.u32);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD215C:
	// lbz r4,4(r25)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// cmplwi cr6,r4,32
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 32, ctx.xer);
	// blt cr6,0x82dd2194
	if (ctx.cr6.lt) goto loc_82DD2194;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82e02ae0
	ctx.lr = 0x82DD2170;
	sub_82E02AE0(ctx, base);
	// b 0x82dd2194
	goto loc_82DD2194;
loc_82DD2174:
	// lbz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 4);
	// rotlwi r11,r11,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
loc_82DD217C:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
loc_82DD2190:
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DD2194:
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82dd2328
	if (ctx.cr6.eq) goto loc_82DD2328;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add. r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82dd21c4
	if (!ctx.cr0.eq) goto loc_82DD21C4;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD21C4:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd21f0
	if (ctx.cr6.eq) goto loc_82DD21F0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82e02c60
	ctx.lr = 0x82DD21EC;
	sub_82E02C60(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD21F0:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2244
	if (ctx.cr6.eq) goto loc_82DD2244;
	// lwz r10,492(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// lfs f0,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,2028(r26)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r26.u32 + 2028);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mullw r11,r10,r8
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DD2240;
	sub_82D99380(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD2244:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd228c
	if (ctx.cr6.eq) goto loc_82DD228C;
	// lwz r10,488(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// lfs f0,2020(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 2020);
	ctx.f0.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f30
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DD2288;
	sub_82D99540(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD228C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd22dc
	if (ctx.cr6.eq) goto loc_82DD22DC;
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bge cr6,0x82dd22b4
	if (!ctx.cr6.lt) goto loc_82DD22B4;
	// li r10,1
	ctx.r10.s64 = 1;
loc_82DD22B4:
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// divw r11,r18,r10
	ctx.r11.s32 = ctx.r18.s32 / ctx.r10.s32;
	// twllei r10,0
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DD22D8;
	sub_82D9B8E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD22DC:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2328
	if (ctx.cr6.eq) goto loc_82DD2328;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r23,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r23.u8);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// bl 0x82d9cb18
	ctx.lr = 0x82DD2314;
	sub_82D9CB18(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DD2320;
	sub_82D8B3E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,504(r11)
	PPC_STORE_U32(ctx.r11.u32 + 504, ctx.r23.u32);
loc_82DD2328:
	// lwz r11,756(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 756);
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
	// addi r25,r25,5
	ctx.r25.s64 = ctx.r25.s64 + 5;
	// cmpw cr6,r22,r11
	ctx.cr6.compare<int32_t>(ctx.r22.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd18c8
	if (ctx.cr6.lt) goto loc_82DD18C8;
loc_82DD233C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// lfd f30,-168(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD2354"))) PPC_WEAK_FUNC(sub_82DD2354);
PPC_FUNC_IMPL(__imp__sub_82DD2354) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD2358"))) PPC_WEAK_FUNC(sub_82DD2358);
PPC_FUNC_IMPL(__imp__sub_82DD2358) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DD2360;
	__savegprlr_20(ctx, base);
	// stfd f29,-128(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -128, ctx.f29.u64);
	// stfd f30,-120(r1)
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f30.u64);
	// stfd f31,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,2056(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2056);
	// lwz r9,488(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r8,2052(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// lwz r10,756(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 756);
	// lbz r11,500(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 500);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mullw r11,r8,r10
	ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// add r26,r9,r11
	ctx.r26.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82dd2c80
	if (ctx.cr6.eq) goto loc_82DD2C80;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// mr r25,r29
	ctx.r25.u64 = ctx.r29.u64;
	// ble cr6,0x82dd2c80
	if (!ctx.cr6.gt) goto loc_82DD2C80;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r8,-32222
	ctx.r8.s64 = -2111700992;
	// addi r27,r11,-19064
	ctx.r27.s64 = ctx.r11.s64 + -19064;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r9,-32222
	ctx.r9.s64 = -2111700992;
	// addi r23,r11,-17904
	ctx.r23.s64 = ctx.r11.s64 + -17904;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lfs f30,-17360(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -17360);
	ctx.f30.f64 = double(temp.f32);
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// addi r22,r11,-17952
	ctx.r22.s64 = ctx.r11.s64 + -17952;
	// lis r11,21845
	ctx.r11.s64 = 1431633920;
	// lfs f31,-17348(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -17348);
	ctx.f31.f64 = double(temp.f32);
	// li r20,64
	ctx.r20.s64 = 64;
	// ori r24,r11,21846
	ctx.r24.u64 = ctx.r11.u64 | 21846;
	// lis r11,218
	ctx.r11.s64 = 14286848;
	// lfs f29,-16020(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -16020);
	ctx.f29.f64 = double(temp.f32);
	// ori r21,r11,30208
	ctx.r21.u64 = ctx.r11.u64 | 30208;
loc_82DD2404:
	// addi r11,r25,190
	ctx.r11.s64 = ctx.r25.s64 + 190;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r29.u32);
	// lwz r10,1296(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1296);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r30
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dd243c
	if (!ctx.cr6.lt) goto loc_82DD243C;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r28,r11,2076
	ctx.r28.s64 = ctx.r11.s64 + 2076;
	// b 0x82dd2440
	goto loc_82DD2440;
loc_82DD243C:
	// mr r28,r22
	ctx.r28.u64 = ctx.r22.u64;
loc_82DD2440:
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r9,r31
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dd245c
	if (!ctx.cr6.eq) goto loc_82DD245C;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x82dd2460
	if (ctx.cr6.eq) goto loc_82DD2460;
loc_82DD245C:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82DD2460:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2470
	if (ctx.cr6.eq) goto loc_82DD2470;
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
loc_82DD2470:
	// lbz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 4);
	// lbz r10,3(r26)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r26.u32 + 3);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// stw r29,492(r9)
	PPC_STORE_U32(ctx.r9.u32 + 492, ctx.r29.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r10,17
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 17, ctx.xer);
	// stw r29,496(r9)
	PPC_STORE_U32(ctx.r9.u32 + 496, ctx.r29.u32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r29,476(r9)
	PPC_STORE_U8(ctx.r9.u32 + 476, ctx.r29.u8);
	// rlwinm r9,r11,28,4,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// bgt cr6,0x82dd2ae0
	if (ctx.cr6.gt) goto loc_82DD2AE0;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,9404
	ctx.r12.s64 = ctx.r12.s64 + 9404;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD2504;
	case 1:
		goto loc_82DD2510;
	case 2:
		goto loc_82DD2544;
	case 3:
		goto loc_82DD2584;
	case 4:
		goto loc_82DD2590;
	case 5:
		goto loc_82DD259C;
	case 6:
		goto loc_82DD25FC;
	case 7:
		goto loc_82DD2718;
	case 8:
		goto loc_82DD272C;
	case 9:
		goto loc_82DD2AE0;
	case 10:
		goto loc_82DD2AE0;
	case 11:
		goto loc_82DD2AE0;
	case 12:
		goto loc_82DD2AE0;
	case 13:
		goto loc_82DD2740;
	case 14:
		goto loc_82DD293C;
	case 15:
		goto loc_82DD2948;
	case 16:
		goto loc_82DD2AE0;
	case 17:
		goto loc_82DD2AD8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,9476(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9476);
	// lwz r22,9488(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9488);
	// lwz r22,9540(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9540);
	// lwz r22,9604(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9604);
	// lwz r22,9616(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9616);
	// lwz r22,9628(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9628);
	// lwz r22,9724(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 9724);
	// lwz r22,10008(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10008);
	// lwz r22,10028(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10028);
	// lwz r22,10976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10976);
	// lwz r22,10976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10976);
	// lwz r22,10976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10976);
	// lwz r22,10976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10976);
	// lwz r22,10048(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10048);
	// lwz r22,10556(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10556);
	// lwz r22,10568(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10568);
	// lwz r22,10976(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10976);
	// lwz r22,10968(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10968);
loc_82DD2504:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd1350
	ctx.lr = 0x82DD250C;
	sub_82DD1350(ctx, base);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2510:
	// lbz r10,644(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// cmplwi cr6,r10,224
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 224, ctx.xer);
	// bge cr6,0x82dd2530
	if (!ctx.cr6.lt) goto loc_82DD2530;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
loc_82DD2530:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
loc_82DD2538:
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2544:
	// lbz r11,644(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 644);
	// cmplwi cr6,r11,224
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 224, ctx.xer);
	// bge cr6,0x82dd2ae0
	if (!ctx.cr6.lt) goto loc_82DD2AE0;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,480(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 480);
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// bge cr6,0x82dd2538
	if (!ctx.cr6.lt) goto loc_82DD2538;
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2584:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd13d0
	ctx.lr = 0x82DD258C;
	sub_82DD13D0(ctx, base);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2590:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd1450
	ctx.lr = 0x82DD2598;
	sub_82DD1450(ctx, base);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD259C:
	// lbz r11,678(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// lbz r10,679(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dd25bc
	if (ctx.cr6.lt) goto loc_82DD25BC;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// neg r10,r10
	ctx.r10.s64 = -ctx.r10.s64;
	// stw r10,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r10.u32);
loc_82DD25BC:
	// lbz r11,678(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 678);
	// lbz r9,679(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 679);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r10,680(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 680);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// stb r11,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r11.u8);
	// blt cr6,0x82dd25e8
	if (ctx.cr6.lt) goto loc_82DD25E8;
	// stb r29,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r29.u8);
loc_82DD25E8:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD25FC:
	// lbz r10,681(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 681);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dd2ae0
	if (ctx.cr6.eq) goto loc_82DD2AE0;
	// lwz r11,2040(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2040);
	// rlwinm r8,r10,28,28,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xF;
	// clrlwi r7,r9,28
	ctx.r7.u64 = ctx.r9.u32 & 0xF;
	// mulhw r10,r11,r24
	ctx.r10.s64 = (int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32)) >> 32;
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82dd2694
	if (ctx.cr6.eq) goto loc_82DD2694;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82dd2704
	if (!ctx.cr6.eq) goto loc_82DD2704;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lbz r11,609(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// beq cr6,0x82dd268c
	if (ctx.cr6.eq) goto loc_82DD268C;
	// clrlwi r9,r7,24
	ctx.r9.u64 = ctx.r7.u32 & 0xFF;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rotlwi r11,r11,2
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r10,0
	// twllei r10,0
	// lwzx r11,r11,r27
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// lwzx r9,r9,r27
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r27.u32);
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r9,r9,r10
	ctx.r9.u32 = ctx.r9.u32 / ctx.r10.u32;
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// b 0x82dd26fc
	goto loc_82DD26FC;
loc_82DD268C:
	// clrlwi r10,r7,24
	ctx.r10.u64 = ctx.r7.u32 & 0xFF;
	// b 0x82dd26e4
	goto loc_82DD26E4;
loc_82DD2694:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lbz r11,609(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 609);
	// beq cr6,0x82dd26e0
	if (ctx.cr6.eq) goto loc_82DD26E0;
	// clrlwi r9,r8,24
	ctx.r9.u64 = ctx.r8.u32 & 0xFF;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rotlwi r11,r11,2
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// twllei r10,0
	// twllei r10,0
	// lwzx r11,r11,r27
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// lwzx r9,r9,r27
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r27.u32);
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// divwu r9,r9,r10
	ctx.r9.u32 = ctx.r9.u32 / ctx.r10.u32;
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// b 0x82dd26fc
	goto loc_82DD26FC;
loc_82DD26E0:
	// clrlwi r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
loc_82DD26E4:
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rotlwi r11,r11,2
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r27
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r27.u32);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82DD26FC:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,496(r10)
	PPC_STORE_U32(ctx.r10.u32 + 496, ctx.r11.u32);
loc_82DD2704:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2718:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd1450
	ctx.lr = 0x82DD2720;
	sub_82DD1450(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd1350
	ctx.lr = 0x82DD2728;
	sub_82DD1350(ctx, base);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD272C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd13d0
	ctx.lr = 0x82DD2734;
	sub_82DD13D0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd1350
	ctx.lr = 0x82DD273C;
	sub_82DD1350(ctx, base);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2740:
	// lbz r11,652(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 652);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2ae0
	if (ctx.cr6.eq) goto loc_82DD2AE0;
	// lwz r9,2040(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2040);
	// twllei r11,0
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / ctx.r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// subf. r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// twlgei r11,-1
	// bne 0x82dd2ae0
	if (!ctx.cr0.eq) goto loc_82DD2AE0;
	// lbz r11,651(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 651);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd28d4
	if (ctx.cr6.eq) goto loc_82DD28D4;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,14
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 14, ctx.xer);
	// bgt cr6,0x82dd28ac
	if (ctx.cr6.gt) goto loc_82DD28AC;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,10148
	ctx.r12.s64 = ctx.r12.s64 + 10148;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD27E0;
	case 1:
		goto loc_82DD27F0;
	case 2:
		goto loc_82DD2800;
	case 3:
		goto loc_82DD2810;
	case 4:
		goto loc_82DD2820;
	case 5:
		goto loc_82DD2830;
	case 6:
		goto loc_82DD283C;
	case 7:
		goto loc_82DD28AC;
	case 8:
		goto loc_82DD284C;
	case 9:
		goto loc_82DD285C;
	case 10:
		goto loc_82DD286C;
	case 11:
		goto loc_82DD287C;
	case 12:
		goto loc_82DD288C;
	case 13:
		goto loc_82DD28AC;
	case 14:
		goto loc_82DD289C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10208(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10208);
	// lwz r22,10224(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10224);
	// lwz r22,10240(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10240);
	// lwz r22,10256(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10256);
	// lwz r22,10272(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10272);
	// lwz r22,10288(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10288);
	// lwz r22,10300(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10300);
	// lwz r22,10412(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10412);
	// lwz r22,10316(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10316);
	// lwz r22,10332(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10332);
	// lwz r22,10348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10348);
	// lwz r22,10364(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10364);
	// lwz r22,10380(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10380);
	// lwz r22,10412(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10412);
	// lwz r22,10396(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 10396);
loc_82DD27E0:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD27F0:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD2800:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD2810:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,-8
	ctx.r10.s64 = ctx.r10.s64 + -8;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD2820:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,-16
	ctx.r10.s64 = ctx.r10.s64 + -16;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD2830:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r29,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r29.u32);
	// b 0x82dd28ac
	goto loc_82DD28AC;
loc_82DD283C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD284C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD285C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD286C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD287C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD288C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// b 0x82dd28a8
	goto loc_82DD28A8;
loc_82DD289C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DD28A8:
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
loc_82DD28AC:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd28c4
	if (!ctx.cr6.gt) goto loc_82DD28C4;
	// stw r20,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r20.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD28C4:
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dd28d8
	if (!ctx.cr6.lt) goto loc_82DD28D8;
	// stw r29,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r29.u32);
loc_82DD28D4:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD28D8:
	// add r10,r25,r30
	ctx.r10.u64 = ctx.r25.u64 + ctx.r30.u64;
	// lbz r10,1148(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1148);
	// stw r10,488(r11)
	PPC_STORE_U32(ctx.r11.u32 + 488, ctx.r10.u32);
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r29,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r29.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD293C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd1578
	ctx.lr = 0x82DD2944;
	sub_82DD1578(ctx, base);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2948:
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// cmpwi cr6,r10,12
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 12, ctx.xer);
	// beq cr6,0x82dd2aac
	if (ctx.cr6.eq) goto loc_82DD2AAC;
	// cmpwi cr6,r10,13
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 13, ctx.xer);
	// bne cr6,0x82dd2ae0
	if (!ctx.cr6.eq) goto loc_82DD2AE0;
	// lwz r10,2040(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2040);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bne cr6,0x82dd2a6c
	if (!ctx.cr6.eq) goto loc_82DD2A6C;
	// cmplw cr6,r11,r23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r23.u32, ctx.xer);
	// bne cr6,0x82dd299c
	if (!ctx.cr6.eq) goto loc_82DD299C;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DD298C;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dd299c
	if (ctx.cr6.eq) goto loc_82DD299C;
	// stw r23,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r23.u32);
	// stw r22,464(r23)
	PPC_STORE_U32(ctx.r23.u32 + 464, ctx.r22.u32);
loc_82DD299C:
	// lbz r11,1(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd29ec
	if (ctx.cr6.eq) goto loc_82DD29EC;
	// lbz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 8);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bge cr6,0x82dd29c8
	if (!ctx.cr6.lt) goto loc_82DD29C8;
	// stb r29,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r29.u8);
loc_82DD29C8:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// bge cr6,0x82dd29d8
	if (!ctx.cr6.lt) goto loc_82DD29D8;
	// stb r29,666(r31)
	PPC_STORE_U8(ctx.r31.u32 + 666, ctx.r29.u8);
loc_82DD29D8:
	// stb r29,678(r31)
	PPC_STORE_U8(ctx.r31.u32 + 678, ctx.r29.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DD29EC:
	// add r11,r25,r30
	ctx.r11.u64 = ctx.r25.u64 + ctx.r30.u64;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r11,1148(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1148);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r29,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r29.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lbz r11,2(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 2);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2a58
	if (ctx.cr6.eq) goto loc_82DD2A58;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DD2A58:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2A6C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,253
	ctx.r10.u64 = ctx.r10.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,251
	ctx.r10.u64 = ctx.r10.u64 & 251;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2AAC:
	// lwz r10,2040(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2040);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82dd2ae0
	if (!ctx.cr6.eq) goto loc_82DD2AE0;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r29,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r29.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd2ae0
	goto loc_82DD2AE0;
loc_82DD2AD8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd16c0
	ctx.lr = 0x82DD2AE0;
	sub_82DD16C0(ctx, base);
loc_82DD2AE0:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add. r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82dd2b08
	if (!ctx.cr0.eq) goto loc_82DD2B08;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD2B08:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2b34
	if (ctx.cr6.eq) goto loc_82DD2B34;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e02c60
	ctx.lr = 0x82DD2B30;
	sub_82E02C60(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD2B34:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2b88
	if (ctx.cr6.eq) goto loc_82DD2B88;
	// lwz r10,492(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// lfs f0,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,2028(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2028);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mullw r11,r10,r8
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DD2B84;
	sub_82D99380(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD2B88:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2bd0
	if (ctx.cr6.eq) goto loc_82DD2BD0;
	// lwz r10,488(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// lfs f0,2020(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 2020);
	ctx.f0.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f30
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DD2BCC;
	sub_82D99540(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD2BD0:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2c20
	if (ctx.cr6.eq) goto loc_82DD2C20;
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bge cr6,0x82dd2bf8
	if (!ctx.cr6.lt) goto loc_82DD2BF8;
	// li r10,1
	ctx.r10.s64 = 1;
loc_82DD2BF8:
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// divw r11,r21,r10
	ctx.r11.s32 = ctx.r21.s32 / ctx.r10.s32;
	// twllei r10,0
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DD2C1C;
	sub_82D9B8E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD2C20:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd2c6c
	if (ctx.cr6.eq) goto loc_82DD2C6C;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r29,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r29.u8);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// bl 0x82d9cb18
	ctx.lr = 0x82DD2C58;
	sub_82D9CB18(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DD2C64;
	sub_82D8B3E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r29,504(r11)
	PPC_STORE_U32(ctx.r11.u32 + 504, ctx.r29.u32);
loc_82DD2C6C:
	// lwz r11,756(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 756);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r26,r26,5
	ctx.r26.s64 = ctx.r26.s64 + 5;
	// cmpw cr6,r25,r11
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd2404
	if (ctx.cr6.lt) goto loc_82DD2404;
loc_82DD2C80:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f29,-128(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// lfd f30,-120(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f31,-112(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD2C98"))) PPC_WEAK_FUNC(sub_82DD2C98);
PPC_FUNC_IMPL(__imp__sub_82DD2C98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dd2d5c
	if (!ctx.cr6.eq) goto loc_82DD2D5C;
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2ce0
	if (ctx.cr6.eq) goto loc_82DD2CE0;
	// lbz r11,2038(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2038);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd2ce0
	if (!ctx.cr6.eq) goto loc_82DD2CE0;
	// bl 0x82e02b60
	ctx.lr = 0x82DD2CDC;
	sub_82E02B60(ctx, base);
	// b 0x82dd2d70
	goto loc_82DD2D70;
loc_82DD2CE0:
	// lwz r11,2072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2072);
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dd2cf8
	if (ctx.cr6.lt) goto loc_82DD2CF8;
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// stw r10,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r10.u32);
loc_82DD2CF8:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dd2d0c
	if (ctx.cr6.lt) goto loc_82DD2D0C;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82DD2D0C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd17e0
	ctx.lr = 0x82DD2D14;
	sub_82DD17E0(ctx, base);
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82dd2d70
	if (!ctx.cr6.eq) goto loc_82DD2D70;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
	// blt cr6,0x82dd2d70
	if (ctx.cr6.lt) goto loc_82DD2D70;
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// lwz r10,1280(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1280);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
	// blt cr6,0x82dd2d54
	if (ctx.cr6.lt) goto loc_82DD2D54;
	// lwz r11,2012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2012);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
loc_82DD2D54:
	// stw r30,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r30.u32);
	// b 0x82dd2d70
	goto loc_82DD2D70;
loc_82DD2D5C:
	// clrlwi r11,r4,24
	ctx.r11.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2d70
	if (ctx.cr6.eq) goto loc_82DD2D70;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd2358
	ctx.lr = 0x82DD2D70;
	sub_82DD2358(ctx, base);
loc_82DD2D70:
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// lwz r10,2044(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2044);
	// lwz r9,2060(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2060);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r11.u32);
	// blt cr6,0x82dd2d98
	if (ctx.cr6.lt) goto loc_82DD2D98;
	// stw r30,2060(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2060, ctx.r30.u32);
	// stw r30,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r30.u32);
loc_82DD2D98:
	// lwz r10,1136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,1132(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,1136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1136, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD2DC4"))) PPC_WEAK_FUNC(sub_82DD2DC4);
PPC_FUNC_IMPL(__imp__sub_82DD2DC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD2DC8"))) PPC_WEAK_FUNC(sub_82DD2DC8);
PPC_FUNC_IMPL(__imp__sub_82DD2DC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DD2DD0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DD2DDC;
	sub_82E02B60(ctx, base);
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// li r27,0
	ctx.r27.s64 = 0;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd2e2c
	if (!ctx.cr6.gt) goto loc_82DD2E2C;
	// addi r30,r31,2076
	ctx.r30.s64 = ctx.r31.s64 + 2076;
loc_82DD2DF4:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd2e18
	if (ctx.cr6.eq) goto loc_82DD2E18;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD2E14;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r27,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r27.u32);
loc_82DD2E18:
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,48
	ctx.r30.s64 = ctx.r30.s64 + 48;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd2df4
	if (ctx.cr6.lt) goto loc_82DD2DF4;
loc_82DD2E2C:
	// lwz r4,1020(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1020);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r28,-31909
	ctx.r28.s64 = -2091188224;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// addi r29,r11,9672
	ctx.r29.s64 = ctx.r11.s64 + 9672;
	// beq cr6,0x82dd2e60
	if (ctx.cr6.eq) goto loc_82DD2E60;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2525
	ctx.r6.s64 = 2525;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD2E5C;
	sub_82D861B0(ctx, base);
	// stw r27,1020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1020, ctx.r27.u32);
loc_82DD2E60:
	// lwz r3,1024(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1024);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd2e74
	if (ctx.cr6.eq) goto loc_82DD2E74;
	// bl 0x82da94d0
	ctx.lr = 0x82DD2E70;
	sub_82DA94D0(ctx, base);
	// stw r27,1024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1024, ctx.r27.u32);
loc_82DD2E74:
	// lwz r4,1028(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd2e9c
	if (ctx.cr6.eq) goto loc_82DD2E9C;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2536
	ctx.r6.s64 = 2536;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD2E98;
	sub_82D861B0(ctx, base);
	// stw r27,1028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1028, ctx.r27.u32);
loc_82DD2E9C:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd2f28
	if (ctx.cr6.eq) goto loc_82DD2F28;
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// mr r26,r27
	ctx.r26.u64 = ctx.r27.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd2f08
	if (!ctx.cr6.gt) goto loc_82DD2F08;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
loc_82DD2EBC:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd2ef4
	if (ctx.cr6.eq) goto loc_82DD2EF4;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2546
	ctx.r6.s64 = 2546;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD2EE8;
	sub_82D861B0(ctx, base);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r27,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r27.u32);
loc_82DD2EF4:
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// cmpw cr6,r26,r11
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd2ebc
	if (ctx.cr6.lt) goto loc_82DD2EBC;
loc_82DD2F08:
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2551
	ctx.r6.s64 = 2551;
	// lwz r4,488(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD2F24;
	sub_82D861B0(ctx, base);
	// stw r27,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r27.u32);
loc_82DD2F28:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// mr r26,r27
	ctx.r26.u64 = ctx.r27.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd2f78
	if (!ctx.cr6.gt) goto loc_82DD2F78;
	// addi r30,r31,760
	ctx.r30.s64 = ctx.r31.s64 + 760;
loc_82DD2F3C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd2f64
	if (ctx.cr6.eq) goto loc_82DD2F64;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2559
	ctx.r6.s64 = 2559;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD2F60;
	sub_82D861B0(ctx, base);
	// stw r27,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r27.u32);
loc_82DD2F64:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r26,r11
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd2f3c
	if (ctx.cr6.lt) goto loc_82DD2F3C;
loc_82DD2F78:
	// lwz r4,496(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd2fa0
	if (ctx.cr6.eq) goto loc_82DD2FA0;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2566
	ctx.r6.s64 = 2566;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD2F9C;
	sub_82D861B0(ctx, base);
	// stw r27,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r27.u32);
loc_82DD2FA0:
	// lwz r3,492(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 492);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd2fc4
	if (ctx.cr6.eq) goto loc_82DD2FC4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD2FC0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r27,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r27.u32);
loc_82DD2FC4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD2FD0"))) PPC_WEAK_FUNC(sub_82DD2FD0);
PPC_FUNC_IMPL(__imp__sub_82DD2FD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DD2FD8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,256
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 256, ctx.xer);
	// bne cr6,0x82dd3004
	if (!ctx.cr6.eq) goto loc_82DD3004;
	// bl 0x82e032f8
	ctx.lr = 0x82DD2FF0;
	sub_82E032F8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r30.u32);
	// stw r30,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DD3004:
	// cmplwi cr6,r6,2
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 2, ctx.xer);
	// bne cr6,0x82dd3080
	if (!ctx.cr6.eq) goto loc_82DD3080;
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dd3074
	if (ctx.cr6.eq) goto loc_82DD3074;
	// bge cr6,0x82dd302c
	if (!ctx.cr6.lt) goto loc_82DD302C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e032f8
	ctx.lr = 0x82DD3028;
	sub_82E032F8(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
loc_82DD302C:
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82dd3050
	if (!ctx.cr6.lt) goto loc_82DD3050;
loc_82DD3038:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd2c98
	ctx.lr = 0x82DD3044;
	sub_82DD2C98(ctx, base);
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82dd3038
	if (ctx.cr6.lt) goto loc_82DD3038;
loc_82DD3050:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd3074
	if (ctx.cr6.eq) goto loc_82DD3074;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lbz r30,2036(r31)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2036);
	// lbz r29,2037(r31)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// bl 0x82e02b60
	ctx.lr = 0x82DD306C;
	sub_82E02B60(ctx, base);
	// stb r30,2036(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2036, ctx.r30.u8);
	// stb r29,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r29.u8);
loc_82DD3074:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DD3080:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD308C"))) PPC_WEAK_FUNC(sub_82DD308C);
PPC_FUNC_IMPL(__imp__sub_82DD308C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD3090"))) PPC_WEAK_FUNC(sub_82DD3090);
PPC_FUNC_IMPL(__imp__sub_82DD3090) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd30a0
	if (!ctx.cr6.eq) goto loc_82DD30A0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD30A0:
	// b 0x82dd2dc8
	sub_82DD2DC8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD30A4"))) PPC_WEAK_FUNC(sub_82DD30A4);
PPC_FUNC_IMPL(__imp__sub_82DD30A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD30A8"))) PPC_WEAK_FUNC(sub_82DD30A8);
PPC_FUNC_IMPL(__imp__sub_82DD30A8) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd30b8
	if (!ctx.cr6.eq) goto loc_82DD30B8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD30B8:
	// b 0x82dd2fd0
	sub_82DD2FD0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD30BC"))) PPC_WEAK_FUNC(sub_82DD30BC);
PPC_FUNC_IMPL(__imp__sub_82DD30BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD30C0"))) PPC_WEAK_FUNC(sub_82DD30C0);
PPC_FUNC_IMPL(__imp__sub_82DD30C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// bl 0x82e032f8
	ctx.lr = 0x82DD30E4;
	sub_82E032F8(ctx, base);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd311c
	if (!ctx.cr6.eq) goto loc_82DD311C;
loc_82DD30F0:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd2c98
	ctx.lr = 0x82DD30FC;
	sub_82DD2C98(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,1132(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// lwz r9,272(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd30f0
	if (ctx.cr6.eq) goto loc_82DD30F0;
loc_82DD311C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DD3124;
	sub_82E02B60(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD313C"))) PPC_WEAK_FUNC(sub_82DD313C);
PPC_FUNC_IMPL(__imp__sub_82DD313C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD3140"))) PPC_WEAK_FUNC(sub_82DD3140);
PPC_FUNC_IMPL(__imp__sub_82DD3140) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DD3148;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r21,r5
	ctx.r21.u64 = ctx.r5.u64;
	// mr r20,r6
	ctx.r20.u64 = ctx.r6.u64;
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r22,4408(r10)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4408);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// beq cr6,0x82dd32ac
	if (ctx.cr6.eq) goto loc_82DD32AC;
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dd32ac
	if (ctx.cr6.gt) goto loc_82DD32AC;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,12700
	ctx.r12.s64 = ctx.r12.s64 + 12700;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD3208;
	case 1:
		goto loc_82DD31C8;
	case 2:
		goto loc_82DD31D0;
	case 3:
		goto loc_82DD31D8;
	case 4:
		goto loc_82DD31E0;
	case 5:
		goto loc_82DD31E0;
	case 6:
		goto loc_82DD3208;
	case 7:
		goto loc_82DD3208;
	case 8:
		goto loc_82DD3208;
	case 9:
		goto loc_82DD3208;
	case 10:
		goto loc_82DD3208;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12808);
	// lwz r22,12744(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12744);
	// lwz r22,12752(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12752);
	// lwz r22,12760(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12760);
	// lwz r22,12768(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12768);
	// lwz r22,12768(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12768);
	// lwz r22,12808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12808);
	// lwz r22,12808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12808);
	// lwz r22,12808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12808);
	// lwz r22,12808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12808);
	// lwz r22,12808(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12808);
loc_82DD31C8:
	// li r11,8
	ctx.r11.s64 = 8;
	// b 0x82dd31e4
	goto loc_82DD31E4;
loc_82DD31D0:
	// li r11,16
	ctx.r11.s64 = 16;
	// b 0x82dd31e4
	goto loc_82DD31E4;
loc_82DD31D8:
	// li r11,24
	ctx.r11.s64 = 24;
	// b 0x82dd31e4
	goto loc_82DD31E4;
loc_82DD31E0:
	// li r11,32
	ctx.r11.s64 = 32;
loc_82DD31E4:
	// li r9,0
	ctx.r9.s64 = 0;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// rldimi r9,r21,3,29
	ctx.r9.u64 = (__builtin_rotateleft64(ctx.r21.u64, 3) & 0x7FFFFFFF8) | (ctx.r9.u64 & 0xFFFFFFF800000007);
	// tdllei r11,0
	// divdu r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 / ctx.r11.u64;
	// twllei r10,0
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd32b0
	goto loc_82DD32B0;
loc_82DD3208:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,12832
	ctx.r12.s64 = ctx.r12.s64 + 12832;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,12956(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12956);
	// lwz r22,12972(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12972);
	// lwz r22,12972(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12972);
	// lwz r22,12972(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12972);
	// lwz r22,12972(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12972);
	// lwz r22,12972(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12972);
	// lwz r22,12876(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12876);
	// lwz r22,12896(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12896);
	// lwz r22,12928(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12928);
	// lwz r22,12948(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12948);
	// lwz r22,12948(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12948);
	// mulli r11,r21,14
	ctx.r11.s64 = ctx.r21.s64 * 14;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd32b0
	goto loc_82DD32B0;
	// lis r9,14563
	ctx.r9.s64 = 954400768;
	// rlwinm r11,r21,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 6) & 0xFFFFFFC0;
	// ori r9,r9,36409
	ctx.r9.u64 = ctx.r9.u64 | 36409;
	// twllei r10,0
	// mulhwu r11,r11,r9
	ctx.r11.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd32b0
	goto loc_82DD32B0;
	// mulli r11,r21,28
	ctx.r11.s64 = ctx.r21.s64 * 28;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd32b0
	goto loc_82DD32B0;
	// mr r24,r21
	ctx.r24.u64 = ctx.r21.u64;
	// b 0x82dd32b0
	goto loc_82DD32B0;
	// li r11,0
	ctx.r11.s64 = 0;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd32b0
	goto loc_82DD32B0;
loc_82DD32AC:
	// lwz r24,88(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD32B0:
	// lbz r11,2036(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd3538
	if (ctx.cr6.eq) goto loc_82DD3538;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,2016(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 2016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x82dd3538
	if (ctx.cr6.eq) goto loc_82DD3538;
	// lwz r27,1128(r25)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1128);
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82dd3534
	if (ctx.cr6.eq) goto loc_82DD3534;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// lwz r29,88(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// ori r30,r11,18725
	ctx.r30.u64 = ctx.r11.u64 | 18725;
loc_82DD32F0:
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82dd331c
	if (!ctx.cr6.eq) goto loc_82DD331C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82dd2c98
	ctx.lr = 0x82DD3308;
	sub_82DD2C98(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd3548
	if (!ctx.cr6.eq) goto loc_82DD3548;
	// lwz r11,1132(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1132);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// b 0x82dd3320
	goto loc_82DD3320;
loc_82DD331C:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82DD3320:
	// add r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 + ctx.r28.u64;
	// cmplw cr6,r10,r24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r24.u32, ctx.xer);
	// ble cr6,0x82dd3330
	if (!ctx.cr6.gt) goto loc_82DD3330;
	// subf r11,r28,r24
	ctx.r11.s64 = ctx.r24.s64 - ctx.r28.s64;
loc_82DD3330:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82da41c0
	ctx.lr = 0x82DD333C;
	sub_82DA41C0(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dd3384
	if (ctx.cr6.eq) goto loc_82DD3384;
	// lwz r3,492(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 492);
	// li r9,1000
	ctx.r9.s64 = 1000;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD3370;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x82dd3550
	if (!ctx.cr6.eq) goto loc_82DD3550;
	// lwz r3,492(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 492);
	// bl 0x82d938a0
	ctx.lr = 0x82DD3384;
	sub_82D938A0(ctx, base);
loc_82DD3384:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DD338C;
	sub_82DA4200(ctx, base);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dd34fc
	if (ctx.cr6.gt) goto loc_82DD34FC;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,13240
	ctx.r12.s64 = ctx.r12.s64 + 13240;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD3424;
	case 1:
		goto loc_82DD33E4;
	case 2:
		goto loc_82DD33F4;
	case 3:
		goto loc_82DD3404;
	case 4:
		goto loc_82DD3414;
	case 5:
		goto loc_82DD3414;
	case 6:
		goto loc_82DD3424;
	case 7:
		goto loc_82DD3424;
	case 8:
		goto loc_82DD3424;
	case 9:
		goto loc_82DD3424;
	case 10:
		goto loc_82DD3424;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13348);
	// lwz r22,13284(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13284);
	// lwz r22,13300(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13300);
	// lwz r22,13316(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13316);
	// lwz r22,13332(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13332);
	// lwz r22,13332(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13332);
	// lwz r22,13348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13348);
	// lwz r22,13348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13348);
	// lwz r22,13348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13348);
	// lwz r22,13348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13348);
	// lwz r22,13348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13348);
loc_82DD33E4:
	// li r11,8
	ctx.r11.s64 = 8;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd34f4
	goto loc_82DD34F4;
loc_82DD33F4:
	// li r11,16
	ctx.r11.s64 = 16;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd34f4
	goto loc_82DD34F4;
loc_82DD3404:
	// li r11,24
	ctx.r11.s64 = 24;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd34f4
	goto loc_82DD34F4;
loc_82DD3414:
	// li r11,32
	ctx.r11.s64 = 32;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd34f4
	goto loc_82DD34F4;
loc_82DD3424:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,13372
	ctx.r12.s64 = ctx.r12.s64 + 13372;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,13552(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13552);
	// lwz r22,13564(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13564);
	// lwz r22,13564(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13564);
	// lwz r22,13564(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13564);
	// lwz r22,13564(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13564);
	// lwz r22,13564(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13564);
	// lwz r22,13416(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13416);
	// lwz r22,13468(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13468);
	// lwz r22,13492(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13492);
	// lwz r22,13544(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13544);
	// lwz r22,13544(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 13544);
	// addi r11,r9,13
	ctx.r11.s64 = ctx.r9.s64 + 13;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd34f4
	goto loc_82DD34F4;
	// addi r11,r9,63
	ctx.r11.s64 = ctx.r9.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dd34f4
	goto loc_82DD34F4;
	// addi r11,r9,27
	ctx.r11.s64 = ctx.r9.s64 + 27;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dd34f4
	goto loc_82DD34F4;
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// b 0x82dd34fc
	goto loc_82DD34FC;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD34F4:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mullw r29,r11,r10
	ctx.r29.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82DD34FC:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r26,r4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82dd3520
	if (ctx.cr6.eq) goto loc_82DD3520;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dd3520
	if (ctx.cr6.eq) goto loc_82DD3520;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DD351C;
	sub_82CB1160(ctx, base);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD3520:
	// add r28,r9,r28
	ctx.r28.u64 = ctx.r9.u64 + ctx.r28.u64;
	// add r26,r29,r26
	ctx.r26.u64 = ctx.r29.u64 + ctx.r26.u64;
	// subf r27,r9,r27
	ctx.r27.s64 = ctx.r27.s64 - ctx.r9.s64;
	// cmplw cr6,r28,r24
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82dd32f0
	if (ctx.cr6.lt) goto loc_82DD32F0;
loc_82DD3534:
	// stw r27,1128(r25)
	PPC_STORE_U32(ctx.r25.u32 + 1128, ctx.r27.u32);
loc_82DD3538:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82dd3544
	if (ctx.cr6.eq) goto loc_82DD3544;
	// stw r21,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r21.u32);
loc_82DD3544:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD3548:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DD3550:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DD3558;
	sub_82DA4200(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD3564"))) PPC_WEAK_FUNC(sub_82DD3564);
PPC_FUNC_IMPL(__imp__sub_82DD3564) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD3568"))) PPC_WEAK_FUNC(sub_82DD3568);
PPC_FUNC_IMPL(__imp__sub_82DD3568) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd3578
	if (!ctx.cr6.eq) goto loc_82DD3578;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD3578:
	// b 0x82dd3140
	sub_82DD3140(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD357C"))) PPC_WEAK_FUNC(sub_82DD357C);
PPC_FUNC_IMPL(__imp__sub_82DD357C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD3580"))) PPC_WEAK_FUNC(sub_82DD3580);
PPC_FUNC_IMPL(__imp__sub_82DD3580) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DD35AC;
	sub_82D9B4A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD35C4"))) PPC_WEAK_FUNC(sub_82DD35C4);
PPC_FUNC_IMPL(__imp__sub_82DD35C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD35C8"))) PPC_WEAK_FUNC(sub_82DD35C8);
PPC_FUNC_IMPL(__imp__sub_82DD35C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DD35D0;
	__savegprlr_14(ctx, base);
	// stwu r1,-2736(r1)
	ea = -2736 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// stw r4,2764(r1)
	PPC_STORE_U32(ctx.r1.u32 + 2764, ctx.r4.u32);
	// stw r5,2772(r1)
	PPC_STORE_U32(ctx.r1.u32 + 2772, ctx.r5.u32);
	// lwz r11,224(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// lwz r11,388(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dd3604
	if (ctx.cr6.eq) goto loc_82DD3604;
loc_82DD35F8:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,2736
	ctx.r1.s64 = ctx.r1.s64 + 2736;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DD3604:
	// lwz r11,20(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r25,0
	ctx.r25.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,19872(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19872, ctx.r11.u32);
	// li r11,17
	ctx.r11.s64 = 17;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// stw r25,220(r28)
	PPC_STORE_U32(ctx.r28.u32 + 220, ctx.r25.u32);
	// stw r25,24(r28)
	PPC_STORE_U32(ctx.r28.u32 + 24, ctx.r25.u32);
	// stw r25,28(r28)
	PPC_STORE_U32(ctx.r28.u32 + 28, ctx.r25.u32);
	// stw r11,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r11.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DD3638;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD3658;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,44
	ctx.r4.s64 = 44;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3670;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// bl 0x82da76a0
	ctx.lr = 0x82DD3690;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r27,r11,9764
	ctx.r27.s64 = ctx.r11.s64 + 9764;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82da45e8
	ctx.lr = 0x82DD36B0;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd35f8
	if (!ctx.cr6.eq) goto loc_82DD35F8;
	// addi r30,r28,760
	ctx.r30.s64 = ctx.r28.s64 + 760;
	// li r17,64
	ctx.r17.s64 = 64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r10,r17
	ctx.r10.u64 = ctx.r17.u64;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DD36D0:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82dd36d0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD36D0;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r10,6
	ctx.r10.s64 = 6;
	// stw r25,488(r28)
	PPC_STORE_U32(ctx.r28.u32 + 488, ctx.r25.u32);
	// li r9,125
	ctx.r9.s64 = 125;
	// stb r17,1276(r28)
	PPC_STORE_U8(ctx.r28.u32 + 1276, ctx.r17.u8);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r25,1284(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1284, ctx.r25.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r25,2012(r28)
	PPC_STORE_U32(ctx.r28.u32 + 2012, ctx.r25.u32);
	// lfs f0,15108(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15108);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// stfs f0,2020(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 2020, temp.u32);
	// stw r10,1140(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1140, ctx.r10.u32);
	// stw r9,1144(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1144, ctx.r9.u32);
	// addi r31,r28,1140
	ctx.r31.s64 = ctx.r28.s64 + 1140;
	// addi r29,r28,1144
	ctx.r29.s64 = ctx.r28.s64 + 1144;
	// lfs f13,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,2016(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + 2016, temp.u32);
	// bl 0x82da7e70
	ctx.lr = 0x82DD372C;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r28,232
	ctx.r4.s64 = ctx.r28.s64 + 232;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,28
	ctx.r6.s64 = 28;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82da76a0
	ctx.lr = 0x82DD374C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD3760;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,32
	ctx.r4.s64 = 32;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3778;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD378C;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r28,1296
	ctx.r4.s64 = ctx.r28.s64 + 1296;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7d80
	ctx.lr = 0x82DD37A0;
	sub_82DA7D80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD37B4;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD37C8;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// li r26,1
	ctx.r26.s64 = 1;
	// rlwinm r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd37ec
	if (ctx.cr6.eq) goto loc_82DD37EC;
	// sth r26,2034(r28)
	PPC_STORE_U16(ctx.r28.u32 + 2034, ctx.r26.u16);
	// b 0x82dd37f0
	goto loc_82DD37F0;
loc_82DD37EC:
	// sth r25,2034(r28)
	PPC_STORE_U16(ctx.r28.u32 + 2034, ctx.r25.u16);
loc_82DD37F0:
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD37FC;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lhz r11,82(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// clrlwi r11,r11,20
	ctx.r11.u64 = ctx.r11.u32 & 0xFFF;
	// cmplwi cr6,r11,300
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 300, ctx.xer);
	// bne cr6,0x82dd3818
	if (!ctx.cr6.eq) goto loc_82DD3818;
	// sth r26,2034(r28)
	PPC_STORE_U16(ctx.r28.u32 + 2034, ctx.r26.u16);
loc_82DD3818:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,44
	ctx.r4.s64 = 44;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3828;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// bl 0x82da76a0
	ctx.lr = 0x82DD3848;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x82da45e8
	ctx.lr = 0x82DD3860;
	sub_82DA45E8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd35f8
	if (!ctx.cr6.eq) goto loc_82DD35F8;
	// addi r4,r28,2028
	ctx.r4.s64 = ctx.r28.s64 + 2028;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DD3874;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c40
	ctx.lr = 0x82DD3888;
	sub_82DA7C40(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7b50
	ctx.lr = 0x82DD389C;
	sub_82DA7B50(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,94
	ctx.r4.s64 = ctx.r1.s64 + 94;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD38B0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD38C4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,98
	ctx.r4.s64 = ctx.r1.s64 + 98;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD38D8;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,64
	ctx.r4.s64 = 64;
	// bl 0x82da7e70
	ctx.lr = 0x82DD38F0;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// stw r25,756(r28)
	PPC_STORE_U32(ctx.r28.u32 + 756, ctx.r25.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r15,r28,756
	ctx.r15.s64 = ctx.r28.s64 + 756;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
	// li r18,255
	ctx.r18.s64 = 255;
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// std r10,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r10.u64);
	// std r10,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r10.u64);
	// std r10,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r10.u64);
loc_82DD3920:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD392C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// bge cr6,0x82dd3970
	if (!ctx.cr6.lt) goto loc_82DD3970;
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// cmplwi cr6,r10,7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 7, ctx.xer);
	// stbx r11,r31,r9
	PPC_STORE_U8(ctx.r31.u32 + ctx.r9.u32, ctx.r11.u8);
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// bgt cr6,0x82dd3960
	if (ctx.cr6.gt) goto loc_82DD3960;
	// stb r25,1148(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1148, ctx.r25.u8);
	// b 0x82dd3964
	goto loc_82DD3964;
loc_82DD3960:
	// stb r18,1148(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1148, ctx.r18.u8);
loc_82DD3964:
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r15)
	PPC_STORE_U32(ctx.r15.u32 + 0, ctx.r11.u32);
loc_82DD3970:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmpwi cr6,r31,32
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 32, ctx.xer);
	// blt cr6,0x82dd3920
	if (ctx.cr6.lt) goto loc_82DD3920;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r5,r11,9168
	ctx.r5.s64 = ctx.r11.s64 + 9168;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r15
	ctx.r6.u64 = ctx.r15.u64;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DD39A0;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// mr r29,r25
	ctx.r29.u64 = ctx.r25.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r14,r11,9672
	ctx.r14.s64 = ctx.r11.s64 + 9672;
	// ble cr6,0x82dd3a28
	if (!ctx.cr6.gt) goto loc_82DD3A28;
loc_82DD39C0:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1760
	ctx.r6.s64 = 1760;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// li r4,704
	ctx.r4.s64 = 704;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD39E0;
	sub_82D862B0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dd3a04
	if (ctx.cr6.eq) goto loc_82DD3A04;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r25,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r25.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DD3A00;
	sub_82D9B4A8(ctx, base);
	// b 0x82dd3a08
	goto loc_82DD3A08;
loc_82DD3A04:
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
loc_82DD3A08:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd39c0
	if (ctx.cr6.lt) goto loc_82DD39C0;
loc_82DD3A28:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,96
	ctx.r4.s64 = 96;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3A38;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r31,r28,500
	ctx.r31.s64 = ctx.r28.s64 + 500;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// lhz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r1.u32 + 96);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD3A5C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lhz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 96);
	// stw r25,1280(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1280, ctx.r25.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r25,1284(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1284, ctx.r25.u32);
	// beq cr6,0x82dd3ad0
	if (ctx.cr6.eq) goto loc_82DD3AD0;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// subfic r9,r28,-500
	ctx.xer.ca = ctx.r28.u32 <= 4294966796;
	ctx.r9.s64 = -500 - ctx.r28.s64;
loc_82DD3A80:
	// lwz r10,1280(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1280);
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r28,r10
	ctx.r10.u64 = ctx.r28.u64 + ctx.r10.u64;
	// stb r8,500(r10)
	PPC_STORE_U8(ctx.r10.u32 + 500, ctx.r8.u8);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,254
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 254, ctx.xer);
	// bge cr6,0x82dd3abc
	if (!ctx.cr6.lt) goto loc_82DD3ABC;
	// lwz r10,1280(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1280);
	// lwz r8,1284(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1284);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,1280(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1280, ctx.r10.u32);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r8
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, ctx.xer);
	// ble cr6,0x82dd3abc
	if (!ctx.cr6.gt) goto loc_82DD3ABC;
	// stw r10,1284(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1284, ctx.r10.u32);
loc_82DD3ABC:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 96);
	// add r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmpw cr6,r8,r10
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd3a80
	if (ctx.cr6.lt) goto loc_82DD3A80;
loc_82DD3AD0:
	// addi r10,r28,1296
	ctx.r10.s64 = ctx.r28.s64 + 1296;
	// lwz r9,1284(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1284);
	// lhz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,1872
	ctx.r4.s64 = ctx.r1.s64 + 1872;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,1284(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1284, ctx.r9.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DD3B00;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r11,98(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 98);
	// cmplwi cr6,r11,252
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 252, ctx.xer);
	// bne cr6,0x82dd3b5c
	if (!ctx.cr6.eq) goto loc_82DD3B5C;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
loc_82DD3B18:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD3B24;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd3b50
	if (ctx.cr6.eq) goto loc_82DD3B50;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lbzx r11,r31,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r10.u32);
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// stb r9,1148(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1148, ctx.r9.u8);
loc_82DD3B50:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmpwi cr6,r31,32
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 32, ctx.xer);
	// blt cr6,0x82dd3b18
	if (ctx.cr6.lt) goto loc_82DD3B18;
loc_82DD3B5C:
	// lbz r11,94(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 94);
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd3b88
	if (!ctx.cr6.eq) goto loc_82DD3B88;
	// addi r11,r28,1148
	ctx.r11.s64 = ctx.r28.s64 + 1148;
	// li r9,128
	ctx.r9.s64 = 128;
	// li r10,32
	ctx.r10.s64 = 32;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DD3B7C:
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bdnz 0x82dd3b7c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD3B7C;
loc_82DD3B88:
	// addi r11,r28,1296
	ctx.r11.s64 = ctx.r28.s64 + 1296;
	// mr r22,r25
	ctx.r22.u64 = ctx.r25.u64;
	// li r16,2
	ctx.r16.s64 = 2;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd3ecc
	if (!ctx.cr6.gt) goto loc_82DD3ECC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r21,r1,1472
	ctx.r21.s64 = ctx.r1.s64 + 1472;
	// addi r23,r1,1872
	ctx.r23.s64 = ctx.r1.s64 + 1872;
	// addi r29,r28,2092
	ctx.r29.s64 = ctx.r28.s64 + 2092;
	// addi r19,r11,9440
	ctx.r19.s64 = ctx.r11.s64 + 9440;
	// li r20,108
	ctx.r20.s64 = 108;
loc_82DD3BB8:
	// addi r25,r29,-16
	ctx.r25.s64 = ctx.r29.s64 + -16;
	// li r5,48
	ctx.r5.s64 = 48;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// li r24,1
	ctx.r24.s64 = 1;
	// bl 0x82cb16f0
	ctx.lr = 0x82DD3BD0;
	sub_82CB16F0(ctx, base);
	// lhz r11,0(r23)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r23.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// rotlwi r4,r11,4
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r11.u32, 4);
	// bl 0x82da7e70
	ctx.lr = 0x82DD3BE4;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,13
	ctx.r4.s64 = 13;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3BFC;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD3C10;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD3C24;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// li r7,0
	ctx.r7.s64 = 0;
	// lhz r10,82(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// li r6,1
	ctx.r6.s64 = 1;
	// rotlwi r11,r11,16
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 16);
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r5,4
	ctx.r5.s64 = 4;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
	// bl 0x82da76a0
	ctx.lr = 0x82DD3C58;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r26,r29,-4
	ctx.r26.s64 = ctx.r29.s64 + -4;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD3C7C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82da76a0
	ctx.lr = 0x82DD3C9C;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r27,r29,-12
	ctx.r27.s64 = ctx.r29.s64 + -12;
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r4,r27,4
	ctx.r4.s64 = ctx.r27.s64 + 4;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD3CC4;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7c90
	ctx.lr = 0x82DD3CD8;
	sub_82DA7C90(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r1,95
	ctx.r4.s64 = ctx.r1.s64 + 95;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD3CEC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ce0
	ctx.lr = 0x82DD3D00;
	sub_82DA7CE0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,14
	ctx.r4.s64 = 14;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3D18;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,28
	ctx.r5.s64 = 28;
	// addi r4,r1,304
	ctx.r4.s64 = ctx.r1.s64 + 304;
	// bl 0x82da76a0
	ctx.lr = 0x82DD3D38;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// addi r3,r1,448
	ctx.r3.s64 = ctx.r1.s64 + 448;
	// bl 0x82cb61f0
	ctx.lr = 0x82DD3D50;
	sub_82CB61F0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,28
	ctx.r7.s64 = 28;
	// addi r6,r1,304
	ctx.r6.s64 = ctx.r1.s64 + 304;
	// addi r5,r1,448
	ctx.r5.s64 = ctx.r1.s64 + 448;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82de89a0
	ctx.lr = 0x82DD3D70;
	sub_82DE89A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3D88;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r11,95(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 95);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd3dc4
	if (ctx.cr6.eq) goto loc_82DD3DC4;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// ble cr6,0x82dd3dc4
	if (!ctx.cr6.gt) goto loc_82DD3DC4;
	// li r30,74
	ctx.r30.s64 = 74;
	// b 0x82dd3dd4
	goto loc_82DD3DD4;
loc_82DD3DB8:
	// li r3,42
	ctx.r3.s64 = 42;
	// addi r1,r1,2736
	ctx.r1.s64 = ctx.r1.s64 + 2736;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DD3DC4:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r9.u32);
	// li r30,73
	ctx.r30.s64 = 73;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
loc_82DD3DD4:
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// li r31,1
	ctx.r31.s64 = 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd3df0
	if (ctx.cr6.eq) goto loc_82DD3DF0;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r31,r16
	ctx.r31.u64 = ctx.r16.u64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
loc_82DD3DF0:
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd3e08
	if (ctx.cr6.eq) goto loc_82DD3E08;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r24,r16
	ctx.r24.u64 = ctx.r16.u64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
loc_82DD3E08:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dd3ea8
	if (ctx.cr6.eq) goto loc_82DD3EA8;
	// addi r11,r1,336
	ctx.r11.s64 = ctx.r1.s64 + 336;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r8,13
	ctx.r8.s64 = 13;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_82DD3E20:
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dd3e20
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD3E20;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r6,r1,336
	ctx.r6.s64 = ctx.r1.s64 + 336;
	// ori r5,r30,1024
	ctx.r5.u64 = ctx.r30.u64 | 1024;
	// lwz r3,16(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r20,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, ctx.r20.u32);
	// stw r9,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r9.u32);
	// stw r24,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r24.u32);
	// stw r11,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r11.u32);
	// stw r31,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r31.u32);
	// bl 0x82d910a0
	ctx.lr = 0x82DD3E60;
	sub_82D910A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// rlwinm r11,r30,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd3ea8
	if (ctx.cr6.eq) goto loc_82DD3EA8;
	// lwz r3,0(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r4,0(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// li r5,2
	ctx.r5.s64 = 2;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// add r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 + ctx.r11.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r6,r11,-1
	ctx.r6.s64 = ctx.r11.s64 + -1;
	// lwz r11,160(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD3EA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
loc_82DD3EA8:
	// addi r11,r28,1296
	ctx.r11.s64 = ctx.r28.s64 + 1296;
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
	// addi r23,r23,2
	ctx.r23.s64 = ctx.r23.s64 + 2;
	// addi r21,r21,4
	ctx.r21.s64 = ctx.r21.s64 + 4;
	// addi r29,r29,48
	ctx.r29.s64 = ctx.r29.s64 + 48;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r22,r11
	ctx.cr6.compare<int32_t>(ctx.r22.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd3bb8
	if (ctx.cr6.lt) goto loc_82DD3BB8;
	// li r25,0
	ctx.r25.s64 = 0;
loc_82DD3ECC:
	// lwz r11,1284(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1284);
	// lhz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dd3ee0
	if (ctx.cr6.gt) goto loc_82DD3EE0;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82DD3EE0:
	// stw r11,1288(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1288, ctx.r11.u32);
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2015
	ctx.r6.s64 = 2015;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD3F04;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,488(r28)
	PPC_STORE_U32(ctx.r28.u32 + 488, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// lhz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd4114
	if (ctx.cr6.eq) goto loc_82DD4114;
	// li r24,0
	ctx.r24.s64 = 0;
	// mr r26,r24
	ctx.r26.u64 = ctx.r24.u64;
loc_82DD3F28:
	// addi r11,r28,1296
	ctx.r11.s64 = ctx.r28.s64 + 1296;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// addi r10,r1,1872
	ctx.r10.s64 = ctx.r1.s64 + 1872;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 + ctx.r25.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r10.u32);
	// rotlwi r11,r11,4
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 4);
	// addi r4,r11,2
	ctx.r4.s64 = ctx.r11.s64 + 2;
	// bl 0x82da7e70
	ctx.lr = 0x82DD3F54;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r11,488(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 488);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// add r29,r26,r11
	ctx.r29.u64 = ctx.r26.u64 + ctx.r11.u64;
	// li r6,2050
	ctx.r6.s64 = 2050;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// stw r17,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r17.u32);
	// lwz r10,19872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19872);
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r4,r11,6,0,25
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x82d862b0
	ctx.lr = 0x82DD3F94;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// mr r27,r24
	ctx.r27.u64 = ctx.r24.u64;
loc_82DD3FA4:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD3FB0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82dd40ec
	if (ctx.cr6.eq) goto loc_82DD40EC;
	// clrlwi r10,r8,27
	ctx.r10.u64 = ctx.r8.u32 & 0x1F;
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// lbzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bge cr6,0x82dd3ff8
	if (!ctx.cr6.lt) goto loc_82DD3FF8;
	// mullw r11,r11,r27
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r27.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// add r31,r11,r10
	ctx.r31.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82dd3ffc
	goto loc_82DD3FFC;
loc_82DD3FF8:
	// addi r31,r1,104
	ctx.r31.s64 = ctx.r1.s64 + 104;
loc_82DD3FFC:
	// rlwinm r11,r8,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd407c
	if (ctx.cr6.eq) goto loc_82DD407C;
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7b00
	ctx.lr = 0x82DD4014;
	sub_82DA7B00(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lhz r10,82(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,254
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 254, ctx.xer);
	// beq cr6,0x82dd4064
	if (ctx.cr6.eq) goto loc_82DD4064;
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// beq cr6,0x82dd405c
	if (ctx.cr6.eq) goto loc_82DD405C;
	// rlwinm r9,r10,28,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFF;
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stb r11,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r11.u8);
	// b 0x82dd4068
	goto loc_82DD4068;
loc_82DD405C:
	// stb r24,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r24.u8);
	// b 0x82dd4068
	goto loc_82DD4068;
loc_82DD4064:
	// stb r18,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r18.u8);
loc_82DD4068:
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD4074;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
loc_82DD407C:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// rlwinm r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd40b0
	if (ctx.cr6.eq) goto loc_82DD40B0;
	// addi r30,r31,2
	ctx.r30.s64 = ctx.r31.s64 + 2;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82da7ab0
	ctx.lr = 0x82DD409C;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stb r11,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r11.u8);
loc_82DD40B0:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd40f0
	if (ctx.cr6.eq) goto loc_82DD40F0;
	// addi r4,r31,3
	ctx.r4.s64 = ctx.r31.s64 + 3;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD40CC;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// addi r4,r31,4
	ctx.r4.s64 = ctx.r31.s64 + 4;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// bl 0x82da7ab0
	ctx.lr = 0x82DD40E0;
	sub_82DA7AB0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// b 0x82dd40f0
	goto loc_82DD40F0;
loc_82DD40EC:
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
loc_82DD40F0:
	// cmpwi cr6,r27,64
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 64, ctx.xer);
	// blt cr6,0x82dd3fa4
	if (ctx.cr6.lt) goto loc_82DD3FA4;
	// lhz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 92);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r26,r26,8
	ctx.r26.s64 = ctx.r26.s64 + 8;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmpw cr6,r25,r10
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd3f28
	if (ctx.cr6.lt) goto loc_82DD3F28;
	// li r25,0
	ctx.r25.s64 = 0;
loc_82DD4114:
	// lwz r10,1284(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1284);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// ble cr6,0x82dd418c
	if (!ctx.cr6.gt) goto loc_82DD418C;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmpw cr6,r29,r10
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dd418c
	if (!ctx.cr6.lt) goto loc_82DD418C;
	// rlwinm r30,r29,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 3) & 0xFFFFFFF8;
loc_82DD4134:
	// lwz r11,488(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 488);
	// lis r10,-31909
	ctx.r10.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// add r31,r30,r11
	ctx.r31.u64 = ctx.r30.u64 + ctx.r11.u64;
	// li r6,2170
	ctx.r6.s64 = 2170;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// stw r17,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r17.u32);
	// lwz r10,19872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19872);
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r4,r11,6,0,25
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x82d862b0
	ctx.lr = 0x82DD416C;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// lwz r11,1284(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1284);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd4134
	if (ctx.cr6.lt) goto loc_82DD4134;
loc_82DD418C:
	// addi r11,r28,1296
	ctx.r11.s64 = ctx.r28.s64 + 1296;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd4554
	if (!ctx.cr6.gt) goto loc_82DD4554;
	// addi r26,r1,1472
	ctx.r26.s64 = ctx.r1.s64 + 1472;
	// addi r27,r28,2076
	ctx.r27.s64 = ctx.r28.s64 + 2076;
loc_82DD41A4:
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// rlwinm r4,r11,4,0,27
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82da7e70
	ctx.lr = 0x82DD41B8;
	sub_82DA7E70(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd4534
	if (ctx.cr6.eq) goto loc_82DD4534;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD41E4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,104
	ctx.r7.s64 = ctx.r1.s64 + 104;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD4218;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd4510
	if (ctx.cr6.eq) goto loc_82DD4510;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82dd4510
	if (ctx.cr6.eq) goto loc_82DD4510;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// lwz r11,64(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// bne cr6,0x82dd43b0
	if (!ctx.cr6.eq) goto loc_82DD43B0;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dd426c
	if (!ctx.cr6.eq) goto loc_82DD426C;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// rlwinm r6,r6,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	// li r5,2
	ctx.r5.s64 = 2;
	// bl 0x82da76a0
	ctx.lr = 0x82DD4268;
	sub_82DA76A0(ctx, base);
	// b 0x82dd436c
	goto loc_82DD436C;
loc_82DD426C:
	// rlwinm r30,r6,30,2,31
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dd42ec
	if (ctx.cr6.eq) goto loc_82DD42EC;
loc_82DD427C:
	// cmplwi cr6,r30,512
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dd428c
	if (ctx.cr6.gt) goto loc_82DD428C;
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
loc_82DD428C:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,448
	ctx.r4.s64 = ctx.r1.s64 + 448;
	// bl 0x82da76a0
	ctx.lr = 0x82DD42A4;
	sub_82DA76A0(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dd42d8
	if (ctx.cr6.eq) goto loc_82DD42D8;
	// rlwinm r9,r29,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,448
	ctx.r10.s64 = ctx.r1.s64 + 448;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82DD42B8:
	// lhz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// sthx r8,r9,r7
	PPC_STORE_U16(ctx.r9.u32 + ctx.r7.u32, ctx.r8.u16);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne cr6,0x82dd42b8
	if (!ctx.cr6.eq) goto loc_82DD42B8;
loc_82DD42D8:
	// subf r30,r31,r30
	ctx.r30.s64 = ctx.r30.s64 - ctx.r31.s64;
	// add r29,r31,r29
	ctx.r29.u64 = ctx.r31.u64 + ctx.r29.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dd427c
	if (!ctx.cr6.eq) goto loc_82DD427C;
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD42EC:
	// rlwinm r30,r6,30,2,31
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dd4370
	if (ctx.cr6.eq) goto loc_82DD4370;
loc_82DD42FC:
	// cmplwi cr6,r30,512
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dd430c
	if (ctx.cr6.gt) goto loc_82DD430C;
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
loc_82DD430C:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,448
	ctx.r4.s64 = ctx.r1.s64 + 448;
	// bl 0x82da76a0
	ctx.lr = 0x82DD4324;
	sub_82DA76A0(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dd435c
	if (ctx.cr6.eq) goto loc_82DD435C;
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,448
	ctx.r9.s64 = ctx.r1.s64 + 448;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82DD4338:
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lhz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// sth r7,2(r8)
	PPC_STORE_U16(ctx.r8.u32 + 2, ctx.r7.u16);
	// bne cr6,0x82dd4338
	if (!ctx.cr6.eq) goto loc_82DD4338;
loc_82DD435C:
	// subf r30,r31,r30
	ctx.r30.s64 = ctx.r30.s64 - ctx.r31.s64;
	// add r29,r31,r29
	ctx.r29.u64 = ctx.r31.u64 + ctx.r29.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dd42fc
	if (!ctx.cr6.eq) goto loc_82DD42FC;
loc_82DD436C:
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD4370:
	// rlwinm r11,r6,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd44fc
	if (ctx.cr6.eq) goto loc_82DD44FC;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD4384:
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lhzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r9.u32 + ctx.r11.u32);
	// xori r8,r8,32768
	ctx.r8.u64 = ctx.r8.u64 ^ 32768;
	// sthx r8,r9,r11
	PPC_STORE_U16(ctx.r9.u32 + ctx.r11.u32, ctx.r8.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// rlwinm r9,r6,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82dd4384
	if (ctx.cr6.lt) goto loc_82DD4384;
	// b 0x82dd44fc
	goto loc_82DD44FC;
loc_82DD43B0:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82dd43d4
	if (!ctx.cr6.eq) goto loc_82DD43D4;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82da76a0
	ctx.lr = 0x82DD43C8;
	sub_82DA76A0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// b 0x82dd44cc
	goto loc_82DD44CC;
loc_82DD43D4:
	// rlwinm r30,r6,30,2,31
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dd4450
	if (ctx.cr6.eq) goto loc_82DD4450;
loc_82DD43E4:
	// cmplwi cr6,r30,512
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dd43f4
	if (ctx.cr6.gt) goto loc_82DD43F4;
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
loc_82DD43F4:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,448
	ctx.r4.s64 = ctx.r1.s64 + 448;
	// bl 0x82da76a0
	ctx.lr = 0x82DD440C;
	sub_82DA76A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dd443c
	if (ctx.cr6.eq) goto loc_82DD443C;
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DD441C:
	// addi r9,r1,448
	ctx.r9.s64 = ctx.r1.s64 + 448;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stbx r9,r8,r10
	PPC_STORE_U8(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u8);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// blt cr6,0x82dd441c
	if (ctx.cr6.lt) goto loc_82DD441C;
loc_82DD443C:
	// subf r30,r31,r30
	ctx.r30.s64 = ctx.r30.s64 - ctx.r31.s64;
	// add r29,r31,r29
	ctx.r29.u64 = ctx.r31.u64 + ctx.r29.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dd43e4
	if (!ctx.cr6.eq) goto loc_82DD43E4;
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD4450:
	// rlwinm r30,r6,30,2,31
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82dd44d0
	if (ctx.cr6.eq) goto loc_82DD44D0;
loc_82DD4460:
	// cmplwi cr6,r30,512
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 512, ctx.xer);
	// li r31,512
	ctx.r31.s64 = 512;
	// bgt cr6,0x82dd4470
	if (ctx.cr6.gt) goto loc_82DD4470;
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
loc_82DD4470:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,224(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 224);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,448
	ctx.r4.s64 = ctx.r1.s64 + 448;
	// bl 0x82da76a0
	ctx.lr = 0x82DD4488;
	sub_82DA76A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82dd44bc
	if (ctx.cr6.eq) goto loc_82DD44BC;
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
loc_82DD4498:
	// addi r8,r1,448
	ctx.r8.s64 = ctx.r1.s64 + 448;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lbzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// stb r8,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r8.u8);
	// blt cr6,0x82dd4498
	if (ctx.cr6.lt) goto loc_82DD4498;
loc_82DD44BC:
	// subf r30,r31,r30
	ctx.r30.s64 = ctx.r30.s64 - ctx.r31.s64;
	// add r29,r31,r29
	ctx.r29.u64 = ctx.r31.u64 + ctx.r29.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82dd4460
	if (!ctx.cr6.eq) goto loc_82DD4460;
loc_82DD44CC:
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD44D0:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82dd44fc
	if (ctx.cr6.eq) goto loc_82DD44FC;
loc_82DD44DC:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lbzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// xori r9,r9,128
	ctx.r9.u64 = ctx.r9.u64 ^ 128;
	// stbx r9,r11,r10
	PPC_STORE_U8(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r11,r6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82dd44dc
	if (ctx.cr6.lt) goto loc_82DD44DC;
loc_82DD44FC:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dd450c
	if (ctx.cr6.eq) goto loc_82DD450C;
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
loc_82DD450C:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82DD4510:
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r7,120(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD452C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
loc_82DD4534:
	// addi r11,r28,1296
	ctx.r11.s64 = ctx.r28.s64 + 1296;
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r26,r26,4
	ctx.r26.s64 = ctx.r26.s64 + 4;
	// addi r27,r27,48
	ctx.r27.s64 = ctx.r27.s64 + 48;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r25,r11
	ctx.cr6.compare<int32_t>(ctx.r25.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd41a4
	if (ctx.cr6.lt) goto loc_82DD41A4;
	// li r25,0
	ctx.r25.s64 = 0;
loc_82DD4554:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2357
	ctx.r6.s64 = 2357;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// li r4,296
	ctx.r4.s64 = 296;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD4574;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,56(r28)
	PPC_STORE_U32(ctx.r28.u32 + 56, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r31,5
	ctx.r31.s64 = 5;
	// lwz r11,2772(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 2772);
	// stw r3,28(r28)
	PPC_STORE_U32(ctx.r28.u32 + 28, ctx.r3.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,268(r3)
	PPC_STORE_U32(ctx.r3.u32 + 268, ctx.r10.u32);
	// beq cr6,0x82dd45b8
	if (ctx.cr6.eq) goto loc_82DD45B8;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dd45b8
	if (ctx.cr6.eq) goto loc_82DD45B8;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// lwz r26,2764(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 2764);
	// stw r11,256(r10)
	PPC_STORE_U32(ctx.r10.u32 + 256, ctx.r11.u32);
	// b 0x82dd45d8
	goto loc_82DD45D8;
loc_82DD45B8:
	// lwz r26,2764(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 2764);
	// rlwinm r11,r26,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// beq cr6,0x82dd45d4
	if (ctx.cr6.eq) goto loc_82DD45D4;
	// stw r31,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r31.u32);
	// b 0x82dd45d8
	goto loc_82DD45D8;
loc_82DD45D4:
	// stw r16,256(r11)
	PPC_STORE_U32(ctx.r11.u32 + 256, ctx.r16.u32);
loc_82DD45D8:
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r4,r28,232
	ctx.r4.s64 = ctx.r28.s64 + 232;
	// stw r16,260(r11)
	PPC_STORE_U32(ctx.r11.u32 + 260, ctx.r16.u32);
	// lwz r3,28(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// bl 0x82da4468
	ctx.lr = 0x82DD45F0;
	sub_82DA4468(ctx, base);
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// addi r11,r11,264
	ctx.r11.s64 = ctx.r11.s64 + 264;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd460c
	if (ctx.cr6.eq) goto loc_82DD460C;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lwz r10,1244(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1244);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
loc_82DD460C:
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// stw r25,156(r28)
	PPC_STORE_U32(ctx.r28.u32 + 156, ctx.r25.u32);
	// lwz r10,256(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lwz r9,260(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// bgt cr6,0x82dd4728
	if (ctx.cr6.gt) goto loc_82DD4728;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,17980
	ctx.r12.s64 = ctx.r12.s64 + 17980;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD46A8;
	case 1:
		goto loc_82DD4668;
	case 2:
		goto loc_82DD4678;
	case 3:
		goto loc_82DD4688;
	case 4:
		goto loc_82DD4698;
	case 5:
		goto loc_82DD4698;
	case 6:
		goto loc_82DD46A8;
	case 7:
		goto loc_82DD46A8;
	case 8:
		goto loc_82DD46A8;
	case 9:
		goto loc_82DD46A8;
	case 10:
		goto loc_82DD46A8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18088(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18088);
	// lwz r22,18024(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18024);
	// lwz r22,18040(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18040);
	// lwz r22,18056(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18056);
	// lwz r22,18072(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18072);
	// lwz r22,18072(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18072);
	// lwz r22,18088(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18088);
	// lwz r22,18088(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18088);
	// lwz r22,18088(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18088);
	// lwz r22,18088(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18088);
	// lwz r22,18088(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18088);
loc_82DD4668:
	// li r10,8
	ctx.r10.s64 = 8;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
loc_82DD4678:
	// li r10,16
	ctx.r10.s64 = 16;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
loc_82DD4688:
	// li r10,24
	ctx.r10.s64 = 24;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
loc_82DD4698:
	// li r10,32
	ctx.r10.s64 = 32;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
loc_82DD46A8:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,18112
	ctx.r12.s64 = ctx.r12.s64 + 18112;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,18200(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18200);
	// lwz r22,18216(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18216);
	// lwz r22,18216(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18216);
	// lwz r22,18216(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18216);
	// lwz r22,18216(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18216);
	// lwz r22,18216(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18216);
	// lwz r22,18156(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18156);
	// lwz r22,18168(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18168);
	// lwz r22,18180(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18180);
	// lwz r22,18192(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18192);
	// lwz r22,18192(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 18192);
	// li r10,8
	ctx.r10.s64 = 8;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
	// li r10,36
	ctx.r10.s64 = 36;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
	// li r10,16
	ctx.r10.s64 = 16;
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
	// b 0x82dd471c
	goto loc_82DD471C;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82dd4724
	goto loc_82DD4724;
	// stw r25,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r25.u32);
loc_82DD471C:
	// lwz r10,276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// mullw r10,r9,r10
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
loc_82DD4724:
	// stw r10,276(r11)
	PPC_STORE_U32(ctx.r11.u32 + 276, ctx.r10.u32);
loc_82DD4728:
	// addi r11,r1,252
	ctx.r11.s64 = ctx.r1.s64 + 252;
	// stw r25,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, ctx.r25.u32);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// li r10,17
	ctx.r10.s64 = 17;
	// stw r11,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, ctx.r11.u32);
	// addi r11,r1,252
	ctx.r11.s64 = ctx.r1.s64 + 252;
	// stw r11,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r11.u32);
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82DD474C:
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82dd474c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82DD474C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// addi r4,r11,9740
	ctx.r4.s64 = ctx.r11.s64 + 9740;
	// bl 0x82da4448
	ctx.lr = 0x82DD4768;
	sub_82DA4448(ctx, base);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// addi r27,r28,492
	ctx.r27.s64 = ctx.r28.s64 + 492;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// lwz r3,16(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// stw r10,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r10.u32);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// stw r10,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// stw r31,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r31.u32);
	// stw r11,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r11.u32);
	// bl 0x82d8ced0
	ctx.lr = 0x82DD47A4;
	sub_82D8CED0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r6,2422
	ctx.r6.s64 = 2422;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,220(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 220, temp.u32);
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// mulli r4,r11,608
	ctx.r4.s64 = ctx.r11.s64 * 608;
	// stw r11,1016(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1016, ctx.r11.u32);
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD47F8;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1020(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1020, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// lwz r11,1016(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1016);
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd4850
	if (!ctx.cr6.gt) goto loc_82DD4850;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
loc_82DD4818:
	// lwz r11,1020(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1020);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd483c
	if (ctx.cr6.eq) goto loc_82DD483C;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stw r25,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r25.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DD483C;
	sub_82D9B4A8(ctx, base);
loc_82DD483C:
	// lwz r11,1016(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1016);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r31,r31,608
	ctx.r31.s64 = ctx.r31.s64 + 608;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd4818
	if (ctx.cr6.lt) goto loc_82DD4818;
loc_82DD4850:
	// lis r31,-31909
	ctx.r31.s64 = -2091188224;
	// lwz r10,1016(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1016);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2439
	ctx.r6.s64 = 2439;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r11,19872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 19872);
	// rlwinm r29,r10,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD4878;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd4888
	if (ctx.cr6.eq) goto loc_82DD4888;
	// bl 0x82da9430
	ctx.lr = 0x82DD4884;
	sub_82DA9430(ctx, base);
	// b 0x82dd488c
	goto loc_82DD488C;
loc_82DD4888:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
loc_82DD488C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,1024(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1024, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lwz r4,16(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82da9450
	ctx.lr = 0x82DD48A8;
	sub_82DA9450(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd49ac
	if (!ctx.cr6.eq) goto loc_82DD49AC;
	// lwz r11,19872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2451
	ctx.r6.s64 = 2451;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// mulli r4,r29,760
	ctx.r4.s64 = ctx.r29.s64 * 760;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD48CC;
	sub_82D862B0(ctx, base);
	// stw r3,1028(r28)
	PPC_STORE_U32(ctx.r28.u32 + 1028, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82dd4938
	if (!ctx.cr6.gt) goto loc_82DD4938;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
loc_82DD48E8:
	// lwz r11,1028(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1028);
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd48fc
	if (ctx.cr6.eq) goto loc_82DD48FC;
	// bl 0x82e01520
	ctx.lr = 0x82DD48FC;
	sub_82E01520(ctx, base);
loc_82DD48FC:
	// lwz r11,1028(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1028);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r6,0(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// add r5,r11,r31
	ctx.r5.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r3,1024(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1024);
	// bl 0x82da9828
	ctx.lr = 0x82DD4914;
	sub_82DA9828(ctx, base);
	// lwz r11,1028(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1028);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r31,r31,760
	ctx.r31.s64 = ctx.r31.s64 + 760;
	// cmpw cr6,r30,r29
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r29.s32, ctx.xer);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// ori r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 2048;
	// stw r10,104(r11)
	PPC_STORE_U32(ctx.r11.u32 + 104, ctx.r10.u32);
	// blt cr6,0x82dd48e8
	if (ctx.cr6.lt) goto loc_82DD48E8;
loc_82DD4938:
	// rlwinm r11,r26,0,17,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd4964
	if (!ctx.cr6.eq) goto loc_82DD4964;
	// rlwinm r11,r26,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd4964
	if (!ctx.cr6.eq) goto loc_82DD4964;
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r25,496(r28)
	PPC_STORE_U32(ctx.r28.u32 + 496, ctx.r25.u32);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// b 0x82dd499c
	goto loc_82DD499C;
loc_82DD4964:
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// lwz r10,1280(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1280);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2467
	ctx.r6.s64 = 2467;
	// mr r5,r14
	ctx.r5.u64 = ctx.r14.u64;
	// rlwinm r4,r10,8,0,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// lwz r11,19872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 19872);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d862b0
	ctx.lr = 0x82DD4988;
	sub_82D862B0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,496(r28)
	PPC_STORE_U32(ctx.r28.u32 + 496, ctx.r3.u32);
	// beq cr6,0x82dd3db8
	if (ctx.cr6.eq) goto loc_82DD3DB8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82dd30c0
	ctx.lr = 0x82DD499C;
	sub_82DD30C0(ctx, base);
loc_82DD499C:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r25,24(r28)
	PPC_STORE_U32(ctx.r28.u32 + 24, ctx.r25.u32);
	// bl 0x82e032f8
	ctx.lr = 0x82DD49A8;
	sub_82E032F8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD49AC:
	// addi r1,r1,2736
	ctx.r1.s64 = ctx.r1.s64 + 2736;
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD49B4"))) PPC_WEAK_FUNC(sub_82DD49B4);
PPC_FUNC_IMPL(__imp__sub_82DD49B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD49B8"))) PPC_WEAK_FUNC(sub_82DD49B8);
PPC_FUNC_IMPL(__imp__sub_82DD49B8) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd49c8
	if (!ctx.cr6.eq) goto loc_82DD49C8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD49C8:
	// b 0x82dd35c8
	sub_82DD35C8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD49CC"))) PPC_WEAK_FUNC(sub_82DD49CC);
PPC_FUNC_IMPL(__imp__sub_82DD49CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD49D0"))) PPC_WEAK_FUNC(sub_82DD49D0);
PPC_FUNC_IMPL(__imp__sub_82DD49D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31909
	ctx.r11.s64 = -2091188224;
	// li r5,92
	ctx.r5.s64 = 92;
	// addi r31,r11,31160
	ctx.r31.s64 = ctx.r11.s64 + 31160;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cb16f0
	ctx.lr = 0x82DD49FC;
	sub_82CB16F0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r30,-32035
	ctx.r30.s64 = -2099445760;
	// addi r11,r11,9772
	ctx.r11.s64 = ctx.r11.s64 + 9772;
	// lis r3,-32035
	ctx.r3.s64 = -2099445760;
	// lis r4,-32035
	ctx.r4.s64 = -2099445760;
	// lis r5,-32032
	ctx.r5.s64 = -2099249152;
	// lis r6,-32035
	ctx.r6.s64 = -2099445760;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// lis r7,-32032
	ctx.r7.s64 = -2099249152;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// lis r8,-32032
	ctx.r8.s64 = -2099249152;
	// lis r9,-32032
	ctx.r9.s64 = -2099249152;
	// lis r10,-32032
	ctx.r10.s64 = -2099249152;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// li r11,1794
	ctx.r11.s64 = 1794;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r30,18872
	ctx.r11.s64 = ctx.r30.s64 + 18872;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r11,r3,12432
	ctx.r11.s64 = ctx.r3.s64 + 12432;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// addi r11,r4,13672
	ctx.r11.s64 = ctx.r4.s64 + 13672;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r11,r5,12544
	ctx.r11.s64 = ctx.r5.s64 + 12544;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// addi r11,r6,12456
	ctx.r11.s64 = ctx.r6.s64 + 12456;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// addi r11,r7,12656
	ctx.r11.s64 = ctx.r7.s64 + 12656;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// addi r11,r8,12752
	ctx.r11.s64 = ctx.r8.s64 + 12752;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// addi r11,r9,12800
	ctx.r11.s64 = ctx.r9.s64 + 12800;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// addi r11,r10,12904
	ctx.r11.s64 = ctx.r10.s64 + 12904;
	// stw r11,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r11.u32);
	// li r11,17
	ctx.r11.s64 = 17;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// li r11,6828
	ctx.r11.s64 = 6828;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD4ABC"))) PPC_WEAK_FUNC(sub_82DD4ABC);
PPC_FUNC_IMPL(__imp__sub_82DD4ABC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD4AC0"))) PPC_WEAK_FUNC(sub_82DD4AC0);
PPC_FUNC_IMPL(__imp__sub_82DD4AC0) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r10,388(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	// beq cr6,0x82dd4ae4
	if (ctx.cr6.eq) goto loc_82DD4AE4;
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stw r10,388(r11)
	PPC_STORE_U32(ctx.r11.u32 + 388, ctx.r10.u32);
	// blr 
	return;
loc_82DD4AE4:
	// rlwinm r10,r10,0,29,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// stw r10,388(r11)
	PPC_STORE_U32(ctx.r11.u32 + 388, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD4AF0"))) PPC_WEAK_FUNC(sub_82DD4AF0);
PPC_FUNC_IMPL(__imp__sub_82DD4AF0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-19064
	ctx.r11.s64 = ctx.r11.s64 + -19064;
	// twllei r5,0
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r11,-4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// divwu r3,r11,r5
	ctx.r3.u32 = ctx.r11.u32 / ctx.r5.u32;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD4B14"))) PPC_WEAK_FUNC(sub_82DD4B14);
PPC_FUNC_IMPL(__imp__sub_82DD4B14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD4B18"))) PPC_WEAK_FUNC(sub_82DD4B18);
PPC_FUNC_IMPL(__imp__sub_82DD4B18) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dd4b4c
	if (!ctx.cr6.lt) goto loc_82DD4B4C;
	// lbz r9,660(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// rotlwi r9,r9,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 2);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82dd4b4c
	if (!ctx.cr6.gt) goto loc_82DD4B4C;
	// stw r9,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r9.u32);
loc_82DD4B4C:
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82dd4b80
	if (!ctx.cr6.gt) goto loc_82DD4B80;
	// lbz r10,660(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r9,656(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 656);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82dd4b80
	if (!ctx.cr6.lt) goto loc_82DD4B80;
	// stw r9,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r9.u32);
loc_82DD4B80:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD4B94"))) PPC_WEAK_FUNC(sub_82DD4B94);
PPC_FUNC_IMPL(__imp__sub_82DD4B94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD4B98"))) PPC_WEAK_FUNC(sub_82DD4B98);
PPC_FUNC_IMPL(__imp__sub_82DD4B98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,694(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// lbz r11,662(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r9,r11,27
	ctx.r9.u64 = ctx.r11.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dd4c44
	if (ctx.cr6.gt) goto loc_82DD4C44;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,19428
	ctx.r12.s64 = ctx.r12.s64 + 19428;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD4BF4;
	case 1:
		goto loc_82DD4C08;
	case 2:
		goto loc_82DD4C30;
	case 3:
		goto loc_82DD4C38;
	default:
		__builtin_unreachable();
	}
	// lwz r22,19444(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19444);
	// lwz r22,19464(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19464);
	// lwz r22,19504(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19504);
	// lwz r22,19512(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19512);
loc_82DD4BF4:
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// addi r11,r11,-19352
	ctx.r11.s64 = ctx.r11.s64 + -19352;
	// lbzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82dd4c48
	goto loc_82DD4C48;
loc_82DD4C08:
	// rlwinm r10,r9,3,21,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x7F8;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dd4c28
	if (!ctx.cr6.lt) goto loc_82DD4C28;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DD4C28:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dd4c48
	goto loc_82DD4C48;
loc_82DD4C30:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dd4c48
	goto loc_82DD4C48;
loc_82DD4C38:
	// bl 0x82cb2308
	ctx.lr = 0x82DD4C3C;
	sub_82CB2308(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// b 0x82dd4c48
	goto loc_82DD4C48;
loc_82DD4C44:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD4C48:
	// lbz r10,664(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 664);
	// lbz r9,662(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// srawi r11,r11,5
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 5;
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// blt cr6,0x82dd4c68
	if (ctx.cr6.lt) goto loc_82DD4C68;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
loc_82DD4C68:
	// stw r11,496(r30)
	PPC_STORE_U32(ctx.r30.u32 + 496, ctx.r11.u32);
	// lbz r10,662(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 662);
	// lbz r9,663(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 663);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
	// ble cr6,0x82dd4c94
	if (!ctx.cr6.gt) goto loc_82DD4C94;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r11.u8);
loc_82DD4C94:
	// lbz r11,476(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stb r11,476(r30)
	PPC_STORE_U8(ctx.r30.u32 + 476, ctx.r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD4CBC"))) PPC_WEAK_FUNC(sub_82DD4CBC);
PPC_FUNC_IMPL(__imp__sub_82DD4CBC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD4CC0"))) PPC_WEAK_FUNC(sub_82DD4CC0);
PPC_FUNC_IMPL(__imp__sub_82DD4CC0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,694(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 694);
	// lbz r9,666(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 666);
	// rlwinm r10,r11,28,30,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0x3;
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r11,r9,27
	ctx.r11.u64 = ctx.r9.u32 & 0x1F;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bgt cr6,0x82dd4d48
	if (ctx.cr6.gt) goto loc_82DD4D48;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,19700
	ctx.r12.s64 = ctx.r12.s64 + 19700;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD4D04;
	case 1:
		goto loc_82DD4D18;
	case 2:
		goto loc_82DD4D40;
	case 3:
		goto loc_82DD4D04;
	default:
		__builtin_unreachable();
	}
	// lwz r22,19716(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19716);
	// lwz r22,19736(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19736);
	// lwz r22,19776(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19776);
	// lwz r22,19716(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 19716);
loc_82DD4D04:
	// lis r10,-31908
	ctx.r10.s64 = -2091122688;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r10,r10,-19352
	ctx.r10.s64 = ctx.r10.s64 + -19352;
	// lbzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// b 0x82dd4d4c
	goto loc_82DD4D4C;
loc_82DD4D18:
	// rlwinm r11,r11,3,21,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0x7F8;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dd4d38
	if (!ctx.cr6.lt) goto loc_82DD4D38;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// subfic r11,r11,255
	ctx.xer.ca = ctx.r11.u32 <= 255;
	ctx.r11.s64 = 255 - ctx.r11.s64;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82DD4D38:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// b 0x82dd4d4c
	goto loc_82DD4D4C;
loc_82DD4D40:
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82dd4d4c
	goto loc_82DD4D4C;
loc_82DD4D48:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD4D4C:
	// lbz r10,668(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 668);
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// lwz r10,484(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 484);
	// srawi r11,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 6;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// blt cr6,0x82dd4d7c
	if (ctx.cr6.lt) goto loc_82DD4D7C;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + ctx.r11.u64;
	// cmpwi cr6,r9,64
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 64, ctx.xer);
	// ble cr6,0x82dd4d90
	if (!ctx.cr6.gt) goto loc_82DD4D90;
	// subfic r11,r10,64
	ctx.xer.ca = ctx.r10.u32 <= 64;
	ctx.r11.s64 = 64 - ctx.r10.s64;
	// b 0x82dd4d90
	goto loc_82DD4D90;
loc_82DD4D7C:
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bge cr6,0x82dd4d90
	if (!ctx.cr6.lt) goto loc_82DD4D90;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82DD4D90:
	// stw r11,492(r8)
	PPC_STORE_U32(ctx.r8.u32 + 492, ctx.r11.u32);
	// lbz r10,666(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 666);
	// lbz r9,667(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 667);
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,31
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 31, ctx.xer);
	// stb r11,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r11.u8);
	// ble cr6,0x82dd4dbc
	if (!ctx.cr6.gt) goto loc_82DD4DBC;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// stb r11,666(r3)
	PPC_STORE_U8(ctx.r3.u32 + 666, ctx.r11.u8);
loc_82DD4DBC:
	// lbz r11,476(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 476);
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stb r11,476(r8)
	PPC_STORE_U8(ctx.r8.u32 + 476, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD4DD0"))) PPC_WEAK_FUNC(sub_82DD4DD0);
PPC_FUNC_IMPL(__imp__sub_82DD4DD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b0
	ctx.lr = 0x82DD4DD8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6ae8
	ctx.lr = 0x82DD4DE0;
	__savefpr_28(ctx, base);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r16,r23
	ctx.r16.u64 = ctx.r23.u64;
	// lwz r9,2056(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2056);
	// lwz r7,488(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 488);
	// add r8,r9,r30
	ctx.r8.u64 = ctx.r9.u64 + ctx.r30.u64;
	// lwz r10,2052(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// lwz r11,756(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 756);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// lbz r8,500(r8)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + 500);
	// rotlwi r8,r8,3
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 3);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// add r24,r8,r11
	ctx.r24.u64 = ctx.r8.u64 + ctx.r11.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82dd568c
	if (ctx.cr6.eq) goto loc_82DD568C;
	// lwz r11,496(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 496);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd4e70
	if (ctx.cr6.eq) goto loc_82DD4E70;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lbzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82dd4e68
	if (ctx.cr6.eq) goto loc_82DD4E68;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r11,2037(r30)
	PPC_STORE_U8(ctx.r30.u32 + 2037, ctx.r11.u8);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DD4E64;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
loc_82DD4E68:
	// li r9,1
	ctx.r9.s64 = 1;
	// stbx r9,r11,r10
	PPC_STORE_U8(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u8);
loc_82DD4E70:
	// lwz r11,756(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 756);
	// mr r22,r23
	ctx.r22.u64 = ctx.r23.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd568c
	if (!ctx.cr6.gt) goto loc_82DD568C;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r7,-32222
	ctx.r7.s64 = -2111700992;
	// addi r20,r11,-19064
	ctx.r20.s64 = ctx.r11.s64 + -19064;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r8,-32222
	ctx.r8.s64 = -2111700992;
	// addi r19,r11,-17952
	ctx.r19.s64 = ctx.r11.s64 + -17952;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lfs f28,-17360(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -17360);
	ctx.f28.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// addi r21,r11,-17904
	ctx.r21.s64 = ctx.r11.s64 + -17904;
	// lfs f29,-17348(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -17348);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,218
	ctx.r11.s64 = 14286848;
	// clrlwi r14,r4,24
	ctx.r14.u64 = ctx.r4.u32 & 0xFF;
	// lfs f30,6380(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6380);
	ctx.f30.f64 = double(temp.f32);
	// li r15,8
	ctx.r15.s64 = 8;
	// lfs f31,-15896(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -15896);
	ctx.f31.f64 = double(temp.f32);
	// li r17,64
	ctx.r17.s64 = 64;
	// ori r18,r11,30208
	ctx.r18.u64 = ctx.r11.u64 | 30208;
loc_82DD4ECC:
	// addi r10,r22,190
	ctx.r10.s64 = ctx.r22.s64 + 190;
	// lbz r11,4(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// stw r23,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r23.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r11,28,4,31
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r29,r11,28
	ctx.r29.u64 = ctx.r11.u32 & 0xF;
	// lwzx r31,r10,r30
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82dd4f04
	if (!ctx.cr6.eq) goto loc_82DD4F04;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq cr6,0x82dd4f08
	if (ctx.cr6.eq) goto loc_82DD4F08;
loc_82DD4F04:
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82DD4F08:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd4f20
	if (ctx.cr6.eq) goto loc_82DD4F20;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// stw r19,464(r21)
	PPC_STORE_U32(ctx.r21.u32 + 464, ctx.r19.u32);
	// b 0x82dd4f24
	goto loc_82DD4F24;
loc_82DD4F20:
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
loc_82DD4F24:
	// lbz r11,1(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 1);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd4f40
	if (ctx.cr6.eq) goto loc_82DD4F40;
	// addi r11,r11,255
	ctx.r11.s64 = ctx.r11.s64 + 255;
	// stb r11,608(r31)
	PPC_STORE_U8(ctx.r31.u32 + 608, ctx.r11.u8);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD4F40:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// lwz r10,1296(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1296);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dd4f68
	if (!ctx.cr6.lt) goto loc_82DD4F68;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r25,r11,2076
	ctx.r25.s64 = ctx.r11.s64 + 2076;
	// b 0x82dd4f6c
	goto loc_82DD4F6C;
loc_82DD4F68:
	// mr r25,r19
	ctx.r25.u64 = ctx.r19.u64;
loc_82DD4F6C:
	// lbz r11,616(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 616);
	// lwz r28,484(r9)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 484);
	// lwz r27,480(r9)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + 480);
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// bne cr6,0x82dd4f9c
	if (!ctx.cr6.eq) goto loc_82DD4F9C;
	// lbz r11,3(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 3);
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82dd4f9c
	if (ctx.cr6.eq) goto loc_82DD4F9C;
	// lwz r11,492(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 492);
	// rotlwi r10,r28,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r28.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,484(r9)
	PPC_STORE_U32(ctx.r9.u32 + 484, ctx.r11.u32);
loc_82DD4F9C:
	// lbz r11,3(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 3);
	// stb r11,616(r31)
	PPC_STORE_U8(ctx.r31.u32 + 616, ctx.r11.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,492(r11)
	PPC_STORE_U32(ctx.r11.u32 + 492, ctx.r23.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r23,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r23.u8);
	// lbz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5084
	if (ctx.cr6.eq) goto loc_82DD5084;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r11,r21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r21.u32, ctx.xer);
	// bne cr6,0x82dd5000
	if (!ctx.cr6.eq) goto loc_82DD5000;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DD4FF0;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dd5000
	if (ctx.cr6.eq) goto loc_82DD5000;
	// stw r21,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r21.u32);
	// stw r19,464(r21)
	PPC_STORE_U32(ctx.r21.u32 + 464, ctx.r19.u32);
loc_82DD5000:
	// lbz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 0);
	// add r9,r22,r30
	ctx.r9.u64 = ctx.r22.u64 + ctx.r30.u64;
	// rotlwi r10,r11,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// add r10,r10,r20
	ctx.r10.u64 = ctx.r10.u64 + ctx.r20.u64;
	// stb r11,609(r31)
	PPC_STORE_U8(ctx.r31.u32 + 609, ctx.r11.u8);
	// lwz r11,-4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// twllei r10,0
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// lbz r11,1148(r9)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 1148);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bge cr6,0x82dd504c
	if (!ctx.cr6.lt) goto loc_82DD504C;
	// stb r23,662(r31)
	PPC_STORE_U8(ctx.r31.u32 + 662, ctx.r23.u8);
loc_82DD504C:
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// bge cr6,0x82dd505c
	if (!ctx.cr6.lt) goto loc_82DD505C;
	// stb r23,666(r31)
	PPC_STORE_U8(ctx.r31.u32 + 666, ctx.r23.u8);
loc_82DD505C:
	// lbz r11,3(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 3);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82dd507c
	if (ctx.cr6.eq) goto loc_82DD507C;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// beq cr6,0x82dd507c
	if (ctx.cr6.eq) goto loc_82DD507C;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
loc_82DD507C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r15,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r15.u8);
loc_82DD5084:
	// lbz r11,1(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd509c
	if (ctx.cr6.eq) goto loc_82DD509C;
	// lbz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 8);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
loc_82DD509C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,496(r11)
	PPC_STORE_U32(ctx.r11.u32 + 496, ctx.r23.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,7
	ctx.r10.u64 = ctx.r10.u64 | 7;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lbz r11,3(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 3);
	// addi r11,r11,-3
	ctx.r11.s64 = ctx.r11.s64 + -3;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82dd54e8
	if (ctx.cr6.gt) goto loc_82DD54E8;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,20700
	ctx.r12.s64 = ctx.r12.s64 + 20700;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD5120;
	case 1:
		goto loc_82DD515C;
	case 2:
		goto loc_82DD5130;
	case 3:
		goto loc_82DD54E8;
	case 4:
		goto loc_82DD5180;
	case 5:
		goto loc_82DD51B4;
	case 6:
		goto loc_82DD51D8;
	case 7:
		goto loc_82DD54E8;
	case 8:
		goto loc_82DD5214;
	case 9:
		goto loc_82DD5110;
	case 10:
		goto loc_82DD523C;
	case 11:
		goto loc_82DD52BC;
	case 12:
		goto loc_82DD5294;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20768(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20768);
	// lwz r22,20828(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20828);
	// lwz r22,20784(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20784);
	// lwz r22,21736(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21736);
	// lwz r22,20864(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20864);
	// lwz r22,20916(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20916);
	// lwz r22,20952(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20952);
	// lwz r22,21736(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21736);
	// lwz r22,21012(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21012);
	// lwz r22,20752(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20752);
	// lwz r22,21052(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21052);
	// lwz r22,21180(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21180);
	// lwz r22,21140(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21140);
loc_82DD5110:
	// lbz r11,4(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5120:
	// lbz r11,4(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5130
	if (ctx.cr6.eq) goto loc_82DD5130;
	// stb r11,660(r31)
	PPC_STORE_U8(ctx.r31.u32 + 660, ctx.r11.u8);
loc_82DD5130:
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// stw r11,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD515C:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd516c
	if (ctx.cr6.eq) goto loc_82DD516C;
	// stb r26,663(r31)
	PPC_STORE_U8(ctx.r31.u32 + 663, ctx.r26.u8);
loc_82DD516C:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd54e8
	if (ctx.cr6.eq) goto loc_82DD54E8;
	// stb r29,664(r31)
	PPC_STORE_U8(ctx.r31.u32 + 664, ctx.r29.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5180:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5190
	if (ctx.cr6.eq) goto loc_82DD5190;
	// stb r26,667(r31)
	PPC_STORE_U8(ctx.r31.u32 + 667, ctx.r26.u8);
loc_82DD5190:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd51a0
	if (ctx.cr6.eq) goto loc_82DD51A0;
	// stb r29,668(r31)
	PPC_STORE_U8(ctx.r31.u32 + 668, ctx.r29.u8);
loc_82DD51A0:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,253
	ctx.r10.u64 = ctx.r10.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD51B4:
	// lbz r11,4(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rotlwi r11,r11,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD51D8:
	// lbz r11,4(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd51e8
	if (ctx.cr6.eq) goto loc_82DD51E8;
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
loc_82DD51E8:
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// lwz r9,12(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// rlwinm r11,r11,8,0,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFFFFFF00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82dd5208
	if (ctx.cr6.lt) goto loc_82DD5208;
	// addi r11,r10,-1
	ctx.r11.s64 = ctx.r10.s64 + -1;
loc_82DD5208:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,504(r10)
	PPC_STORE_U32(ctx.r10.u32 + 504, ctx.r11.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5214:
	// lbz r11,4(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// lwz r10,1280(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1280);
	// stw r23,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r23.u32);
	// stw r11,2072(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2072, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd5234
	if (ctx.cr6.lt) goto loc_82DD5234;
	// stw r23,2072(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2072, ctx.r23.u32);
loc_82DD5234:
	// li r16,1
	ctx.r16.s64 = 1;
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD523C:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// clrlwi r10,r29,24
	ctx.r10.u64 = ctx.r29.u32 & 0xFF;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmpwi cr6,r11,63
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 63, ctx.xer);
	// stw r11,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r11.u32);
	// ble cr6,0x82dd5264
	if (!ctx.cr6.gt) goto loc_82DD5264;
	// stw r23,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r23.u32);
loc_82DD5264:
	// clrlwi r11,r16,24
	ctx.r11.u64 = ctx.r16.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd527c
	if (!ctx.cr6.eq) goto loc_82DD527C;
	// lwz r11,2056(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2056);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,2072(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2072, ctx.r11.u32);
loc_82DD527C:
	// lwz r11,2072(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2072);
	// lwz r10,1280(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1280);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82dd54e8
	if (ctx.cr6.lt) goto loc_82DD54E8;
	// stw r23,2072(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2072, ctx.r23.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5294:
	// lbz r4,4(r24)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r24.u32 + 4);
	// cmplwi cr6,r4,32
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 32, ctx.xer);
	// bge cr6,0x82dd52b0
	if (!ctx.cr6.lt) goto loc_82DD52B0;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd54e8
	if (ctx.cr6.eq) goto loc_82DD54E8;
	// stw r4,2044(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2044, ctx.r4.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD52B0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e02ae0
	ctx.lr = 0x82DD52B8;
	sub_82E02AE0(ctx, base);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD52BC:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,13
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 13, ctx.xer);
	// bgt cr6,0x82dd54e8
	if (ctx.cr6.gt) goto loc_82DD54E8;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,21220
	ctx.r12.s64 = ctx.r12.s64 + 21220;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD531C;
	case 1:
		goto loc_82DD5334;
	case 2:
		goto loc_82DD54E8;
	case 3:
		goto loc_82DD534C;
	case 4:
		goto loc_82DD5364;
	case 5:
		goto loc_82DD5378;
	case 6:
		goto loc_82DD5404;
	case 7:
		goto loc_82DD5414;
	case 8:
		goto loc_82DD54E8;
	case 9:
		goto loc_82DD5434;
	case 10:
		goto loc_82DD5460;
	case 11:
		goto loc_82DD54E8;
	case 12:
		goto loc_82DD548C;
	case 13:
		goto loc_82DD54D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21276(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21276);
	// lwz r22,21300(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21300);
	// lwz r22,21736(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21736);
	// lwz r22,21324(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21324);
	// lwz r22,21348(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21348);
	// lwz r22,21368(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21368);
	// lwz r22,21508(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21508);
	// lwz r22,21524(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21524);
	// lwz r22,21736(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21736);
	// lwz r22,21556(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21556);
	// lwz r22,21600(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21600);
	// lwz r22,21736(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21736);
	// lwz r22,21644(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21644);
	// lwz r22,21720(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 21720);
loc_82DD531C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r9,r29,2,22,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0x3FC;
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5334:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r10,r29,2,22,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0x3FC;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD534C:
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// clrlwi r10,r29,24
	ctx.r10.u64 = ctx.r29.u32 & 0xFF;
	// rlwinm r11,r11,0,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stb r11,694(r31)
	PPC_STORE_U8(ctx.r31.u32 + 694, ctx.r11.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5364:
	// addi r5,r25,4
	ctx.r5.s64 = ctx.r25.s64 + 4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e02e10
	ctx.lr = 0x82DD5374;
	sub_82E02E10(ctx, base);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5378:
	// clrlwi r10,r29,24
	ctx.r10.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82dd5390
	if (!ctx.cr6.eq) goto loc_82DD5390;
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5390:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dd53a4
	if (!ctx.cr6.eq) goto loc_82DD53A4;
	// stw r10,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r10.u32);
	// b 0x82dd53ac
	goto loc_82DD53AC;
loc_82DD53A4:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r11.u32);
loc_82DD53AC:
	// lwz r11,688(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82dd54e8
	if (ctx.cr6.eq) goto loc_82DD54E8;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,496(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 496);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r11.u32);
	// beq cr6,0x82dd54e8
	if (ctx.cr6.eq) goto loc_82DD54E8;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// lwz r10,2052(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bgt cr6,0x82dd54e8
	if (ctx.cr6.gt) goto loc_82DD54E8;
loc_82DD53DC:
	// lwz r10,2056(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2056);
	// lwz r9,496(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 496);
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stbx r23,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + ctx.r11.u32, ctx.r23.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,2052(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82dd53dc
	if (!ctx.cr6.gt) goto loc_82DD53DC;
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5404:
	// lbz r11,694(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 694);
	// rlwimi r11,r29,4,20,27
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r29.u32, 4) & 0xFF0) | (ctx.r11.u64 & 0xFFFFFFFFFFFFF00F);
	// stb r11,694(r31)
	PPC_STORE_U8(ctx.r31.u32 + 694, ctx.r11.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5414:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r29,4,20,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 4) & 0xFF0;
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5434:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r10,r29,24
	ctx.r10.u64 = ctx.r29.u32 & 0xFF;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd54e8
	if (!ctx.cr6.gt) goto loc_82DD54E8;
	// stw r17,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r17.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD5460:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// clrlwi r9,r29,24
	ctx.r9.u64 = ctx.r29.u32 & 0xFF;
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dd54e8
	if (!ctx.cr6.lt) goto loc_82DD54E8;
	// stw r23,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r23.u32);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD548C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r28,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r28.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r27,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r27.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r23,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r23.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,253
	ctx.r10.u64 = ctx.r10.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// b 0x82dd54e8
	goto loc_82DD54E8;
loc_82DD54D8:
	// lwz r11,2044(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2044);
	// clrlwi r10,r29,24
	ctx.r10.u64 = ctx.r29.u32 & 0xFF;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,2060(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2060, ctx.r11.u32);
loc_82DD54E8:
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82dd5678
	if (ctx.cr6.eq) goto loc_82DD5678;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add. r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82dd5518
	if (!ctx.cr0.eq) goto loc_82DD5518;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5518:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5544
	if (ctx.cr6.eq) goto loc_82DD5544;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e02c60
	ctx.lr = 0x82DD5540;
	sub_82E02C60(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5544:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5594
	if (ctx.cr6.eq) goto loc_82DD5594;
	// lwz r10,492(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// lfs f0,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// extsw r11,r10
	ctx.r11.s64 = ctx.r10.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f30
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DD5590;
	sub_82D99380(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5594:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd55dc
	if (ctx.cr6.eq) goto loc_82DD55DC;
	// lwz r10,488(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// lfs f0,2020(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 2020);
	ctx.f0.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f28
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DD55D8;
	sub_82D99540(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD55DC:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd562c
	if (ctx.cr6.eq) goto loc_82DD562C;
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bge cr6,0x82dd5604
	if (!ctx.cr6.lt) goto loc_82DD5604;
	// li r10,1
	ctx.r10.s64 = 1;
loc_82DD5604:
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// divw r11,r18,r10
	ctx.r11.s32 = ctx.r18.s32 / ctx.r10.s32;
	// twllei r10,0
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DD5628;
	sub_82D9B8E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD562C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5678
	if (ctx.cr6.eq) goto loc_82DD5678;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r23,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r23.u8);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// bl 0x82d9cb18
	ctx.lr = 0x82DD5664;
	sub_82D9CB18(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DD5670;
	sub_82D8B3E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r23,504(r11)
	PPC_STORE_U32(ctx.r11.u32 + 504, ctx.r23.u32);
loc_82DD5678:
	// lwz r11,756(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 756);
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
	// addi r24,r24,5
	ctx.r24.s64 = ctx.r24.s64 + 5;
	// cmpw cr6,r22,r11
	ctx.cr6.compare<int32_t>(ctx.r22.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd4ecc
	if (ctx.cr6.lt) goto loc_82DD4ECC;
loc_82DD568C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82cb6b34
	ctx.lr = 0x82DD569C;
	__restfpr_28(ctx, base);
	// b 0x82cb1100
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD56A0"))) PPC_WEAK_FUNC(sub_82DD56A0);
PPC_FUNC_IMPL(__imp__sub_82DD56A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10b8
	ctx.lr = 0x82DD56A8;
	__savegprlr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82cb6ae8
	ctx.lr = 0x82DD56B0;
	__savefpr_28(ctx, base);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r11,2056(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2056);
	// lwz r9,488(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 488);
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lwz r8,2052(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2052);
	// lwz r10,756(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 756);
	// lbz r11,500(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 500);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mullw r11,r8,r10
	ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5da0
	if (ctx.cr6.eq) goto loc_82DD5DA0;
	// li r25,0
	ctx.r25.s64 = 0;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// mr r21,r25
	ctx.r21.u64 = ctx.r25.u64;
	// ble cr6,0x82dd5da0
	if (!ctx.cr6.gt) goto loc_82DD5DA0;
	// addi r24,r11,4
	ctx.r24.s64 = ctx.r11.s64 + 4;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r7,-32222
	ctx.r7.s64 = -2111700992;
	// addi r26,r11,-19064
	ctx.r26.s64 = ctx.r11.s64 + -19064;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lis r8,-32222
	ctx.r8.s64 = -2111700992;
	// addi r23,r11,-17904
	ctx.r23.s64 = ctx.r11.s64 + -17904;
	// lis r11,-31908
	ctx.r11.s64 = -2091122688;
	// lfs f28,-17360(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -17360);
	ctx.f28.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r20,r11,-17952
	ctx.r20.s64 = ctx.r11.s64 + -17952;
	// lis r11,21845
	ctx.r11.s64 = 1431633920;
	// lfs f29,-17348(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -17348);
	ctx.f29.f64 = double(temp.f32);
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// ori r22,r11,21846
	ctx.r22.u64 = ctx.r11.u64 | 21846;
	// lis r11,218
	ctx.r11.s64 = 14286848;
	// lfs f30,6380(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6380);
	ctx.f30.f64 = double(temp.f32);
	// addi r19,r28,760
	ctx.r19.s64 = ctx.r28.s64 + 760;
	// li r16,56
	ctx.r16.s64 = 56;
	// lfs f31,-15896(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -15896);
	ctx.f31.f64 = double(temp.f32);
	// li r18,64
	ctx.r18.s64 = 64;
	// ori r17,r11,30208
	ctx.r17.u64 = ctx.r11.u64 | 30208;
loc_82DD575C:
	// lwz r29,0(r19)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// stw r25,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r25.u32);
	// lwz r10,1296(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1296);
	// lbz r11,608(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 608);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82dd578c
	if (!ctx.cr6.lt) goto loc_82DD578C;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// addi r27,r11,2076
	ctx.r27.s64 = ctx.r11.s64 + 2076;
	// b 0x82dd5790
	goto loc_82DD5790;
loc_82DD578C:
	// mr r27,r20
	ctx.r27.u64 = ctx.r20.u64;
loc_82DD5790:
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r9,r29
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82dd57ac
	if (!ctx.cr6.eq) goto loc_82DD57AC;
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x82dd57b0
	if (ctx.cr6.eq) goto loc_82DD57B0;
loc_82DD57AC:
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
loc_82DD57B0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd57c0
	if (ctx.cr6.eq) goto loc_82DD57C0;
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
loc_82DD57C0:
	// lbz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 0);
	// lbz r10,-1(r24)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r24.u32 + -1);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// rlwinm r31,r11,28,4,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// stw r25,492(r9)
	PPC_STORE_U32(ctx.r9.u32 + 492, ctx.r25.u32);
	// clrlwi r30,r11,28
	ctx.r30.u64 = ctx.r11.u32 & 0xF;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r10,14
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 14, ctx.xer);
	// stw r25,496(r9)
	PPC_STORE_U32(ctx.r9.u32 + 496, ctx.r25.u32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stb r25,476(r9)
	PPC_STORE_U8(ctx.r9.u32 + 476, ctx.r25.u8);
	// bgt cr6,0x82dd5c00
	if (ctx.cr6.gt) goto loc_82DD5C00;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,22536
	ctx.r12.s64 = ctx.r12.s64 + 22536;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82DD5844;
	case 1:
		goto loc_82DD58E0;
	case 2:
		goto loc_82DD591C;
	case 3:
		goto loc_82DD5944;
	case 4:
		goto loc_82DD5950;
	case 5:
		goto loc_82DD595C;
	case 6:
		goto loc_82DD59E4;
	case 7:
		goto loc_82DD5A2C;
	case 8:
		goto loc_82DD5C00;
	case 9:
		goto loc_82DD5C00;
	case 10:
		goto loc_82DD5A38;
	case 11:
		goto loc_82DD5C00;
	case 12:
		goto loc_82DD5C00;
	case 13:
		goto loc_82DD5C00;
	case 14:
		goto loc_82DD5A78;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22596(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 22596);
	// lwz r22,22752(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 22752);
	// lwz r22,22812(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 22812);
	// lwz r22,22852(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 22852);
	// lwz r22,22864(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 22864);
	// lwz r22,22876(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 22876);
	// lwz r22,23012(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23012);
	// lwz r22,23084(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23084);
	// lwz r22,23552(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23552);
	// lwz r22,23552(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23552);
	// lwz r22,23096(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23096);
	// lwz r22,23552(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23552);
	// lwz r22,23552(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23552);
	// lwz r22,23552(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23552);
	// lwz r22,23160(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 23160);
loc_82DD5844:
	// lbz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5c00
	if (ctx.cr6.eq) goto loc_82DD5C00;
	// lwz r11,2040(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2040);
	// mulhw r10,r11,r22
	ctx.r10.s64 = (int64_t(ctx.r11.s32) * int64_t(ctx.r22.s32)) >> 32;
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82dd5884
	if (ctx.cr6.eq) goto loc_82DD5884;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82dd58d0
	if (!ctx.cr6.eq) goto loc_82DD58D0;
	// clrlwi r9,r30,24
	ctx.r9.u64 = ctx.r30.u32 & 0xFF;
	// b 0x82dd5888
	goto loc_82DD5888;
loc_82DD5884:
	// clrlwi r9,r31,24
	ctx.r9.u64 = ctx.r31.u32 & 0xFF;
loc_82DD5888:
	// lbz r11,609(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 609);
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// add r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rotlwi r9,r11,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r26
	ctx.r9.u64 = ctx.r9.u64 + ctx.r26.u64;
	// add r11,r11,r26
	ctx.r11.u64 = ctx.r11.u64 + ctx.r26.u64;
	// twllei r10,0
	// twllei r10,0
	// lwz r9,-4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// lwz r11,-4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// mulli r9,r9,8363
	ctx.r9.s64 = ctx.r9.s64 * 8363;
	// mulli r11,r11,8363
	ctx.r11.s64 = ctx.r11.s64 * 8363;
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// divwu r10,r9,r10
	ctx.r10.u32 = ctx.r9.u32 / ctx.r10.u32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,496(r10)
	PPC_STORE_U32(ctx.r10.u32 + 496, ctx.r11.u32);
loc_82DD58D0:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD58E0:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r24.u32 + 0);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// cmpwi cr6,r10,56
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 56, ctx.xer);
	// bge cr6,0x82dd5910
	if (!ctx.cr6.lt) goto loc_82DD5910;
	// stw r16,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r16.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5910:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD591C:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r24.u32 + 0);
	// rotlwi r10,r10,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 2);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,480(r11)
	PPC_STORE_U32(ctx.r11.u32 + 480, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD5944:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dd4b18
	ctx.lr = 0x82DD594C;
	sub_82DD4B18(ctx, base);
	// b 0x82dd5c00
	goto loc_82DD5C00;
loc_82DD5950:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dd4b98
	ctx.lr = 0x82DD5958;
	sub_82DD4B98(ctx, base);
	// b 0x82dd5c00
	goto loc_82DD5C00;
loc_82DD595C:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dd4b18
	ctx.lr = 0x82DD5964;
	sub_82DD4B18(ctx, base);
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd59a4
	if (ctx.cr6.eq) goto loc_82DD59A4;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd59d8
	if (!ctx.cr6.gt) goto loc_82DD59D8;
	// stw r18,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r18.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD59A4:
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd59d4
	if (ctx.cr6.eq) goto loc_82DD59D4;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// subf r11,r11,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r11.s64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82dd59d8
	if (!ctx.cr6.lt) goto loc_82DD59D8;
	// stw r25,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r25.u32);
loc_82DD59D4:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD59D8:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD59E4:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dd4b98
	ctx.lr = 0x82DD59EC;
	sub_82DD4B98(ctx, base);
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd59a4
	if (ctx.cr6.eq) goto loc_82DD59A4;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 484);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd59d8
	if (!ctx.cr6.gt) goto loc_82DD59D8;
	// stw r18,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r18.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD5A2C:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82dd4cc0
	ctx.lr = 0x82DD5A34;
	sub_82DD4CC0(ctx, base);
	// b 0x82dd5c00
	goto loc_82DD5C00;
loc_82DD5A38:
	// clrlwi r10,r31,24
	ctx.r10.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd59a4
	if (ctx.cr6.eq) goto loc_82DD59A4;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r10.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,484(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// cmpwi cr6,r10,64
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 64, ctx.xer);
	// ble cr6,0x82dd59d8
	if (!ctx.cr6.gt) goto loc_82DD59D8;
	// stw r18,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r18.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD5A78:
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// beq cr6,0x82dd5b9c
	if (ctx.cr6.eq) goto loc_82DD5B9C;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82dd5b74
	if (ctx.cr6.eq) goto loc_82DD5B74;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82dd5c00
	if (!ctx.cr6.eq) goto loc_82DD5C00;
	// lwz r11,2040(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2040);
	// clrlwi r10,r30,24
	ctx.r10.u64 = ctx.r30.u32 & 0xFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bne cr6,0x82dd5b48
	if (!ctx.cr6.eq) goto loc_82DD5B48;
	// cmplw cr6,r11,r23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r23.u32, ctx.xer);
	// bne cr6,0x82dd5ad4
	if (!ctx.cr6.eq) goto loc_82DD5AD4;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82e02948
	ctx.lr = 0x82DD5AC4;
	sub_82E02948(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82dd5ad4
	if (ctx.cr6.eq) goto loc_82DD5AD4;
	// stw r23,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r23.u32);
	// stw r20,464(r23)
	PPC_STORE_U32(ctx.r23.u32 + 464, ctx.r20.u32);
loc_82DD5AD4:
	// lbz r11,-3(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + -3);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5afc
	if (ctx.cr6.eq) goto loc_82DD5AFC;
	// lbz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r27.u32 + 8);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 484, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DD5AFC:
	// add r11,r21,r28
	ctx.r11.u64 = ctx.r21.u64 + ctx.r28.u64;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r11,1148(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1148);
	// stw r11,488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 488, ctx.r11.u32);
	// lwz r11,612(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 612);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, ctx.r11.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD5B48:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,253
	ctx.r10.u64 = ctx.r10.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// andi. r10,r10,247
	ctx.r10.u64 = ctx.r10.u64 & 247;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD5B74:
	// lwz r11,2040(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2040);
	// clrlwi r10,r30,24
	ctx.r10.u64 = ctx.r30.u32 & 0xFF;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82dd5c00
	if (!ctx.cr6.eq) goto loc_82DD5C00;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r25,484(r11)
	PPC_STORE_U32(ctx.r11.u32 + 484, ctx.r25.u32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// b 0x82dd5bfc
	goto loc_82DD5BFC;
loc_82DD5B9C:
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5c00
	if (ctx.cr6.eq) goto loc_82DD5C00;
	// lwz r9,2040(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2040);
	// twllei r11,0
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / ctx.r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// subf. r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// twlgei r11,-1
	// bne 0x82dd5c00
	if (!ctx.cr0.eq) goto loc_82DD5C00;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
loc_82DD5BFC:
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
loc_82DD5C00:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add. r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82dd5c28
	if (!ctx.cr0.eq) goto loc_82DD5C28;
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stb r10,476(r11)
	PPC_STORE_U8(ctx.r11.u32 + 476, ctx.r10.u8);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5C28:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5c54
	if (ctx.cr6.eq) goto loc_82DD5C54;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82e02c60
	ctx.lr = 0x82DD5C50;
	sub_82E02C60(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5C54:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5ca4
	if (ctx.cr6.eq) goto loc_82DD5CA4;
	// lwz r10,492(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// lwz r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	// lfs f0,640(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// extsw r11,r10
	ctx.r11.s64 = ctx.r10.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f30
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// bl 0x82d99380
	ctx.lr = 0x82DD5CA0;
	sub_82D99380(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5CA4:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5cec
	if (ctx.cr6.eq) goto loc_82DD5CEC;
	// lwz r10,488(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	// lfs f0,2020(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 2020);
	ctx.f0.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f28
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// bl 0x82d99540
	ctx.lr = 0x82DD5CE8;
	sub_82D99540(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5CEC:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5d3c
	if (ctx.cr6.eq) goto loc_82DD5D3C;
	// lwz r10,496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bge cr6,0x82dd5d14
	if (!ctx.cr6.lt) goto loc_82DD5D14;
	// li r10,1
	ctx.r10.s64 = 1;
loc_82DD5D14:
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// divw r11,r17,r10
	ctx.r11.s32 = ctx.r17.s32 / ctx.r10.s32;
	// twllei r10,0
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// bl 0x82d9b8e0
	ctx.lr = 0x82DD5D38;
	sub_82D9B8E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82DD5D3C:
	// lbz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 476);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82dd5d88
	if (ctx.cr6.eq) goto loc_82DD5D88;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r25,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r25.u8);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r11,24
	ctx.r3.s64 = ctx.r11.s64 + 24;
	// bl 0x82d9cb18
	ctx.lr = 0x82DD5D74;
	sub_82D9CB18(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,16(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// bl 0x82d8b3e0
	ctx.lr = 0x82DD5D80;
	sub_82D8B3E0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r25,504(r11)
	PPC_STORE_U32(ctx.r11.u32 + 504, ctx.r25.u32);
loc_82DD5D88:
	// lwz r11,756(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 756);
	// addi r21,r21,1
	ctx.r21.s64 = ctx.r21.s64 + 1;
	// addi r19,r19,4
	ctx.r19.s64 = ctx.r19.s64 + 4;
	// addi r24,r24,5
	ctx.r24.s64 = ctx.r24.s64 + 5;
	// cmpw cr6,r21,r11
	ctx.cr6.compare<int32_t>(ctx.r21.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd575c
	if (ctx.cr6.lt) goto loc_82DD575C;
loc_82DD5DA0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82cb6b34
	ctx.lr = 0x82DD5DB0;
	__restfpr_28(ctx, base);
	// b 0x82cb1108
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD5DB4"))) PPC_WEAK_FUNC(sub_82DD5DB4);
PPC_FUNC_IMPL(__imp__sub_82DD5DB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD5DB8"))) PPC_WEAK_FUNC(sub_82DD5DB8);
PPC_FUNC_IMPL(__imp__sub_82DD5DB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DD5DC0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,-1
	ctx.r30.s64 = -1;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82dd5e74
	if (!ctx.cr6.eq) goto loc_82DD5E74;
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5dfc
	if (ctx.cr6.eq) goto loc_82DD5DFC;
	// lbz r11,2038(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2038);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd5dfc
	if (!ctx.cr6.eq) goto loc_82DD5DFC;
	// bl 0x82e02b60
	ctx.lr = 0x82DD5DF8;
	sub_82E02B60(ctx, base);
	// b 0x82dd5e88
	goto loc_82DD5E88;
loc_82DD5DFC:
	// lwz r11,2072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2072);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dd5e10
	if (ctx.cr6.lt) goto loc_82DD5E10;
	// stw r11,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r11.u32);
	// stw r30,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r30.u32);
loc_82DD5E10:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt cr6,0x82dd5e24
	if (ctx.cr6.lt) goto loc_82DD5E24;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
	// stw r30,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r30.u32);
loc_82DD5E24:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd4dd0
	ctx.lr = 0x82DD5E2C;
	sub_82DD4DD0(ctx, base);
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82dd5e88
	if (!ctx.cr6.eq) goto loc_82DD5E88;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
	// blt cr6,0x82dd5e88
	if (ctx.cr6.lt) goto loc_82DD5E88;
	// lwz r11,2056(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2056);
	// lwz r10,1280(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1280);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
	// blt cr6,0x82dd5e6c
	if (ctx.cr6.lt) goto loc_82DD5E6C;
	// lwz r11,2012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2012);
	// stw r11,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r11.u32);
loc_82DD5E6C:
	// stw r29,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r29.u32);
	// b 0x82dd5e88
	goto loc_82DD5E88;
loc_82DD5E74:
	// clrlwi r11,r4,24
	ctx.r11.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd5e88
	if (ctx.cr6.eq) goto loc_82DD5E88;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd56a0
	ctx.lr = 0x82DD5E88;
	sub_82DD56A0(ctx, base);
loc_82DD5E88:
	// lwz r9,2044(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2044);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82dd5ebc
	if (ctx.cr6.eq) goto loc_82DD5EBC;
	// lwz r11,2040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2040);
	// lwz r10,2060(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2060);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// stw r11,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r11.u32);
	// blt cr6,0x82dd5ec8
	if (ctx.cr6.lt) goto loc_82DD5EC8;
	// stw r29,2060(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2060, ctx.r29.u32);
	// stw r29,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r29.u32);
	// b 0x82dd5ec8
	goto loc_82DD5EC8;
loc_82DD5EBC:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r30,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r30.u32);
	// stb r11,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r11.u8);
loc_82DD5EC8:
	// lwz r10,1136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,1132(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,1136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1136, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD5EE4"))) PPC_WEAK_FUNC(sub_82DD5EE4);
PPC_FUNC_IMPL(__imp__sub_82DD5EE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD5EE8"))) PPC_WEAK_FUNC(sub_82DD5EE8);
PPC_FUNC_IMPL(__imp__sub_82DD5EE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e0
	ctx.lr = 0x82DD5EF0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DD5EFC;
	sub_82E02B60(ctx, base);
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// li r27,0
	ctx.r27.s64 = 0;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd5f4c
	if (!ctx.cr6.gt) goto loc_82DD5F4C;
	// addi r30,r31,2076
	ctx.r30.s64 = ctx.r31.s64 + 2076;
loc_82DD5F14:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd5f38
	if (ctx.cr6.eq) goto loc_82DD5F38;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD5F34;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r27,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r27.u32);
loc_82DD5F38:
	// lwz r11,1296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1296);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,48
	ctx.r30.s64 = ctx.r30.s64 + 48;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd5f14
	if (ctx.cr6.lt) goto loc_82DD5F14;
loc_82DD5F4C:
	// lwz r4,1020(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1020);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r28,-31909
	ctx.r28.s64 = -2091188224;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// addi r29,r11,9792
	ctx.r29.s64 = ctx.r11.s64 + 9792;
	// beq cr6,0x82dd5f80
	if (ctx.cr6.eq) goto loc_82DD5F80;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1974
	ctx.r6.s64 = 1974;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD5F7C;
	sub_82D861B0(ctx, base);
	// stw r27,1020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1020, ctx.r27.u32);
loc_82DD5F80:
	// lwz r3,1024(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1024);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd5f94
	if (ctx.cr6.eq) goto loc_82DD5F94;
	// bl 0x82da94d0
	ctx.lr = 0x82DD5F90;
	sub_82DA94D0(ctx, base);
	// stw r27,1024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1024, ctx.r27.u32);
loc_82DD5F94:
	// lwz r4,1028(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1028);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd5fbc
	if (ctx.cr6.eq) goto loc_82DD5FBC;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1985
	ctx.r6.s64 = 1985;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD5FB8;
	sub_82D861B0(ctx, base);
	// stw r27,1028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1028, ctx.r27.u32);
loc_82DD5FBC:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd6048
	if (ctx.cr6.eq) goto loc_82DD6048;
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// mr r26,r27
	ctx.r26.u64 = ctx.r27.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd6028
	if (!ctx.cr6.gt) goto loc_82DD6028;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
loc_82DD5FDC:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd6014
	if (ctx.cr6.eq) goto loc_82DD6014;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1995
	ctx.r6.s64 = 1995;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD6008;
	sub_82D861B0(ctx, base);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r27,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r27.u32);
loc_82DD6014:
	// lwz r11,1284(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1284);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// cmpw cr6,r26,r11
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd5fdc
	if (ctx.cr6.lt) goto loc_82DD5FDC;
loc_82DD6028:
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2000
	ctx.r6.s64 = 2000;
	// lwz r4,488(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD6044;
	sub_82D861B0(ctx, base);
	// stw r27,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r27.u32);
loc_82DD6048:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// mr r26,r27
	ctx.r26.u64 = ctx.r27.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82dd6098
	if (!ctx.cr6.gt) goto loc_82DD6098;
	// addi r30,r31,760
	ctx.r30.s64 = ctx.r31.s64 + 760;
loc_82DD605C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd6084
	if (ctx.cr6.eq) goto loc_82DD6084;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2008
	ctx.r6.s64 = 2008;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD6080;
	sub_82D861B0(ctx, base);
	// stw r27,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r27.u32);
loc_82DD6084:
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpw cr6,r26,r11
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82dd605c
	if (ctx.cr6.lt) goto loc_82DD605C;
loc_82DD6098:
	// lwz r4,496(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 496);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82dd60c0
	if (ctx.cr6.eq) goto loc_82DD60C0;
	// lwz r11,19872(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 19872);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2015
	ctx.r6.s64 = 2015;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d861b0
	ctx.lr = 0x82DD60BC;
	sub_82D861B0(ctx, base);
	// stw r27,496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 496, ctx.r27.u32);
loc_82DD60C0:
	// lwz r3,492(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 492);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82dd60e4
	if (ctx.cr6.eq) goto loc_82DD60E4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD60E0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r27,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r27.u32);
loc_82DD60E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82cb1130
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD60F0"))) PPC_WEAK_FUNC(sub_82DD60F0);
PPC_FUNC_IMPL(__imp__sub_82DD60F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x82DD60F8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,256
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 256, ctx.xer);
	// bne cr6,0x82dd6124
	if (!ctx.cr6.eq) goto loc_82DD6124;
	// bl 0x82e032f8
	ctx.lr = 0x82DD6110;
	sub_82E032F8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r30.u32);
	// stw r30,2072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2072, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DD6124:
	// cmplwi cr6,r6,2
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 2, ctx.xer);
	// bne cr6,0x82dd61a0
	if (!ctx.cr6.eq) goto loc_82DD61A0;
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82dd6194
	if (ctx.cr6.eq) goto loc_82DD6194;
	// bge cr6,0x82dd614c
	if (!ctx.cr6.lt) goto loc_82DD614C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e032f8
	ctx.lr = 0x82DD6148;
	sub_82E032F8(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
loc_82DD614C:
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82dd6170
	if (!ctx.cr6.lt) goto loc_82DD6170;
loc_82DD6158:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd5db8
	ctx.lr = 0x82DD6164;
	sub_82DD5DB8(ctx, base);
	// lwz r11,1136(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1136);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82dd6158
	if (ctx.cr6.lt) goto loc_82DD6158;
loc_82DD6170:
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd6194
	if (ctx.cr6.eq) goto loc_82DD6194;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lbz r30,2036(r31)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2036);
	// lbz r29,2037(r31)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// bl 0x82e02b60
	ctx.lr = 0x82DD618C;
	sub_82E02B60(ctx, base);
	// stb r30,2036(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2036, ctx.r30.u8);
	// stb r29,2037(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2037, ctx.r29.u8);
loc_82DD6194:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_82DD61A0:
	// li r3,25
	ctx.r3.s64 = 25;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD61AC"))) PPC_WEAK_FUNC(sub_82DD61AC);
PPC_FUNC_IMPL(__imp__sub_82DD61AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD61B0"))) PPC_WEAK_FUNC(sub_82DD61B0);
PPC_FUNC_IMPL(__imp__sub_82DD61B0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd61c0
	if (!ctx.cr6.eq) goto loc_82DD61C0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD61C0:
	// b 0x82dd5ee8
	sub_82DD5EE8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD61C4"))) PPC_WEAK_FUNC(sub_82DD61C4);
PPC_FUNC_IMPL(__imp__sub_82DD61C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD61C8"))) PPC_WEAK_FUNC(sub_82DD61C8);
PPC_FUNC_IMPL(__imp__sub_82DD61C8) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd61d8
	if (!ctx.cr6.eq) goto loc_82DD61D8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD61D8:
	// b 0x82dd60f0
	sub_82DD60F0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD61DC"))) PPC_WEAK_FUNC(sub_82DD61DC);
PPC_FUNC_IMPL(__imp__sub_82DD61DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD61E0"))) PPC_WEAK_FUNC(sub_82DD61E0);
PPC_FUNC_IMPL(__imp__sub_82DD61E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// bl 0x82e032f8
	ctx.lr = 0x82DD6204;
	sub_82E032F8(ctx, base);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82dd623c
	if (!ctx.cr6.eq) goto loc_82DD623C;
loc_82DD6210:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82dd5db8
	ctx.lr = 0x82DD621C;
	sub_82DD5DB8(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,1132(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1132);
	// lwz r9,272(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lbz r11,2037(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2037);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd6210
	if (ctx.cr6.eq) goto loc_82DD6210;
loc_82DD623C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e02b60
	ctx.lr = 0x82DD6244;
	sub_82E02B60(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD625C"))) PPC_WEAK_FUNC(sub_82DD625C);
PPC_FUNC_IMPL(__imp__sub_82DD625C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD6260"))) PPC_WEAK_FUNC(sub_82DD6260);
PPC_FUNC_IMPL(__imp__sub_82DD6260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c8
	ctx.lr = 0x82DD6268;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r21,r5
	ctx.r21.u64 = ctx.r5.u64;
	// mr r20,r6
	ctx.r20.u64 = ctx.r6.u64;
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r22,4408(r10)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4408);
	// lwz r10,260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// beq cr6,0x82dd63cc
	if (ctx.cr6.eq) goto loc_82DD63CC;
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dd63cc
	if (ctx.cr6.gt) goto loc_82DD63CC;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,25276
	ctx.r12.s64 = ctx.r12.s64 + 25276;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD6328;
	case 1:
		goto loc_82DD62E8;
	case 2:
		goto loc_82DD62F0;
	case 3:
		goto loc_82DD62F8;
	case 4:
		goto loc_82DD6300;
	case 5:
		goto loc_82DD6300;
	case 6:
		goto loc_82DD6328;
	case 7:
		goto loc_82DD6328;
	case 8:
		goto loc_82DD6328;
	case 9:
		goto loc_82DD6328;
	case 10:
		goto loc_82DD6328;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25384(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25384);
	// lwz r22,25320(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25320);
	// lwz r22,25328(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25328);
	// lwz r22,25336(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25336);
	// lwz r22,25344(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25344);
	// lwz r22,25344(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25344);
	// lwz r22,25384(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25384);
	// lwz r22,25384(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25384);
	// lwz r22,25384(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25384);
	// lwz r22,25384(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25384);
	// lwz r22,25384(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25384);
loc_82DD62E8:
	// li r11,8
	ctx.r11.s64 = 8;
	// b 0x82dd6304
	goto loc_82DD6304;
loc_82DD62F0:
	// li r11,16
	ctx.r11.s64 = 16;
	// b 0x82dd6304
	goto loc_82DD6304;
loc_82DD62F8:
	// li r11,24
	ctx.r11.s64 = 24;
	// b 0x82dd6304
	goto loc_82DD6304;
loc_82DD6300:
	// li r11,32
	ctx.r11.s64 = 32;
loc_82DD6304:
	// li r9,0
	ctx.r9.s64 = 0;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// rldimi r9,r21,3,29
	ctx.r9.u64 = (__builtin_rotateleft64(ctx.r21.u64, 3) & 0x7FFFFFFF8) | (ctx.r9.u64 & 0xFFFFFFF800000007);
	// tdllei r11,0
	// divdu r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 / ctx.r11.u64;
	// twllei r10,0
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd63d0
	goto loc_82DD63D0;
loc_82DD6328:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,25408
	ctx.r12.s64 = ctx.r12.s64 + 25408;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,25532(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25532);
	// lwz r22,25548(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25548);
	// lwz r22,25548(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25548);
	// lwz r22,25548(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25548);
	// lwz r22,25548(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25548);
	// lwz r22,25548(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25548);
	// lwz r22,25452(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25452);
	// lwz r22,25472(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25472);
	// lwz r22,25504(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25504);
	// lwz r22,25524(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25524);
	// lwz r22,25524(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25524);
	// mulli r11,r21,14
	ctx.r11.s64 = ctx.r21.s64 * 14;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd63d0
	goto loc_82DD63D0;
	// lis r9,14563
	ctx.r9.s64 = 954400768;
	// rlwinm r11,r21,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 6) & 0xFFFFFFC0;
	// ori r9,r9,36409
	ctx.r9.u64 = ctx.r9.u64 | 36409;
	// twllei r10,0
	// mulhwu r11,r11,r9
	ctx.r11.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd63d0
	goto loc_82DD63D0;
	// mulli r11,r21,28
	ctx.r11.s64 = ctx.r21.s64 * 28;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd63d0
	goto loc_82DD63D0;
	// mr r24,r21
	ctx.r24.u64 = ctx.r21.u64;
	// b 0x82dd63d0
	goto loc_82DD63D0;
	// li r11,0
	ctx.r11.s64 = 0;
	// twllei r10,0
	// divwu r24,r11,r10
	ctx.r24.u32 = ctx.r11.u32 / ctx.r10.u32;
	// b 0x82dd63d0
	goto loc_82DD63D0;
loc_82DD63CC:
	// lwz r24,88(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD63D0:
	// lbz r11,2036(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82dd6658
	if (ctx.cr6.eq) goto loc_82DD6658;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,2016(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 2016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x82dd6658
	if (ctx.cr6.eq) goto loc_82DD6658;
	// lwz r27,1128(r25)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1128);
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82dd6654
	if (ctx.cr6.eq) goto loc_82DD6654;
	// lis r11,9362
	ctx.r11.s64 = 613548032;
	// lwz r29,88(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// ori r30,r11,18725
	ctx.r30.u64 = ctx.r11.u64 | 18725;
loc_82DD6410:
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82dd643c
	if (!ctx.cr6.eq) goto loc_82DD643C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82dd5db8
	ctx.lr = 0x82DD6428;
	sub_82DD5DB8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82dd6668
	if (!ctx.cr6.eq) goto loc_82DD6668;
	// lwz r11,1132(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1132);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// b 0x82dd6440
	goto loc_82DD6440;
loc_82DD643C:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82DD6440:
	// add r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 + ctx.r28.u64;
	// cmplw cr6,r10,r24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r24.u32, ctx.xer);
	// ble cr6,0x82dd6450
	if (!ctx.cr6.gt) goto loc_82DD6450;
	// subf r11,r28,r24
	ctx.r11.s64 = ctx.r24.s64 - ctx.r28.s64;
loc_82DD6450:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82da41c0
	ctx.lr = 0x82DD645C;
	sub_82DA41C0(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dd64a4
	if (ctx.cr6.eq) goto loc_82DD64A4;
	// lwz r3,492(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 492);
	// li r9,1000
	ctx.r9.s64 = 1000;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82DD6490;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x82dd6670
	if (!ctx.cr6.eq) goto loc_82DD6670;
	// lwz r3,492(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 492);
	// bl 0x82d938a0
	ctx.lr = 0x82DD64A4;
	sub_82D938A0(ctx, base);
loc_82DD64A4:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DD64AC;
	sub_82DA4200(ctx, base);
	// lwz r11,28(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 28);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82dd661c
	if (ctx.cr6.gt) goto loc_82DD661C;
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,25816
	ctx.r12.s64 = ctx.r12.s64 + 25816;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82DD6544;
	case 1:
		goto loc_82DD6504;
	case 2:
		goto loc_82DD6514;
	case 3:
		goto loc_82DD6524;
	case 4:
		goto loc_82DD6534;
	case 5:
		goto loc_82DD6534;
	case 6:
		goto loc_82DD6544;
	case 7:
		goto loc_82DD6544;
	case 8:
		goto loc_82DD6544;
	case 9:
		goto loc_82DD6544;
	case 10:
		goto loc_82DD6544;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25924(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25924);
	// lwz r22,25860(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25860);
	// lwz r22,25876(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25876);
	// lwz r22,25892(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25892);
	// lwz r22,25908(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25908);
	// lwz r22,25908(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25908);
	// lwz r22,25924(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25924);
	// lwz r22,25924(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25924);
	// lwz r22,25924(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25924);
	// lwz r22,25924(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25924);
	// lwz r22,25924(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25924);
loc_82DD6504:
	// li r11,8
	ctx.r11.s64 = 8;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd6614
	goto loc_82DD6614;
loc_82DD6514:
	// li r11,16
	ctx.r11.s64 = 16;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd6614
	goto loc_82DD6614;
loc_82DD6524:
	// li r11,24
	ctx.r11.s64 = 24;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd6614
	goto loc_82DD6614;
loc_82DD6534:
	// li r11,32
	ctx.r11.s64 = 32;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd6614
	goto loc_82DD6614;
loc_82DD6544:
	// lis r12,-32035
	ctx.r12.s64 = -2099445760;
	// addi r12,r12,25948
	ctx.r12.s64 = ctx.r12.s64 + 25948;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
	// lwz r22,26128(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26128);
	// lwz r22,26140(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26140);
	// lwz r22,26140(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26140);
	// lwz r22,26140(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26140);
	// lwz r22,26140(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26140);
	// lwz r22,26140(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26140);
	// lwz r22,25992(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25992);
	// lwz r22,26044(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26044);
	// lwz r22,26068(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26068);
	// lwz r22,26120(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26120);
	// lwz r22,26120(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 26120);
	// addi r11,r9,13
	ctx.r11.s64 = ctx.r9.s64 + 13;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mulli r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 * 112;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x82dd6614
	goto loc_82DD6614;
	// addi r11,r9,63
	ctx.r11.s64 = ctx.r9.s64 + 63;
	// rlwinm r11,r11,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,6,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FFFFFC;
	// b 0x82dd6614
	goto loc_82DD6614;
	// addi r11,r9,27
	ctx.r11.s64 = ctx.r9.s64 + 27;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r11,r11,448
	ctx.r11.s64 = ctx.r11.s64 * 448;
	// mulhwu r10,r11,r30
	ctx.r10.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r30.u32)) >> 32;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,28,4,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
	// b 0x82dd6614
	goto loc_82DD6614;
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// b 0x82dd661c
	goto loc_82DD661C;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82DD6614:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mullw r29,r11,r10
	ctx.r29.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82DD661C:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r26,r4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82dd6640
	if (ctx.cr6.eq) goto loc_82DD6640;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82dd6640
	if (ctx.cr6.eq) goto loc_82DD6640;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82cb1160
	ctx.lr = 0x82DD663C;
	sub_82CB1160(ctx, base);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82DD6640:
	// add r28,r9,r28
	ctx.r28.u64 = ctx.r9.u64 + ctx.r28.u64;
	// add r26,r29,r26
	ctx.r26.u64 = ctx.r29.u64 + ctx.r26.u64;
	// subf r27,r9,r27
	ctx.r27.s64 = ctx.r27.s64 - ctx.r9.s64;
	// cmplw cr6,r28,r24
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82dd6410
	if (ctx.cr6.lt) goto loc_82DD6410;
loc_82DD6654:
	// stw r27,1128(r25)
	PPC_STORE_U32(ctx.r25.u32 + 1128, ctx.r27.u32);
loc_82DD6658:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82dd6664
	if (ctx.cr6.eq) goto loc_82DD6664;
	// stw r21,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r21.u32);
loc_82DD6664:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD6668:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
loc_82DD6670:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82da4200
	ctx.lr = 0x82DD6678;
	sub_82DA4200(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82cb1118
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD6684"))) PPC_WEAK_FUNC(sub_82DD6684);
PPC_FUNC_IMPL(__imp__sub_82DD6684) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD6688"))) PPC_WEAK_FUNC(sub_82DD6688);
PPC_FUNC_IMPL(__imp__sub_82DD6688) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r3,r3,-24
	ctx.r3.s64 = ctx.r3.s64 + -24;
	// bne cr6,0x82dd6698
	if (!ctx.cr6.eq) goto loc_82DD6698;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82DD6698:
	// b 0x82dd6260
	sub_82DD6260(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82DD669C"))) PPC_WEAK_FUNC(sub_82DD669C);
PPC_FUNC_IMPL(__imp__sub_82DD669C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82DD66A0"))) PPC_WEAK_FUNC(sub_82DD66A0);
PPC_FUNC_IMPL(__imp__sub_82DD66A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82d9b4a8
	ctx.lr = 0x82DD66CC;
	sub_82D9B4A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82DD66E4"))) PPC_WEAK_FUNC(sub_82DD66E4);
PPC_FUNC_IMPL(__imp__sub_82DD66E4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

