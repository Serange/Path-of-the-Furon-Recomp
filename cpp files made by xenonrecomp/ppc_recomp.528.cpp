#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_8308A8F8"))) PPC_WEAK_FUNC(sub_8308A8F8);
PPC_FUNC_IMPL(__imp__sub_8308A8F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r10,r11,412
	ctx.r10.s64 = ctx.r11.s64 + 412;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// bl 0x831f2f08
	ctx.lr = 0x8308A924;
	sub_831F2F08(ctx, base);
	// clrlwi r9,r30,31
	ctx.r9.u64 = ctx.r30.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8308a94c
	if (ctx.cr6.eq) goto loc_8308A94C;
	// lis r11,-31901
	ctx.r11.s64 = -2090663936;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,-32308(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -32308);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x8308A94C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_8308A94C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A968"))) PPC_WEAK_FUNC(sub_8308A968);
PPC_FUNC_IMPL(__imp__sub_8308A968) {
	PPC_FUNC_PROLOGUE();
	// lis r10,0
	ctx.r10.s64 = 0;
	// lhz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 36);
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cntlzw r8,r9
	ctx.r8.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// rlwinm r7,r8,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r3,r7,1
	ctx.r3.u64 = ctx.r7.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A988"))) PPC_WEAK_FUNC(sub_8308A988);
PPC_FUNC_IMPL(__imp__sub_8308A988) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,188(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 188);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A990"))) PPC_WEAK_FUNC(sub_8308A990);
PPC_FUNC_IMPL(__imp__sub_8308A990) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,144
	ctx.r3.s64 = ctx.r3.s64 + 144;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A998"))) PPC_WEAK_FUNC(sub_8308A998);
PPC_FUNC_IMPL(__imp__sub_8308A998) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,268(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 268);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9A0"))) PPC_WEAK_FUNC(sub_8308A9A0);
PPC_FUNC_IMPL(__imp__sub_8308A9A0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,328(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 328);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9A8"))) PPC_WEAK_FUNC(sub_8308A9A8);
PPC_FUNC_IMPL(__imp__sub_8308A9A8) {
	PPC_FUNC_PROLOGUE();
	// stw r4,328(r3)
	PPC_STORE_U32(ctx.r3.u32 + 328, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9B0"))) PPC_WEAK_FUNC(sub_8308A9B0);
PPC_FUNC_IMPL(__imp__sub_8308A9B0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9B4"))) PPC_WEAK_FUNC(sub_8308A9B4);
PPC_FUNC_IMPL(__imp__sub_8308A9B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308A9B8"))) PPC_WEAK_FUNC(sub_8308A9B8);
PPC_FUNC_IMPL(__imp__sub_8308A9B8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9BC"))) PPC_WEAK_FUNC(sub_8308A9BC);
PPC_FUNC_IMPL(__imp__sub_8308A9BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308A9C0"))) PPC_WEAK_FUNC(sub_8308A9C0);
PPC_FUNC_IMPL(__imp__sub_8308A9C0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9C4"))) PPC_WEAK_FUNC(sub_8308A9C4);
PPC_FUNC_IMPL(__imp__sub_8308A9C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308A9C8"))) PPC_WEAK_FUNC(sub_8308A9C8);
PPC_FUNC_IMPL(__imp__sub_8308A9C8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9CC"))) PPC_WEAK_FUNC(sub_8308A9CC);
PPC_FUNC_IMPL(__imp__sub_8308A9CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308A9D0"))) PPC_WEAK_FUNC(sub_8308A9D0);
PPC_FUNC_IMPL(__imp__sub_8308A9D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9DC"))) PPC_WEAK_FUNC(sub_8308A9DC);
PPC_FUNC_IMPL(__imp__sub_8308A9DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308A9E0"))) PPC_WEAK_FUNC(sub_8308A9E0);
PPC_FUNC_IMPL(__imp__sub_8308A9E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9EC"))) PPC_WEAK_FUNC(sub_8308A9EC);
PPC_FUNC_IMPL(__imp__sub_8308A9EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308A9F0"))) PPC_WEAK_FUNC(sub_8308A9F0);
PPC_FUNC_IMPL(__imp__sub_8308A9F0) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9F8"))) PPC_WEAK_FUNC(sub_8308A9F8);
PPC_FUNC_IMPL(__imp__sub_8308A9F8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308A9FC"))) PPC_WEAK_FUNC(sub_8308A9FC);
PPC_FUNC_IMPL(__imp__sub_8308A9FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA00"))) PPC_WEAK_FUNC(sub_8308AA00);
PPC_FUNC_IMPL(__imp__sub_8308AA00) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA04"))) PPC_WEAK_FUNC(sub_8308AA04);
PPC_FUNC_IMPL(__imp__sub_8308AA04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA08"))) PPC_WEAK_FUNC(sub_8308AA08);
PPC_FUNC_IMPL(__imp__sub_8308AA08) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA0C"))) PPC_WEAK_FUNC(sub_8308AA0C);
PPC_FUNC_IMPL(__imp__sub_8308AA0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA10"))) PPC_WEAK_FUNC(sub_8308AA10);
PPC_FUNC_IMPL(__imp__sub_8308AA10) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA14"))) PPC_WEAK_FUNC(sub_8308AA14);
PPC_FUNC_IMPL(__imp__sub_8308AA14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA18"))) PPC_WEAK_FUNC(sub_8308AA18);
PPC_FUNC_IMPL(__imp__sub_8308AA18) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA1C"))) PPC_WEAK_FUNC(sub_8308AA1C);
PPC_FUNC_IMPL(__imp__sub_8308AA1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA20"))) PPC_WEAK_FUNC(sub_8308AA20);
PPC_FUNC_IMPL(__imp__sub_8308AA20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA2C"))) PPC_WEAK_FUNC(sub_8308AA2C);
PPC_FUNC_IMPL(__imp__sub_8308AA2C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA30"))) PPC_WEAK_FUNC(sub_8308AA30);
PPC_FUNC_IMPL(__imp__sub_8308AA30) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA34"))) PPC_WEAK_FUNC(sub_8308AA34);
PPC_FUNC_IMPL(__imp__sub_8308AA34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA38"))) PPC_WEAK_FUNC(sub_8308AA38);
PPC_FUNC_IMPL(__imp__sub_8308AA38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA44"))) PPC_WEAK_FUNC(sub_8308AA44);
PPC_FUNC_IMPL(__imp__sub_8308AA44) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA48"))) PPC_WEAK_FUNC(sub_8308AA48);
PPC_FUNC_IMPL(__imp__sub_8308AA48) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA4C"))) PPC_WEAK_FUNC(sub_8308AA4C);
PPC_FUNC_IMPL(__imp__sub_8308AA4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA50"))) PPC_WEAK_FUNC(sub_8308AA50);
PPC_FUNC_IMPL(__imp__sub_8308AA50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA5C"))) PPC_WEAK_FUNC(sub_8308AA5C);
PPC_FUNC_IMPL(__imp__sub_8308AA5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA60"))) PPC_WEAK_FUNC(sub_8308AA60);
PPC_FUNC_IMPL(__imp__sub_8308AA60) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA64"))) PPC_WEAK_FUNC(sub_8308AA64);
PPC_FUNC_IMPL(__imp__sub_8308AA64) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA68"))) PPC_WEAK_FUNC(sub_8308AA68);
PPC_FUNC_IMPL(__imp__sub_8308AA68) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA70"))) PPC_WEAK_FUNC(sub_8308AA70);
PPC_FUNC_IMPL(__imp__sub_8308AA70) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA74"))) PPC_WEAK_FUNC(sub_8308AA74);
PPC_FUNC_IMPL(__imp__sub_8308AA74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA78"))) PPC_WEAK_FUNC(sub_8308AA78);
PPC_FUNC_IMPL(__imp__sub_8308AA78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA84"))) PPC_WEAK_FUNC(sub_8308AA84);
PPC_FUNC_IMPL(__imp__sub_8308AA84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA88"))) PPC_WEAK_FUNC(sub_8308AA88);
PPC_FUNC_IMPL(__imp__sub_8308AA88) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA8C"))) PPC_WEAK_FUNC(sub_8308AA8C);
PPC_FUNC_IMPL(__imp__sub_8308AA8C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AA90"))) PPC_WEAK_FUNC(sub_8308AA90);
PPC_FUNC_IMPL(__imp__sub_8308AA90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AA9C"))) PPC_WEAK_FUNC(sub_8308AA9C);
PPC_FUNC_IMPL(__imp__sub_8308AA9C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AAA0"))) PPC_WEAK_FUNC(sub_8308AAA0);
PPC_FUNC_IMPL(__imp__sub_8308AAA0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAA4"))) PPC_WEAK_FUNC(sub_8308AAA4);
PPC_FUNC_IMPL(__imp__sub_8308AAA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AAA8"))) PPC_WEAK_FUNC(sub_8308AAA8);
PPC_FUNC_IMPL(__imp__sub_8308AAA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAB4"))) PPC_WEAK_FUNC(sub_8308AAB4);
PPC_FUNC_IMPL(__imp__sub_8308AAB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AAB8"))) PPC_WEAK_FUNC(sub_8308AAB8);
PPC_FUNC_IMPL(__imp__sub_8308AAB8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AABC"))) PPC_WEAK_FUNC(sub_8308AABC);
PPC_FUNC_IMPL(__imp__sub_8308AABC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AAC0"))) PPC_WEAK_FUNC(sub_8308AAC0);
PPC_FUNC_IMPL(__imp__sub_8308AAC0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// addi r10,r11,-1496
	ctx.r10.s64 = ctx.r11.s64 + -1496;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAD0"))) PPC_WEAK_FUNC(sub_8308AAD0);
PPC_FUNC_IMPL(__imp__sub_8308AAD0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// addi r10,r11,-1496
	ctx.r10.s64 = ctx.r11.s64 + -1496;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAE0"))) PPC_WEAK_FUNC(sub_8308AAE0);
PPC_FUNC_IMPL(__imp__sub_8308AAE0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAE4"))) PPC_WEAK_FUNC(sub_8308AAE4);
PPC_FUNC_IMPL(__imp__sub_8308AAE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AAE8"))) PPC_WEAK_FUNC(sub_8308AAE8);
PPC_FUNC_IMPL(__imp__sub_8308AAE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAF4"))) PPC_WEAK_FUNC(sub_8308AAF4);
PPC_FUNC_IMPL(__imp__sub_8308AAF4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AAF8"))) PPC_WEAK_FUNC(sub_8308AAF8);
PPC_FUNC_IMPL(__imp__sub_8308AAF8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AAFC"))) PPC_WEAK_FUNC(sub_8308AAFC);
PPC_FUNC_IMPL(__imp__sub_8308AAFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB00"))) PPC_WEAK_FUNC(sub_8308AB00);
PPC_FUNC_IMPL(__imp__sub_8308AB00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB0C"))) PPC_WEAK_FUNC(sub_8308AB0C);
PPC_FUNC_IMPL(__imp__sub_8308AB0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB10"))) PPC_WEAK_FUNC(sub_8308AB10);
PPC_FUNC_IMPL(__imp__sub_8308AB10) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB18"))) PPC_WEAK_FUNC(sub_8308AB18);
PPC_FUNC_IMPL(__imp__sub_8308AB18) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB20"))) PPC_WEAK_FUNC(sub_8308AB20);
PPC_FUNC_IMPL(__imp__sub_8308AB20) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB28"))) PPC_WEAK_FUNC(sub_8308AB28);
PPC_FUNC_IMPL(__imp__sub_8308AB28) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB2C"))) PPC_WEAK_FUNC(sub_8308AB2C);
PPC_FUNC_IMPL(__imp__sub_8308AB2C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB30"))) PPC_WEAK_FUNC(sub_8308AB30);
PPC_FUNC_IMPL(__imp__sub_8308AB30) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB38"))) PPC_WEAK_FUNC(sub_8308AB38);
PPC_FUNC_IMPL(__imp__sub_8308AB38) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB40"))) PPC_WEAK_FUNC(sub_8308AB40);
PPC_FUNC_IMPL(__imp__sub_8308AB40) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB48"))) PPC_WEAK_FUNC(sub_8308AB48);
PPC_FUNC_IMPL(__imp__sub_8308AB48) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB4C"))) PPC_WEAK_FUNC(sub_8308AB4C);
PPC_FUNC_IMPL(__imp__sub_8308AB4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB50"))) PPC_WEAK_FUNC(sub_8308AB50);
PPC_FUNC_IMPL(__imp__sub_8308AB50) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB58"))) PPC_WEAK_FUNC(sub_8308AB58);
PPC_FUNC_IMPL(__imp__sub_8308AB58) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB60"))) PPC_WEAK_FUNC(sub_8308AB60);
PPC_FUNC_IMPL(__imp__sub_8308AB60) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB64"))) PPC_WEAK_FUNC(sub_8308AB64);
PPC_FUNC_IMPL(__imp__sub_8308AB64) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB68"))) PPC_WEAK_FUNC(sub_8308AB68);
PPC_FUNC_IMPL(__imp__sub_8308AB68) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB70"))) PPC_WEAK_FUNC(sub_8308AB70);
PPC_FUNC_IMPL(__imp__sub_8308AB70) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB74"))) PPC_WEAK_FUNC(sub_8308AB74);
PPC_FUNC_IMPL(__imp__sub_8308AB74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB78"))) PPC_WEAK_FUNC(sub_8308AB78);
PPC_FUNC_IMPL(__imp__sub_8308AB78) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB80"))) PPC_WEAK_FUNC(sub_8308AB80);
PPC_FUNC_IMPL(__imp__sub_8308AB80) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB88"))) PPC_WEAK_FUNC(sub_8308AB88);
PPC_FUNC_IMPL(__imp__sub_8308AB88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB94"))) PPC_WEAK_FUNC(sub_8308AB94);
PPC_FUNC_IMPL(__imp__sub_8308AB94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AB98"))) PPC_WEAK_FUNC(sub_8308AB98);
PPC_FUNC_IMPL(__imp__sub_8308AB98) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AB9C"))) PPC_WEAK_FUNC(sub_8308AB9C);
PPC_FUNC_IMPL(__imp__sub_8308AB9C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308ABA0"))) PPC_WEAK_FUNC(sub_8308ABA0);
PPC_FUNC_IMPL(__imp__sub_8308ABA0) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABA8"))) PPC_WEAK_FUNC(sub_8308ABA8);
PPC_FUNC_IMPL(__imp__sub_8308ABA8) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABB0"))) PPC_WEAK_FUNC(sub_8308ABB0);
PPC_FUNC_IMPL(__imp__sub_8308ABB0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABB4"))) PPC_WEAK_FUNC(sub_8308ABB4);
PPC_FUNC_IMPL(__imp__sub_8308ABB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308ABB8"))) PPC_WEAK_FUNC(sub_8308ABB8);
PPC_FUNC_IMPL(__imp__sub_8308ABB8) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABC0"))) PPC_WEAK_FUNC(sub_8308ABC0);
PPC_FUNC_IMPL(__imp__sub_8308ABC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABCC"))) PPC_WEAK_FUNC(sub_8308ABCC);
PPC_FUNC_IMPL(__imp__sub_8308ABCC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308ABD0"))) PPC_WEAK_FUNC(sub_8308ABD0);
PPC_FUNC_IMPL(__imp__sub_8308ABD0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABD4"))) PPC_WEAK_FUNC(sub_8308ABD4);
PPC_FUNC_IMPL(__imp__sub_8308ABD4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308ABD8"))) PPC_WEAK_FUNC(sub_8308ABD8);
PPC_FUNC_IMPL(__imp__sub_8308ABD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABE4"))) PPC_WEAK_FUNC(sub_8308ABE4);
PPC_FUNC_IMPL(__imp__sub_8308ABE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308ABE8"))) PPC_WEAK_FUNC(sub_8308ABE8);
PPC_FUNC_IMPL(__imp__sub_8308ABE8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABEC"))) PPC_WEAK_FUNC(sub_8308ABEC);
PPC_FUNC_IMPL(__imp__sub_8308ABEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308ABF0"))) PPC_WEAK_FUNC(sub_8308ABF0);
PPC_FUNC_IMPL(__imp__sub_8308ABF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ABFC"))) PPC_WEAK_FUNC(sub_8308ABFC);
PPC_FUNC_IMPL(__imp__sub_8308ABFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AC00"))) PPC_WEAK_FUNC(sub_8308AC00);
PPC_FUNC_IMPL(__imp__sub_8308AC00) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC04"))) PPC_WEAK_FUNC(sub_8308AC04);
PPC_FUNC_IMPL(__imp__sub_8308AC04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AC08"))) PPC_WEAK_FUNC(sub_8308AC08);
PPC_FUNC_IMPL(__imp__sub_8308AC08) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC10"))) PPC_WEAK_FUNC(sub_8308AC10);
PPC_FUNC_IMPL(__imp__sub_8308AC10) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC14"))) PPC_WEAK_FUNC(sub_8308AC14);
PPC_FUNC_IMPL(__imp__sub_8308AC14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AC18"))) PPC_WEAK_FUNC(sub_8308AC18);
PPC_FUNC_IMPL(__imp__sub_8308AC18) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC20"))) PPC_WEAK_FUNC(sub_8308AC20);
PPC_FUNC_IMPL(__imp__sub_8308AC20) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC24"))) PPC_WEAK_FUNC(sub_8308AC24);
PPC_FUNC_IMPL(__imp__sub_8308AC24) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AC28"))) PPC_WEAK_FUNC(sub_8308AC28);
PPC_FUNC_IMPL(__imp__sub_8308AC28) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC30"))) PPC_WEAK_FUNC(sub_8308AC30);
PPC_FUNC_IMPL(__imp__sub_8308AC30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC3C"))) PPC_WEAK_FUNC(sub_8308AC3C);
PPC_FUNC_IMPL(__imp__sub_8308AC3C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AC40"))) PPC_WEAK_FUNC(sub_8308AC40);
PPC_FUNC_IMPL(__imp__sub_8308AC40) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC48"))) PPC_WEAK_FUNC(sub_8308AC48);
PPC_FUNC_IMPL(__imp__sub_8308AC48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f0,8(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC60"))) PPC_WEAK_FUNC(sub_8308AC60);
PPC_FUNC_IMPL(__imp__sub_8308AC60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f0,8(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC78"))) PPC_WEAK_FUNC(sub_8308AC78);
PPC_FUNC_IMPL(__imp__sub_8308AC78) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC80"))) PPC_WEAK_FUNC(sub_8308AC80);
PPC_FUNC_IMPL(__imp__sub_8308AC80) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC88"))) PPC_WEAK_FUNC(sub_8308AC88);
PPC_FUNC_IMPL(__imp__sub_8308AC88) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC90"))) PPC_WEAK_FUNC(sub_8308AC90);
PPC_FUNC_IMPL(__imp__sub_8308AC90) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AC94"))) PPC_WEAK_FUNC(sub_8308AC94);
PPC_FUNC_IMPL(__imp__sub_8308AC94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AC98"))) PPC_WEAK_FUNC(sub_8308AC98);
PPC_FUNC_IMPL(__imp__sub_8308AC98) {
	PPC_FUNC_PROLOGUE();
	// lhz r3,304(r3)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + 304);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACA0"))) PPC_WEAK_FUNC(sub_8308ACA0);
PPC_FUNC_IMPL(__imp__sub_8308ACA0) {
	PPC_FUNC_PROLOGUE();
	// lhz r3,306(r3)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + 306);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACA8"))) PPC_WEAK_FUNC(sub_8308ACA8);
PPC_FUNC_IMPL(__imp__sub_8308ACA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,148(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACB0"))) PPC_WEAK_FUNC(sub_8308ACB0);
PPC_FUNC_IMPL(__imp__sub_8308ACB0) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACB8"))) PPC_WEAK_FUNC(sub_8308ACB8);
PPC_FUNC_IMPL(__imp__sub_8308ACB8) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACC0"))) PPC_WEAK_FUNC(sub_8308ACC0);
PPC_FUNC_IMPL(__imp__sub_8308ACC0) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACC8"))) PPC_WEAK_FUNC(sub_8308ACC8);
PPC_FUNC_IMPL(__imp__sub_8308ACC8) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACD0"))) PPC_WEAK_FUNC(sub_8308ACD0);
PPC_FUNC_IMPL(__imp__sub_8308ACD0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,312(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 312);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACD8"))) PPC_WEAK_FUNC(sub_8308ACD8);
PPC_FUNC_IMPL(__imp__sub_8308ACD8) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,140(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 140);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACE0"))) PPC_WEAK_FUNC(sub_8308ACE0);
PPC_FUNC_IMPL(__imp__sub_8308ACE0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,144(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 144);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACE8"))) PPC_WEAK_FUNC(sub_8308ACE8);
PPC_FUNC_IMPL(__imp__sub_8308ACE8) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACF0"))) PPC_WEAK_FUNC(sub_8308ACF0);
PPC_FUNC_IMPL(__imp__sub_8308ACF0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,292(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 292);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ACF8"))) PPC_WEAK_FUNC(sub_8308ACF8);
PPC_FUNC_IMPL(__imp__sub_8308ACF8) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,288(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 288);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD00"))) PPC_WEAK_FUNC(sub_8308AD00);
PPC_FUNC_IMPL(__imp__sub_8308AD00) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,312(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 312);
	// and r10,r11,r4
	ctx.r10.u64 = ctx.r11.u64 & ctx.r4.u64;
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r3,r8,1
	ctx.r3.u64 = ctx.r8.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD18"))) PPC_WEAK_FUNC(sub_8308AD18);
PPC_FUNC_IMPL(__imp__sub_8308AD18) {
	PPC_FUNC_PROLOGUE();
	// lhz r3,306(r3)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + 306);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD20"))) PPC_WEAK_FUNC(sub_8308AD20);
PPC_FUNC_IMPL(__imp__sub_8308AD20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,148(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD28"))) PPC_WEAK_FUNC(sub_8308AD28);
PPC_FUNC_IMPL(__imp__sub_8308AD28) {
	PPC_FUNC_PROLOGUE();
	// lhz r3,304(r3)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + 304);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD30"))) PPC_WEAK_FUNC(sub_8308AD30);
PPC_FUNC_IMPL(__imp__sub_8308AD30) {
	PPC_FUNC_PROLOGUE();
	// lhz r3,304(r3)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r3.u32 + 304);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD38"))) PPC_WEAK_FUNC(sub_8308AD38);
PPC_FUNC_IMPL(__imp__sub_8308AD38) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,272(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 272);
	// addi r11,r4,272
	ctx.r11.s64 = ctx.r4.s64 + 272;
	// lwz r9,276(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 276);
	// lwz r8,280(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 280);
	// lwz r7,284(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 284);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r8,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r8.u32);
	// stw r7,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r7.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD60"))) PPC_WEAK_FUNC(sub_8308AD60);
PPC_FUNC_IMPL(__imp__sub_8308AD60) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,300(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 300);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD68"))) PPC_WEAK_FUNC(sub_8308AD68);
PPC_FUNC_IMPL(__imp__sub_8308AD68) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,312(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 312);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD70"))) PPC_WEAK_FUNC(sub_8308AD70);
PPC_FUNC_IMPL(__imp__sub_8308AD70) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,312(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 312);
	// clrlwi r10,r11,29
	ctx.r10.u64 = ctx.r11.u32 & 0x7;
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r3,r8,1
	ctx.r3.u64 = ctx.r8.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD88"))) PPC_WEAK_FUNC(sub_8308AD88);
PPC_FUNC_IMPL(__imp__sub_8308AD88) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD90"))) PPC_WEAK_FUNC(sub_8308AD90);
PPC_FUNC_IMPL(__imp__sub_8308AD90) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AD94"))) PPC_WEAK_FUNC(sub_8308AD94);
PPC_FUNC_IMPL(__imp__sub_8308AD94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AD98"))) PPC_WEAK_FUNC(sub_8308AD98);
PPC_FUNC_IMPL(__imp__sub_8308AD98) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ADA0"))) PPC_WEAK_FUNC(sub_8308ADA0);
PPC_FUNC_IMPL(__imp__sub_8308ADA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f0,8(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308ADB8"))) PPC_WEAK_FUNC(sub_8308ADB8);
PPC_FUNC_IMPL(__imp__sub_8308ADB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r7,-32222
	ctx.r7.s64 = -2111700992;
	// lis r6,-32235
	ctx.r6.s64 = -2112552960;
	// lfs f0,6140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,-11796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11796);
	ctx.f13.f64 = double(temp.f32);
	// addi r5,r6,-1496
	ctx.r5.s64 = ctx.r6.s64 + -1496;
	// lfs f12,7676(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,7712(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7712);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-18272(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -18272);
	ctx.f10.f64 = double(temp.f32);
	// stw r5,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r5.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f13,8(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f12,12(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// stfs f11,16(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// stfs f10,20(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AE04"))) PPC_WEAK_FUNC(sub_8308AE04);
PPC_FUNC_IMPL(__imp__sub_8308AE04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AE08"))) PPC_WEAK_FUNC(sub_8308AE08);
PPC_FUNC_IMPL(__imp__sub_8308AE08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r7,-32222
	ctx.r7.s64 = -2111700992;
	// lis r6,-32235
	ctx.r6.s64 = -2112552960;
	// lfs f0,6140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,-11796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11796);
	ctx.f13.f64 = double(temp.f32);
	// addi r5,r6,-1496
	ctx.r5.s64 = ctx.r6.s64 + -1496;
	// lfs f12,7676(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,7712(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7712);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-18272(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -18272);
	ctx.f10.f64 = double(temp.f32);
	// stw r5,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r5.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f13,8(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f12,12(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// stfs f11,16(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// stfs f10,20(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308AE54"))) PPC_WEAK_FUNC(sub_8308AE54);
PPC_FUNC_IMPL(__imp__sub_8308AE54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308AE58"))) PPC_WEAK_FUNC(sub_8308AE58);
PPC_FUNC_IMPL(__imp__sub_8308AE58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ac4
	ctx.lr = 0x8308AE68;
	__savefpr_19(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwz r11,264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308b1f4
	if (ctx.cr6.eq) goto loc_8308B1F4;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,60(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8308b1f4
	if (ctx.cr6.eq) goto loc_8308B1F4;
	// lfs f11,220(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f7,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// lfs f9,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f9.f64 = double(temp.f32);
	// fneg f4,f7
	ctx.f4.u64 = ctx.f7.u64 ^ 0x8000000000000000;
	// lfs f5,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f5.f64 = double(temp.f32);
	// fmr f6,f9
	ctx.f6.f64 = ctx.f9.f64;
	// fneg f2,f5
	ctx.f2.u64 = ctx.f5.u64 ^ 0x8000000000000000;
	// lfs f12,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// lfs f3,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f3.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// fneg f1,f3
	ctx.f1.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// lfs f7,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f7.f64 = double(temp.f32);
	// lfs f13,6380(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6380);
	ctx.f13.f64 = double(temp.f32);
	// fmr f20,f7
	ctx.f20.f64 = ctx.f7.f64;
	// fmsubs f5,f7,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f7.f64 - ctx.f13.f64));
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f3,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f3.f64 = double(temp.f32);
	// addi r9,r11,188
	ctx.r9.s64 = ctx.r11.s64 + 188;
	// fmr f31,f3
	ctx.f31.f64 = ctx.f3.f64;
	// lfs f30,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f29.f64 = double(temp.f32);
	// addi r9,r11,216
	ctx.r9.s64 = ctx.r11.s64 + 216;
	// fmuls f26,f8,f4
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f28,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f28.f64 = double(temp.f32);
	// lfs f0,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f27,f28,f28,f13
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64 - ctx.f13.f64));
	// fmuls f25,f6,f2
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f23,f8,f2
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// fmuls f24,f1,f10
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fneg f12,f12
	ctx.f12.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fmuls f21,f2,f5
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f22,f5,f4
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fneg f11,f11
	ctx.f11.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// fmsubs f2,f2,f10,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 - ctx.f26.f64));
	// fneg f9,f9
	ctx.f9.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// fmsubs f26,f8,f1,f25
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f1.f64 - ctx.f25.f64));
	// fmadds f1,f6,f1,f23
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmsubs f25,f6,f4,f24
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// fmadds f4,f10,f4,f1
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f1.f64));
	// fmuls f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fsubs f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fsubs f1,f22,f26
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fmuls f5,f4,f10
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f10,f8,f4
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fsubs f7,f21,f7
	ctx.f7.f64 = double(float(ctx.f21.f64 - ctx.f7.f64));
	// fmuls f8,f6,f4
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fadds f6,f1,f5
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f5,f7,f10
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f4,f2,f8
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fmuls f2,f6,f0
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f10,f4,f0
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f8,f30,f2
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmuls f4,f27,f2
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f7,f29,f1
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// fmuls f6,f10,f31
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f29,f10
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmuls f26,f1,f27
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmuls f27,f10,f27
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmsubs f8,f1,f31,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f31.f64 - ctx.f8.f64));
	// fmsubs f7,f30,f10,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 - ctx.f7.f64));
	// fmsubs f6,f29,f2,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 - ctx.f6.f64));
	// fmadds f5,f31,f2,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f2.f64 + ctx.f5.f64));
	// fmuls f2,f8,f28
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// fmuls f10,f7,f28
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmuls f8,f6,f28
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmadds f7,f30,f1,f5
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f5.f64));
	// fadds f6,f27,f2
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fadds f5,f4,f10
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f4,f26,f8
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fmuls f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f1,f30,f7
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmuls f10,f29,f7
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// fmr f8,f30
	ctx.f8.f64 = ctx.f30.f64;
	// fmuls f7,f20,f3
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmr f31,f28
	ctx.f31.f64 = ctx.f28.f64;
	// fmuls f30,f20,f8
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f28,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f9,f31
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f19,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f27,f12,f3
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// lfs f26,136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f7,f9,f8,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f7.f64));
	// lfs f25,132(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfs f6,112(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fadds f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// lfs f4,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// addi r9,r10,112
	ctx.r9.s64 = ctx.r10.s64 + 112;
	// lfs f24,116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 116);
	ctx.f24.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f23,124(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// addi r8,r10,64
	ctx.r8.s64 = ctx.r10.s64 + 64;
	// fmadds f30,f11,f31,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f30.f64));
	// lfs f22,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f20,f28,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 + ctx.f29.f64));
	// fmsubs f27,f20,f31,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 - ctx.f27.f64));
	// fmadds f7,f12,f31,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f7.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmadds f31,f12,f28,f30
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 + ctx.f30.f64));
	// fmadds f30,f11,f3,f29
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f29.f64));
	// fnmsubs f29,f11,f8,f27
	ctx.f29.f64 = double(float(-(ctx.f11.f64 * ctx.f8.f64 - ctx.f27.f64)));
	// fnmsubs f7,f11,f28,f7
	ctx.f7.f64 = double(float(-(ctx.f11.f64 * ctx.f28.f64 - ctx.f7.f64)));
	// fadds f27,f19,f10
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f10.f64));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fadds f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fnmsubs f3,f9,f3,f31
	ctx.f3.f64 = double(float(-(ctx.f9.f64 * ctx.f3.f64 - ctx.f31.f64)));
	// fnmsubs f8,f12,f8,f30
	ctx.f8.f64 = double(float(-(ctx.f12.f64 * ctx.f8.f64 - ctx.f30.f64)));
	// fnmsubs f9,f9,f28,f29
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f28.f64 - ctx.f29.f64)));
	// fmuls f12,f7,f26
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// fmuls f22,f7,f6
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f11,f3,f2
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f10,f8,f25
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fmuls f31,f8,f26
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmsubs f13,f9,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f9.f64 - ctx.f13.f64));
	// fmuls f30,f3,f4
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmuls f29,f8,f6
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmsubs f12,f8,f2,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 - ctx.f12.f64));
	// fmuls f28,f9,f4
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmsubs f11,f7,f25,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f11.f64));
	// fmsubs f10,f3,f26,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 - ctx.f10.f64));
	// fmadds f31,f3,f25,f31
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 + ctx.f31.f64));
	// fmuls f21,f13,f2
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmadds f30,f9,f6,f30
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fmuls f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// fmadds f29,f9,f24,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmadds f2,f7,f2,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 + ctx.f31.f64));
	// fmadds f31,f7,f23,f30
	ctx.f31.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 + ctx.f30.f64));
	// fmadds f30,f3,f23,f29
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f29.f64));
	// fadds f12,f25,f12
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f12.f64));
	// fadds f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// fadds f10,f21,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fmuls f13,f2,f7
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f29,f3,f2
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f8,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// fnmsubs f31,f8,f24,f31
	ctx.f31.f64 = double(float(-(ctx.f8.f64 * ctx.f24.f64 - ctx.f31.f64)));
	// fnmsubs f30,f7,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f7.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fadds f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fadds f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f29.f64));
	// fadds f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f2,f12,f0
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// fadds f12,f2,f1
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fadds f11,f13,f27
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// fmadds f5,f8,f23,f28
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f23.f64 + ctx.f28.f64));
	// fmsubs f2,f9,f23,f22
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f23.f64 - ctx.f22.f64));
	// fmuls f1,f30,f30
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f13,6140(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f30,f31
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// addi r11,r1,-160
	ctx.r11.s64 = ctx.r1.s64 + -160;
	// fmadds f7,f7,f24,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f24.f64 + ctx.f5.f64));
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// fmuls f29,f31,f31
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r7,9
	ctx.r7.s64 = 9;
	// fnmsubs f5,f3,f24,f2
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f24.f64 - ctx.f2.f64)));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f7,f3,f6,f7
	ctx.f7.f64 = double(float(-(ctx.f3.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// fnmsubs f9,f29,f0,f13
	ctx.f9.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fnmsubs f6,f8,f4,f5
	ctx.f6.f64 = double(float(-(ctx.f8.f64 * ctx.f4.f64 - ctx.f5.f64)));
	// fsubs f5,f13,f2
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f3,f7,f7
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// fsubs f4,f9,f2
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfs f4,-128(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -128, temp.u32);
	// fmuls f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f13,f7,f30
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmuls f7,f6,f30
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f4,f3,f0
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f3,f2,f0
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f13,f8,f0
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f8,f7,f0
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f6,-160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// fsubs f5,f9,f4
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f5,-144(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -144, temp.u32);
	// fsubs f4,f1,f13
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f13.f64));
	// stfs f4,-156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -156, temp.u32);
	// fadds f0,f8,f3
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f0,-152(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -152, temp.u32);
	// fsubs f9,f2,f7
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f9,-140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -140, temp.u32);
	// fadds f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// stfs f13,-148(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -148, temp.u32);
	// fsubs f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// stfs f8,-136(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -136, temp.u32);
	// fadds f7,f7,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfs f7,-132(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -132, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_8308B1C8:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x8308b1c8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308B1C8;
	// stfs f10,36(r8)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + 36, temp.u32);
	// stfs f12,40(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 40, temp.u32);
	// stfs f11,44(r8)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + 44, temp.u32);
	// lwz r11,264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,60(r10)
	PPC_STORE_U32(ctx.r10.u32 + 60, ctx.r9.u32);
loc_8308B1F4:
	// addi r3,r10,64
	ctx.r3.s64 = ctx.r10.s64 + 64;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6b10
	ctx.lr = 0x8308B200;
	__restfpr_19(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308B20C"))) PPC_WEAK_FUNC(sub_8308B20C);
PPC_FUNC_IMPL(__imp__sub_8308B20C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308B210"))) PPC_WEAK_FUNC(sub_8308B210);
PPC_FUNC_IMPL(__imp__sub_8308B210) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ac0
	ctx.lr = 0x8308B220;
	__savefpr_18(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r10,264(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8308b434
	if (ctx.cr6.eq) goto loc_8308B434;
	// lwz r9,280(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 280);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8308b434
	if (ctx.cr6.eq) goto loc_8308B434;
	// lfs f12,252(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f11,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// fmuls f9,f11,f12
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f7,244(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f6.f64 = double(temp.f32);
	// fmr f30,f7
	ctx.f30.f64 = ctx.f7.f64;
	// fmuls f3,f6,f7
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f1,248(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 248);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f6,f12
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f8,256(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 256);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f11,f7
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f4,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fmr f29,f1
	ctx.f29.f64 = ctx.f1.f64;
	// lfs f31,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f31.f64 = double(temp.f32);
	// lfs f28,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lfs f27,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f26,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,112
	ctx.r9.s64 = ctx.r11.s64 + 112;
	// fmuls f25,f26,f10
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f13,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f9,f4,f8,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f9.f64));
	// lfs f23,260(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 260);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f28,f30
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f0,7676(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f3,f11,f8,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f3.f64));
	// lfs f22,264(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f31,f8,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f2.f64));
	// lfs f20,268(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f5,f6,f8,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 - ctx.f5.f64));
	// addi r9,r10,244
	ctx.r9.s64 = ctx.r10.s64 + 244;
	// fmuls f18,f27,f30
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// addi r8,r11,12
	ctx.r8.s64 = ctx.r11.s64 + 12;
	// fmuls f19,f27,f29
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// fmsubs f24,f8,f8,f13
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f8.f64 - ctx.f13.f64));
	// lfs f13,6140(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f25,f28,f29,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f25.f64));
	// fmadds f9,f6,f1,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f9.f64));
	// fmsubs f21,f27,f10,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f21.f64));
	// fmadds f3,f31,f1,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 + ctx.f3.f64));
	// fmadds f2,f4,f7,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fnmsubs f5,f4,f1,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f1.f64 - ctx.f5.f64)));
	// fmadds f18,f28,f10,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f18.f64));
	// fmsubs f19,f26,f30,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 - ctx.f19.f64));
	// fmuls f6,f26,f24
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// fmuls f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// fnmsubs f9,f31,f7,f9
	ctx.f9.f64 = double(float(-(ctx.f31.f64 * ctx.f7.f64 - ctx.f9.f64)));
	// fmuls f7,f25,f8
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fnmsubs f4,f4,f12,f3
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fnmsubs f3,f11,f1,f2
	ctx.f3.f64 = double(float(-(ctx.f11.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// fnmsubs f5,f31,f12,f5
	ctx.f5.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// fmuls f2,f21,f8
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmadds f12,f26,f29,f18
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 + ctx.f18.f64));
	// fmuls f1,f19,f8
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fmuls f11,f9,f9
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// fadds f8,f27,f7
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fmuls f7,f9,f4
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f31,f3,f3
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// fmuls f27,f5,f3
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fadds f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fmuls f2,f12,f29
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fadds f2,f1,f10
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fsubs f1,f13,f11
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f10,f7,f30
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// stfs f10,-156(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -156, temp.u32);
	// fmuls f10,f3,f4
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// stfs f1,-160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// fmuls f1,f5,f9
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fmuls f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// addi r10,r1,-160
	ctx.r10.s64 = ctx.r1.s64 + -160;
	// fmuls f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// fmuls f29,f4,f4
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// li r7,9
	ctx.r7.s64 = 9;
	// fadds f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fmuls f3,f2,f0
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f6,f0
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f12,f30,f7
	ctx.f12.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// stfs f12,-148(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -148, temp.u32);
	// fmuls f8,f1,f0
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f6,f9,f0
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fnmsubs f7,f29,f0,f13
	ctx.f7.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f20,f3
	ctx.f13.f64 = double(float(ctx.f20.f64 + ctx.f3.f64));
	// fadds f0,f22,f2
	ctx.f0.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// fadds f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f3,-152(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -152, temp.u32);
	// fsubs f1,f10,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f1,-136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -136, temp.u32);
	// fsubs f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfs f12,-140(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -140, temp.u32);
	// fsubs f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// stfs f2,-144(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -144, temp.u32);
	// fadds f10,f5,f6
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f10,-132(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -132, temp.u32);
	// fsubs f9,f7,f11
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f11.f64));
	// stfs f9,-128(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -128, temp.u32);
	// fadds f12,f4,f23
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_8308B408:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x8308b408
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308B408;
	// stfs f12,36(r8)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 36, temp.u32);
	// stfs f0,40(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 40, temp.u32);
	// stfs f13,44(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 44, temp.u32);
	// lwz r10,264(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// lwz r9,280(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 280);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
loc_8308B434:
	// addi r3,r11,12
	ctx.r3.s64 = ctx.r11.s64 + 12;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6b0c
	ctx.lr = 0x8308B440;
	__restfpr_18(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308B44C"))) PPC_WEAK_FUNC(sub_8308B44C);
PPC_FUNC_IMPL(__imp__sub_8308B44C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308B450"))) PPC_WEAK_FUNC(sub_8308B450);
PPC_FUNC_IMPL(__imp__sub_8308B450) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ac4
	ctx.lr = 0x8308B460;
	__savefpr_19(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwz r11,264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308b7ec
	if (ctx.cr6.eq) goto loc_8308B7EC;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,60(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8308b7ec
	if (ctx.cr6.eq) goto loc_8308B7EC;
	// lfs f11,220(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f7,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// lfs f9,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f9.f64 = double(temp.f32);
	// fneg f4,f7
	ctx.f4.u64 = ctx.f7.u64 ^ 0x8000000000000000;
	// lfs f5,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f5.f64 = double(temp.f32);
	// fmr f6,f9
	ctx.f6.f64 = ctx.f9.f64;
	// lfs f3,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f3.f64 = double(temp.f32);
	// fneg f2,f5
	ctx.f2.u64 = ctx.f5.u64 ^ 0x8000000000000000;
	// lfs f12,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fneg f1,f3
	ctx.f1.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f7,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f7.f64 = double(temp.f32);
	// lfs f13,6380(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6380);
	ctx.f13.f64 = double(temp.f32);
	// fmr f20,f7
	ctx.f20.f64 = ctx.f7.f64;
	// fmsubs f5,f7,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f7.f64 - ctx.f13.f64));
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f3,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f3.f64 = double(temp.f32);
	// addi r9,r11,188
	ctx.r9.s64 = ctx.r11.s64 + 188;
	// fmr f31,f3
	ctx.f31.f64 = ctx.f3.f64;
	// lfs f30,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f29.f64 = double(temp.f32);
	// addi r9,r11,216
	ctx.r9.s64 = ctx.r11.s64 + 216;
	// fmuls f26,f8,f4
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f28,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f28.f64 = double(temp.f32);
	// lfs f0,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f27,f28,f28,f13
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64 - ctx.f13.f64));
	// fmuls f25,f6,f2
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmuls f24,f1,f10
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fneg f12,f12
	ctx.f12.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fmuls f21,f5,f2
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmuls f22,f5,f4
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fneg f11,f11
	ctx.f11.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// fmsubs f26,f10,f2,f26
	ctx.f26.f64 = double(float(ctx.f10.f64 * ctx.f2.f64 - ctx.f26.f64));
	// fneg f9,f9
	ctx.f9.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// fmsubs f1,f8,f1,f25
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f1.f64 - ctx.f25.f64));
	// fmadds f2,f8,f2,f23
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmsubs f25,f6,f4,f24
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmadds f4,f10,f4,f2
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fmuls f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fsubs f2,f5,f26
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// fsubs f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f1.f64));
	// fmuls f5,f4,f10
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f10,f8,f4
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fsubs f7,f21,f7
	ctx.f7.f64 = double(float(ctx.f21.f64 - ctx.f7.f64));
	// fmuls f8,f6,f4
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fadds f6,f1,f5
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f5,f7,f10
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f4,f2,f8
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fmuls f2,f6,f0
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f10,f4,f0
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f8,f30,f2
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmuls f4,f27,f2
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f7,f29,f1
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// fmuls f6,f10,f31
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f29,f10
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmuls f26,f1,f27
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmuls f27,f10,f27
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmsubs f8,f1,f31,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f31.f64 - ctx.f8.f64));
	// fmsubs f7,f30,f10,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 - ctx.f7.f64));
	// fmsubs f6,f29,f2,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 - ctx.f6.f64));
	// fmadds f5,f31,f2,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f2.f64 + ctx.f5.f64));
	// fmuls f2,f8,f28
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// fmuls f10,f7,f28
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmuls f8,f6,f28
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmadds f7,f30,f1,f5
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f5.f64));
	// fadds f6,f27,f2
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fadds f5,f4,f10
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f4,f26,f8
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fmuls f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f1,f30,f7
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmuls f10,f29,f7
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// fmr f8,f30
	ctx.f8.f64 = ctx.f30.f64;
	// fmuls f7,f20,f3
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmr f31,f28
	ctx.f31.f64 = ctx.f28.f64;
	// fmuls f30,f20,f8
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f28,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f9,f31
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f19,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f27,f12,f3
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// lfs f26,136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f7,f9,f8,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f7.f64));
	// lfs f25,132(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfs f6,112(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fadds f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// lfs f4,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// addi r9,r10,112
	ctx.r9.s64 = ctx.r10.s64 + 112;
	// lfs f24,116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 116);
	ctx.f24.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f23,124(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// addi r8,r10,64
	ctx.r8.s64 = ctx.r10.s64 + 64;
	// fmadds f30,f11,f31,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f30.f64));
	// lfs f22,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f20,f28,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 + ctx.f29.f64));
	// fmsubs f27,f20,f31,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 - ctx.f27.f64));
	// fmadds f7,f12,f31,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f7.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmadds f31,f12,f28,f30
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 + ctx.f30.f64));
	// fmadds f30,f11,f3,f29
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f29.f64));
	// fnmsubs f29,f11,f8,f27
	ctx.f29.f64 = double(float(-(ctx.f11.f64 * ctx.f8.f64 - ctx.f27.f64)));
	// fnmsubs f7,f11,f28,f7
	ctx.f7.f64 = double(float(-(ctx.f11.f64 * ctx.f28.f64 - ctx.f7.f64)));
	// fadds f27,f19,f10
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f10.f64));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fadds f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fnmsubs f3,f9,f3,f31
	ctx.f3.f64 = double(float(-(ctx.f9.f64 * ctx.f3.f64 - ctx.f31.f64)));
	// fnmsubs f8,f12,f8,f30
	ctx.f8.f64 = double(float(-(ctx.f12.f64 * ctx.f8.f64 - ctx.f30.f64)));
	// fnmsubs f9,f9,f28,f29
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f28.f64 - ctx.f29.f64)));
	// fmuls f12,f7,f26
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// fmuls f22,f7,f6
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f11,f3,f2
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f10,f8,f25
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fmuls f31,f8,f26
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmsubs f13,f9,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f9.f64 - ctx.f13.f64));
	// fmuls f30,f3,f4
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmuls f29,f8,f6
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmsubs f12,f8,f2,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 - ctx.f12.f64));
	// fmuls f28,f9,f4
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmsubs f11,f7,f25,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f11.f64));
	// fmsubs f10,f3,f26,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 - ctx.f10.f64));
	// fmadds f31,f3,f25,f31
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 + ctx.f31.f64));
	// fmuls f21,f13,f2
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmadds f30,f9,f6,f30
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fmuls f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// fmadds f29,f9,f24,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmadds f2,f7,f2,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 + ctx.f31.f64));
	// fmadds f31,f7,f23,f30
	ctx.f31.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 + ctx.f30.f64));
	// fmadds f30,f3,f23,f29
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f29.f64));
	// fadds f12,f25,f12
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f12.f64));
	// fadds f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// fadds f10,f21,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fmuls f13,f2,f7
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f29,f3,f2
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f8,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// fnmsubs f31,f8,f24,f31
	ctx.f31.f64 = double(float(-(ctx.f8.f64 * ctx.f24.f64 - ctx.f31.f64)));
	// fnmsubs f30,f7,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f7.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fadds f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fadds f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f29.f64));
	// fadds f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f2,f12,f0
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// fadds f12,f2,f1
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fadds f11,f13,f27
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// fmadds f5,f8,f23,f28
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f23.f64 + ctx.f28.f64));
	// fmsubs f2,f9,f23,f22
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f23.f64 - ctx.f22.f64));
	// fmuls f1,f30,f30
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f13,6140(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f30,f31
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// addi r11,r1,-160
	ctx.r11.s64 = ctx.r1.s64 + -160;
	// fmadds f7,f7,f24,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f24.f64 + ctx.f5.f64));
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// fmuls f29,f31,f31
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r7,9
	ctx.r7.s64 = 9;
	// fnmsubs f5,f3,f24,f2
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f24.f64 - ctx.f2.f64)));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f7,f3,f6,f7
	ctx.f7.f64 = double(float(-(ctx.f3.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// fnmsubs f9,f29,f0,f13
	ctx.f9.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fnmsubs f6,f8,f4,f5
	ctx.f6.f64 = double(float(-(ctx.f8.f64 * ctx.f4.f64 - ctx.f5.f64)));
	// fsubs f5,f13,f2
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f3,f7,f7
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// fsubs f4,f9,f2
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfs f4,-128(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -128, temp.u32);
	// fmuls f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f13,f7,f30
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmuls f7,f6,f30
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f4,f3,f0
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f3,f2,f0
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f13,f8,f0
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f8,f7,f0
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f6,-160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// fsubs f5,f9,f4
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f5,-144(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -144, temp.u32);
	// fsubs f4,f1,f13
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f13.f64));
	// stfs f4,-156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -156, temp.u32);
	// fadds f0,f8,f3
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f0,-152(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -152, temp.u32);
	// fsubs f9,f2,f7
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f9,-140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -140, temp.u32);
	// fadds f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// stfs f13,-148(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -148, temp.u32);
	// fsubs f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// stfs f8,-136(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -136, temp.u32);
	// fadds f7,f7,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfs f7,-132(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -132, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_8308B7C0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x8308b7c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308B7C0;
	// stfs f10,36(r8)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + 36, temp.u32);
	// stfs f12,40(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 40, temp.u32);
	// stfs f11,44(r8)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + 44, temp.u32);
	// lwz r11,264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,60(r10)
	PPC_STORE_U32(ctx.r10.u32 + 60, ctx.r9.u32);
loc_8308B7EC:
	// addi r3,r10,64
	ctx.r3.s64 = ctx.r10.s64 + 64;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6b10
	ctx.lr = 0x8308B7F8;
	__restfpr_19(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308B804"))) PPC_WEAK_FUNC(sub_8308B804);
PPC_FUNC_IMPL(__imp__sub_8308B804) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308B808"))) PPC_WEAK_FUNC(sub_8308B808);
PPC_FUNC_IMPL(__imp__sub_8308B808) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x8308B810;
	__savegprlr_29(ctx, base);
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82cb6ab0
	ctx.lr = 0x8308B818;
	__savefpr_14(ctx, base);
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lhz r11,260(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 260);
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
	// beq cr6,0x8308b8f4
	if (ctx.cr6.eq) goto loc_8308B8F4;
	// addi r30,r31,224
	ctx.r30.s64 = ctx.r31.s64 + 224;
	// lwz r31,252(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// lhz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
	// bne cr6,0x8308b84c
	if (!ctx.cr6.eq) goto loc_8308B84C;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x8308b8b0
	goto loc_8308B8B0;
loc_8308B84C:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// rlwinm r10,r9,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x8308b898
	if (!ctx.cr6.eq) goto loc_8308B898;
	// lis r10,-31890
	ctx.r10.s64 = -2089943040;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r9,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r9.u32);
	// lwz r9,24264(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24264);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8308b898
	if (ctx.cr6.eq) goto loc_8308B898;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r10,24264(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24264);
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r4,r11,r8
	ctx.r4.u64 = ctx.r11.u64 + ctx.r8.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308B898;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_8308B898:
	// lhz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 36);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// rotlwi r10,r11,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
loc_8308B8B0:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,4(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + 4, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,8(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 8, temp.u32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,12(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 12, temp.u32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,16(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + 16, temp.u32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,20(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 20, temp.u32);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82cb6afc
	ctx.lr = 0x8308B8F0;
	__restfpr_14(ctx, base);
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
loc_8308B8F4:
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// beq cr6,0x8308bba8
	if (ctx.cr6.eq) goto loc_8308BBA8;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308B918;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// lfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r7,56(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 56);
	// lfs f29,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f28.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x8308B944;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lis r5,-32256
	ctx.r5.s64 = -2113929216;
	// lwz r4,264(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// lfs f13,4(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f13
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f13,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f8,12(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f31,7676(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 7676);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f10,f8
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f5,f13,f8
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f30,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f4,f10,f10
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// fmuls f3,f11,f11
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// fmuls f0,f12,f31
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// fmuls f13,f9,f31
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f12,f7,f31
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f11,f6,f31
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f10,f5,f31
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f9,f4,f31
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fnmsubs f8,f3,f31,f30
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// fmuls f7,f2,f31
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f6,f1,f31
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fsubs f5,f30,f0
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f0.f64));
	// fadds f4,f11,f13
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f27,f13,f11
	ctx.f27.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f26,f8,f9
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fsubs f25,f12,f10
	ctx.f25.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f24,f7,f6
	ctx.f24.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f23,f6,f7
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f22,f5,f9
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fsubs f21,f8,f0
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x8308B9F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f2,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f2,f2
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f2,f1
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f13
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmuls f9,f13,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lwz r4,264(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// fmuls f8,f13,f1
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// fmuls f7,f2,f11
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f6,f1,f1
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fmuls f5,f0,f31
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f4,f12,f31
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f3,f10,f31
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f0,f9,f31
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f12,f8,f31
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f10,f13,f2
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f9,f1,f11
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fmuls f8,f7,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fnmsubs f7,f6,f31,f30
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// fsubs f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// fsubs f30,f4,f0
	ctx.f30.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// fadds f20,f0,f4
	ctx.f20.f64 = double(float(ctx.f0.f64 + ctx.f4.f64));
	// fmuls f4,f10,f31
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f2,f9,f31
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// fadds f31,f8,f12
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f17,f12,f8
	ctx.f17.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fsubs f19,f7,f3
	ctx.f19.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fsubs f18,f6,f3
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fsubs f16,f7,f5
	ctx.f16.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fsubs f15,f4,f2
	ctx.f15.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f14,f2,f4
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x8308BA90;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// fmuls f1,f30,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f29.f64));
	// fmuls f0,f15,f28
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f16,f28
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f31,f25
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f31,f23
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f6,f15,f25
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// stfs f3,88(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f2,f16,f25
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f25,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f7,f31,f21
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// stfs f25,84(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f5,f20,f27
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f25,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f4,f19,f24
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// stfs f25,80(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f25,f14,f24
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f24.f64));
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// fmadds f1,f31,f28,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f28.f64 + ctx.f1.f64));
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// fmuls f3,f17,f27
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmadds f12,f17,f13,f12
	ctx.f12.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f0,f20,f13,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f0.f64));
	// fmadds f10,f18,f22,f10
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f10.f64));
	// fmadds f9,f27,f18,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 + ctx.f9.f64));
	// fmadds f7,f11,f18,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f18.f64 + ctx.f7.f64));
	// fmadds f6,f20,f22,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 + ctx.f6.f64));
	// fmadds f5,f15,f23,f5
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f5.f64));
	// fmadds f4,f15,f21,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f21.f64 + ctx.f4.f64));
	// fmadds f2,f17,f22,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f2.f64));
	// fmadds f31,f16,f21,f25
	ctx.f31.f64 = double(float(ctx.f16.f64 * ctx.f21.f64 + ctx.f25.f64));
	// fmadds f1,f18,f13,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmadds f3,f16,f23,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f3.f64));
	// fmadds f13,f14,f29,f12
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 + ctx.f12.f64));
	// fmadds f0,f19,f29,f0
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f0.f64));
	// fmadds f12,f30,f8,f10
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 + ctx.f10.f64));
	// stfs f12,128(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmadds f10,f30,f26,f9
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f26.f64 + ctx.f9.f64));
	// stfs f10,132(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmadds f9,f30,f24,f7
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 + ctx.f7.f64));
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f7,f19,f8,f6
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f6.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f6,f19,f26,f5
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f5.f64));
	// stfs f9,136(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f5,f20,f11,f4
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f4.f64));
	// stfs f7,140(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmadds f4,f14,f8,f2
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f8.f64 + ctx.f2.f64));
	// stfs f6,144(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmadds f2,f17,f11,f31
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f31.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f3,f14,f26,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f3.f64));
	// stfs f5,148(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f4,152(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f27,f12,f13
	ctx.f27.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// stfs f2,160(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f29,f10,f1
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8308BB90:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308bb90
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308BB90;
	// b 0x8308bcb8
	goto loc_8308BCB8;
loc_8308BBA8:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308BBB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lfs f12,4(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lwz r5,52(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 52);
	// fmuls f11,f12,f12
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// lfs f10,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f7,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f9,f9
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// lfs f0,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fmuls f3,f12,f7
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f13,6140(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f9,f10
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f1,f9,f12
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmuls f2,f10,f10
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fmuls f12,f10,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f8,f0
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f9,f6,f0
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f8,f5,f0
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f7,f4,f0
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f1,f0
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fnmsubs f5,f2,f0,f13
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f3,f12,f0
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f1,f10,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f1,132(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f0,f8,f10
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f13,f6,f7
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f10,f7,f6
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f10,152(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f12,f5,f9
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfs f12,144(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f8,f4,f3
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f7,156(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f6,f2,f9
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f6,128(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// stfs f5,160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mtctr r5
	ctx.ctr.u64 = ctx.r5.u64;
	// bctrl 
	ctx.lr = 0x8308BC88;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f29,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lfs f28,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f28.f64 = double(temp.f32);
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// lfs f27,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f27.f64 = double(temp.f32);
	// li r9,9
	ctx.r9.s64 = 9;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8308BCA4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308bca4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308BCA4;
loc_8308BCB8:
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r9,-32222
	ctx.r9.s64 = -2111700992;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f0,-18264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,512(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 512);
	// lfs f13,-18268(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -18268);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f0,100(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f13,108(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f13,116(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x8308BCF8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f13,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// fadds f2,f13,f12
	ctx.f2.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// lfs f11,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fsubs f13,f11,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// fadds f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f8,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,6380(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 6380);
	ctx.f0.f64 = double(temp.f32);
	// fadds f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f10,f9,f8
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f6.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f3.f64 = double(temp.f32);
	// lfs f5,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f2,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f8,f1,f0
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f30,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f31,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f0,f9,f7
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fmuls f26,f9,f6
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f24,f13,f3
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f25,f13,f4
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f7,f8,f7
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f23,f12,f5
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmuls f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f5,f13,f5
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f13,f2,f8
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmuls f8,f10,f1
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// fmadds f1,f11,f1,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f0.f64));
	// fmadds f0,f12,f3,f26
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f26.f64));
	// fabs f26,f24
	ctx.f26.u64 = ctx.f24.u64 & ~0x8000000000000000;
	// fabs f3,f25
	ctx.f3.u64 = ctx.f25.u64 & ~0x8000000000000000;
	// fabs f7,f7
	ctx.f7.u64 = ctx.f7.u64 & ~0x8000000000000000;
	// fmuls f25,f10,f30
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmadds f24,f11,f31,f23
	ctx.f24.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f23.f64));
	// fabs f6,f6
	ctx.f6.u64 = ctx.f6.u64 & ~0x8000000000000000;
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & ~0x8000000000000000;
	// fabs f13,f13
	ctx.f13.u64 = ctx.f13.u64 & ~0x8000000000000000;
	// fmadds f12,f12,f4,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f1.f64));
	// fmadds f11,f11,f30,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f0.f64));
	// fabs f4,f8
	ctx.f4.u64 = ctx.f8.u64 & ~0x8000000000000000;
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fadds f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fabs f1,f25
	ctx.f1.u64 = ctx.f25.u64 & ~0x8000000000000000;
	// fmadds f0,f2,f9,f24
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f24.f64));
	// fadds f3,f26,f6
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// fadds f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fadds f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f29.f64));
	// fadds f11,f28,f11
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f11.f64));
	// fabs f10,f10
	ctx.f10.u64 = ctx.f10.u64 & ~0x8000000000000000;
	// fadds f9,f7,f4
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f7,f27,f0
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f0.f64));
	// fadds f8,f3,f1
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fadds f6,f13,f10
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fsubs f5,f12,f9
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f5,0(r29)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f4,f11,f8
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfs f4,4(r29)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + 4, temp.u32);
	// fadds f3,f9,f12
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fadds f2,f11,f8
	ctx.f2.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fsubs f1,f7,f6
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f1,8(r29)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r29.u32 + 8, temp.u32);
	// fadds f0,f7,f6
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// stfs f3,12(r29)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r29.u32 + 12, temp.u32);
	// stfs f2,16(r29)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r29.u32 + 16, temp.u32);
	// stfs f0,20(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 20, temp.u32);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82cb6afc
	ctx.lr = 0x8308BE3C;
	__restfpr_14(ctx, base);
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308BE40"))) PPC_WEAK_FUNC(sub_8308BE40);
PPC_FUNC_IMPL(__imp__sub_8308BE40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x83088de0
	ctx.lr = 0x8308BE60;
	sub_83088DE0(ctx, base);
	// clrlwi r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308be88
	if (ctx.cr6.eq) goto loc_8308BE88;
	// lis r11,-31901
	ctx.r11.s64 = -2090663936;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,-32308(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -32308);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x8308BE88;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_8308BE88:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308BEA4"))) PPC_WEAK_FUNC(sub_8308BEA4);
PPC_FUNC_IMPL(__imp__sub_8308BEA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308BEA8"))) PPC_WEAK_FUNC(sub_8308BEA8);
PPC_FUNC_IMPL(__imp__sub_8308BEA8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,300(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 300);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r11,308(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 308);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 | 32;
	// stw r10,308(r3)
	PPC_STORE_U32(ctx.r3.u32 + 308, ctx.r10.u32);
	// b 0x83089e10
	sub_83089E10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308BED0"))) PPC_WEAK_FUNC(sub_8308BED0);
PPC_FUNC_IMPL(__imp__sub_8308BED0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308BED4"))) PPC_WEAK_FUNC(sub_8308BED4);
PPC_FUNC_IMPL(__imp__sub_8308BED4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308BED8"))) PPC_WEAK_FUNC(sub_8308BED8);
PPC_FUNC_IMPL(__imp__sub_8308BED8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x8308BEE0;
	__savegprlr_29(ctx, base);
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82cb6ab0
	ctx.lr = 0x8308BEE8;
	__savefpr_14(ctx, base);
	// stwu r1,-496(r1)
	ea = -496 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lhz r11,260(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 260);
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
	// beq cr6,0x8308bf9c
	if (ctx.cr6.eq) goto loc_8308BF9C;
	// addi r30,r31,224
	ctx.r30.s64 = ctx.r31.s64 + 224;
	// lwz r31,252(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// lhz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
	// bne cr6,0x8308bf1c
	if (!ctx.cr6.eq) goto loc_8308BF1C;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x8308bf80
	goto loc_8308BF80;
loc_8308BF1C:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// rlwinm r10,r9,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x8308bf68
	if (!ctx.cr6.eq) goto loc_8308BF68;
	// lis r10,-31890
	ctx.r10.s64 = -2089943040;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r9,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r9.u32);
	// lwz r9,24264(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24264);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8308bf68
	if (ctx.cr6.eq) goto loc_8308BF68;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r10,24264(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24264);
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r4,r11,r8
	ctx.r4.u64 = ctx.r11.u64 + ctx.r8.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308BF68;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_8308BF68:
	// lhz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 36);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// rotlwi r10,r11,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
loc_8308BF80:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// b 0x8308c4c4
	goto loc_8308C4C4;
loc_8308BF9C:
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// beq cr6,0x8308c258
	if (ctx.cr6.eq) goto loc_8308C258;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308BFC0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,304
	ctx.r3.s64 = ctx.r1.s64 + 304;
	// lfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r7,56(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 56);
	// lfs f29,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f28.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x8308BFEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lis r5,-32256
	ctx.r5.s64 = -2113929216;
	// lwz r4,264(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// lfs f13,4(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f13
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f13,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f8,12(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f31,7676(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 7676);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f10,f8
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f5,f13,f8
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f30,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f4,f10,f10
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// fmuls f3,f11,f11
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// fmuls f0,f12,f31
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// fmuls f13,f9,f31
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f12,f7,f31
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f11,f6,f31
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f10,f5,f31
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f9,f4,f31
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fnmsubs f8,f3,f31,f30
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// fmuls f7,f2,f31
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f6,f1,f31
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fsubs f5,f30,f0
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f0.f64));
	// fsubs f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f27,f11,f13
	ctx.f27.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f26,f8,f9
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fsubs f25,f12,f10
	ctx.f25.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f24,f7,f6
	ctx.f24.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f23,f6,f7
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f22,f5,f9
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fsubs f21,f8,f0
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x8308C0A0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f2,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f2,f2
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f2,f1
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f13
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmuls f9,f13,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lwz r4,264(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// fmuls f8,f13,f1
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// fmuls f7,f2,f11
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f6,f1,f1
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fmuls f5,f0,f31
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f4,f12,f31
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f3,f10,f31
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f0,f9,f31
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f12,f8,f31
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f10,f13,f2
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f9,f1,f11
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fmuls f8,f7,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fnmsubs f7,f6,f31,f30
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// fsubs f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// fsubs f30,f4,f0
	ctx.f30.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// fadds f20,f0,f4
	ctx.f20.f64 = double(float(ctx.f0.f64 + ctx.f4.f64));
	// fmuls f4,f10,f31
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f2,f9,f31
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// fadds f31,f8,f12
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f17,f12,f8
	ctx.f17.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fsubs f19,f7,f3
	ctx.f19.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fsubs f18,f6,f3
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fsubs f16,f7,f5
	ctx.f16.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fsubs f15,f4,f2
	ctx.f15.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f14,f2,f4
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x8308C138;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f10,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f13,f30,f27
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f1,f16,f28
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f31,f23
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f7,f19,f26
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// stfs f3,88(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f4,f14,f26
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f31,f21
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// lfs f3,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f8,f15,f25
	ctx.f8.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// stfs f3,80(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f15,f28
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// stfs f29,120(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f5,f16,f25
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmuls f6,f19,f24
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// fmadds f13,f31,f25,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f25.f64 + ctx.f13.f64));
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// fmuls f2,f14,f24
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f24.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmadds f1,f17,f0,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f1.f64));
	// fmuls f29,f30,f29
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64));
	// fmadds f11,f12,f18,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f18.f64 + ctx.f11.f64));
	// fmadds f7,f15,f23,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f7.f64));
	// fmadds f4,f16,f23,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f4.f64));
	// fmadds f3,f20,f0,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f3.f64));
	// fmadds f9,f10,f18,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f18.f64 + ctx.f9.f64));
	// fmadds f8,f20,f22,f8
	ctx.f8.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 + ctx.f8.f64));
	// fmadds f13,f18,f22,f13
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f13.f64));
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmadds f6,f15,f21,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f21.f64 + ctx.f6.f64));
	// fmadds f5,f17,f22,f5
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f5.f64));
	// fmadds f2,f16,f21,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f21.f64 + ctx.f2.f64));
	// fmadds f31,f31,f28,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f28.f64 + ctx.f29.f64));
	// fmadds f11,f30,f26,f11
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f26.f64 + ctx.f11.f64));
	// stfs f11,132(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmadds f7,f20,f12,f7
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f7.f64));
	// stfs f7,144(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmadds f4,f17,f12,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f4.f64));
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f9,f30,f24,f9
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 + ctx.f9.f64));
	// fmadds f1,f14,f25,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f25.f64 + ctx.f1.f64));
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f19,f25,f3
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f3.f64));
	// stfs f9,136(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f8,f19,f27,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f8.f64));
	// stfs f8,140(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmadds f6,f20,f10,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f6.f64));
	// stfs f6,148(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmadds f5,f14,f27,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f5.f64));
	// stfs f5,152(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmadds f2,f17,f10,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmadds f0,f18,f0,f31
	ctx.f0.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f31.f64));
	// stfs f2,160(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f27,f12,f1
	ctx.f27.f64 = double(float(ctx.f12.f64 + ctx.f1.f64));
	// fadds f28,f11,f13
	ctx.f28.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fadds f29,f10,f0
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8308C240:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308c240
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308C240;
	// b 0x8308c368
	goto loc_8308C368;
loc_8308C258:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308C268;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// lfs f12,4(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lwz r5,52(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 52);
	// fmuls f11,f12,f12
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// lfs f10,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f7,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f9,f9
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// lfs f0,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fmuls f3,f12,f7
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f13,6140(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f9,f10
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f1,f9,f12
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmuls f2,f10,f10
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fmuls f12,f10,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f8,f0
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f9,f6,f0
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f8,f5,f0
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f7,f4,f0
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f1,f0
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fnmsubs f5,f2,f0,f13
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f3,f12,f0
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f1,f10,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f1,132(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f0,f8,f10
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f13,f6,f7
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f10,f7,f6
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f10,152(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f12,f5,f9
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfs f12,144(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f8,f4,f3
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f7,156(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f6,f2,f9
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f6,128(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// stfs f5,160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mtctr r5
	ctx.ctr.u64 = ctx.r5.u64;
	// bctrl 
	ctx.lr = 0x8308C338;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f29,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lfs f28,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f28.f64 = double(temp.f32);
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// lfs f27,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f27.f64 = double(temp.f32);
	// li r9,9
	ctx.r9.s64 = 9;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8308C354:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308c354
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308C354;
loc_8308C368:
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r9,-32222
	ctx.r9.s64 = -2111700992;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f0,-18264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,512(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 512);
	// lfs f13,-18268(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -18268);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f0,100(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f13,108(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f13,116(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x8308C3A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// fadds f2,f13,f12
	ctx.f2.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fsubs f13,f11,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// fadds f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f0,6380(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 6380);
	ctx.f0.f64 = double(temp.f32);
	// fadds f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f7,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f2,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f8,f1,f0
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f31,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f30,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f0,f9,f7
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fmuls f26,f9,f6
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f25,f13,f4
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f24,f3,f13
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f7,f8,f7
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f5,f8,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f13,f2,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f8,f10,f1
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// fmadds f4,f12,f4,f0
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f0.f64));
	// fmadds f0,f11,f31,f26
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f26.f64));
	// fabs f26,f25
	ctx.f26.u64 = ctx.f25.u64 & ~0x8000000000000000;
	// fmadds f9,f11,f30,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f9.f64));
	// fmuls f31,f10,f31
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fabs f7,f7
	ctx.f7.u64 = ctx.f7.u64 & ~0x8000000000000000;
	// fabs f6,f6
	ctx.f6.u64 = ctx.f6.u64 & ~0x8000000000000000;
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & ~0x8000000000000000;
	// fabs f25,f24
	ctx.f25.u64 = ctx.f24.u64 & ~0x8000000000000000;
	// fabs f13,f13
	ctx.f13.u64 = ctx.f13.u64 & ~0x8000000000000000;
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmadds f3,f3,f12,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f0.f64));
	// fmadds f4,f11,f1,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f4.f64));
	// fmadds f2,f2,f12,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f9.f64));
	// fabs f0,f8
	ctx.f0.u64 = ctx.f8.u64 & ~0x8000000000000000;
	// fadds f1,f26,f7
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// fabs f11,f31
	ctx.f11.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// fadds f12,f6,f25
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f25.f64));
	// fadds f9,f5,f13
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fabs f8,f10
	ctx.f8.u64 = ctx.f10.u64 & ~0x8000000000000000;
	// fadds f6,f28,f3
	ctx.f6.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// fadds f7,f4,f29
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f5,f27,f2
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fadds f4,f1,f0
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// fadds f3,f12,f11
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fadds f2,f9,f8
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f0,f7,f4
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fsubs f13,f6,f3
	ctx.f13.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fsubs f12,f5,f2
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fadds f11,f4,f7
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fadds f10,f6,f3
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fadds f9,f5,f2
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
loc_8308C4C4:
	// stfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f13,4(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + 4, temp.u32);
	// stfs f12,8(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 8, temp.u32);
	// stfs f11,12(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 12, temp.u32);
	// stfs f10,16(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + 16, temp.u32);
	// stfs f9,20(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 20, temp.u32);
	// addi r1,r1,496
	ctx.r1.s64 = ctx.r1.s64 + 496;
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82cb6afc
	ctx.lr = 0x8308C4E8;
	__restfpr_14(ctx, base);
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308C4EC"))) PPC_WEAK_FUNC(sub_8308C4EC);
PPC_FUNC_IMPL(__imp__sub_8308C4EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C4F0"))) PPC_WEAK_FUNC(sub_8308C4F0);
PPC_FUNC_IMPL(__imp__sub_8308C4F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,312(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 312);
	// rlwinm r11,r11,0,17,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8308c544
	if (!ctx.cr6.eq) goto loc_8308C544;
	// rlwinm r10,r30,0,17,17
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8308c53c
	if (ctx.cr6.eq) goto loc_8308C53C;
	// lwz r11,268(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// addi r4,r31,224
	ctx.r4.s64 = ctx.r31.s64 + 224;
	// addi r3,r11,288
	ctx.r3.s64 = ctx.r11.s64 + 288;
	// bl 0x831c6e88
	ctx.lr = 0x8308C538;
	sub_831C6E88(ctx, base);
	// b 0x8308c560
	goto loc_8308C560;
loc_8308C53C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308c560
	if (ctx.cr6.eq) goto loc_8308C560;
loc_8308C544:
	// rlwinm r11,r30,0,17,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8308c560
	if (!ctx.cr6.eq) goto loc_8308C560;
	// lwz r11,268(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// addi r4,r31,224
	ctx.r4.s64 = ctx.r31.s64 + 224;
	// addi r3,r11,288
	ctx.r3.s64 = ctx.r11.s64 + 288;
	// bl 0x831c6de0
	ctx.lr = 0x8308C560;
	sub_831C6DE0(ctx, base);
loc_8308C560:
	// lwz r11,312(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 312);
	// stw r30,312(r31)
	PPC_STORE_U32(ctx.r31.u32 + 312, ctx.r30.u32);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8308c580
	if (ctx.cr6.eq) goto loc_8308C580;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x83089e10
	ctx.lr = 0x8308C580;
	sub_83089E10(ctx, base);
loc_8308C580:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C598"))) PPC_WEAK_FUNC(sub_8308C598);
PPC_FUNC_IMPL(__imp__sub_8308C598) {
	PPC_FUNC_PROLOGUE();
	// b 0x8308a0a0
	sub_8308A0A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308C59C"))) PPC_WEAK_FUNC(sub_8308C59C);
PPC_FUNC_IMPL(__imp__sub_8308C59C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C5A0"))) PPC_WEAK_FUNC(sub_8308C5A0);
PPC_FUNC_IMPL(__imp__sub_8308C5A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x8308c5d4
	if (ctx.cr6.lt) goto loc_8308C5D4;
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f1,1004(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1004);
	ctx.f1.f64 = double(temp.f32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_8308C5D4:
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f0,-18324(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18324);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x8308c5fc
	if (ctx.cr6.gt) goto loc_8308C5FC;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,11004(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11004);
	ctx.f1.f64 = double(temp.f32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_8308C5FC:
	// bl 0x82cb43f8
	ctx.lr = 0x8308C600;
	sub_82CB43F8(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C614"))) PPC_WEAK_FUNC(sub_8308C614);
PPC_FUNC_IMPL(__imp__sub_8308C614) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C618"))) PPC_WEAK_FUNC(sub_8308C618);
PPC_FUNC_IMPL(__imp__sub_8308C618) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bne cr6,0x8308c64c
	if (!ctx.cr6.eq) goto loc_8308C64C;
	// lfs f0,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bne cr6,0x8308c64c
	if (!ctx.cr6.eq) goto loc_8308C64C;
	// lfs f0,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// lfs f13,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// beq cr6,0x8308c650
	if (ctx.cr6.eq) goto loc_8308C650;
loc_8308C64C:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8308C650:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C658"))) PPC_WEAK_FUNC(sub_8308C658);
PPC_FUNC_IMPL(__imp__sub_8308C658) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f30,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// bl 0x82cb4940
	ctx.lr = 0x8308C67C;
	sub_82CB4940(ctx, base);
	// frsp f30,f1
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = double(float(ctx.f1.f64));
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82cb4860
	ctx.lr = 0x8308C688;
	sub_82CB4860(ctx, base);
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f30,32(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// stfs f30,0(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f12,8(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8, temp.u32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// stfs f0,12(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// stfs f13,16(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// fneg f11,f12
	ctx.f11.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// stfs f0,20(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stfs f0,28(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 28, temp.u32);
	// stfs f11,24(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-32(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C6E0"))) PPC_WEAK_FUNC(sub_8308C6E0);
PPC_FUNC_IMPL(__imp__sub_8308C6E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f30,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// bl 0x82cb4940
	ctx.lr = 0x8308C704;
	sub_82CB4940(ctx, base);
	// frsp f30,f1
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = double(float(ctx.f1.f64));
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82cb4860
	ctx.lr = 0x8308C710;
	sub_82CB4860(ctx, base);
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f30,16(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// stfs f30,0(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f12,12(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,8(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8, temp.u32);
	// stfs f0,20(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stfs f0,24(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// fneg f11,f12
	ctx.f11.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// stfs f0,28(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 28, temp.u32);
	// stfs f13,32(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// stfs f11,4(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-32(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C768"))) PPC_WEAK_FUNC(sub_8308C768);
PPC_FUNC_IMPL(__imp__sub_8308C768) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x8308c7c0
	if (ctx.cr6.lt) goto loc_8308C7C0;
	// lfs f13,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bgt cr6,0x8308c7c0
	if (ctx.cr6.gt) goto loc_8308C7C0;
	// lfs f0,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x8308c7c0
	if (ctx.cr6.lt) goto loc_8308C7C0;
	// lfs f13,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bgt cr6,0x8308c7c0
	if (ctx.cr6.gt) goto loc_8308C7C0;
	// lfs f0,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blt cr6,0x8308c7c0
	if (ctx.cr6.lt) goto loc_8308C7C0;
	// lfs f13,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// li r3,1
	ctx.r3.s64 = 1;
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// blelr cr6
	if (!ctx.cr6.gt) return;
loc_8308C7C0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C7C8"))) PPC_WEAK_FUNC(sub_8308C7C8);
PPC_FUNC_IMPL(__imp__sub_8308C7C8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_8308C7DC"))) PPC_WEAK_FUNC(sub_8308C7DC);
PPC_FUNC_IMPL(__imp__sub_8308C7DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C7E0"))) PPC_WEAK_FUNC(sub_8308C7E0);
PPC_FUNC_IMPL(__imp__sub_8308C7E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// fabs f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f1.u64 & ~0x8000000000000000;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,6140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6140);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,-18324(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18324);
	ctx.f11.f64 = double(temp.f32);
	// fsel f12,f1,f12,f11
	ctx.f12.f64 = ctx.f1.f64 >= 0.0 ? ctx.f12.f64 : ctx.f11.f64;
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308c824
	if (!ctx.cr6.lt) goto loc_8308C824;
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f0,f0
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fnmsubs f10,f11,f0,f11
	ctx.f10.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fadds f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// fmuls f8,f9,f13
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f1,f8,f12
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// blr 
	return;
loc_8308C824:
	// lfs f13,12(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308c878
	if (!ctx.cr6.lt) goto loc_8308C878;
	// lfs f11,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// fsubs f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fsubs f9,f13,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// lfs f8,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f7,f8
	ctx.f6.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// lfs f0,7676(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,7980(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 7980);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 / ctx.f9.f64));
	// fmuls f4,f5,f5
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmsubs f1,f4,f13,f2
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f2.f64));
	// fmadds f0,f1,f6,f8
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f8.f64));
	// fmuls f1,f0,f12
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// blr 
	return;
loc_8308C878:
	// lfs f0,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f0,f12
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C884"))) PPC_WEAK_FUNC(sub_8308C884);
PPC_FUNC_IMPL(__imp__sub_8308C884) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C888"))) PPC_WEAK_FUNC(sub_8308C888);
PPC_FUNC_IMPL(__imp__sub_8308C888) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,648
	ctx.r3.s64 = ctx.r3.s64 + 648;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C890"))) PPC_WEAK_FUNC(sub_8308C890);
PPC_FUNC_IMPL(__imp__sub_8308C890) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,712(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C898"))) PPC_WEAK_FUNC(sub_8308C898);
PPC_FUNC_IMPL(__imp__sub_8308C898) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,640(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C8A0"))) PPC_WEAK_FUNC(sub_8308C8A0);
PPC_FUNC_IMPL(__imp__sub_8308C8A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C8A8"))) PPC_WEAK_FUNC(sub_8308C8A8);
PPC_FUNC_IMPL(__imp__sub_8308C8A8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C8AC"))) PPC_WEAK_FUNC(sub_8308C8AC);
PPC_FUNC_IMPL(__imp__sub_8308C8AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C8B0"))) PPC_WEAK_FUNC(sub_8308C8B0);
PPC_FUNC_IMPL(__imp__sub_8308C8B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f13,420(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 420);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-18264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x8308c964
	if (ctx.cr6.eq) goto loc_8308C964;
	// lfs f0,336(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 336);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f13,340(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 340);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,4(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// lfs f12,344(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 344);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,8(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// lfs f11,348(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,12(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// lfs f10,352(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 352);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,16(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// lfs f9,356(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 356);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,20(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// lfs f8,384(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 384);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,48(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 48, temp.u32);
	// lhz r11,392(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 392);
	// sth r11,68(r4)
	PPC_STORE_U16(ctx.r4.u32 + 68, ctx.r11.u16);
	// lfs f7,396(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 396);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,52(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 52, temp.u32);
	// lfs f6,400(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,56(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 56, temp.u32);
	// lfs f5,408(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 408);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,60(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 60, temp.u32);
	// lfs f4,404(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 404);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,64(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 64, temp.u32);
	// lfs f3,360(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 360);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,36(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 36, temp.u32);
	// lfs f2,364(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 364);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,40(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 40, temp.u32);
	// lfs f1,368(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 368);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,44(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 44, temp.u32);
	// lfs f0,372(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 372);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,24(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 24, temp.u32);
	// lfs f13,376(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 376);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,28(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 28, temp.u32);
	// lfs f12,380(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 380);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,32(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 32, temp.u32);
	// lfs f11,420(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 420);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,72(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 72, temp.u32);
	// lwz r3,388(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 388);
	// blr 
	return;
loc_8308C964:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308C96C"))) PPC_WEAK_FUNC(sub_8308C96C);
PPC_FUNC_IMPL(__imp__sub_8308C96C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308C970"))) PPC_WEAK_FUNC(sub_8308C970);
PPC_FUNC_IMPL(__imp__sub_8308C970) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10ec
	ctx.lr = 0x8308C978;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,756
	ctx.r31.s64 = ctx.r3.s64 + 756;
	// li r30,4
	ctx.r30.s64 = 4;
	// li r29,0
	ctx.r29.s64 = 0;
loc_8308C988:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308c99c
	if (ctx.cr6.eq) goto loc_8308C99C;
	// bl 0x8315c3a0
	ctx.lr = 0x8308C998;
	sub_8315C3A0(ctx, base);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
loc_8308C99C:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x8308c988
	if (!ctx.cr0.eq) goto loc_8308C988;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82cb113c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308C9B0"))) PPC_WEAK_FUNC(sub_8308C9B0);
PPC_FUNC_IMPL(__imp__sub_8308C9B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308c9e0
	if (ctx.cr6.eq) goto loc_8308C9E0;
	// bl 0x8315c3a0
	ctx.lr = 0x8308C9DC;
	sub_8315C3A0(ctx, base);
	// stw r30,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r30.u32);
loc_8308C9E0:
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308c9f4
	if (ctx.cr6.eq) goto loc_8308C9F4;
	// bl 0x8315c3a0
	ctx.lr = 0x8308C9F0;
	sub_8315C3A0(ctx, base);
	// stw r30,760(r31)
	PPC_STORE_U32(ctx.r31.u32 + 760, ctx.r30.u32);
loc_8308C9F4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308CA0C"))) PPC_WEAK_FUNC(sub_8308CA0C);
PPC_FUNC_IMPL(__imp__sub_8308CA0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308CA10"))) PPC_WEAK_FUNC(sub_8308CA10);
PPC_FUNC_IMPL(__imp__sub_8308CA10) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308CA18"))) PPC_WEAK_FUNC(sub_8308CA18);
PPC_FUNC_IMPL(__imp__sub_8308CA18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f0,8(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// fneg f11,f12
	ctx.f11.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// stfs f11,4(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// stfs f0,12(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// stfs f0,16(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// stfs f0,20(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308CA4C"))) PPC_WEAK_FUNC(sub_8308CA4C);
PPC_FUNC_IMPL(__imp__sub_8308CA4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308CA50"))) PPC_WEAK_FUNC(sub_8308CA50);
PPC_FUNC_IMPL(__imp__sub_8308CA50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,8(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// stfs f0,4(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f0,644(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f0,6380(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6380);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f11,12(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8308CA84"))) PPC_WEAK_FUNC(sub_8308CA84);
PPC_FUNC_IMPL(__imp__sub_8308CA84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308CA88"))) PPC_WEAK_FUNC(sub_8308CA88);
PPC_FUNC_IMPL(__imp__sub_8308CA88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x8308CA90;
	__savegprlr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// bl 0x8308a278
	ctx.lr = 0x8308CAA8;
	sub_8308A278(ctx, base);
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// addi r7,r11,1040
	ctx.r7.s64 = ctx.r11.s64 + 1040;
	// li r10,4
	ctx.r10.s64 = 4;
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// lis r6,-32235
	ctx.r6.s64 = -2112552960;
	// lfs f31,6048(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6048);
	ctx.f31.f64 = double(temp.f32);
	// stw r10,540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 540, ctx.r10.u32);
	// stfs f31,588(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 588, temp.u32);
	// lis r5,-32255
	ctx.r5.s64 = -2113863680;
	// stfs f31,584(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 584, temp.u32);
	// lis r4,-32256
	ctx.r4.s64 = -2113929216;
	// stfs f31,580(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 580, temp.u32);
	// lis r3,-32256
	ctx.r3.s64 = -2113929216;
	// lfs f0,6140(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6140);
	ctx.f0.f64 = double(temp.f32);
	// lis r9,-32222
	ctx.r9.s64 = -2111700992;
	// stfs f0,544(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 544, temp.u32);
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// stfs f31,548(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 548, temp.u32);
	// addi r7,r6,-1484
	ctx.r7.s64 = ctx.r6.s64 + -1484;
	// stfs f31,552(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 552, temp.u32);
	// addi r6,r8,-1496
	ctx.r6.s64 = ctx.r8.s64 + -1496;
	// stfs f31,556(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 556, temp.u32);
	// addi r11,r31,536
	ctx.r11.s64 = ctx.r31.s64 + 536;
	// stfs f0,560(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 560, temp.u32);
	// li r8,8
	ctx.r8.s64 = 8;
	// stfs f31,564(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 564, temp.u32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// stfs f31,568(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// stfs f31,572(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 572, temp.u32);
	// stfs f0,576(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 576, temp.u32);
	// stfs f0,544(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 544, temp.u32);
	// stfs f31,548(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 548, temp.u32);
	// stfs f31,552(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 552, temp.u32);
	// stfs f31,556(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 556, temp.u32);
	// stfs f0,560(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 560, temp.u32);
	// stfs f31,564(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 564, temp.u32);
	// stfs f31,568(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// stfs f31,572(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 572, temp.u32);
	// stfs f0,576(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 576, temp.u32);
	// stfs f31,588(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 588, temp.u32);
	// stfs f31,584(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 584, temp.u32);
	// stfs f31,580(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 580, temp.u32);
	// stw r7,536(r31)
	PPC_STORE_U32(ctx.r31.u32 + 536, ctx.r7.u32);
	// stfs f31,648(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 648, temp.u32);
	// lis r7,-32222
	ctx.r7.s64 = -2111700992;
	// stfs f31,652(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 652, temp.u32);
	// stfs f31,656(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 656, temp.u32);
	// stw r6,660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 660, ctx.r6.u32);
	// lfs f13,-11796(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -11796);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,7676(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 7676);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,7712(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 7712);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-18272(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -18272);
	ctx.f10.f64 = double(temp.f32);
	// stfs f0,664(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 664, temp.u32);
	// stfs f13,668(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 668, temp.u32);
	// stfs f12,672(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 672, temp.u32);
	// stfs f11,676(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 676, temp.u32);
	// stfs f10,680(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 680, temp.u32);
	// stw r6,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r6.u32);
	// stfs f0,688(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 688, temp.u32);
	// stfs f13,692(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 692, temp.u32);
	// stfs f12,696(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 696, temp.u32);
	// stfs f11,700(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 700, temp.u32);
	// stfs f10,704(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 704, temp.u32);
	// stfs f0,544(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 544, temp.u32);
	// stfs f31,548(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 548, temp.u32);
	// stfs f31,552(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 552, temp.u32);
	// stfs f31,556(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 556, temp.u32);
	// stfs f0,560(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 560, temp.u32);
	// stfs f31,564(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 564, temp.u32);
	// stfs f31,568(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 568, temp.u32);
	// stfs f31,572(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 572, temp.u32);
	// stfs f0,576(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 576, temp.u32);
	// stfs f31,588(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 588, temp.u32);
	// stfs f31,584(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 584, temp.u32);
	// stfs f31,580(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 580, temp.u32);
	// stfs f0,604(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 604, temp.u32);
	// li r30,0
	ctx.r30.s64 = 0;
	// stfs f0,640(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 640, temp.u32);
	// stw r8,592(r31)
	PPC_STORE_U32(ctx.r31.u32 + 592, ctx.r8.u32);
	// stfs f0,644(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 644, temp.u32);
	// sth r30,596(r31)
	PPC_STORE_U16(ctx.r31.u32 + 596, ctx.r30.u16);
	// stfs f0,708(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 708, temp.u32);
	// sth r30,598(r31)
	PPC_STORE_U16(ctx.r31.u32 + 598, ctx.r30.u16);
	// stfs f31,716(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 716, temp.u32);
	// stw r30,600(r31)
	PPC_STORE_U32(ctx.r31.u32 + 600, ctx.r30.u32);
	// stfs f31,720(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 720, temp.u32);
	// stw r30,616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 616, ctx.r30.u32);
	// stfs f31,724(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 724, temp.u32);
	// stw r30,620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 620, ctx.r30.u32);
	// stw r30,624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 624, ctx.r30.u32);
	// lfs f0,-18324(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -18324);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,612(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 612, temp.u32);
	// stw r30,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r30.u32);
	// stfs f0,608(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 608, temp.u32);
	// stw r30,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r30.u32);
	// stw r30,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r30.u32);
	// lis r6,-32222
	ctx.r6.s64 = -2111700992;
	// stw r30,712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 712, ctx.r30.u32);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// stw r30,728(r31)
	PPC_STORE_U32(ctx.r31.u32 + 728, ctx.r30.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r10,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r10.u32);
	// lfs f0,92(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,640(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 640, temp.u32);
	// lfs f13,96(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,644(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 644, temp.u32);
	// lfs f12,100(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,648(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 648, temp.u32);
	// lfs f11,104(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,652(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 652, temp.u32);
	// lfs f10,108(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 108);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,656(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 656, temp.u32);
	// lfs f9,112(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,664(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 664, temp.u32);
	// lfs f8,116(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,668(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 668, temp.u32);
	// lfs f7,120(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,672(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 672, temp.u32);
	// lfs f6,124(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 124);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,676(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 676, temp.u32);
	// lfs f5,128(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,680(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 680, temp.u32);
	// lfs f4,132(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,688(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 688, temp.u32);
	// lfs f3,136(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,692(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 692, temp.u32);
	// lfs f2,140(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,696(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 696, temp.u32);
	// lfs f1,144(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,700(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 700, temp.u32);
	// lfs f0,148(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 148);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,704(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 704, temp.u32);
	// lfs f13,152(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,708(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 708, temp.u32);
	// lwz r5,156(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 156);
	// lfs f0,-18264(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -18264);
	ctx.f0.f64 = double(temp.f32);
	// stw r5,712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 712, ctx.r5.u32);
	// lfs f12,160(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,716(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 716, temp.u32);
	// lfs f11,164(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,720(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 720, temp.u32);
	// lfs f10,168(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 168);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,724(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 724, temp.u32);
	// lwz r11,172(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 172);
	// stfs f0,520(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 520, temp.u32);
	// stw r11,728(r31)
	PPC_STORE_U32(ctx.r31.u32 + 728, ctx.r11.u32);
	// bl 0x83046180
	ctx.lr = 0x8308CCFC;
	sub_83046180(ctx, base);
	// stfs f31,444(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 444, temp.u32);
	// stfs f31,440(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 440, temp.u32);
	// addi r4,r31,436
	ctx.r4.s64 = ctx.r31.s64 + 436;
	// stfs f31,436(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 436, temp.u32);
	// addi r3,r31,336
	ctx.r3.s64 = ctx.r31.s64 + 336;
	// stfs f31,456(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 456, temp.u32);
	// stfs f31,452(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 452, temp.u32);
	// stfs f31,448(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 448, temp.u32);
	// stw r30,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r30.u32);
	// stfs f31,484(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 484, temp.u32);
	// sth r30,492(r31)
	PPC_STORE_U16(ctx.r31.u32 + 492, ctx.r30.u16);
	// stfs f31,504(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 504, temp.u32);
	// stfs f31,508(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
	// stfs f31,500(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 500, temp.u32);
	// stfs f31,496(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 496, temp.u32);
	// stfs f31,468(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 468, temp.u32);
	// stfs f31,464(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 464, temp.u32);
	// stfs f31,460(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 460, temp.u32);
	// stfs f31,480(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 480, temp.u32);
	// stfs f31,476(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 476, temp.u32);
	// stfs f31,472(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 472, temp.u32);
	// stw r30,516(r31)
	PPC_STORE_U32(ctx.r31.u32 + 516, ctx.r30.u32);
	// stfs f31,512(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// bl 0x830424f0
	ctx.lr = 0x8308CD5C;
	sub_830424F0(ctx, base);
	// stfs f31,732(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 732, temp.u32);
	// stfs f31,736(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 736, temp.u32);
	// stw r30,740(r31)
	PPC_STORE_U32(ctx.r31.u32 + 740, ctx.r30.u32);
	// stw r30,744(r31)
	PPC_STORE_U32(ctx.r31.u32 + 744, ctx.r30.u32);
	// addi r11,r31,756
	ctx.r11.s64 = ctx.r31.s64 + 756;
	// stw r30,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r30,760(r31)
	PPC_STORE_U32(ctx.r31.u32 + 760, ctx.r30.u32);
	// stw r30,764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 764, ctx.r30.u32);
	// stw r30,768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 768, ctx.r30.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308CD90"))) PPC_WEAK_FUNC(sub_8308CD90);
PPC_FUNC_IMPL(__imp__sub_8308CD90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x8308CD98;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r10,r11,1040
	ctx.r10.s64 = ctx.r11.s64 + 1040;
	// stw r10,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r10.u32);
	// lwz r3,268(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 268);
	// bl 0x830440a8
	ctx.lr = 0x8308CDB8;
	sub_830440A8(ctx, base);
	// addi r31,r29,756
	ctx.r31.s64 = ctx.r29.s64 + 756;
	// li r30,4
	ctx.r30.s64 = 4;
	// li r28,0
	ctx.r28.s64 = 0;
loc_8308CDC4:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308cdd8
	if (ctx.cr6.eq) goto loc_8308CDD8;
	// bl 0x8315c3a0
	ctx.lr = 0x8308CDD4;
	sub_8315C3A0(ctx, base);
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
loc_8308CDD8:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x8308cdc4
	if (!ctx.cr0.eq) goto loc_8308CDC4;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lis r10,-32243
	ctx.r10.s64 = -2113077248;
	// addi r9,r11,-1496
	ctx.r9.s64 = ctx.r11.s64 + -1496;
	// addi r8,r10,30348
	ctx.r8.s64 = ctx.r10.s64 + 30348;
	// stw r9,684(r29)
	PPC_STORE_U32(ctx.r29.u32 + 684, ctx.r9.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r9,660(r29)
	PPC_STORE_U32(ctx.r29.u32 + 660, ctx.r9.u32);
	// stw r8,536(r29)
	PPC_STORE_U32(ctx.r29.u32 + 536, ctx.r8.u32);
	// bl 0x83088de0
	ctx.lr = 0x8308CE08;
	sub_83088DE0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308CE10"))) PPC_WEAK_FUNC(sub_8308CE10);
PPC_FUNC_IMPL(__imp__sub_8308CE10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10d8
	ctx.lr = 0x8308CE18;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82cb6ab0
	ctx.lr = 0x8308CE20;
	__savefpr_14(ctx, base);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lfs f30,6140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f30.f64 = double(temp.f32);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lfs f31,7676(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f31.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f28,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f28.f64 = double(temp.f32);
	// beq cr6,0x8308d050
	if (ctx.cr6.eq) goto loc_8308D050;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8308d050
	if (ctx.cr6.eq) goto loc_8308D050;
	// lfs f0,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// lfs f11,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f9,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f9.f64 = double(temp.f32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// fmr f7,f9
	ctx.f7.f64 = ctx.f9.f64;
	// lfs f5,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f1,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f5,f9
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f3,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f26,f6,f6,f28
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f6.f64 - ctx.f28.f64));
	// lfs f27,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f29,f3,f0
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f24,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f25,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f12,f25
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f10,f1,f6,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f27,f8
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f7,f24
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f24.f64));
	// addi r11,r31,12
	ctx.r11.s64 = ctx.r31.s64 + 12;
	// fmuls f17,f7,f25
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmsubs f4,f3,f6,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 - ctx.f4.f64));
	// fmadds f2,f3,f11,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f2.f64));
	// fmadds f29,f5,f6,f29
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 + ctx.f29.f64));
	// fmuls f16,f25,f26
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f15,f27,f26
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f23,f7,f27,f23
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 - ctx.f23.f64));
	// fmadds f3,f3,f9,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f10.f64));
	// fmsubs f10,f12,f24,f20
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f24.f64 - ctx.f20.f64));
	// fmsubs f25,f25,f8,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f18.f64));
	// fmadds f20,f24,f8,f17
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f17.f64));
	// fnmsubs f4,f1,f9,f4
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f9.f64 - ctx.f4.f64)));
	// fmadds f2,f13,f6,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 + ctx.f2.f64));
	// fmadds f29,f1,f11,f29
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fmuls f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmuls f24,f23,f6
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fnmsubs f3,f5,f11,f3
	ctx.f3.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fmuls f11,f10,f6
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f10,f25,f6
	ctx.f10.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmadds f6,f12,f27,f20
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 + ctx.f20.f64));
	// fnmsubs f2,f1,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fnmsubs f1,f13,f9,f29
	ctx.f1.f64 = double(float(-(ctx.f13.f64 * ctx.f9.f64 - ctx.f29.f64)));
	// fnmsubs f9,f5,f0,f4
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fadds f5,f26,f24
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// fmuls f4,f3,f3
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// fadds f0,f16,f11
	ctx.f0.f64 = double(float(ctx.f16.f64 + ctx.f11.f64));
	// fadds f13,f15,f10
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f10.f64));
	// fmuls f11,f7,f6
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f10,f12,f6
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f29,f9,f1
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmuls f12,f1,f1
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fmuls f6,f4,f31
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fadds f4,f0,f11
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fadds f0,f13,f10
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fmuls f11,f7,f31
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fadds f5,f5,f8
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fmuls f7,f29,f31
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// fmuls f10,f12,f31
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fsubs f13,f30,f6
	ctx.f13.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// fmuls f12,f4,f31
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f8,f0,f31
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fsubs f4,f11,f7
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f4,100(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// stfs f4,96(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f4,f9,f3
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fadds f0,f22,f12
	ctx.f0.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fadds f13,f21,f8
	ctx.f13.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fmuls f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fmuls f29,f2,f2
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// fmuls f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f1,f7,f11
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfs f1,108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f11,f8,f31
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f9,f4,f31
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fadds f12,f19,f5
	ctx.f12.f64 = double(float(ctx.f19.f64 + ctx.f5.f64));
	// fnmsubs f8,f29,f31,f30
	ctx.f8.f64 = double(float(-(ctx.f29.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// fmuls f7,f3,f31
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f5,f2,f31
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fadds f4,f9,f11
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f4,104(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f2,f11,f9
	ctx.f2.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f2,120(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// stfs f3,112(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f10,f8,f6
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f10,128(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f1,f7,f5
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfs f1,116(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f11,f5,f7
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfs f11,124(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_8308D024:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x8308d024
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308D024;
	// stfs f12,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f0,40(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f13,44(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_8308D050:
	// lfs f11,8(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f0,52(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,56(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// lfs f9,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// lfs f7,48(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	ctx.f7.f64 = double(temp.f32);
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f11,f9,f7
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfs f8,88(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// beq cr6,0x8308d270
	if (ctx.cr6.eq) goto loc_8308D270;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8308d270
	if (ctx.cr6.eq) goto loc_8308D270;
	// lfs f0,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// lfs f10,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f13,f0
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f8,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fmr f7,f10
	ctx.f7.f64 = ctx.f10.f64;
	// fmr f6,f8
	ctx.f6.f64 = ctx.f8.f64;
	// lfs f4,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f4,f10
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f2,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f4,f0
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f29,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f3,f13,f10
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f26,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f25,f5,f5,f28
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// lfs f24,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// addi r9,r31,12
	ctx.r9.s64 = ctx.r31.s64 + 12;
	// fmuls f22,f26,f12
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f9,f2,f5,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f9.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f29,f7
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f6
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f16,f26,f6
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fmadds f1,f13,f5,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmadds f27,f23,f5,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f27.f64));
	// fmsubs f3,f4,f5,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 - ctx.f3.f64));
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f14,f29,f25
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// fmsubs f22,f29,f6,f22
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmadds f9,f4,f8,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f9.f64));
	// fmsubs f4,f24,f12,f19
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fmsubs f26,f26,f7,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f17.f64));
	// fmadds f19,f24,f7,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f16.f64));
	// fmadds f1,f23,f8,f1
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 + ctx.f1.f64));
	// fmadds f27,f2,f10,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 + ctx.f27.f64));
	// fnmsubs f3,f2,f8,f3
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f3.f64)));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f24,f22,f5
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fnmsubs f10,f23,f10,f9
	ctx.f10.f64 = double(float(-(ctx.f23.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// fmuls f9,f4,f5
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmadds f4,f29,f12,f19
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fnmsubs f2,f2,f0,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fnmsubs f1,f13,f8,f27
	ctx.f1.f64 = double(float(-(ctx.f13.f64 * ctx.f8.f64 - ctx.f27.f64)));
	// fnmsubs f8,f23,f0,f3
	ctx.f8.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fadds f3,f25,f24
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f0,f10,f10
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fadds f13,f15,f9
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f9.f64));
	// fadds f9,f14,f5
	ctx.f9.f64 = double(float(ctx.f14.f64 + ctx.f5.f64));
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fmuls f5,f12,f4
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fmuls f12,f10,f2
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f29,f1,f1
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fmuls f27,f8,f1
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f4,f0,f31
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fadds f0,f13,f6
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fadds f13,f9,f5
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f5,f3,f7
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f9,f29,f31
	ctx.f9.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// fmuls f6,f27,f31
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fsubs f3,f30,f4
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fsubs f7,f12,f6
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// stfs f7,100(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f7,f1,f2
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fsubs f3,f3,f9
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// stfs f3,96(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fadds f0,f21,f0
	ctx.f0.f64 = double(float(ctx.f21.f64 + ctx.f0.f64));
	// fadds f13,f20,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 + ctx.f13.f64));
	// fmuls f29,f2,f2
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// fmuls f10,f8,f2
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f8,f6,f12
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f12,f5,f18
	ctx.f12.f64 = double(float(ctx.f5.f64 + ctx.f18.f64));
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fnmsubs f5,f29,f31,f30
	ctx.f5.f64 = double(float(-(ctx.f29.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// fmuls f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f2,f10,f31
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fadds f1,f6,f7
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f1,104(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f10,f5,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfs f10,112(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f9,120(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f8,f3,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f8,116(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f7,124(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f6,128(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_8308D244:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308d244
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308D244;
	// stfs f13,44(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// stfs f0,40(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// stfs f12,36(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_8308D270:
	// lfs f0,40(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f0.f64 = double(temp.f32);
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f10,16(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,28(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,520(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f7,f10,f11,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f12.f64));
	// fnmadds f29,f9,f8,f7
	ctx.f29.f64 = double(float(-(ctx.f9.f64 * ctx.f8.f64 + ctx.f7.f64)));
	// fcmpu cr6,f29,f0
	ctx.cr6.compare(ctx.f29.f64, ctx.f0.f64);
	// bge cr6,0x8308d64c
	if (!ctx.cr6.lt) goto loc_8308D64C;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f13,-18264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bne cr6,0x8308d2bc
	if (!ctx.cr6.eq) goto loc_8308D2BC;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,268(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x830462a8
	ctx.lr = 0x8308D2BC;
	sub_830462A8(ctx, base);
loc_8308D2BC:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8308d3a0
	if (ctx.cr6.eq) goto loc_8308D3A0;
	// lwz r11,264(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 264);
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x8308d38c
	if (ctx.cr6.eq) goto loc_8308D38C;
	// lfs f13,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,152
	ctx.r10.s64 = ctx.r11.s64 + 152;
	// lfs f12,4(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f10,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f7,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f5,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f1,f2,f2,f28
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f28.f64));
	// fmuls f0,f4,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f13,f3,f8
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f10,f3,f6
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f9,f1,f11
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fmuls f7,f8,f1
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmsubs f0,f8,f5,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 - ctx.f0.f64));
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmsubs f13,f4,f6,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 - ctx.f13.f64));
	// fmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64));
	// fmadds f11,f5,f11,f10
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f10.f64));
	// fmuls f10,f0,f2
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f6,f13,f2
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f2,f12,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmadds f0,f4,f8,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f11.f64));
	// fsubs f13,f1,f10
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// fsubs f12,f9,f6
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f11,f7,f2
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fmuls f10,f0,f5
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f8,f3,f0
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fadds f6,f11,f9
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// fadds f5,f13,f8
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fmuls f4,f7,f31
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f4,524(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 524, temp.u32);
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f3,528(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 528, temp.u32);
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f2,532(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 532, temp.u32);
	// b 0x8308d3a0
	goto loc_8308D3A0;
loc_8308D38C:
	// stfs f0,524(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 524, temp.u32);
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,528(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 528, temp.u32);
	// lfs f12,8(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,532(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 532, temp.u32);
loc_8308D3A0:
	// stfs f29,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 520, temp.u32);
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,436(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 436, temp.u32);
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,440(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 440, temp.u32);
	// lfs f12,8(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,444(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 444, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308d5b0
	if (ctx.cr6.eq) goto loc_8308D5B0;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8308d5b0
	if (ctx.cr6.eq) goto loc_8308D5B0;
	// lfs f0,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// lfs f11,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f9,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f9.f64 = double(temp.f32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// fmr f7,f9
	ctx.f7.f64 = ctx.f9.f64;
	// lfs f5,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f29,f5,f0
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f3,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f5,f11
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f1,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f27,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f28,f6,f6,f28
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f6.f64 - ctx.f28.f64));
	// lfs f26,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f25,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f12,f1
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f23,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f3,f6,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f10.f64));
	// lfs f22,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f8,f1
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f20,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f7,f27
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmadds f29,f26,f6,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f29.f64));
	// fmadds f2,f13,f6,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 + ctx.f2.f64));
	// fmsubs f4,f5,f6,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 - ctx.f4.f64));
	// fmuls f18,f12,f25
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f17,f28,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f16,f28,f1
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fmadds f24,f7,f25,f24
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 + ctx.f24.f64));
	// fmadds f10,f5,f9,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f10.f64));
	// fmsubs f5,f12,f27,f21
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f21.f64));
	// fmsubs f25,f8,f25,f19
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 - ctx.f19.f64));
	// fmadds f29,f3,f11,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fmadds f2,f26,f9,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f2.f64));
	// fnmsubs f4,f3,f9,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f9.f64 - ctx.f4.f64)));
	// fmuls f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f27.f64));
	// fmsubs f1,f7,f1,f18
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 - ctx.f18.f64));
	// fmadds f27,f8,f27,f24
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f24.f64));
	// fnmsubs f11,f26,f11,f10
	ctx.f11.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmuls f10,f5,f6
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f5,f25,f6
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fnmsubs f3,f3,f0,f2
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fnmsubs f2,f13,f9,f29
	ctx.f2.f64 = double(float(-(ctx.f13.f64 * ctx.f9.f64 - ctx.f29.f64)));
	// fnmsubs f4,f26,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f0,f7,f27
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmuls f13,f11,f11
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f12,f12,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// fadds f9,f16,f5
	ctx.f9.f64 = double(float(ctx.f16.f64 + ctx.f5.f64));
	// fadds f10,f17,f10
	ctx.f10.f64 = double(float(ctx.f17.f64 + ctx.f10.f64));
	// fmuls f7,f11,f3
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f6,f2,f2
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// fmuls f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmuls f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fmuls f29,f13,f31
	ctx.f29.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f13,f9,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fadds f0,f10,f0
	ctx.f0.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// fmuls f12,f7,f31
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f10,f6,f31
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f9,f5,f31
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fadds f8,f1,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f7,f30,f29
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fmuls f5,f13,f31
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f6,f0,f31
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,100(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fsubs f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// stfs f7,96(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f13,f22,f5
	ctx.f13.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fadds f0,f23,f6
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fmuls f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f5,f4,f11
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// fmuls f1,f3,f3
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmuls f11,f2,f11
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fadds f4,f9,f12
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// stfs f4,108(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fadds f12,f8,f20
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// fmuls f9,f7,f31
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fnmsubs f1,f1,f31,f30
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f31.f64 - ctx.f30.f64)));
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f8,104(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f6,f3,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f6,120(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f7,f1,f10
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f5,f11,f9
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f4,f9,f11
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f4,124(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f3,f1,f29
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f3,128(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8308D584:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308d584
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308D584;
	// stfs f13,44(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 44, temp.u32);
	// stfs f0,40(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 40, temp.u32);
	// stfs f12,36(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 36, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_8308D5B0:
	// lfs f0,16(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,4(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f11,28(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f7,f11,f10,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f12.f64));
	// fmadds f6,f8,f9,f7
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fcmpu cr6,f6,f0
	ctx.cr6.compare(ctx.f6.f64, ctx.f0.f64);
	// ble cr6,0x8308d60c
	if (!ctx.cr6.gt) goto loc_8308D60C;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// stw r11,740(r31)
	PPC_STORE_U32(ctx.r31.u32 + 740, ctx.r11.u32);
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// stw r10,744(r31)
	PPC_STORE_U32(ctx.r31.u32 + 744, ctx.r10.u32);
	// lfs f0,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,448(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 448, temp.u32);
	// lfs f13,4(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,452(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 452, temp.u32);
	// lfs f12,8(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// b 0x8308d63c
	goto loc_8308D63C;
loc_8308D60C:
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// stw r11,740(r31)
	PPC_STORE_U32(ctx.r31.u32 + 740, ctx.r11.u32);
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// stw r10,744(r31)
	PPC_STORE_U32(ctx.r31.u32 + 744, ctx.r10.u32);
	// lfs f13,4(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fneg f9,f13
	ctx.f9.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f11,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,8(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fneg f10,f11
	ctx.f10.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfs f10,448(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 448, temp.u32);
	// fneg f12,f0
	ctx.f12.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f9,452(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 452, temp.u32);
loc_8308D63C:
	// stfs f12,456(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 456, temp.u32);
	// stw r26,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r26.u32);
	// sth r25,492(r31)
	PPC_STORE_U16(ctx.r31.u32 + 492, ctx.r25.u16);
	// stw r24,516(r31)
	PPC_STORE_U32(ctx.r31.u32 + 516, ctx.r24.u32);
loc_8308D64C:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82cb6afc
	ctx.lr = 0x8308D658;
	__restfpr_14(ctx, base);
	// b 0x82cb1128
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308D65C"))) PPC_WEAK_FUNC(sub_8308D65C);
PPC_FUNC_IMPL(__imp__sub_8308D65C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8308D660"))) PPC_WEAK_FUNC(sub_8308D660);
PPC_FUNC_IMPL(__imp__sub_8308D660) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x8308D668;
	__savegprlr_28(ctx, base);
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// fmr f29,f2
	ctx.f29.f64 = ctx.f2.f64;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r10,712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f30,-18264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r8,r10,0,27,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// lfs f31,6048(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6048);
	ctx.f31.f64 = double(temp.f32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x8308d760
	if (!ctx.cr6.eq) goto loc_8308D760;
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x8308d6d8
	if (ctx.cr6.eq) goto loc_8308D6D8;
	// lbz r11,96(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 96);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8308d6d8
	if (!ctx.cr6.eq) goto loc_8308D6D8;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-64(r1)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
loc_8308D6D8:
	// lfs f0,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// beq cr6,0x8308d70c
	if (ctx.cr6.eq) goto loc_8308D70C;
	// lfs f0,680(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bne cr6,0x8308d6fc
	if (!ctx.cr6.eq) goto loc_8308D6FC;
	// rlwinm r11,r10,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308d70c
	if (ctx.cr6.eq) goto loc_8308D70C;
loc_8308D6FC:
	// lfs f0,736(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 736);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// stfs f12,512(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
loc_8308D70C:
	// lfs f0,716(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 716);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f0,f1
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f12,708(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 708);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,512(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,720(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 720);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f12
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmadds f0,f13,f12,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// fmuls f13,f9,f1
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// ble cr6,0x8308d74c
	if (!ctx.cr6.gt) goto loc_8308D74C;
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bge cr6,0x8308d760
	if (!ctx.cr6.lt) goto loc_8308D760;
	// b 0x8308d75c
	goto loc_8308D75C;
loc_8308D74C:
	// fadds f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// ble cr6,0x8308d760
	if (!ctx.cr6.gt) goto loc_8308D760;
loc_8308D75C:
	// stfs f31,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
loc_8308D760:
	// lfs f0,732(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 732);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f13,512(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f12,f13,f1,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f0.f64));
	// stfs f12,732(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 732, temp.u32);
	// lfs f0,1008(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1008);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8308d798
	if (!ctx.cr6.gt) goto loc_8308D798;
loc_8308D780:
	// lfs f13,732(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 732);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f12,732(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 732, temp.u32);
	// fmr f11,f12
	ctx.f11.f64 = ctx.f12.f64;
	// fcmpu cr6,f11,f0
	ctx.cr6.compare(ctx.f11.f64, ctx.f0.f64);
	// bgt cr6,0x8308d780
	if (ctx.cr6.gt) goto loc_8308D780;
loc_8308D798:
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f12,732(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 732);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,1592(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1592);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	ctx.cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bge cr6,0x8308d7c4
	if (!ctx.cr6.lt) goto loc_8308D7C4;
loc_8308D7AC:
	// lfs f12,732(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 732);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// stfs f11,732(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 732, temp.u32);
	// fmr f10,f11
	ctx.f10.f64 = ctx.f11.f64;
	// fcmpu cr6,f10,f13
	ctx.cr6.compare(ctx.f10.f64, ctx.f13.f64);
	// blt cr6,0x8308d7ac
	if (ctx.cr6.lt) goto loc_8308D7AC;
loc_8308D7C4:
	// lfs f0,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// bne cr6,0x8308d7fc
	if (!ctx.cr6.eq) goto loc_8308D7FC;
	// addi r30,r31,756
	ctx.r30.s64 = ctx.r31.s64 + 756;
	// li r29,4
	ctx.r29.s64 = 4;
	// li r28,0
	ctx.r28.s64 = 0;
loc_8308D7DC:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d7f0
	if (ctx.cr6.eq) goto loc_8308D7F0;
	// bl 0x8315c3a0
	ctx.lr = 0x8308D7EC;
	sub_8315C3A0(ctx, base);
	// stw r28,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r28.u32);
loc_8308D7F0:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// bne 0x8308d7dc
	if (!ctx.cr0.eq) goto loc_8308D7DC;
loc_8308D7FC:
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// stfs f30,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 520, temp.u32);
	// stfs f31,484(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 484, temp.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d824
	if (ctx.cr6.eq) goto loc_8308D824;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x8315c5e0
	ctx.lr = 0x8308D818;
	sub_8315C5E0(ctx, base);
	// lfs f0,484(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f1,f29,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f0.f64));
	// stfs f13,484(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 484, temp.u32);
loc_8308D824:
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d844
	if (ctx.cr6.eq) goto loc_8308D844;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x8315c5e0
	ctx.lr = 0x8308D838;
	sub_8315C5E0(ctx, base);
	// lfs f0,484(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f1,f29,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f0.f64));
	// stfs f13,484(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 484, temp.u32);
loc_8308D844:
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8308d8f4
	if (ctx.cr6.eq) goto loc_8308D8F4;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d870
	if (ctx.cr6.eq) goto loc_8308D870;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x8315c5e0
	ctx.lr = 0x8308D86C;
	sub_8315C5E0(ctx, base);
	// fabs f30,f1
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = ctx.f1.u64 & ~0x8000000000000000;
loc_8308D870:
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// fmr f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f31.f64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d88c
	if (ctx.cr6.eq) goto loc_8308D88C;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x8315c5e0
	ctx.lr = 0x8308D888;
	sub_8315C5E0(ctx, base);
	// fabs f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = ctx.f1.u64 & ~0x8000000000000000;
loc_8308D88C:
	// lfs f0,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// ble cr6,0x8308d8a8
	if (!ctx.cr6.gt) goto loc_8308D8A8;
	// fcmpu cr6,f30,f0
	ctx.cr6.compare(ctx.f30.f64, ctx.f0.f64);
	// blt cr6,0x8308d8a8
	if (ctx.cr6.lt) goto loc_8308D8A8;
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// b 0x8308d8bc
	goto loc_8308D8BC;
loc_8308D8A8:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bge cr6,0x8308d8c0
	if (!ctx.cr6.lt) goto loc_8308D8C0;
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f30,f0
	ctx.cr6.compare(ctx.f30.f64, ctx.f0.f64);
	// bge cr6,0x8308d8c0
	if (!ctx.cr6.lt) goto loc_8308D8C0;
loc_8308D8BC:
	// stfs f0,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
loc_8308D8C0:
	// lfs f0,504(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 504);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// ble cr6,0x8308d8dc
	if (!ctx.cr6.gt) goto loc_8308D8DC;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// blt cr6,0x8308d8dc
	if (ctx.cr6.lt) goto loc_8308D8DC;
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// b 0x8308d8f0
	goto loc_8308D8F0;
loc_8308D8DC:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bge cr6,0x8308d8f4
	if (!ctx.cr6.lt) goto loc_8308D8F4;
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bge cr6,0x8308d8f4
	if (!ctx.cr6.lt) goto loc_8308D8F4;
loc_8308D8F0:
	// stfs f0,504(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 504, temp.u32);
loc_8308D8F4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8308D908"))) PPC_WEAK_FUNC(sub_8308D908);
PPC_FUNC_IMPL(__imp__sub_8308D908) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10c0
	ctx.lr = 0x8308D910;
	__savegprlr_18(ctx, base);
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6ab0
	ctx.lr = 0x8308D918;
	__savefpr_14(ctx, base);
	// stwu r1,-688(r1)
	ea = -688 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r18,0
	ctx.r18.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// lfs f14,-18264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// bne cr6,0x8308d9c4
	if (!ctx.cr6.eq) goto loc_8308D9C4;
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8308d9d0
	if (!ctx.cr6.eq) goto loc_8308D9D0;
	// lwz r30,4(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8308d9d0
	if (ctx.cr6.eq) goto loc_8308D9D0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r10,460(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308D968;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r28,336(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 336);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8308d9d0
	if (ctx.cr6.eq) goto loc_8308D9D0;
loc_8308D978:
	// lwz r30,0(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// lwz r11,288(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 288);
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x8308d9b8
	if (!ctx.cr6.eq) goto loc_8308D9B8;
	// lwz r3,756(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 756);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d9a4
	if (ctx.cr6.eq) goto loc_8308D9A4;
	// bl 0x8315c3a0
	ctx.lr = 0x8308D9A0;
	sub_8315C3A0(ctx, base);
	// stw r18,756(r30)
	PPC_STORE_U32(ctx.r30.u32 + 756, ctx.r18.u32);
loc_8308D9A4:
	// lwz r3,760(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 760);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308d9b8
	if (ctx.cr6.eq) goto loc_8308D9B8;
	// bl 0x8315c3a0
	ctx.lr = 0x8308D9B4;
	sub_8315C3A0(ctx, base);
	// stw r18,760(r30)
	PPC_STORE_U32(ctx.r30.u32 + 760, ctx.r18.u32);
loc_8308D9B8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x8308d978
	if (!ctx.cr6.eq) goto loc_8308D978;
	// b 0x8308d9d0
	goto loc_8308D9D0;
loc_8308D9C4:
	// lfs f0,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f14
	ctx.cr6.compare(ctx.f0.f64, ctx.f14.f64);
	// beq cr6,0x8309064c
	if (ctx.cr6.eq) goto loc_8309064C;
loc_8308D9D0:
	// lwz r11,268(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// lfs f21,96(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bne cr6,0x8308dad0
	if (!ctx.cr6.eq) goto loc_8308DAD0;
	// lwz r11,728(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 728);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308dad0
	if (ctx.cr6.eq) goto loc_8308DAD0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8308DA04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r8,108(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 108);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x8308DA18;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r7,488(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// lwz r30,728(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 728);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// lwz r25,516(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 516);
	// addi r29,r31,484
	ctx.r29.s64 = ctx.r31.s64 + 484;
	// addi r28,r31,520
	ctx.r28.s64 = ctx.r31.s64 + 520;
	// addi r24,r31,492
	ctx.r24.s64 = ctx.r31.s64 + 492;
	// lwz r6,0(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lwz r23,0(r30)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r5,32(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 32);
	// mtctr r5
	ctx.ctr.u64 = ctx.r5.u64;
	// bctrl 
	ctx.lr = 0x8308DA4C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r11,0(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// addi r6,r31,448
	ctx.r6.s64 = ctx.r31.s64 + 448;
	// addi r5,r31,436
	ctx.r5.s64 = ctx.r31.s64 + 436;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x8308DA7C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8308dad0
	if (!ctx.cr6.eq) goto loc_8308DAD0;
	// addi r31,r31,756
	ctx.r31.s64 = ctx.r31.s64 + 756;
	// li r30,4
	ctx.r30.s64 = 4;
loc_8308DA90:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308daa4
	if (ctx.cr6.eq) goto loc_8308DAA4;
	// bl 0x8315c3a0
	ctx.lr = 0x8308DAA0;
	sub_8315C3A0(ctx, base);
	// stw r18,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r18.u32);
loc_8308DAA4:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x8308da90
	if (!ctx.cr0.eq) goto loc_8308DA90;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// stfs f14,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lfs f0,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308DACC;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308DAD0:
	// lwz r9,712(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f0,436(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 436);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,440(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 440);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r11,r9,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	// lfs f12,444(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 444);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stfs f12,136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// beq cr6,0x8308e694
	if (ctx.cr6.eq) goto loc_8308E694;
	// lwz r3,268(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwz r10,740(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// stfs f0,144(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// addi r11,r31,436
	ctx.r11.s64 = ctx.r31.s64 + 436;
	// stfs f13,148(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stfs f12,152(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f30,96(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 96);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f28.f64 = double(temp.f32);
	// lfs f31,7676(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f31.f64 = double(temp.f32);
	// beq cr6,0x8308dbe0
	if (ctx.cr6.eq) goto loc_8308DBE0;
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r10,152
	ctx.r9.s64 = ctx.r10.s64 + 152;
	// lfs f13,168(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f10,172(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f7,176(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 176);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f5,152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,156(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,160(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,164(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f1,f2,f2,f28
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f28.f64));
	// fmuls f0,f4,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f13,f3,f8
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f10,f3,f6
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f9,f1,f11
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fmuls f7,f8,f1
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmsubs f0,f8,f5,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 - ctx.f0.f64));
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmsubs f13,f4,f6,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 - ctx.f13.f64));
	// fmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64));
	// fmadds f11,f5,f11,f10
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f10.f64));
	// fmuls f10,f0,f2
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f6,f13,f2
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f2,f12,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmadds f0,f4,f8,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f11.f64));
	// fsubs f13,f1,f10
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// fsubs f12,f9,f6
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f11,f7,f2
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fmuls f10,f0,f5
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f8,f3,f0
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fadds f6,f11,f9
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// fadds f5,f13,f8
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fmuls f4,f7,f31
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f4,144(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f3,148(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f2,152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
loc_8308DBE0:
	// lwz r9,744(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8308dca0
	if (ctx.cr6.eq) goto loc_8308DCA0;
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r8,r9,152
	ctx.r8.s64 = ctx.r9.s64 + 152;
	// lfs f13,168(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f10,172(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f7,176(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 176);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f5,152(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,156(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,160(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,164(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f1,f2,f2,f28
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f28.f64));
	// fmuls f0,f4,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f13,f3,f8
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f10,f3,f6
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f9,f1,f11
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fmuls f7,f8,f1
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmsubs f0,f8,f5,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 - ctx.f0.f64));
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmsubs f13,f4,f6,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 - ctx.f13.f64));
	// fmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64));
	// fmadds f11,f5,f11,f10
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f10.f64));
	// fmuls f10,f0,f2
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f6,f13,f2
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f2,f12,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmadds f0,f4,f8,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f11.f64));
	// fsubs f13,f1,f10
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// fsubs f12,f9,f6
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f11,f7,f2
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fmuls f10,f0,f5
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f8,f3,f0
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fadds f6,f11,f9
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// fadds f5,f13,f8
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fmuls f4,f7,f31
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f4,128(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f3,132(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f2,136(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
loc_8308DCA0:
	// cmplwi cr6,r27,1
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 1, ctx.xer);
	// bne cr6,0x8308dfe4
	if (!ctx.cr6.eq) goto loc_8308DFE4;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,644(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// lfs f29,6048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f29.f64 = double(temp.f32);
	// fcmpu cr6,f0,f29
	ctx.cr6.compare(ctx.f0.f64, ctx.f29.f64);
	// ble cr6,0x8308dfc0
	if (!ctx.cr6.gt) goto loc_8308DFC0;
	// lfs f13,520(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// fsubs f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// lfs f10,148(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 656);
	ctx.f9.f64 = double(temp.f32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lfs f0,448(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 448);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,452(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 452);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f8.f64 = double(temp.f32);
	// lfs f12,456(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// fadds f7,f11,f8
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fadds f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f30,f6,f9
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// beq cr6,0x8308dd84
	if (ctx.cr6.eq) goto loc_8308DD84;
	// lfs f11,152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,156(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f8,160(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f0
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f5,164(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmsubs f3,f5,f5,f28
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// fmsubs f2,f8,f0,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f11,f0,f4
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f12,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f6.f64));
	// fmuls f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f7,f10,f13,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fmuls f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fsubs f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f4,f3,f1
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fmuls f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fsubs f3,f6,f9
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// fmuls f1,f10,f7
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f11,f8,f7
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fadds f10,f3,f2
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// fadds f9,f5,f1
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fadds f8,f4,f11
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fmuls f7,f10,f31
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f7,96(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f6,f9,f31
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// stfs f6,100(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f5,f8,f31
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x8308dd90
	goto loc_8308DD90;
loc_8308DD84:
	// stfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f12,104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
loc_8308DD90:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8308de18
	if (ctx.cr6.eq) goto loc_8308DE18;
	// lfs f11,152(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,156(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f8,160(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f0
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f5,164(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmsubs f3,f5,f5,f28
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// fmsubs f2,f8,f0,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmsubs f9,f10,f12,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f6.f64));
	// fmadds f7,f11,f0,f4
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f0,f9,f5
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f13,f10,f13,f7
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fsubs f12,f4,f2
	ctx.f12.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f9,f3,f1
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fsubs f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// fmuls f6,f13,f11
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f3,f7,f6
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fadds f2,f12,f5
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fadds f1,f9,f4
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
loc_8308DE18:
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// stfs f12,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8308df44
	if (!ctx.cr6.eq) goto loc_8308DF44;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x8308DE38;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308de60
	if (ctx.cr6.eq) goto loc_8308DE60;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308DE60:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308de78
	if (ctx.cr6.eq) goto loc_8308DE78;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308DE78:
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x8308DE84;
	sub_83043388(ctx, base);
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r21,1
	ctx.r21.s64 = 1;
	// lwz r9,152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lfs f0,648(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lwz r7,132(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lfs f12,652(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 652);
	ctx.f12.f64 = double(temp.f32);
	// lwz r6,136(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lfs f11,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f11.f64 = double(temp.f32);
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f29,228(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lwz r30,104(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stfs f30,220(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lwz r29,108(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// stfs f0,236(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lwz r28,112(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stfs f13,252(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lwz r27,116(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stfs f12,240(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stw r11,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r11.u32);
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// stw r10,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r10.u32);
	// stw r9,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r9.u32);
	// stw r8,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r8.u32);
	// stw r7,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r7.u32);
	// stw r6,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r6.u32);
	// stw r5,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r5.u32);
	// stw r3,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r3.u32);
	// stw r30,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r30.u32);
	// stw r29,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r29.u32);
	// stw r28,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r28.u32);
	// stw r27,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r27.u32);
	// stw r21,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r21.u32);
	// stw r21,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r21.u32);
	// lwz r11,268(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x8308DF30;
	sub_8315C330(ctx, base);
	// stw r3,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r3.u32);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308DF40;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308DF44:
	// li r4,4
	ctx.r4.s64 = 4;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x8308DF50;
	sub_8315C4D0(ctx, base);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// bl 0x8315c738
	ctx.lr = 0x8308DF68;
	sub_8315C738(ctx, base);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 108);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// bl 0x8315c738
	ctx.lr = 0x8308DF80;
	sub_8315C738(ctx, base);
	// lwz r9,152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// li r4,0
	ctx.r4.s64 = 0;
	// ld r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// rldicr r6,r9,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// bl 0x8315c738
	ctx.lr = 0x8308DF98;
	sub_8315C738(ctx, base);
	// lwz r8,136(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// li r4,1
	ctx.r4.s64 = 1;
	// ld r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// rldicr r6,r8,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// bl 0x8315c738
	ctx.lr = 0x8308DFB0;
	sub_8315C738(ctx, base);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308DFBC;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308DFC0:
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8309064c
	if (ctx.cr6.eq) goto loc_8309064C;
	// bl 0x8315c3a0
	ctx.lr = 0x8308DFD0;
	sub_8315C3A0(ctx, base);
	// stw r18,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r18.u32);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308DFE0;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308DFE4:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x8309064c
	if (!ctx.cr6.eq) goto loc_8309064C;
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// addi r30,r31,460
	ctx.r30.s64 = ctx.r31.s64 + 460;
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r31.u32);
	// addi r22,r31,472
	ctx.r22.s64 = ctx.r31.s64 + 472;
	// lhz r10,492(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 492);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// lhz r5,306(r31)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r31.u32 + 306);
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// rotlwi r4,r10,16
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 16);
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// addi r7,r1,288
	ctx.r7.s64 = ctx.r1.s64 + 288;
	// or r5,r4,r5
	ctx.r5.u64 = ctx.r4.u64 | ctx.r5.u64;
	// addi r6,r31,448
	ctx.r6.s64 = ctx.r31.s64 + 448;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// bl 0x83136000
	ctx.lr = 0x8308E028;
	sub_83136000(ctx, base);
	// lis r3,-32256
	ctx.r3.s64 = -2113929216;
	// lfs f0,288(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,484(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	ctx.f13.f64 = double(temp.f32);
	// fmr f27,f0
	ctx.f27.f64 = ctx.f0.f64;
	// lfs f12,504(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 504);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f11,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f11.f64 = double(temp.f32);
	// lfs f29,6048(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 6048);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f11,f0
	ctx.f26.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f29
	ctx.cr6.compare(ctx.f12.f64, ctx.f29.f64);
	// blt cr6,0x8308e064
	if (ctx.cr6.lt) goto loc_8308E064;
	// lfs f0,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f30,f0
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f13,504(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 504, temp.u32);
	// b 0x8308e07c
	goto loc_8308E07C;
loc_8308E064:
	// lfs f0,300(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmuls f11,f12,f30
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fneg f10,f11
	ctx.f10.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfs f10,504(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 504, temp.u32);
loc_8308E07C:
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e118
	if (ctx.cr6.eq) goto loc_8308E118;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f12,f11
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f28
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f13,f10,f4
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f10,f8,f0,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmuls f11,f9,f5
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fsubs f9,f4,f2
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f8,f6,f1
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fmuls f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f7,f3,f11
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fmuls f5,f13,f10
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fadds f3,f8,f6
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fadds f2,f9,f5
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f1,f7,f4
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// b 0x8308e124
	goto loc_8308E124;
loc_8308E118:
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
loc_8308E124:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// stfs f12,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e1cc
	if (ctx.cr6.eq) goto loc_8308E1CC;
	// lfs f0,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f12,f11
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f28
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f13,f10,f4
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f10,f8,f0,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmuls f11,f9,f5
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fsubs f9,f4,f2
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f8,f6,f1
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fmuls f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f7,f3,f11
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fmuls f5,f13,f10
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fadds f3,f8,f6
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fadds f2,f9,f5
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f1,f7,f4
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// b 0x8308e1d8
	goto loc_8308E1D8;
loc_8308E1CC:
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
loc_8308E1D8:
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// stfs f12,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// ld r24,144(r1)
	ctx.r24.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// ld r23,128(r1)
	ctx.r23.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lwz r28,148(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r21,1
	ctx.r21.s64 = 1;
	// lwz r27,144(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// lwz r26,132(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r25,128(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// bne cr6,0x8308e2f4
	if (!ctx.cr6.eq) goto loc_8308E2F4;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x8308E214;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e23c
	if (ctx.cr6.eq) goto loc_8308E23C;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308E23C:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e254
	if (ctx.cr6.eq) goto loc_8308E254;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308E254:
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x8308E260;
	sub_83043388(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfs f0,504(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 504);
	ctx.f0.f64 = double(temp.f32);
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfs f13,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f13.f64 = double(temp.f32);
	// lwz r8,108(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfs f11,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f11.f64 = double(temp.f32);
	// lwz r7,112(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fabs f12,f0
	ctx.f12.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// lwz r6,116(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// fnabs f10,f0
	ctx.f10.u64 = ctx.f0.u64 | 0x8000000000000000;
	// lwz r30,152(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// stfs f13,252(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lwz r29,136(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stfs f12,232(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// stfs f10,228(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stw r27,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r27.u32);
	// stw r28,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r28.u32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// stw r30,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r30.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r25.u32);
	// stw r26,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r26.u32);
	// stw r29,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r29.u32);
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// stw r10,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r10.u32);
	// stw r9,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r9.u32);
	// stw r8,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r8.u32);
	// stw r7,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r7.u32);
	// stw r6,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r6.u32);
	// stw r21,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r21.u32);
	// lwz r5,268(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x8308E2EC;
	sub_8315C330(ctx, base);
	// stw r3,768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 768, ctx.r3.u32);
	// b 0x8308e378
	goto loc_8308E378;
loc_8308E2F4:
	// lfs f0,504(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 504);
	ctx.f0.f64 = double(temp.f32);
	// li r4,7
	ctx.r4.s64 = 7;
	// fabs f1,f0
	ctx.f1.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// bl 0x8315c4d0
	ctx.lr = 0x8308E304;
	sub_8315C4D0(ctx, base);
	// lfs f13,504(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 504);
	ctx.f13.f64 = double(temp.f32);
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// fnabs f1,f13
	ctx.f1.u64 = ctx.f13.u64 | 0x8000000000000000;
	// bl 0x8315c4d0
	ctx.lr = 0x8308E318;
	sub_8315C4D0(ctx, base);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// bl 0x8315c738
	ctx.lr = 0x8308E330;
	sub_8315C738(ctx, base);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 108);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// bl 0x8315c738
	ctx.lr = 0x8308E348;
	sub_8315C738(ctx, base);
	// lwz r30,152(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// rldicr r6,r30,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r30.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8315c738
	ctx.lr = 0x8308E360;
	sub_8315C738(ctx, base);
	// lwz r29,136(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// rldicr r6,r29,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r29.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8315c738
	ctx.lr = 0x8308E378;
	sub_8315C738(ctx, base);
loc_8308E378:
	// lfs f0,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f29
	ctx.cr6.compare(ctx.f0.f64, ctx.f29.f64);
	// blt cr6,0x8308e390
	if (ctx.cr6.lt) goto loc_8308E390;
	// fmuls f0,f30,f27
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// stfs f0,508(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
	// b 0x8308e39c
	goto loc_8308E39C;
loc_8308E390:
	// fmuls f0,f30,f26
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// fneg f13,f0
	ctx.f13.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f13,508(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
loc_8308E39C:
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e444
	if (ctx.cr6.eq) goto loc_8308E444;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f28
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f8,f0,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f10,f9,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f9,f12,f11,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fsubs f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f4,f13,f9
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f0,f6,f3
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f11,104(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x8308e45c
	goto loc_8308E45C;
loc_8308E444:
	// lfs f0,0(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f12,104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
loc_8308E45C:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e4f8
	if (ctx.cr6.eq) goto loc_8308E4F8;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f8,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f11,f12
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f28
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f28.f64));
	// fmsubs f2,f8,f12,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64));
	// fmsubs f1,f11,f13,f7
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f7.f64));
	// fmadds f7,f10,f13,f4
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f10,f8,f0,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmuls f11,f9,f5
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fsubs f9,f4,f2
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f8,f6,f1
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fmuls f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f7,f3,f11
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fmuls f5,f13,f10
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fadds f3,f8,f6
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fadds f2,f9,f5
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f1,f7,f4
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// b 0x8308e504
	goto loc_8308E504;
loc_8308E4F8:
	// lfs f0,0(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
loc_8308E504:
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// stfs f12,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8308e608
	if (!ctx.cr6.eq) goto loc_8308E608;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x8308E524;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e54c
	if (ctx.cr6.eq) goto loc_8308E54C;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308E54C:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308e564
	if (ctx.cr6.eq) goto loc_8308E564;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308E564:
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x8308E570;
	sub_83043388(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfs f0,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f0.f64 = double(temp.f32);
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// fabs f12,f0
	ctx.f12.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// lwz r8,112(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfs f13,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f13.f64 = double(temp.f32);
	// lwz r7,116(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfs f11,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f11.f64 = double(temp.f32);
	// lwz r6,108(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// stfs f12,232(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// fnabs f10,f0
	ctx.f10.u64 = ctx.f0.u64 | 0x8000000000000000;
	// stw r27,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r27.u32);
	// stfs f13,252(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stw r28,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r28.u32);
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r30,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r30.u32);
	// stfs f10,228(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r25.u32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// stw r26,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r26.u32);
	// stw r29,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r29.u32);
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// stw r10,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r10.u32);
	// stw r9,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r9.u32);
	// stw r8,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r8.u32);
	// stw r7,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r7.u32);
	// stw r21,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r21.u32);
	// stw r6,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r6.u32);
	// lwz r5,268(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x8308E5F4;
	sub_8315C330(ctx, base);
	// stw r3,764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 764, ctx.r3.u32);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308E604;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308E608:
	// lfs f0,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f0.f64 = double(temp.f32);
	// li r4,7
	ctx.r4.s64 = 7;
	// fabs f1,f0
	ctx.f1.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// bl 0x8315c4d0
	ctx.lr = 0x8308E618;
	sub_8315C4D0(ctx, base);
	// lfs f13,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f13.f64 = double(temp.f32);
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// fnabs f1,f13
	ctx.f1.u64 = ctx.f13.u64 | 0x8000000000000000;
	// bl 0x8315c4d0
	ctx.lr = 0x8308E62C;
	sub_8315C4D0(ctx, base);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// bl 0x8315c738
	ctx.lr = 0x8308E644;
	sub_8315C738(ctx, base);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 108);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// bl 0x8315c738
	ctx.lr = 0x8308E65C;
	sub_8315C738(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// rldicr r6,r30,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r30.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8315c738
	ctx.lr = 0x8308E670;
	sub_8315C738(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// rldicr r6,r29,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r29.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8315c738
	ctx.lr = 0x8308E684;
	sub_8315C738(ctx, base);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308E690;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308E694:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f12,104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// addi r19,r31,436
	ctx.r19.s64 = ctx.r31.s64 + 436;
	// fmr f2,f0
	ctx.f2.f64 = ctx.f0.f64;
	// lfs f15,6380(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6380);
	ctx.f15.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f19,6140(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6140);
	ctx.f19.f64 = double(temp.f32);
	// fmr f1,f13
	ctx.f1.f64 = ctx.f13.f64;
	// lfs f18,6048(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 6048);
	ctx.f18.f64 = double(temp.f32);
	// fmr f30,f12
	ctx.f30.f64 = ctx.f12.f64;
	// lfs f31,7676(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 7676);
	ctx.f31.f64 = double(temp.f32);
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// stfs f19,280(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stfs f18,272(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// beq cr6,0x8308eea0
	if (ctx.cr6.eq) goto loc_8308EEA0;
	// lfs f11,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r8,r9,0,25,25
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	// lfs f10,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r11,152
	ctx.r10.s64 = ctx.r11.s64 + 152;
	// lfs f9,4(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f11,f10
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f7,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f7.f64 = double(temp.f32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// lfs f6,8(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f4,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfs f7,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f4,f7,f7,f15
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f7.f64 - ctx.f15.f64));
	// lfs f11,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// lfs f10,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f9.f64 = double(temp.f32);
	// lfs f28,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f6,f8,f10
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f29,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f28.f64));
	// lfs f26,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f9,f5
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f28,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// lfs f29,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f25,f11,f3
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f22,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f9,f3
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// lfs f24,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f4,f8
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f20,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f4,f5
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmsubs f6,f11,f5,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fmsubs f3,f10,f3,f27
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 - ctx.f27.f64));
	// fmuls f27,f0,f26
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fmsubs f25,f8,f9,f25
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 - ctx.f25.f64));
	// fmadds f8,f11,f8,f23
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f23.f64));
	// fmuls f23,f29,f12
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fmuls f15,f28,f13
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f6,f7,f6
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// fmsubs f29,f29,f13,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 - ctx.f27.f64));
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmadds f5,f10,f5,f8
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f8.f64));
	// fmsubs f8,f0,f28,f23
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f28.f64 - ctx.f23.f64));
	// fmsubs f28,f26,f12,f15
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fsubs f27,f17,f3
	ctx.f27.f64 = double(float(ctx.f17.f64 - ctx.f3.f64));
	// fadds f4,f29,f20
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f20.f64));
	// fsubs f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 - ctx.f7.f64));
	// fmuls f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fmuls f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fadds f5,f8,f22
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f22.f64));
	// fadds f3,f28,f24
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// fmr f22,f4
	ctx.f22.f64 = ctx.f4.f64;
	// fadds f8,f27,f11
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f11.f64));
	// fadds f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f6,f6,f9
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fmr f23,f5
	ctx.f23.f64 = ctx.f5.f64;
	// fmr f24,f3
	ctx.f24.f64 = ctx.f3.f64;
	// fmuls f11,f8,f31
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f11,128(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f10,f7,f31
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f10,132(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f9,f6,f31
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f9,136(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// beq cr6,0x8308e8f0
	if (ctx.cr6.eq) goto loc_8308E8F0;
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lfs f11,496(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,500(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	ctx.f10.f64 = double(temp.f32);
	// fdivs f9,f19,f21
	ctx.f9.f64 = double(float(ctx.f19.f64 / ctx.f21.f64));
	// lfs f8,504(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 504);
	ctx.f8.f64 = double(temp.f32);
	// lwz r8,276(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// lfs f7,508(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 508);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,512(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 512);
	ctx.f6.f64 = double(temp.f32);
	// clrlwi r7,r8,31
	ctx.r7.u64 = ctx.r8.u32 & 0x1;
	// lfs f29,108(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,516(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 516);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f11,f11,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f10,f10,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f27,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfs f26,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f25,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f24,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f28,488(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	ctx.f23.f64 = double(temp.f32);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmuls f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f22,f8,f9
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f20,f7,f9
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f17,f6,f9
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// fmuls f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fadds f8,f11,f27
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f27.f64));
	// fadds f7,f26,f10
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// fadds f6,f25,f22
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fadds f11,f20,f24
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fadds f10,f28,f17
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// fadds f9,f23,f9
	ctx.f9.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// bne cr6,0x8308e8b4
	if (!ctx.cr6.eq) goto loc_8308E8B4;
	// lfs f29,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f29.f64 = double(temp.f32);
	// fadds f8,f29,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// lfs f28,84(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,88(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	ctx.f29.f64 = double(temp.f32);
	// fadds f7,f28,f7
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fadds f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
loc_8308E8B4:
	// fmuls f29,f9,f13
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f28,f11,f12
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f27,f10,f0
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmsubs f12,f10,f12,f29
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f29.f64));
	// fmsubs f10,f9,f0,f28
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmsubs f9,f11,f13,f27
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f27.f64));
	// fadds f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fadds f7,f10,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fadds f6,f9,f6
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fmuls f0,f8,f21
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// fmuls f13,f7,f21
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// fmuls f12,f6,f21
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fadds f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 + ctx.f3.f64));
	// fadds f23,f13,f5
	ctx.f23.f64 = double(float(ctx.f13.f64 + ctx.f5.f64));
	// fadds f22,f12,f4
	ctx.f22.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
loc_8308E8F0:
	// lfs f15,264(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
loc_8308E8F8:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308eb10
	if (ctx.cr6.eq) goto loc_8308EB10;
	// lfs f9,8(r19)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r9,r9,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	// lfs f7,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f7.f64 = double(temp.f32);
	// addi r10,r11,152
	ctx.r10.s64 = ctx.r11.s64 + 152;
	// lfs f13,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f0,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmr f9,f13
	ctx.f9.f64 = ctx.f13.f64;
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f12,4(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// fsubs f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f4,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f7,f10,f10,f15
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f10.f64 - ctx.f15.f64));
	// lfs f5,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f13,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f1,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f13.f64));
	// lfs f28,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f25,f6,f5
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f26,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f0,f2,f9
	ctx.f0.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// lfs f2,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f9,f4,f11
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f1,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f12,f30,f2
	ctx.f12.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// lfs f30,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f3,f8
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfs f20,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f4,f8
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f2,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f8,f7
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f17,f7,f11
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fmsubs f9,f8,f5,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 - ctx.f9.f64));
	// fmuls f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmsubs f7,f4,f6,f29
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 - ctx.f29.f64));
	// fmadds f6,f3,f6,f27
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f27.f64));
	// fmsubs f29,f3,f11,f25
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f25.f64));
	// fmuls f27,f28,f0
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f25,f26,f13
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f14,f1,f12
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmadds f6,f5,f11,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f6.f64));
	// fmuls f11,f29,f10
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmsubs f10,f1,f13,f27
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - ctx.f27.f64));
	// fmsubs f1,f28,f12,f25
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f25.f64));
	// fmsubs f29,f26,f0,f14
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f14.f64));
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fsubs f8,f17,f7
	ctx.f8.f64 = double(float(ctx.f17.f64 - ctx.f7.f64));
	// fmuls f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f5,f4,f6
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fmuls f4,f3,f6
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fsubs f3,f16,f11
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f11.f64));
	// fadds f11,f10,f30
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// fadds f10,f1,f20
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// fadds f6,f29,f2
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f1,f9,f4
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fadds f9,f3,f5
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f11.f64));
	// fsubs f24,f24,f10
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f10.f64));
	// fsubs f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// fmuls f8,f2,f31
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f8,96(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f7,f1,f31
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f7,104(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f6,f9,f31
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// stfs f6,100(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// beq cr6,0x8308eb0c
	if (ctx.cr6.eq) goto loc_8308EB0C;
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lfs f11,496(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	ctx.f11.f64 = double(temp.f32);
	// lfs f8,504(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 504);
	ctx.f8.f64 = double(temp.f32);
	// fdivs f9,f19,f21
	ctx.f9.f64 = double(float(ctx.f19.f64 / ctx.f21.f64));
	// lfs f7,508(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 508);
	ctx.f7.f64 = double(temp.f32);
	// lwz r9,276(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	// lfs f10,500(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,512(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 512);
	ctx.f6.f64 = double(temp.f32);
	// clrlwi r8,r9,31
	ctx.r8.u64 = ctx.r9.u32 & 0x1;
	// lfs f5,108(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f11
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f3,516(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 516);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f11,f8,f5
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f30,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// lfs f1,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f29,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f2,f10,f5
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f5.f64));
	// lfs f10,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,488(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	ctx.f3.f64 = double(temp.f32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// fmuls f4,f9,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmuls f28,f9,f8
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f27,f7,f9
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fmuls f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// fadds f8,f1,f4
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fadds f6,f30,f11
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f11.f64));
	// fadds f11,f29,f28
	ctx.f11.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// fadds f7,f10,f2
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// fadds f10,f5,f27
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fadds f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// bne cr6,0x8308ead0
	if (!ctx.cr6.eq) goto loc_8308EAD0;
	// lfs f5,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,84(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// lfs f3,88(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	ctx.f3.f64 = double(temp.f32);
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
loc_8308EAD0:
	// fmuls f4,f12,f11
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f5,f9,f13
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f3,f10,f0
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmsubs f1,f9,f0,f4
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmsubs f2,f10,f12,f5
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f5.f64));
	// fmsubs f0,f13,f11,f3
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f3.f64));
	// fadds f12,f1,f7
	ctx.f12.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fadds f13,f2,f8
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fadds f11,f0,f6
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f6.f64));
	// fmuls f9,f12,f21
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// fmuls f10,f13,f21
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f8,f11,f21
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// fsubs f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f9.f64));
	// fsubs f24,f24,f10
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f10.f64));
	// fsubs f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f8.f64));
loc_8308EB0C:
	// lfs f14,260(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
loc_8308EB10:
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308ed24
	if (ctx.cr6.eq) goto loc_8308ED24;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8308ed24
	if (ctx.cr6.eq) goto loc_8308ED24;
	// lfs f0,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// lfs f11,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f9,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f9.f64 = double(temp.f32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// fmr f7,f9
	ctx.f7.f64 = ctx.f9.f64;
	// lfs f5,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f5,f11
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f6,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f5,f0
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f3,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f1,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f28,f6,f6,f15
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f6.f64 - ctx.f15.f64));
	// lfs f27,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f26,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f12,f29
	ctx.f25.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// stfd f24,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.f24.u64);
	// fmadds f10,f3,f6,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f10.f64));
	// lfs f19,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f1,f8
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f7,f29
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f18,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f2,f13,f6,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f16,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f30,f27,f6,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f30.f64));
	// addi r11,r31,12
	ctx.r11.s64 = ctx.r31.s64 + 12;
	// fmsubs f4,f5,f6,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 - ctx.f4.f64));
	// fmuls f15,f7,f26
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// fmuls f14,f29,f28
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// fmuls f24,f1,f28
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmsubs f25,f7,f1,f25
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 - ctx.f25.f64));
	// fmadds f10,f5,f9,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f10.f64));
	// fmsubs f5,f12,f26,f20
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 - ctx.f20.f64));
	// fmadds f20,f26,f8,f17
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 + ctx.f17.f64));
	// fmadds f2,f27,f9,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 + ctx.f2.f64));
	// fmadds f30,f3,f11,f30
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f30.f64));
	// fnmsubs f4,f3,f9,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f9.f64 - ctx.f4.f64)));
	// fmsubs f29,f29,f8,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f15.f64));
	// fmuls f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f26,f25,f6
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fnmsubs f11,f27,f11,f10
	ctx.f11.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmuls f10,f5,f6
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmadds f5,f12,f1,f20
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 + ctx.f20.f64));
	// fnmsubs f3,f3,f0,f2
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fnmsubs f2,f13,f9,f30
	ctx.f2.f64 = double(float(-(ctx.f13.f64 * ctx.f9.f64 - ctx.f30.f64)));
	// fnmsubs f4,f27,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f1,f29,f6
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fadds f0,f28,f26
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fmuls f13,f11,f11
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fadds f10,f14,f10
	ctx.f10.f64 = double(float(ctx.f14.f64 + ctx.f10.f64));
	// fmuls f9,f7,f5
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// fmuls f6,f11,f3
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f7,f12,f5
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmuls f30,f4,f2
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmuls f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// fmuls f12,f2,f2
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// fadds f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fmuls f5,f13,f31
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f13,f10,f9
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// fmuls f10,f6,f31
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f6,f30,f31
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fadds f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f8.f64));
	// fmuls f9,f12,f31
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fadds f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f12,f19,f5
	ctx.f12.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// fmuls f8,f13,f31
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fsubs f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// stfs f7,292(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f7,f0,f31
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fsubs f0,f12,f9
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f0,288(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f0,f21,f8
	ctx.f0.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fmuls f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f30,f4,f11
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// addi r10,r1,288
	ctx.r10.s64 = ctx.r1.s64 + 288;
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f29,f3,f3
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f11,f4,f3
	ctx.f11.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// stfs f10,300(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f12,f16,f7
	ctx.f12.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fadds f13,f18,f1
	ctx.f13.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// fmuls f7,f30,f31
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f4,f2,f31
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fnmsubs f6,f29,f31,f19
	ctx.f6.f64 = double(float(-(ctx.f29.f64 * ctx.f31.f64 - ctx.f19.f64)));
	// fmuls f3,f11,f31
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fadds f2,f7,f8
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f2,296(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f11,f8,f7
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f11,312(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f1,f6,f9
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// stfs f1,304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f10,f4,f3
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f10,308(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f9,f3,f4
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f9,316(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fsubs f8,f6,f5
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfs f8,320(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// lfd f24,144(r1)
	ctx.f24.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
loc_8308ECE8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x8308ece8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308ECE8;
	// stfs f13,44(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// stfs f0,40(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f12,36(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_8308ED24:
	// lfs f29,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	ctx.f29.f64 = double(temp.f32);
	// addi r20,r31,12
	ctx.r20.s64 = ctx.r31.s64 + 12;
	// lfs f0,452(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 452);
	ctx.f0.f64 = double(temp.f32);
	// addi r30,r31,448
	ctx.r30.s64 = ctx.r31.s64 + 448;
	// fmuls f13,f0,f29
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// lfs f28,40(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// lfs f12,456(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// lfs f27,16(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// lfs f11,448(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 448);
	ctx.f11.f64 = double(temp.f32);
	// stfs f29,148(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f28,152(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f27,144(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmadds f10,f12,f28,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 + ctx.f13.f64));
	// fmadds f17,f27,f11,f10
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f10.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fcmpu cr6,f17,f18
	ctx.cr6.compare(ctx.f17.f64, ctx.f18.f64);
	// bge cr6,0x8308ed70
	if (!ctx.cr6.lt) goto loc_8308ED70;
	// fmr f17,f18
	ctx.f17.f64 = ctx.f18.f64;
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
loc_8308ED70:
	// cmplwi cr6,r27,1
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 1, ctx.xer);
	// bne cr6,0x8308f638
	if (!ctx.cr6.eq) goto loc_8308F638;
	// lfs f13,644(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 644);
	ctx.f13.f64 = double(temp.f32);
	// lwz r27,132(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r26,128(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r21,1
	ctx.r21.s64 = 1;
	// lwz r25,100(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// fcmpu cr6,f13,f18
	ctx.cr6.compare(ctx.f13.f64, ctx.f18.f64);
	// lwz r24,96(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r29,136(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// ld r23,128(r1)
	ctx.r23.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// lwz r28,104(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// ld r22,96(r1)
	ctx.r22.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// ble cr6,0x8308f0b0
	if (!ctx.cr6.gt) goto loc_8308F0B0;
	// lfs f0,520(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// bge cr6,0x8308edc0
	if (!ctx.cr6.lt) goto loc_8308EDC0;
	// fmr f0,f18
	ctx.f0.f64 = ctx.f18.f64;
loc_8308EDC0:
	// fsubs f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// lfs f13,148(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f12,656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 656);
	ctx.f12.f64 = double(temp.f32);
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// lfs f11,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fadds f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fadds f9,f10,f13
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fsubs f30,f9,f12
	ctx.f30.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// bne cr6,0x8308edf8
	if (!ctx.cr6.eq) goto loc_8308EDF8;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_8308EDF8:
	// lwz r10,740(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8308eeb0
	if (ctx.cr6.eq) goto loc_8308EEB0;
	// lfs f11,152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,156(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f8,160(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f0
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f5,164(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f8,f0,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f11,f0,f4
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f12,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f6.f64));
	// fmuls f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f7,f10,f13,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fmuls f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fsubs f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f4,f3,f1
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fmuls f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fsubs f3,f6,f9
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// fmuls f1,f10,f7
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f11,f8,f7
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fadds f10,f3,f2
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// fadds f9,f5,f1
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fadds f8,f4,f11
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fmuls f7,f10,f31
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f7,96(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f6,f9,f31
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// stfs f6,100(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f5,f8,f31
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x8308eebc
	goto loc_8308EEBC;
loc_8308EEA0:
	// fmr f22,f18
	ctx.fpscr.disableFlushMode();
	ctx.f22.f64 = ctx.f18.f64;
	// fmr f23,f18
	ctx.f23.f64 = ctx.f18.f64;
	// fmr f24,f18
	ctx.f24.f64 = ctx.f18.f64;
	// b 0x8308e8f8
	goto loc_8308E8F8;
loc_8308EEB0:
	// stfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f12,104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
loc_8308EEBC:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308ef48
	if (ctx.cr6.eq) goto loc_8308EF48;
	// lfs f11,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f8,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f0
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f8,f0,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmsubs f9,f10,f12,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f6.f64));
	// fmadds f7,f11,f0,f4
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f0,f9,f5
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f13,f10,f13,f7
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fsubs f12,f4,f2
	ctx.f12.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f9,f3,f1
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fsubs f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// fmuls f6,f13,f11
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f3,f7,f6
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fadds f2,f12,f5
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fadds f1,f9,f4
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
loc_8308EF48:
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// stfs f12,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8308f048
	if (!ctx.cr6.eq) goto loc_8308F048;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x8308EF68;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308ef90
	if (ctx.cr6.eq) goto loc_8308EF90;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308EF90:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308efa8
	if (ctx.cr6.eq) goto loc_8308EFA8;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308EFA8:
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x8308EFB4;
	sub_83043388(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfs f13,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lwz r8,108(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfs f12,652(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 652);
	ctx.f12.f64 = double(temp.f32);
	// lwz r7,112(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfs f0,648(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	ctx.f0.f64 = double(temp.f32);
	// lwz r6,116(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfs f11,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f11.f64 = double(temp.f32);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f30,220(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// stfs f13,252(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// stfs f12,240(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stw r27,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r27.u32);
	// stw r29,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r29.u32);
	// stfs f0,236(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stw r24,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r24.u32);
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r25.u32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// stw r28,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r28.u32);
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// stw r9,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r9.u32);
	// stw r8,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r8.u32);
	// stw r7,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r7.u32);
	// stw r6,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r6.u32);
	// stw r21,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r21.u32);
	// stw r21,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r21.u32);
	// stw r10,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r10.u32);
	// lwz r5,268(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x8308F040;
	sub_8315C330(ctx, base);
	// stw r3,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r3.u32);
	// b 0x8308f0c4
	goto loc_8308F0C4;
loc_8308F048:
	// li r4,4
	ctx.r4.s64 = 4;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x8308F054;
	sub_8315C4D0(ctx, base);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// bl 0x8315c738
	ctx.lr = 0x8308F06C;
	sub_8315C738(ctx, base);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 108);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// bl 0x8315c738
	ctx.lr = 0x8308F084;
	sub_8315C738(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// rldicr r6,r29,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r29.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8315c738
	ctx.lr = 0x8308F098;
	sub_8315C738(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// rldicr r6,r28,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r28.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8315c738
	ctx.lr = 0x8308F0AC;
	sub_8315C738(ctx, base);
	// b 0x8308f0c4
	goto loc_8308F0C4;
loc_8308F0B0:
	// lwz r3,756(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8308f0c4
	if (ctx.cr6.eq) goto loc_8308F0C4;
	// bl 0x8315c3a0
	ctx.lr = 0x8308F0C0;
	sub_8315C3A0(ctx, base);
	// stw r18,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r18.u32);
loc_8308F0C4:
	// lfs f0,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308f614
	if (!ctx.cr6.lt) goto loc_8308F614;
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// lis r10,-32202
	ctx.r10.s64 = -2110390272;
	// lfs f13,148(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r6,r10,31560
	ctx.r6.s64 = ctx.r10.s64 + 31560;
	// li r4,12
	ctx.r4.s64 = 12;
	// lfs f12,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f12.f64 = double(temp.f32);
	// addi r3,r1,400
	ctx.r3.s64 = ctx.r1.s64 + 400;
	// fadds f11,f0,f12
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// fadds f30,f11,f13
	ctx.f30.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// bl 0x82298ff8
	ctx.lr = 0x8308F104;
	sub_82298FF8(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308f1ac
	if (ctx.cr6.eq) goto loc_8308F1AC;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f8,f0,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f10,f9,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f9,f12,f11,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fsubs f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f4,f13,f9
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f0,f6,f3
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f13,400(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f12,404(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f11,408(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// b 0x8308f1c4
	goto loc_8308F1C4;
loc_8308F1AC:
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,400(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stfs f13,404(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// stfs f12,408(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
loc_8308F1C4:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308f26c
	if (ctx.cr6.eq) goto loc_8308F26C;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f8,f0,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f10,f9,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f9,f12,f11,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fsubs f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f4,f13,f9
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f0,f6,f3
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f13,412(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f12,416(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f11,420(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// b 0x8308f284
	goto loc_8308F284;
loc_8308F26C:
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,412(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// stfs f13,416(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// stfs f12,420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
loc_8308F284:
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8308f368
	if (!ctx.cr6.eq) goto loc_8308F368;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x8308F298;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308f2c0
	if (ctx.cr6.eq) goto loc_8308F2C0;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308F2C0:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308f2d8
	if (ctx.cr6.eq) goto loc_8308F2D8;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8308F2D8:
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x8308F2E4;
	sub_83043388(ctx, base);
	// lwz r9,412(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// lwz r8,416(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	// lfs f0,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// lwz r6,420(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// lfs f13,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,400(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lwz r10,408(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	// stfs f30,220(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lwz r7,404(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	// stfs f0,252(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stfs f13,256(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// stw r27,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r27.u32);
	// stw r29,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r29.u32);
	// stw r24,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r24.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r25.u32);
	// stw r28,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r28.u32);
	// stw r21,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r21.u32);
	// stw r21,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r21.u32);
	// stw r9,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r9.u32);
	// stw r8,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r8.u32);
	// stw r6,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r6.u32);
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// stw r10,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r10.u32);
	// stw r7,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r7.u32);
	// lwz r5,268(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x8308F360;
	sub_8315C330(ctx, base);
	// stw r3,760(r31)
	PPC_STORE_U32(ctx.r31.u32 + 760, ctx.r3.u32);
	// b 0x8308f3cc
	goto loc_8308F3CC;
loc_8308F368:
	// li r4,4
	ctx.r4.s64 = 4;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x8308F374;
	sub_8315C4D0(ctx, base);
	// lwz r11,408(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,400(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 400);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// bl 0x8315c738
	ctx.lr = 0x8308F38C;
	sub_8315C738(ctx, base);
	// lwz r10,420(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,412(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 412);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// bl 0x8315c738
	ctx.lr = 0x8308F3A4;
	sub_8315C738(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// rldicr r6,r29,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r29.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8315c738
	ctx.lr = 0x8308F3B8;
	sub_8315C738(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// rldicr r6,r28,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r28.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8315c738
	ctx.lr = 0x8308F3CC;
	sub_8315C738(ctx, base);
loc_8308F3CC:
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lfs f0,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,520(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 520, temp.u32);
	// fmuls f11,f0,f27
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fmuls f10,f29,f0
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f9,f28,f0
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// beq cr6,0x8308f5e0
	if (ctx.cr6.eq) goto loc_8308F5E0;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8308f5e0
	if (ctx.cr6.eq) goto loc_8308F5E0;
	// lfs f0,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// lfs f7,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f13,f0
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmr f5,f7
	ctx.f5.f64 = ctx.f7.f64;
	// lfs f3,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f13,f7
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f29,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f1,f3
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmr f30,f3
	ctx.f30.f64 = ctx.f3.f64;
	// lfs f4,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f4.f64 = double(temp.f32);
	// lfs f27,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f29,f0
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// lfs f25,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f24,f4,f4,f15
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f23,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f22,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f12,f25
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfd f11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.f11.u64);
	// fmadds f6,f27,f4,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f8,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f19,f25,f5
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// lfs f20,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f2,f29,f4,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f2.f64));
	// lfs f18,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f28,f13,f4,f28
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f28.f64));
	// lfs f17,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f30,f23
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// addi r11,r1,288
	ctx.r11.s64 = ctx.r1.s64 + 288;
	// fmadds f26,f1,f4,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmuls f15,f12,f22
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f22.f64));
	// fmuls f14,f22,f24
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// fmuls f11,f25,f24
	ctx.f11.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmadds f21,f30,f22,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f21.f64));
	// fmadds f6,f29,f3,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 + ctx.f6.f64));
	// fmsubs f19,f12,f23,f19
	ctx.f19.f64 = double(float(ctx.f12.f64 * ctx.f23.f64 - ctx.f19.f64));
	// fnmsubs f2,f27,f3,f2
	ctx.f2.f64 = double(float(-(ctx.f27.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// fmadds f29,f29,f7,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f7.f64 + ctx.f28.f64));
	// fmsubs f22,f22,f5,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 - ctx.f16.f64));
	// fmadds f28,f27,f7,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f26.f64));
	// fmsubs f26,f30,f25,f15
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 - ctx.f15.f64));
	// fmuls f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// fmadds f24,f23,f5,f21
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f21.f64));
	// fnmsubs f7,f1,f7,f6
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmuls f6,f19,f4
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fnmsubs f2,f1,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fnmsubs f29,f27,f0,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f29.f64)));
	// fmuls f1,f22,f4
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// fnmsubs f13,f13,f3,f28
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f3.f64 - ctx.f28.f64)));
	// fmuls f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f3,f30,f24
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f24.f64));
	// fmuls f0,f7,f7
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// fadds f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// fmuls f12,f12,f24
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f24.f64));
	// fmuls f30,f7,f29
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// fadds f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// fmuls f27,f2,f13
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fadds f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fmuls f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmuls f28,f13,f13
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmuls f26,f0,f31
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fadds f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fadds f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f12.f64));
	// fmuls f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f30,f27,f31
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fmuls f6,f28,f31
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fsubs f4,f8,f26
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fsubs f0,f12,f30
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f30.f64));
	// stfs f0,292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfs f4,288(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f0,f20,f3
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f3.f64));
	// fmuls f3,f13,f29
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f4,f2,f7
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
	// fmuls f28,f29,f29
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f2,f2,f29
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f29.f64));
	// fadds f13,f30,f12
	ctx.f13.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// stfs f13,300(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f12,f5,f17
	ctx.f12.f64 = double(float(ctx.f5.f64 + ctx.f17.f64));
	// fmuls f5,f3,f31
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fadds f13,f18,f1
	ctx.f13.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fnmsubs f3,f28,f31,f8
	ctx.f3.f64 = double(float(-(ctx.f28.f64 * ctx.f31.f64 - ctx.f8.f64)));
	// fmuls f1,f7,f31
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f8,f2,f31
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fadds f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f7,296(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,312(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfs f6,304(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f4,f1,f8
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f8.f64));
	// stfs f4,308(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f2,f8,f1
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f1.f64));
	// stfs f2,316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fsubs f1,f3,f26
	ctx.f1.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// lfd f11,144(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
loc_8308F5B4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308f5b4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308F5B4;
	// stfs f13,44(r20)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r20.u32 + 44, temp.u32);
	// stfs f0,40(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 40, temp.u32);
	// stfs f12,36(r20)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r20.u32 + 36, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_8308F5E0:
	// lfs f0,48(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f12,f0,f11
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,56(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fsubs f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f12,0(r19)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// stfs f10,4(r19)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r19.u32 + 4, temp.u32);
	// stfs f9,8(r19)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r19.u32 + 8, temp.u32);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308F610;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308F614:
	// lwz r3,760(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 760);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8309064c
	if (ctx.cr6.eq) goto loc_8309064C;
	// bl 0x8315c3a0
	ctx.lr = 0x8308F624;
	sub_8315C3A0(ctx, base);
	// stw r18,760(r31)
	PPC_STORE_U32(ctx.r31.u32 + 760, ctx.r18.u32);
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x8308F634;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
loc_8308F638:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x8309064c
	if (!ctx.cr6.eq) goto loc_8309064C;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308f84c
	if (ctx.cr6.eq) goto loc_8308F84C;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8308f84c
	if (ctx.cr6.eq) goto loc_8308F84C;
	// lfs f0,248(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// lfs f11,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmr f9,f11
	ctx.f9.f64 = ctx.f11.f64;
	// lfs f8,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f6,f8,f8,f15
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f7,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f5,f8
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f3,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f7,f13
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f29,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f11,f5
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// lfs f1,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmr f28,f7
	ctx.f28.f64 = ctx.f7.f64;
	// lfs f27,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f26,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f29,f12
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// stfd f24,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.f24.u64);
	// fmadds f10,f3,f8,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f8.f64 + ctx.f10.f64));
	// lfs f19,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f1,f9
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// lfs f20,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f12,f27
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// lfs f17,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f11,f13,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f2.f64));
	// lfs f15,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f4,f11,f3,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f4.f64));
	// addi r11,r1,288
	ctx.r11.s64 = ctx.r1.s64 + 288;
	// fmsubs f13,f13,f8,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f30.f64));
	// fmuls f30,f29,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// fmuls f14,f29,f6
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fmuls f24,f1,f6
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmadds f25,f9,f27,f25
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmadds f10,f7,f5,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 + ctx.f10.f64));
	// fmsubs f18,f28,f27,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f27.f64 - ctx.f18.f64));
	// fmsubs f29,f29,f9,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 - ctx.f16.f64));
	// fmadds f2,f0,f26,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f26.f64 + ctx.f2.f64));
	// fmadds f4,f26,f8,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 + ctx.f4.f64));
	// fnmsubs f13,f0,f3,f13
	ctx.f13.f64 = double(float(-(ctx.f0.f64 * ctx.f3.f64 - ctx.f13.f64)));
	// fmsubs f30,f1,f12,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f30.f64));
	// fmuls f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmadds f1,f1,f28,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64 + ctx.f25.f64));
	// fnmsubs f11,f11,f26,f10
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f26.f64 - ctx.f10.f64)));
	// fmuls f10,f18,f8
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fnmsubs f5,f0,f5,f4
	ctx.f5.f64 = double(float(-(ctx.f0.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// fnmsubs f4,f7,f3,f2
	ctx.f4.f64 = double(float(-(ctx.f7.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// fnmsubs f3,f7,f26,f13
	ctx.f3.f64 = double(float(-(ctx.f7.f64 * ctx.f26.f64 - ctx.f13.f64)));
	// fmuls f2,f30,f8
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f0,f1,f12
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f13,f11,f11
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fadds f12,f14,f10
	ctx.f12.f64 = double(float(ctx.f14.f64 + ctx.f10.f64));
	// fadds f10,f24,f29
	ctx.f10.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fmuls f29,f1,f28
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f1,f1,f9
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f8,f5,f5
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f7,f4,f11
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fadds f9,f6,f2
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fmuls f30,f3,f5
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// fmuls f6,f13,f31
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f2,f12,f0
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f12,f10,f29
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f29.f64));
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fadds f10,f9,f1
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fmuls f13,f30,f31
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fsubs f9,f19,f6
	ctx.f9.f64 = double(float(ctx.f19.f64 - ctx.f6.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fsubs f1,f7,f13
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f13.f64));
	// stfs f1,292(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfs f9,288(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f0,f20,f2
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f4,f5
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f1,f3,f11
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
	// fmuls f9,f4,f4
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fadds f3,f13,f7
	ctx.f3.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// stfs f3,300(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f13,f17,f12
	ctx.f13.f64 = double(float(ctx.f17.f64 + ctx.f12.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fadds f12,f10,f15
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f15.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f11,f9,f31,f19
	ctx.f11.f64 = double(float(-(ctx.f9.f64 * ctx.f31.f64 - ctx.f19.f64)));
	// fmuls f9,f4,f31
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f10,f5,f31
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fadds f7,f1,f2
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f7,296(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f4,f2,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f4,312(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f5,f11,f8
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfs f5,304(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfs f3,308(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f2,316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fsubs f1,f11,f6
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// lfd f24,144(r1)
	ctx.f24.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
loc_8308F810:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8308f810
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8308F810;
	// stfs f12,36(r20)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r20.u32 + 36, temp.u32);
	// stfs f0,40(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 40, temp.u32);
	// stfs f13,44(r20)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r20.u32 + 44, temp.u32);
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_8308F84C:
	// lfs f0,12(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f11,24(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmr f7,f13
	ctx.f7.f64 = ctx.f13.f64;
	// lfs f9,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmr f6,f10
	ctx.f6.f64 = ctx.f10.f64;
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmadds f4,f10,f11,f12
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f12.f64));
	// fmadds f3,f9,f8,f4
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f4.f64));
	// fmuls f2,f7,f3
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f1,f6,f3
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// fmuls f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// fsubs f29,f0,f2
	ctx.f29.f64 = double(float(ctx.f0.f64 - ctx.f2.f64));
	// fsubs f28,f11,f1
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fsubs f30,f9,f13
	ctx.f30.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// fmuls f12,f29,f29
	ctx.f12.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// fmadds f11,f28,f28,f12
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f28.f64 + ctx.f12.f64));
	// fmadds f10,f30,f30,f11
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f30.f64 + ctx.f11.f64));
	// fsqrts f0,f10
	ctx.f0.f64 = double(float(sqrt(ctx.f10.f64)));
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// beq cr6,0x8308f8bc
	if (ctx.cr6.eq) goto loc_8308F8BC;
	// fdivs f13,f19,f0
	ctx.f13.f64 = double(float(ctx.f19.f64 / ctx.f0.f64));
	// fmuls f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f29,f13,f29
	ctx.f29.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f28,f13,f28
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
loc_8308F8BC:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfd f13,24704(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24704);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// ble cr6,0x8309064c
	if (!ctx.cr6.gt) goto loc_8309064C;
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f30,f13
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f10,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f28,f12
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f8,f29,f10
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f0,724(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 724);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// fmsubs f27,f28,f10,f11
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f11.f64));
	// fmsubs f26,f29,f13,f9
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 - ctx.f9.f64));
	// fmsubs f25,f30,f12,f8
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 - ctx.f8.f64));
	// beq cr6,0x8308f97c
	if (ctx.cr6.eq) goto loc_8308F97C;
	// fmr f20,f0
	ctx.f20.f64 = ctx.f0.f64;
	// fmr f1,f20
	ctx.f1.f64 = ctx.f20.f64;
	// bl 0x82cb4940
	ctx.lr = 0x8308F908;
	sub_82CB4940(ctx, base);
	// frsp f16,f1
	ctx.fpscr.disableFlushMode();
	ctx.f16.f64 = double(float(ctx.f1.f64));
	// fmr f1,f20
	ctx.f1.f64 = ctx.f20.f64;
	// bl 0x82cb4860
	ctx.lr = 0x8308F914;
	sub_82CB4860(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// fmuls f13,f30,f16
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// fmuls f12,f29,f16
	ctx.f12.f64 = double(float(ctx.f29.f64 * ctx.f16.f64));
	// fmuls f11,f28,f16
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// fmuls f10,f16,f26
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// fmuls f9,f27,f16
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// fmuls f8,f25,f16
	ctx.f8.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// fmuls f7,f0,f26
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fmuls f6,f27,f0
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f5,f25,f0
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f2,f28,f0
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f1,f13,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// stfs f1,460(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 460, temp.u32);
	// fsubs f0,f12,f6
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// stfs f0,464(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 464, temp.u32);
	// fsubs f13,f11,f5
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// stfs f13,468(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 468, temp.u32);
	// fadds f12,f4,f10
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f12,472(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 472, temp.u32);
	// fadds f11,f3,f9
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// stfs f11,476(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 476, temp.u32);
	// fadds f10,f2,f8
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// stfs f10,480(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 480, temp.u32);
	// b 0x8308f994
	goto loc_8308F994;
loc_8308F97C:
	// stfs f30,460(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 460, temp.u32);
	// stfs f29,464(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 464, temp.u32);
	// stfs f28,468(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 468, temp.u32);
	// stfs f26,472(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 472, temp.u32);
	// stfs f27,476(r31)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 476, temp.u32);
	// stfs f25,480(r31)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + 480, temp.u32);
loc_8308F994:
	// fmuls f0,f22,f22
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f22.f64));
	// addi r23,r31,460
	ctx.r23.s64 = ctx.r31.s64 + 460;
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// addi r30,r31,472
	ctx.r30.s64 = ctx.r31.s64 + 472;
	// lfs f13,4(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f23
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// lfs f11,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,-18284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18284);
	ctx.f13.f64 = double(temp.f32);
	// lfs f29,-18324(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18324);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f9,f24,f24,f0
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f24.f64 + ctx.f0.f64));
	// fmadds f8,f11,f22,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f22.f64 + ctx.f12.f64));
	// fmadds f7,f23,f23,f9
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f23.f64 + ctx.f9.f64));
	// fmadds f30,f24,f10,f8
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f8.f64));
	// fsqrts f0,f7
	ctx.f0.f64 = double(float(sqrt(ctx.f7.f64)));
	// fabs f6,f0
	ctx.f6.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// fcmpu cr6,f6,f13
	ctx.cr6.compare(ctx.f6.f64, ctx.f13.f64);
	// ble cr6,0x8308f9ec
	if (!ctx.cr6.gt) goto loc_8308F9EC;
	// fdivs f1,f30,f0
	ctx.f1.f64 = double(float(ctx.f30.f64 / ctx.f0.f64));
	// fcmpu cr6,f1,f19
	ctx.cr6.compare(ctx.f1.f64, ctx.f19.f64);
	// blt cr6,0x8308f9f8
	if (ctx.cr6.lt) goto loc_8308F9F8;
loc_8308F9EC:
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f10,1004(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1004);
	ctx.f10.f64 = double(temp.f32);
	// b 0x8308fa14
	goto loc_8308FA14;
loc_8308F9F8:
	// fcmpu cr6,f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f1.f64, ctx.f29.f64);
	// bgt cr6,0x8308fa0c
	if (ctx.cr6.gt) goto loc_8308FA0C;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f10,11004(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11004);
	ctx.f10.f64 = double(temp.f32);
	// b 0x8308fa14
	goto loc_8308FA14;
loc_8308FA0C:
	// bl 0x82cb43f8
	ctx.lr = 0x8308FA10;
	sub_82CB43F8(ctx, base);
	// frsp f10,f1
	ctx.fpscr.disableFlushMode();
	ctx.f10.f64 = double(float(ctx.f1.f64));
loc_8308FA14:
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// fmuls f13,f0,f23
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// lfs f11,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// fmadds f9,f12,f22,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f22.f64 + ctx.f13.f64));
	// fmadds f16,f11,f24,f9
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f24.f64 + ctx.f9.f64));
	// bne cr6,0x8308fab4
	if (!ctx.cr6.eq) goto loc_8308FAB4;
	// lfs f0,680(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// bne cr6,0x8308fa54
	if (!ctx.cr6.eq) goto loc_8308FA54;
	// rlwinm r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308fa60
	if (ctx.cr6.eq) goto loc_8308FA60;
loc_8308FA54:
	// lfs f0,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f13,f16,f0
	ctx.f13.f64 = double(float(ctx.f16.f64 / ctx.f0.f64));
	// stfs f13,512(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
loc_8308FA60:
	// lfs f0,716(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 716);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f0,f21
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// lfs f12,708(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 708);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,512(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,720(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 720);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f12
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmadds f0,f13,f12,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// fmuls f13,f8,f21
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// ble cr6,0x8308faa0
	if (!ctx.cr6.gt) goto loc_8308FAA0;
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// bge cr6,0x8308fab4
	if (!ctx.cr6.lt) goto loc_8308FAB4;
	// b 0x8308fab0
	goto loc_8308FAB0;
loc_8308FAA0:
	// fadds f0,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// ble cr6,0x8308fab4
	if (!ctx.cr6.gt) goto loc_8308FAB4;
loc_8308FAB0:
	// stfs f18,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + 512, temp.u32);
loc_8308FAB4:
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// addi r10,r31,524
	ctx.r10.s64 = ctx.r31.s64 + 524;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x8308fb74
	if (ctx.cr6.eq) goto loc_8308FB74;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r11,152
	ctx.r9.s64 = ctx.r11.s64 + 152;
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,532(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,528(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f0
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f7,524(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 524);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f12,f9
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f5,f13,f7
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f4,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f13,f9
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f2,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f1,f4,f4,f15
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f28,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f8,f12,f7,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f8.f64));
	// fmsubs f6,f13,f11,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f6.f64));
	// fmsubs f5,f9,f0,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmadds f3,f7,f0,f3
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f3.f64));
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// fmuls f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmuls f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fmuls f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmadds f4,f12,f11,f3
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f3.f64));
	// fadds f3,f9,f8
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fadds f11,f7,f6
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fadds f9,f1,f5
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fmuls f7,f13,f4
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f6,f12,f4
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fadds f4,f3,f7
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fadds f5,f11,f8
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fadds f3,f9,f6
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fmuls f0,f4,f31
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f1,f5,f31
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f13,f3,f31
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fadds f0,f28,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// fadds f12,f2,f1
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fadds f13,f27,f13
	ctx.f13.f64 = double(float(ctx.f27.f64 + ctx.f13.f64));
	// b 0x8308fb80
	goto loc_8308FB80;
loc_8308FB74:
	// lfs f12,524(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,528(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,532(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	ctx.f13.f64 = double(temp.f32);
loc_8308FB80:
	// lfs f11,4(r19)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmr f20,f18
	ctx.f20.f64 = ctx.f18.f64;
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// lfs f9,8(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f8,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// lfs f7,148(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f7,f7
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// fmr f23,f18
	ctx.f23.f64 = ctx.f18.f64;
	// fmuls f5,f0,f0
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fmadds f4,f13,f13,f5
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fmadds f3,f12,f12,f4
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f4.f64));
	// fcmpu cr6,f3,f6
	ctx.cr6.compare(ctx.f3.f64, ctx.f6.f64);
	// ble cr6,0x8308fc8c
	if (!ctx.cr6.gt) goto loc_8308FC8C;
	// fmr f0,f8
	ctx.f0.f64 = ctx.f8.f64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// fmr f13,f11
	ctx.f13.f64 = ctx.f11.f64;
	// fmr f12,f9
	ctx.f12.f64 = ctx.f9.f64;
	// beq cr6,0x8308fc7c
	if (ctx.cr6.eq) goto loc_8308FC7C;
	// lfs f11,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// addi r9,r11,152
	ctx.r9.s64 = ctx.r11.s64 + 152;
	// lfs f9,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f0,f11
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// lfs f7,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f13,f9
	ctx.f6.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fsubs f5,f12,f7
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// lfs f3,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// lfs f1,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f0,f1,f1,f15
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fmuls f13,f3,f8
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f12,f2,f6
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f11,f5,f4
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmuls f9,f3,f6
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f7,f0,f8
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f28,f6,f0
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmsubs f13,f6,f4,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f4.f64 - ctx.f13.f64));
	// fmsubs f12,f3,f5,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f5.f64 - ctx.f12.f64));
	// fmsubs f11,f2,f8,f11
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 - ctx.f11.f64));
	// fmadds f9,f2,f5,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f9.f64));
	// fmuls f6,f13,f1
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f5,f12,f1
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmadds f13,f4,f8,f9
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f9.f64));
	// fsubs f12,f0,f6
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// fsubs f11,f7,f5
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fsubs f9,f28,f1
	ctx.f9.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fmuls f8,f13,f4
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f7,f3,f13
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f6,f2,f13
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fadds f5,f11,f8
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fadds f4,f9,f7
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fadds f3,f12,f6
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f2,0(r10)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fmuls f1,f4,f31
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f1,4(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f0,8(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// b 0x8308fce0
	goto loc_8308FCE0;
loc_8308FC7C:
	// stfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// stfs f12,8(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// b 0x8308fce0
	goto loc_8308FCE0;
loc_8308FC8C:
	// lfs f11,512(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f18
	ctx.cr6.compare(ctx.f11.f64, ctx.f18.f64);
	// lfs f11,4(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// beq cr6,0x8308fcb4
	if (ctx.cr6.eq) goto loc_8308FCB4;
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f8,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f6,f8,f13,f9
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f9.f64));
	// fmadds f20,f12,f7,f6
	ctx.f20.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 + ctx.f6.f64));
	// b 0x8308fce0
	goto loc_8308FCE0;
loc_8308FCB4:
	// lfs f9,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f0
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f7,f9,f0
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f6,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f6,f13,f8
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmadds f1,f5,f13,f7
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fmadds f20,f4,f12,f2
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fmadds f23,f3,f12,f1
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f1.f64));
loc_8308FCE0:
	// lfs f0,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,512(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 512);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fneg f8,f12
	ctx.f8.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fadds f11,f8,f16
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f16.f64));
	// fabs f0,f8
	ctx.f0.u64 = ctx.f8.u64 & ~0x8000000000000000;
	// fmr f9,f11
	ctx.f9.f64 = ctx.f11.f64;
	// fcmpu cr6,f0,f19
	ctx.cr6.compare(ctx.f0.f64, ctx.f19.f64);
	// ble cr6,0x8308fd08
	if (!ctx.cr6.gt) goto loc_8308FD08;
	// fdivs f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 / ctx.f0.f64));
loc_8308FD08:
	// lwz r10,712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// rlwinm r11,r10,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8308fd20
	if (ctx.cr6.eq) goto loc_8308FD20;
	// fmr f22,f30
	ctx.fpscr.disableFlushMode();
	ctx.f22.f64 = ctx.f30.f64;
	// b 0x8308fd24
	goto loc_8308FD24;
loc_8308FD20:
	// fmr f22,f10
	ctx.fpscr.disableFlushMode();
	ctx.f22.f64 = ctx.f10.f64;
loc_8308FD24:
	// fabs f0,f22
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f22.u64 & ~0x8000000000000000;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,688(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r31,684
	ctx.r11.s64 = ctx.r31.s64 + 684;
	// fsel f12,f22,f19,f29
	ctx.f12.f64 = ctx.f22.f64 >= 0.0 ? ctx.f19.f64 : ctx.f29.f64;
	// lfs f10,7980(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7980);
	ctx.f10.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308fd60
	if (!ctx.cr6.lt) goto loc_8308FD60;
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f0,f0
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fnmsubs f6,f7,f0,f7
	ctx.f6.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f5,f6,f0
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// fmuls f0,f5,f13
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// b 0x8308fda4
	goto loc_8308FDA4;
loc_8308FD60:
	// lfs f13,12(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308fda0
	if (!ctx.cr6.lt) goto loc_8308FDA0;
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f0,f7
	ctx.f6.f64 = double(float(ctx.f0.f64 - ctx.f7.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f13,f7
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// lfs f3,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f2,f3,f5
	ctx.f2.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fdivs f1,f6,f4
	ctx.f1.f64 = double(float(ctx.f6.f64 / ctx.f4.f64));
	// fmuls f0,f1,f1
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fmuls f13,f0,f1
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f7,f13,f31
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmsubs f6,f0,f10,f7
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f7.f64));
	// fmadds f0,f6,f2,f5
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f5.f64));
	// b 0x8308fda4
	goto loc_8308FDA4;
loc_8308FDA0:
	// lfs f0,16(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
loc_8308FDA4:
	// fmuls f0,f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// rlwinm r11,r10,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fneg f12,f0
	ctx.f12.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// beq cr6,0x8308fdc0
	if (ctx.cr6.eq) goto loc_8308FDC0;
	// fmr f24,f11
	ctx.f24.f64 = ctx.f11.f64;
	// b 0x8308fdc4
	goto loc_8308FDC4;
loc_8308FDC0:
	// fmr f24,f9
	ctx.fpscr.disableFlushMode();
	ctx.f24.f64 = ctx.f9.f64;
loc_8308FDC4:
	// fabs f0,f24
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f24.u64 & ~0x8000000000000000;
	// lfs f13,664(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 664);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r31,660
	ctx.r11.s64 = ctx.r31.s64 + 660;
	// fsel f11,f24,f19,f29
	ctx.f11.f64 = ctx.f24.f64 >= 0.0 ? ctx.f19.f64 : ctx.f29.f64;
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308fdf8
	if (!ctx.cr6.lt) goto loc_8308FDF8;
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f0,f0
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fnmsubs f9,f10,f0,f10
	ctx.f9.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fadds f7,f9,f0
	ctx.f7.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fmuls f0,f7,f13
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// b 0x8308fe3c
	goto loc_8308FE3C;
loc_8308FDF8:
	// lfs f13,12(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8308fe38
	if (!ctx.cr6.lt) goto loc_8308FE38;
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f7,f0,f9
	ctx.f7.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f13,f9
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f4,f6
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fdivs f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 / ctx.f5.f64));
	// fmuls f1,f2,f2
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// fmuls f0,f1,f2
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fmuls f13,f0,f31
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmsubs f10,f1,f10,f13
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f13.f64));
	// fmadds f0,f10,f3,f6
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f6.f64));
	// b 0x8308fe3c
	goto loc_8308FE3C;
loc_8308FE38:
	// lfs f0,16(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
loc_8308FE3C:
	// fmuls f0,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f11,668(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 668);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,692(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f0,508(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
	// fdivs f9,f0,f11
	ctx.f9.f64 = double(float(ctx.f0.f64 / ctx.f11.f64));
	// fmuls f7,f9,f9
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// fmadds f13,f10,f10,f7
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fcmpu cr6,f13,f19
	ctx.cr6.compare(ctx.f13.f64, ctx.f19.f64);
	// ble cr6,0x8308fe7c
	if (!ctx.cr6.gt) goto loc_8308FE7C;
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f10,f19,f13
	ctx.f10.f64 = double(float(ctx.f19.f64 / ctx.f13.f64));
	// fmuls f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f9,508(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
loc_8308FE7C:
	// lfs f0,484(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 484);
	ctx.f0.f64 = double(temp.f32);
	// fmr f27,f19
	ctx.f27.f64 = ctx.f19.f64;
	// fmuls f13,f0,f17
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f10,508(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f10.f64 = double(temp.f32);
	// fcmpu cr6,f21,f18
	ctx.cr6.compare(ctx.f21.f64, ctx.f18.f64);
	// fmuls f28,f13,f21
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f0,f28,f10
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// stfs f0,508(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 508, temp.u32);
	// fmuls f25,f28,f12
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// ble cr6,0x8308fec8
	if (!ctx.cr6.gt) goto loc_8308FEC8;
	// rlwinm r11,r10,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8308fec8
	if (!ctx.cr6.eq) goto loc_8308FEC8;
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f13,1596(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 1596);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f21,f13
	ctx.f13.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f12,f13,f13
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmuls f10,f12,f12
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// fdivs f27,f19,f10
	ctx.f27.f64 = double(float(ctx.f19.f64 / ctx.f10.f64));
loc_8308FEC8:
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f13,680(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// ld r22,128(r1)
	ctx.r22.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// li r21,1
	ctx.r21.s64 = 1;
	// ld r20,96(r1)
	ctx.r20.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcmpu cr6,f13,f18
	ctx.cr6.compare(ctx.f13.f64, ctx.f18.f64);
	// lwz r29,136(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r27,132(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r26,128(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lfs f26,-18268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18268);
	ctx.f26.f64 = double(temp.f32);
	// lwz r28,104(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r25,100(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r24,96(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bne cr6,0x8308ff24
	if (!ctx.cr6.eq) goto loc_8308FF24;
	// rlwinm r11,r10,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8308ff24
	if (!ctx.cr6.eq) goto loc_8308FF24;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x830902ac
	if (ctx.cr6.eq) goto loc_830902AC;
	// bl 0x8315c3a0
	ctx.lr = 0x8308FF1C;
	sub_8315C3A0(ctx, base);
	// stw r18,764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 764, ctx.r18.u32);
	// b 0x830902ac
	goto loc_830902AC;
loc_8308FF24:
	// fmuls f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fneg f29,f8
	ctx.f29.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f23,f18
	ctx.cr6.compare(ctx.f23.f64, ctx.f18.f64);
	// fabs f30,f0
	ctx.f30.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// beq cr6,0x8308ff40
	if (ctx.cr6.eq) goto loc_8308FF40;
	// fmuls f0,f28,f11
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f30,f0,f13
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
loc_8308FF40:
	// lis r11,-32202
	ctx.r11.s64 = -2110390272;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r6,r11,31560
	ctx.r6.s64 = ctx.r11.s64 + 31560;
	// li r4,12
	ctx.r4.s64 = 12;
	// addi r3,r1,368
	ctx.r3.s64 = ctx.r1.s64 + 368;
	// bl 0x82298ff8
	ctx.lr = 0x8308FF58;
	sub_82298FF8(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83090000
	if (ctx.cr6.eq) goto loc_83090000;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f8,f0,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f10,f9,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f9,f12,f11,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fsubs f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f4,f13,f9
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f0,f6,f3
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f13,368(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f12,372(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f11,376(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// b 0x83090018
	goto loc_83090018;
loc_83090000:
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,368(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// stfs f13,372(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// stfs f12,376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
loc_83090018:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830900c0
	if (ctx.cr6.eq) goto loc_830900C0;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f8,f0,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f10,f9,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f9,f12,f11,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fsubs f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f4,f13,f9
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f0,f6,f3
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f13,380(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f12,384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f11,388(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// b 0x830900d8
	goto loc_830900D8;
loc_830900C0:
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,380(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// stfs f13,384(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// stfs f12,388(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
loc_830900D8:
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x830901f4
	if (!ctx.cr6.eq) goto loc_830901F4;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x830900EC;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83090114
	if (ctx.cr6.eq) goto loc_83090114;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_83090114:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8309012c
	if (ctx.cr6.eq) goto loc_8309012C;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_8309012C:
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x83090138;
	sub_83043388(ctx, base);
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f0,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// lfs f13,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,252(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// stfs f13,256(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r27,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r27.u32);
	// stw r29,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r29.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r24,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r24.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r25.u32);
	// stw r28,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r28.u32);
	// beq cr6,0x83090190
	if (ctx.cr6.eq) goto loc_83090190;
	// lfs f0,508(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f0.f64 = double(temp.f32);
	// fabs f13,f0
	ctx.f13.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// stfs f14,236(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stfs f13,232(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fneg f12,f13
	ctx.f12.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// stfs f12,228(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// b 0x830901a0
	goto loc_830901A0;
loc_83090190:
	// fmuls f0,f30,f27
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f26,228(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f0,236(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
loc_830901A0:
	// lwz r10,380(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// stfs f29,224(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lwz r9,388(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lwz r11,368(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// stfs f23,220(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lwz r8,384(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lwz r7,372(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// lwz r6,376(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	// stw r10,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r10.u32);
	// stw r9,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r9.u32);
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// stw r8,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r8.u32);
	// stw r7,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r7.u32);
	// stw r6,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r6.u32);
	// lwz r5,268(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x830901EC;
	sub_8315C330(ctx, base);
	// stw r3,764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 764, ctx.r3.u32);
	// b 0x830902ac
	goto loc_830902AC;
loc_830901F4:
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x83090228
	if (ctx.cr6.eq) goto loc_83090228;
	// lfs f0,508(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 508);
	ctx.f0.f64 = double(temp.f32);
	// li r4,7
	ctx.r4.s64 = 7;
	// fabs f30,f0
	ctx.f30.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// fmr f1,f30
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x83090218;
	sub_8315C4D0(ctx, base);
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// li r4,6
	ctx.r4.s64 = 6;
	// fneg f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = ctx.f30.u64 ^ 0x8000000000000000;
	// b 0x83090230
	goto loc_83090230;
loc_83090228:
	// li r4,9
	ctx.r4.s64 = 9;
	// fmuls f1,f30,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
loc_83090230:
	// bl 0x8315c4d0
	ctx.lr = 0x83090234;
	sub_8315C4D0(ctx, base);
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f29.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x83090244;
	sub_8315C4D0(ctx, base);
	// lwz r11,376(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,368(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 368);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// bl 0x8315c738
	ctx.lr = 0x8309025C;
	sub_8315C738(ctx, base);
	// lwz r10,388(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,380(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 380);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// bl 0x8315c738
	ctx.lr = 0x83090274;
	sub_8315C738(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// rldicr r6,r29,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r29.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8315c738
	ctx.lr = 0x83090288;
	sub_8315C738(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// rldicr r6,r28,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r28.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8315c738
	ctx.lr = 0x8309029C;
	sub_8315C738(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r3,764(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 764);
	// fmr f1,f23
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f23.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x830902AC;
	sub_8315C4D0(ctx, base);
loc_830902AC:
	// lfs f0,704(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 704);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f18
	ctx.cr6.compare(ctx.f0.f64, ctx.f18.f64);
	// bne cr6,0x830902e0
	if (!ctx.cr6.eq) goto loc_830902E0;
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x830902e0
	if (!ctx.cr6.eq) goto loc_830902E0;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8309063c
	if (ctx.cr6.eq) goto loc_8309063C;
	// bl 0x8315c3a0
	ctx.lr = 0x830902D8;
	sub_8315C3A0(ctx, base);
	// stw r18,768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 768, ctx.r18.u32);
	// b 0x8309063c
	goto loc_8309063C;
loc_830902E0:
	// fmuls f13,f0,f25
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fcmpu cr6,f20,f18
	ctx.cr6.compare(ctx.f20.f64, ctx.f18.f64);
	// fabs f30,f13
	ctx.f30.u64 = ctx.f13.u64 & ~0x8000000000000000;
	// beq cr6,0x830902fc
	if (ctx.cr6.eq) goto loc_830902FC;
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f13,692(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f30,f0,f13
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
loc_830902FC:
	// lis r11,-32202
	ctx.r11.s64 = -2110390272;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r6,r11,31560
	ctx.r6.s64 = ctx.r11.s64 + 31560;
	// li r4,12
	ctx.r4.s64 = 12;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x82298ff8
	ctx.lr = 0x83090314;
	sub_82298FF8(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830903bc
	if (ctx.cr6.eq) goto loc_830903BC;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f8,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f12,f8,f9
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// fmsubs f1,f13,f11,f7
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmadds f7,f8,f0,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f10,f9,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmadds f9,f12,f11,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fsubs f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f4,f13,f9
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f0,f6,f3
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f13,336(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f12,340(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f11,344(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// b 0x830903d4
	goto loc_830903D4;
loc_830903BC:
	// lfs f0,0(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,336(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// stfs f13,340(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// stfs f12,344(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
loc_830903D4:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83090470
	if (ctx.cr6.eq) goto loc_83090470;
	// lfs f0,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f8,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f11,f12
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f5,f5,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f2,f8,f12,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64));
	// fmsubs f1,f11,f13,f7
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f7.f64));
	// fmadds f7,f10,f13,f4
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fmsubs f9,f10,f0,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fmuls f4,f10,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fmuls f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f10,f8,f0,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmuls f11,f9,f5
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fsubs f9,f4,f2
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f8,f6,f1
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fmuls f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f7,f3,f11
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fmuls f5,f13,f10
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fadds f3,f8,f6
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fadds f2,f9,f5
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f1,f7,f4
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fmuls f0,f3,f31
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f13,f2,f31
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f12,f1,f31
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// b 0x8309047c
	goto loc_8309047C;
loc_83090470:
	// lfs f0,0(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
loc_8309047C:
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// stfs f12,356(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// stfs f13,352(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// stfs f0,348(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x83090598
	if (!ctx.cr6.eq) goto loc_83090598;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8315c2e0
	ctx.lr = 0x8309049C;
	sub_8315C2E0(ctx, base);
	// lwz r11,740(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 740);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r18.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r18,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r18.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830904c4
	if (ctx.cr6.eq) goto loc_830904C4;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// lhz r5,468(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_830904C4:
	// lwz r11,744(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 744);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830904dc
	if (ctx.cr6.eq) goto loc_830904DC;
	// lwz r10,184(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
	// lhz r6,468(r11)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r11.u32 + 468);
loc_830904DC:
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r4,268(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// bl 0x83043388
	ctx.lr = 0x830904E8;
	sub_83043388(ctx, base);
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f0,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// lfs f13,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,252(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stw r21,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r21.u32);
	// stfs f13,256(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r27,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r27.u32);
	// stw r29,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r29.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r24,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r24.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r25.u32);
	// stw r28,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r28.u32);
	// beq cr6,0x8309053c
	if (ctx.cr6.eq) goto loc_8309053C;
	// fabs f0,f25
	ctx.f0.u64 = ctx.f25.u64 & ~0x8000000000000000;
	// stfs f14,236(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stfs f0,232(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fneg f13,f0
	ctx.f13.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// b 0x8309054c
	goto loc_8309054C;
loc_8309053C:
	// fmuls f0,f30,f27
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f26,228(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f0,236(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
loc_8309054C:
	// lwz r11,336(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// stfs f20,220(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lwz r10,340(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lwz r8,348(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// lwz r6,356(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// lwz r9,344(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// lwz r7,352(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// stw r10,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r10.u32);
	// stw r8,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r8.u32);
	// stw r6,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r6.u32);
	// stw r9,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r9.u32);
	// stw r7,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r7.u32);
	// lwz r5,268(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// lwz r3,1412(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 1412);
	// bl 0x8315c330
	ctx.lr = 0x83090590;
	sub_8315C330(ctx, base);
	// stw r3,768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 768, ctx.r3.u32);
	// b 0x8309063c
	goto loc_8309063C;
loc_83090598:
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x830905c8
	if (ctx.cr6.eq) goto loc_830905C8;
	// fabs f31,f25
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = ctx.f25.u64 & ~0x8000000000000000;
	// li r4,7
	ctx.r4.s64 = 7;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x830905B8;
	sub_8315C4D0(ctx, base);
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// li r4,6
	ctx.r4.s64 = 6;
	// fneg f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = ctx.f31.u64 ^ 0x8000000000000000;
	// b 0x830905d0
	goto loc_830905D0;
loc_830905C8:
	// li r4,9
	ctx.r4.s64 = 9;
	// fmuls f1,f30,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
loc_830905D0:
	// bl 0x8315c4d0
	ctx.lr = 0x830905D4;
	sub_8315C4D0(ctx, base);
	// lwz r11,344(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// li r4,2
	ctx.r4.s64 = 2;
	// ld r5,336(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 336);
	// rldicr r6,r11,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// bl 0x8315c738
	ctx.lr = 0x830905EC;
	sub_8315C738(ctx, base);
	// lwz r10,356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// li r4,3
	ctx.r4.s64 = 3;
	// ld r5,348(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 348);
	// rldicr r6,r10,32,63
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// bl 0x8315c738
	ctx.lr = 0x83090604;
	sub_8315C738(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// rldicr r6,r29,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r29.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8315c738
	ctx.lr = 0x83090618;
	sub_8315C738(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// rldicr r6,r28,32,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r28.u64, 32) & 0xFFFFFFFF00000000;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8315c738
	ctx.lr = 0x8309062C;
	sub_8315C738(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r3,768(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 768);
	// fmr f1,f20
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f20.f64;
	// bl 0x8315c4d0
	ctx.lr = 0x8309063C;
	sub_8315C4D0(ctx, base);
loc_8309063C:
	// stfs f24,496(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + 496, temp.u32);
	// stfs f22,500(r31)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + 500, temp.u32);
	// stfs f25,504(r31)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + 504, temp.u32);
	// stfs f16,736(r31)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + 736, temp.u32);
loc_8309064C:
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82cb6afc
	ctx.lr = 0x83090658;
	__restfpr_14(ctx, base);
	// b 0x82cb1110
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8309065C"))) PPC_WEAK_FUNC(sub_8309065C);
PPC_FUNC_IMPL(__imp__sub_8309065C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83090660"))) PPC_WEAK_FUNC(sub_83090660);
PPC_FUNC_IMPL(__imp__sub_83090660) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82cb10e8
	ctx.lr = 0x83090668;
	__savegprlr_28(ctx, base);
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82cb6ab0
	ctx.lr = 0x83090670;
	__savefpr_14(ctx, base);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lwz r11,312(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 312);
	// rlwinm r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x830911f0
	if (ctx.cr6.eq) goto loc_830911F0;
	// bl 0x83089320
	ctx.lr = 0x83090690;
	sub_83089320(ctx, base);
	// lis r11,-31890
	ctx.r11.s64 = -2089943040;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r9,r11,22552
	ctx.r9.s64 = ctx.r11.s64 + 22552;
	// lfs f30,6048(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6048);
	ctx.f30.f64 = double(temp.f32);
	// lfs f0,156(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 156);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// beq cr6,0x830911f0
	if (ctx.cr6.eq) goto loc_830911F0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x83088cd8
	ctx.lr = 0x830906B4;
	sub_83088CD8(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f29,6140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f29.f64 = double(temp.f32);
	// lfs f24,6380(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6380);
	ctx.f24.f64 = double(temp.f32);
	// lfs f31,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f31.f64 = double(temp.f32);
	// stfs f29,160(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f24,148(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// beq cr6,0x830908c4
	if (ctx.cr6.eq) goto loc_830908C4;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830908c4
	if (ctx.cr6.eq) goto loc_830908C4;
	// lfs f0,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f12,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f8,f0
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f4,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f6,f12
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f2,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f4,f12
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f28,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f28.f64 = double(temp.f32);
	// lfs f9,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f26,f28,f2
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f25,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f28,f0
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfs f27,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f7,f9,f9,f24
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f9.f64 - ctx.f24.f64));
	// fmuls f22,f25,f0
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f11,f4,f9,f11
	ctx.f11.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f11.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f27,f10
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f20,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f5,f6,f9,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f5.f64));
	// addi r11,r31,12
	ctx.r11.s64 = ctx.r31.s64 + 12;
	// fmsubs f3,f13,f9,f3
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f3.f64));
	// fmadds f1,f8,f9,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f1.f64));
	// fmsubs f26,f27,f0,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f26.f64));
	// fmadds f23,f25,f10,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f23.f64));
	// fmuls f17,f25,f7
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmsubs f22,f28,f10,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f22.f64));
	// fmadds f11,f6,f2,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f11.f64));
	// fmsubs f25,f25,f2,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f19.f64));
	// fmadds f5,f13,f12,f5
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fnmsubs f3,f4,f0,f3
	ctx.f3.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fmadds f1,f13,f2,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f1.f64));
	// fmuls f16,f27,f7
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f7,f28,f7
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fmuls f13,f26,f9
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmadds f28,f27,f2,f23
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmuls f27,f22,f9
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// fnmsubs f11,f8,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// fmuls f9,f25,f9
	ctx.f9.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fnmsubs f5,f4,f2,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f5.f64)));
	// fnmsubs f4,f8,f2,f3
	ctx.f4.f64 = double(float(-(ctx.f8.f64 * ctx.f2.f64 - ctx.f3.f64)));
	// fnmsubs f3,f6,f0,f1
	ctx.f3.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fadds f1,f17,f13
	ctx.f1.f64 = double(float(ctx.f17.f64 + ctx.f13.f64));
	// fmuls f13,f28,f10
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmuls f12,f28,f2
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// fmuls f10,f11,f11
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fadds f6,f16,f27
	ctx.f6.f64 = double(float(ctx.f16.f64 + ctx.f27.f64));
	// fmuls f8,f28,f0
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f2,f7,f9
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fmuls f0,f5,f11
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f9,f3,f3
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// fmuls f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmuls f28,f5,f3
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fadds f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fadds f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// fadds f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fmuls f8,f0,f31
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fsubs f0,f29,f10
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f10.f64));
	// fmuls f13,f6,f31
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f6,f2,f31
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fsubs f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f2,100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f2,f5,f5
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fadds f12,f1,f18
	ctx.f12.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// fsubs f1,f0,f9
	ctx.f1.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// stfs f1,96(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f0,f21,f13
	ctx.f0.f64 = double(float(ctx.f21.f64 + ctx.f13.f64));
	// fadds f13,f20,f6
	ctx.f13.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// fmuls f6,f11,f4
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f1,f11,f3
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// fmuls f11,f5,f4
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f5,f28,f31
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fnmsubs f2,f2,f31,f29
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f31.f64 - ctx.f29.f64)));
	// fadds f4,f7,f8
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f4,108(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fadds f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f8,104(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,120(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f7,f2,f9
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f3,f2,f10
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// stfs f3,128(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f5,f1,f11
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f11.f64));
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f4,f11,f1
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// stfs f4,124(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83090898:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83090898
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83090898;
	// stfs f12,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f13,40(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f0,44(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_830908C4:
	// lfs f10,48(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f9,52(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,56(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	ctx.f8.f64 = double(temp.f32);
	// stfs f10,136(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f9,140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f8,144(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// beq cr6,0x83090acc
	if (ctx.cr6.eq) goto loc_83090ACC;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83090acc
	if (ctx.cr6.eq) goto loc_83090ACC;
	// lfs f0,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f13,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f12,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmr f7,f12
	ctx.f7.f64 = ctx.f12.f64;
	// lfs f5,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f5,f0
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f1,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f28,f3,f12
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfs f27,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f1,f12
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f6,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// addi r9,r31,12
	ctx.r9.s64 = ctx.r31.s64 + 12;
	// lfs f25,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f4,f6,f6,f24
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f6.f64 - ctx.f24.f64));
	// lfs f22,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f25,f27
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// fmuls f21,f25,f0
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f24,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f22,f0
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f16,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f11,f1,f6,f11
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f11.f64));
	// lfs f19,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f24,f7
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f18,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f2,f3,f6,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f2.f64));
	// fmsubs f28,f13,f6,f28
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 - ctx.f28.f64));
	// fmadds f26,f5,f6,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fmuls f15,f22,f4
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// fmsubs f23,f24,f0,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f23.f64));
	// fmadds f21,f22,f7,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f21.f64));
	// fmsubs f20,f25,f7,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f20.f64));
	// fmadds f11,f3,f27,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 + ctx.f11.f64));
	// fmsubs f22,f22,f27,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f17.f64));
	// fmadds f2,f13,f12,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fnmsubs f28,f1,f0,f28
	ctx.f28.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// fmadds f13,f13,f27,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 + ctx.f26.f64));
	// fmuls f14,f24,f4
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// fmuls f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmuls f26,f23,f6
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fmadds f25,f24,f27,f21
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 + ctx.f21.f64));
	// fmuls f24,f20,f6
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fnmsubs f11,f5,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// fmuls f6,f22,f6
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fnmsubs f2,f1,f27,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f27.f64 - ctx.f2.f64)));
	// fnmsubs f1,f5,f27,f28
	ctx.f1.f64 = double(float(-(ctx.f5.f64 * ctx.f27.f64 - ctx.f28.f64)));
	// fnmsubs f5,f3,f0,f13
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f3,f15,f26
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// fmuls f13,f25,f7
	ctx.f13.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmuls f12,f25,f27
	ctx.f12.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// fmuls f7,f11,f11
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fadds f28,f14,f24
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// fmuls f0,f25,f0
	ctx.f0.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmuls f4,f2,f11
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f26,f5,f1
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f27,f5,f5
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f25,f2,f5
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fadds f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f13.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fadds f13,f28,f12
	ctx.f13.f64 = double(float(ctx.f28.f64 + ctx.f12.f64));
	// fadds f12,f6,f0
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// fmuls f6,f4,f31
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f28,f26,f31
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f4,f27,f31
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fsubs f0,f29,f7
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f7.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f27,f12,f31
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fsubs f12,f6,f28
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f28.f64));
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f12,f3,f16
	ctx.f12.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// fsubs f3,f0,f4
	ctx.f3.f64 = double(float(ctx.f0.f64 - ctx.f4.f64));
	// stfs f3,96(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f0,f19,f13
	ctx.f0.f64 = double(float(ctx.f19.f64 + ctx.f13.f64));
	// fmuls f3,f11,f1
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fadds f13,f18,f27
	ctx.f13.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// fmuls f27,f2,f2
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f2.f64));
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmuls f5,f2,f1
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// fadds f1,f28,f6
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f6.f64));
	// stfs f1,108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f2,f25,f31
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fnmsubs f3,f27,f31,f29
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f31.f64 - ctx.f29.f64)));
	// fmuls f1,f11,f31
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmuls f11,f5,f31
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fadds f5,f6,f2
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// stfs f4,112(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// stfs f2,120(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f4,f3,f7
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfs f4,128(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f6,f1,f11
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f11.f64));
	// stfs f6,116(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f5,f11,f1
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// stfs f5,124(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83090A9C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x83090a9c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83090A9C;
	// stfs f12,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// stfs f13,40(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// stfs f0,44(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// lfs f24,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_83090ACC:
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f13,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,28(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// li r29,-1
	ctx.r29.s64 = -1;
	// lfs f11,40(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lfs f0,644(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f7,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f7.f64 = double(temp.f32);
	// fneg f12,f12
	ctx.f12.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fneg f11,f11
	ctx.f11.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f1,f7,f0
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f0.f64));
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// fmr f2,f29
	ctx.f2.f64 = ctx.f29.f64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// beq cr6,0x83090b54
	if (ctx.cr6.eq) goto loc_83090B54;
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// fmuls f7,f12,f0
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f6,f13,f0
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f5,f8,f11
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfs f5,232(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f4,f9,f7
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfs f4,228(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fsubs f3,f10,f6
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// stfs f3,224(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// b 0x83090b58
	goto loc_83090B58;
loc_83090B54:
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
loc_83090B58:
	// bl 0x831c0120
	ctx.lr = 0x83090B5C;
	sub_831C0120(ctx, base);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lfs f0,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 520);
	ctx.f0.f64 = double(temp.f32);
	// stfs f29,176(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f30,180(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f30,184(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f13,-18264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f13.f64 = double(temp.f32);
	// stfs f30,188(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// stfs f29,192(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f30,196(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stfs f30,200(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f30,204(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f29,208(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// beq cr6,0x83090bf0
	if (ctx.cr6.eq) goto loc_83090BF0;
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f0,f12
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f8,f0,f11
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f7,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f4,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f7,f12
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfs f2,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f7,f11
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fadds f0,f10,f2
	ctx.f0.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// fadds f13,f9,f6
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fadds f12,f8,f4
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fsubs f11,f0,f5
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f5.f64));
	// stfs f11,212(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f10,f13,f3
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f3.f64));
	// stfs f10,220(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fsubs f9,f12,f1
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f1.f64));
	// stfs f9,216(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// b 0x83090c88
	goto loc_83090C88;
loc_83090BF0:
	// lwz r11,712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 712);
	// lfs f0,644(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x83090c4c
	if (ctx.cr6.eq) goto loc_83090C4C;
	// lfs f13,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f11,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f12,f11
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fadds f2,f5,f8
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfs f2,220(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f1,f4,f7
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f1,216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f0,f3,f6
	ctx.f0.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// b 0x83090c88
	goto loc_83090C88;
loc_83090C4C:
	// lfs f13,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f10,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f0,f12
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f8,f0,f10
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f7,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f11,f7
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// stfs f4,220(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f3,f9,f6
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// stfs f3,216(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f2,f8,f5
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfs f2,212(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
loc_83090C88:
	// lfs f28,724(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 724);
	ctx.f28.f64 = double(temp.f32);
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// bl 0x82cb4940
	ctx.lr = 0x83090C94;
	sub_82CB4940(ctx, base);
	// frsp f29,f1
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = double(float(ctx.f1.f64));
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// bl 0x82cb4860
	ctx.lr = 0x83090CA0;
	sub_82CB4860(ctx, base);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// frsp f26,f1
	ctx.fpscr.disableFlushMode();
	ctx.f26.f64 = double(float(ctx.f1.f64));
	// lfd f27,24728(r11)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24728);
	// fmr f1,f27
	ctx.f1.f64 = ctx.f27.f64;
	// bl 0x82cb4940
	ctx.lr = 0x83090CB4;
	sub_82CB4940(ctx, base);
	// frsp f28,f1
	ctx.fpscr.disableFlushMode();
	ctx.f28.f64 = double(float(ctx.f1.f64));
	// fmr f1,f27
	ctx.f1.f64 = ctx.f27.f64;
	// bl 0x82cb4860
	ctx.lr = 0x83090CC0;
	sub_82CB4860(ctx, base);
	// lfs f23,732(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 732);
	ctx.f23.f64 = double(temp.f32);
	// frsp f25,f1
	ctx.f25.f64 = double(float(ctx.f1.f64));
	// stfs f25,168(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmr f1,f23
	ctx.f1.f64 = ctx.f23.f64;
	// bl 0x82cb4940
	ctx.lr = 0x83090CD4;
	sub_82CB4940(ctx, base);
	// frsp f27,f1
	ctx.fpscr.disableFlushMode();
	ctx.f27.f64 = double(float(ctx.f1.f64));
	// fmr f1,f23
	ctx.f1.f64 = ctx.f23.f64;
	// bl 0x82cb4860
	ctx.lr = 0x83090CE0;
	sub_82CB4860(ctx, base);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,152(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83090eec
	if (ctx.cr6.eq) goto loc_83090EEC;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83090eec
	if (ctx.cr6.eq) goto loc_83090EEC;
	// lfs f13,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f12,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// fmuls f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f10,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f8,f10,f10,f24
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f10.f64 - ctx.f24.f64));
	// lfs f7,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmr f6,f9
	ctx.f6.f64 = ctx.f9.f64;
	// lfs f3,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f7,f13
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f5,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f3,f9
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f1,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f5,f9
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f24,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f24,f13
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f22,f24,f1
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lfs f20,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f23,f13
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f11,f3,f10,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfd f30,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.f30.u64);
	// fmuls f17,f23,f8
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f16,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f20,f6
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f18,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f4,f5,f10,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f14,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f25,f7,f10,f25
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 + ctx.f25.f64));
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmsubs f2,f12,f10,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f2.f64));
	// fmuls f30,f20,f8
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmadds f21,f23,f6,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f21.f64));
	// fmsubs f22,f20,f13,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f22.f64));
	// fmsubs f19,f24,f6,f19
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f19.f64));
	// fmadds f11,f5,f1,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f11.f64));
	// fmuls f8,f24,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// fmsubs f24,f23,f1,f15
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fmadds f4,f12,f9,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f4.f64));
	// fmadds f12,f12,f1,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 + ctx.f25.f64));
	// fnmsubs f2,f3,f13,f2
	ctx.f2.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmadds f23,f20,f1,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f21.f64));
	// fmuls f25,f22,f10
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f22,f19,f10
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fnmsubs f9,f7,f9,f11
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f9.f64 - ctx.f11.f64)));
	// fmuls f11,f24,f10
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fnmsubs f10,f3,f1,f4
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// fnmsubs f5,f5,f13,f12
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fnmsubs f7,f7,f1,f2
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// fmuls f3,f23,f6
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fadds f4,f17,f25
	ctx.f4.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// fmuls f2,f23,f1
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// fmuls f1,f9,f9
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// fadds f12,f30,f22
	ctx.f12.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fmuls f6,f23,f13
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f13,f10,f9
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fmuls f25,f5,f7
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f8,f5,f5
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f24,f10,f5
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f5.f64));
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// fmuls f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fadds f2,f12,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f2.f64));
	// fmuls f1,f13,f31
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f13,f11,f6
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// fmuls f6,f25,f31
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fsubs f12,f0,f3
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f3.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f25,f13,f31
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fsubs f13,f1,f6
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f11,f4,f16
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// fmuls f4,f9,f7
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfs f12,96(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f13,f18,f2
	ctx.f13.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// fmuls f2,f10,f10
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// fmuls f7,f10,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmuls f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fadds f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// stfs f1,108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f10,f4,f31
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fadds f12,f14,f25
	ctx.f12.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// fnmsubs f6,f2,f31,f0
	ctx.f6.f64 = double(float(-(ctx.f2.f64 * ctx.f31.f64 - ctx.f0.f64)));
	// fmuls f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f4,f9,f31
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fadds f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// stfs f1,104(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f10.f64));
	// stfs f10,120(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f0,f6,f8
	ctx.f0.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f7,f6,f3
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// stfs f7,128(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f9,f4,f2
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfs f9,116(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f8,f2,f4
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f8,124(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// lfd f30,160(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
loc_83090EB4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x83090eb4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83090EB4;
	// stfs f12,40(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 40, temp.u32);
	// stfs f11,36(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 36, temp.u32);
	// stfs f13,44(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 44, temp.u32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f25,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_83090EEC:
	// lfs f12,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fneg f13,f26
	ctx.f13.u64 = ctx.f26.u64 ^ 0x8000000000000000;
	// lfs f11,12(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f29
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// lfs f9,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f29
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f7,f9,f29
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f6,32(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,20(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f6,f29
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f3,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f5,f29
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f1,16(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	ctx.f1.f64 = double(temp.f32);
	// fadds f19,f12,f9
	ctx.f19.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fmuls f23,f3,f30
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f21,24(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f1,f30
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f20,28(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f30
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fmuls f17,f6,f13
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmadds f10,f9,f13,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f10.f64));
	// fmadds f9,f5,f13,f8
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmadds f8,f12,f26,f7
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f7.f64));
	// fadds f7,f11,f5
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fmadds f5,f11,f26,f2
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f26.f64 + ctx.f2.f64));
	// fmadds f4,f26,f21,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f21.f64 + ctx.f4.f64));
	// fadds f2,f6,f21
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// fneg f13,f25
	ctx.f13.u64 = ctx.f25.u64 ^ 0x8000000000000000;
	// fmadds f3,f19,f30,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f3.f64));
	// fmadds f12,f29,f21,f17
	ctx.f12.f64 = double(float(ctx.f29.f64 * ctx.f21.f64 + ctx.f17.f64));
	// fadds f11,f10,f23
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f23.f64));
	// fadds f10,f9,f22
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// fadds f9,f8,f23
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f23.f64));
	// fmadds f8,f7,f30,f1
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f1.f64));
	// fadds f7,f5,f22
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// fadds f6,f4,f18
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f18.f64));
	// fmadds f4,f2,f30,f20
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f30.f64 + ctx.f20.f64));
	// fmuls f5,f3,f30
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fadds f2,f12,f18
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f18.f64));
	// fmuls f1,f11,f28
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f12,f10,f28
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f26,f9,f28
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fadds f29,f9,f11
	ctx.f29.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fmuls f22,f10,f25
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fmuls f23,f8,f30
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f21,f4,f30
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmuls f20,f2,f28
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmadds f9,f9,f13,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmadds f1,f7,f13,f12
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f11,f11,f25,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64 + ctx.f26.f64));
	// fmadds f12,f29,f30,f3
	ctx.f12.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 + ctx.f3.f64));
	// fmuls f3,f2,f25
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmadds f10,f10,f30,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f8.f64));
	// fadds f8,f6,f2
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fmadds f7,f7,f28,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f22.f64));
	// fmadds f2,f6,f13,f20
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fneg f13,f0
	ctx.f13.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// fmuls f5,f12,f27
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// fmadds f3,f6,f28,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 + ctx.f3.f64));
	// fmadds f6,f8,f30,f4
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f30.f64 + ctx.f4.f64));
	// fadds f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fadds f4,f2,f21
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// fmuls f2,f9,f27
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f8,f1,f27
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmuls f28,f11,f30
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f29,f1,f13
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmadds f5,f9,f13,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fadds f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fadds f1,f10,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// fadds f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// fmuls f26,f7,f30
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f25,f4,f27
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// fmadds f12,f12,f0,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fmadds f8,f10,f0,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f8.f64));
	// fmadds f2,f10,f27,f29
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f29.f64));
	// fadds f10,f5,f28
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f28.f64));
	// fmadds f9,f9,f30,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f11.f64));
	// fmuls f5,f6,f27
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// stfs f9,104(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmadds f9,f6,f0,f25
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f25.f64));
	// stfs f10,100(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f0,f8,f26
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmadds f8,f1,f30,f7
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f30.f64 + ctx.f7.f64));
	// stfs f8,116(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f10,f6,f4
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// fmuls f11,f3,f30
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fadds f6,f12,f28
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f28.f64));
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f12,f2,f26
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfs f12,112(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// li r9,9
	ctx.r9.s64 = 9;
	// fmadds f7,f4,f13,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fmadds f6,f10,f30,f3
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f3.f64));
	// stfs f6,128(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f5,f9,f11
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f5,120(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f4,f7,f11
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfs f4,124(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_83091094:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x83091094
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091094;
	// lwz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8309116c
	if (ctx.cr6.eq) goto loc_8309116C;
	// lwz r11,264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x8309116c
	if (ctx.cr6.eq) goto loc_8309116C;
	// lfs f11,532(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	ctx.f11.f64 = double(temp.f32);
	// addi r10,r11,152
	ctx.r10.s64 = ctx.r11.s64 + 152;
	// lfs f0,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f0,f11
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f10,528(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f11,f12
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f8,524(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 524);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f5,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f2,f5,f5,f24
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 - ctx.f24.f64));
	// lfs f3,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f9,f8,f12,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64));
	// fmadds f4,f10,f13,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fmsubs f7,f11,f13,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f7.f64));
	// fmsubs f6,f0,f10,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f6.f64));
	// fmuls f29,f2,f8
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f11,f5,f9
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fmuls f9,f7,f5
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// fmuls f7,f5,f6
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmadds f6,f0,f8,f4
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f8.f64 + ctx.f4.f64));
	// fadds f5,f10,f11
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fadds f4,f29,f9
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f9.f64));
	// fadds f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fmuls f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fadds f11,f0,f4
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f4.f64));
	// fadds f10,f5,f13
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fadds f9,f2,f12
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fmuls f8,f11,f31
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmuls f7,f10,f31
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f6,f9,f31
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fadds f12,f3,f8
	ctx.f12.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fadds f0,f1,f7
	ctx.f0.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fadds f13,f30,f6
	ctx.f13.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// b 0x83091178
	goto loc_83091178;
loc_8309116C:
	// lfs f12,524(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,528(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 528);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,532(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	ctx.f13.f64 = double(temp.f32);
loc_83091178:
	// lfs f11,436(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 436);
	ctx.f11.f64 = double(temp.f32);
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bne cr6,0x830911a4
	if (!ctx.cr6.eq) goto loc_830911A4;
	// lfs f12,440(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 440);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	ctx.cr6.compare(ctx.f0.f64, ctx.f12.f64);
	// bne cr6,0x830911a4
	if (!ctx.cr6.eq) goto loc_830911A4;
	// lfs f0,444(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 444);
	ctx.f0.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x830911a8
	if (ctx.cr6.eq) goto loc_830911A8;
loc_830911A4:
	// li r11,1
	ctx.r11.s64 = 1;
loc_830911A8:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830911b8
	if (ctx.cr6.eq) goto loc_830911B8;
	// lis r30,-1
	ctx.r30.s64 = -65536;
loc_830911B8:
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f1,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f1.f64 = double(temp.f32);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// li r4,21
	ctx.r4.s64 = 21;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x831c03d8
	ctx.lr = 0x830911D4;
	sub_831C03D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lfs f1,640(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f1.f64 = double(temp.f32);
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x831c03d8
	ctx.lr = 0x830911F0;
	sub_831C03D8(ctx, base);
loc_830911F0:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82cb6afc
	ctx.lr = 0x830911FC;
	__restfpr_14(ctx, base);
	// b 0x82cb1138
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_83091200"))) PPC_WEAK_FUNC(sub_83091200);
PPC_FUNC_IMPL(__imp__sub_83091200) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ab0
	ctx.lr = 0x83091210;
	__savefpr_14(ctx, base);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,712(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,7676(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x83091898
	if (ctx.cr6.eq) goto loc_83091898;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83091434
	if (ctx.cr6.eq) goto loc_83091434;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83091434
	if (ctx.cr6.eq) goto loc_83091434;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// fmuls f16,f24,f26
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmadds f23,f27,f5,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f20,f24,f5,f18
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f26,f24,f4,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f2,f20,f3
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f26,f4
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,100(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,96(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,108(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f10,f19,f3
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,120(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,116(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,112(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,124(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,128(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83091408:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83091408
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091408;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83091434:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f5,f6,f12
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// beq cr6,0x83091654
	if (ctx.cr6.eq) goto loc_83091654;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83091654
	if (ctx.cr6.eq) goto loc_83091654;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f7,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f11,f12
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f5,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// fmr f4,f7
	ctx.f4.f64 = ctx.f7.f64;
	// fmr f3,f5
	ctx.f3.f64 = ctx.f5.f64;
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f31,f11,f7
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f1,f7
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f9
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f9.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f30,f2,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f6.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f4
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f14,f28,f25
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmsubs f22,f28,f3,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f1,f1,f5,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f6.f64));
	// fmsubs f6,f24,f10,f19
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f26,f26,f4,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f19,f24,f4,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f5,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fmadds f29,f23,f5,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fmadds f27,f30,f7,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmuls f7,f2,f6
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f6,f2,f26
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f2,f28,f10,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f31,f23,f12,f31
	ctx.f31.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f5,f11,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f11,f1,f1
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 + ctx.f7.f64));
	// fadds f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f27,f31,f5
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f28,f5,f5
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f7,f3
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmuls f7,f29,f0
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f3,f27,f0
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fmuls f6,f28,f0
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f31,f1
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fsubs f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f29,f7,f3
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f29,148(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f29,f12,f0
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfs f4,144(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f4,f30,f5
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f10
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f10.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fadds f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f7,f4,f0
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f28,f0
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f10,f18,f29
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f31,f4,f7
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f31,152(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f4,f7,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f4,168(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfs f6,160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f7,f1,f5
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f7,164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// stfs f6,172(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f5,f3,f2
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f5,176(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83091624:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83091624
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091624;
	// stfs f11,44(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f10,36(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
loc_83091654:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfs f6,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f11,f7
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f10,96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f5,100(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f3,104(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// beq cr6,0x83091870
	if (ctx.cr6.eq) goto loc_83091870;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83091870
	if (ctx.cr6.eq) goto loc_83091870;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f31,f12
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f11,f6
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f25,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f31,f6
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f10,f25
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f29,f1,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f3,f27
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f2,f24
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fmuls f16,f2,f25
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmsubs f30,f31,f1,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f9,f25
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f14,f9,f27
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmsubs f22,f2,f27,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f22.f64));
	// fmadds f5,f31,f4,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f31,f10,f24,f19
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f24.f64 - ctx.f19.f64));
	// fmsubs f25,f3,f25,f17
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 - ctx.f17.f64));
	// fmadds f19,f3,f24,f16
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f16.f64));
	// fmuls f9,f9,f24
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmadds f28,f23,f4,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmadds f26,f29,f6,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fnmsubs f30,f29,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmuls f24,f22,f1
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f23,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f1,f31
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f31,f10,f27,f19
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f19.f64));
	// fnmsubs f29,f29,f12,f28
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f28.f64)));
	// fnmsubs f4,f11,f4,f26
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f30,f23,f12,f30
	ctx.f30.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fadds f12,f9,f24
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f24.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// fmuls f1,f31,f10
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmuls f10,f29,f6
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f27,f30,f4
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmuls f28,f4,f4
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f31,f11,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f5,f27,f0
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f9,f28,f0
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f1,f30,f6
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f29,f4
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// fmuls f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f28,f29,f29
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f29,f30
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,156(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f18
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f2,f28,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f13,152(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,168(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,160(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f5,164(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83091844:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83091844
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091844;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83091870:
	// lfs f13,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f13,f8
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// lfs f10,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// stfs f11,108(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfs f9,112(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// b 0x83091ee8
	goto loc_83091EE8;
loc_83091898:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83091a8c
	if (ctx.cr6.eq) goto loc_83091A8C;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83091a8c
	if (ctx.cr6.eq) goto loc_83091A8C;
	// lfs f12,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f6
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f31,f12
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f29,f3,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f27
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f25,f4
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f2,f3,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f1,f31,f3,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f31,f6,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f20,f25,f10,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f31,f31,f8,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f30.f64));
	// fmadds f30,f29,f8,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fnmsubs f1,f29,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmsubs f28,f27,f4,f17
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmuls f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f26,f5,f25,f23
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f23.f64));
	// fnmsubs f8,f2,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f20
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f25,f3,f24
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f30
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f2,f2,f12,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// fnmsubs f1,f29,f12,f31
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fmuls f12,f26,f4
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fadds f4,f15,f25
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f31,f1,f8
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f29,f2,f6
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fmuls f10,f31,f0
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f5,f13,f28
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f31,f10,f4
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f31,f2,f8
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f5,144(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f5,f1,f6
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// fmuls f6,f1,f2
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f1,f1
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,152(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,160(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,176(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83091A60:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83091a60
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091A60;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83091A8C:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,96(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f11,100(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f10,104(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// beq cr6,0x83091c9c
	if (ctx.cr6.eq) goto loc_83091C9C;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83091c9c
	if (ctx.cr6.eq) goto loc_83091C9C;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,148(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,144(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,152(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,160(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,176(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83091C70:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83091c70
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091C70;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83091C9C:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f7,f12,f11
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// lfs f10,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,108(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f11,112(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f10,116(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f6,88(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// beq cr6,0x83091ec4
	if (ctx.cr6.eq) goto loc_83091EC4;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83091ec4
	if (ctx.cr6.eq) goto loc_83091EC4;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f29,f12
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f27,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f11,f6
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f25,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f24,f10
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f27,f1,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f25,f3
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f23,f2
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fmuls f16,f24,f2
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmsubs f30,f29,f1,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f26,f31,f1,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f24,f9
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f14,f25,f9
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmsubs f22,f25,f2,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f22.f64));
	// fmadds f5,f29,f4,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f19,f23,f10,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f24,f24,f3,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmadds f17,f23,f3,f16
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fmadds f29,f29,f6,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f28.f64));
	// fnmsubs f30,f27,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmadds f28,f27,f6,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fmuls f9,f23,f9
	ctx.f9.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// fmuls f26,f22,f1
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f31,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f19,f1
	ctx.f5.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmadds f25,f25,f10,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fnmsubs f29,f27,f12,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f4,f11,f4,f28
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// fadds f12,f9,f26
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f1,f10,f25
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fmuls f10,f6,f29
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f30,f4,f4
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f27,f11,f0
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f9,f30,f0
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f12,f13,f27
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f1,f31,f6
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f4,f29
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f30,f29,f29
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f31,f29
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f29.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,156(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f18
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f2,f30,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f13,152(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,168(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,160(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f5,164(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f3,f2,f27
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83091E98:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83091e98
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83091E98;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83091EC4:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f8
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// lfs f11,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f7
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// stfs f12,108(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f8,f11,f9
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f10,112(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
loc_83091EE8:
	// stfs f8,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f31,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f31.f64 = double(temp.f32);
	// bl 0x831bdd00
	ctx.lr = 0x83091EFC;
	sub_831BDD00(ctx, base);
	// fmuls f0,f31,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r11,1
	ctx.r11.s64 = 1;
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x83091f10
	if (ctx.cr6.lt) goto loc_83091F10;
	// li r11,0
	ctx.r11.s64 = 0;
loc_83091F10:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6afc
	ctx.lr = 0x83091F20;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83091F2C"))) PPC_WEAK_FUNC(sub_83091F2C);
PPC_FUNC_IMPL(__imp__sub_83091F2C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83091F30"))) PPC_WEAK_FUNC(sub_83091F30);
PPC_FUNC_IMPL(__imp__sub_83091F30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ab0
	ctx.lr = 0x83091F40;
	__savefpr_14(ctx, base);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,712(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,7676(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x830925c8
	if (ctx.cr6.eq) goto loc_830925C8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83092164
	if (ctx.cr6.eq) goto loc_83092164;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83092164
	if (ctx.cr6.eq) goto loc_83092164;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// fmuls f16,f24,f26
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmadds f23,f27,f5,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f20,f24,f5,f18
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f26,f24,f4,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f2,f20,f3
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f26,f4
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,100(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,96(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,108(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f10,f19,f3
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,120(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,116(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,112(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,124(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,128(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83092138:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83092138
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83092138;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83092164:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f5,f6,f12
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// beq cr6,0x83092384
	if (ctx.cr6.eq) goto loc_83092384;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83092384
	if (ctx.cr6.eq) goto loc_83092384;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f7,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f11,f12
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f5,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// fmr f4,f7
	ctx.f4.f64 = ctx.f7.f64;
	// fmr f3,f5
	ctx.f3.f64 = ctx.f5.f64;
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f31,f11,f7
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f1,f7
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f9
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f9.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f30,f2,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f6.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f4
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f14,f28,f25
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmsubs f22,f28,f3,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f1,f1,f5,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f6.f64));
	// fmsubs f6,f24,f10,f19
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f26,f26,f4,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f19,f24,f4,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f5,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fmadds f29,f23,f5,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fmadds f27,f30,f7,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmuls f7,f2,f6
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f6,f2,f26
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f2,f28,f10,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f31,f23,f12,f31
	ctx.f31.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f5,f11,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f11,f1,f1
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 + ctx.f7.f64));
	// fadds f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f27,f31,f5
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f28,f5,f5
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f7,f3
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmuls f7,f29,f0
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f3,f27,f0
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fmuls f6,f28,f0
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f31,f1
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fsubs f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f29,f7,f3
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f29,148(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f29,f12,f0
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfs f4,144(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f4,f30,f5
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f10
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f10.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fadds f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f7,f4,f0
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f28,f0
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f10,f18,f29
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f31,f4,f7
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f31,152(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f4,f7,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f4,168(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfs f6,160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f7,f1,f5
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f7,164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// stfs f6,172(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f5,f3,f2
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f5,176(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83092354:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83092354
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83092354;
	// stfs f11,44(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f10,36(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
loc_83092384:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfs f6,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f11,f7
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f10,96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f5,100(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f3,104(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// beq cr6,0x830925a0
	if (ctx.cr6.eq) goto loc_830925A0;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x830925a0
	if (ctx.cr6.eq) goto loc_830925A0;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f31,f12
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f11,f6
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f25,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f31,f6
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f10,f25
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f29,f1,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f3,f27
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f2,f24
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fmuls f16,f2,f25
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmsubs f30,f31,f1,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f9,f25
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f14,f9,f27
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmsubs f22,f2,f27,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f22.f64));
	// fmadds f5,f31,f4,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f31,f10,f24,f19
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f24.f64 - ctx.f19.f64));
	// fmsubs f25,f3,f25,f17
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 - ctx.f17.f64));
	// fmadds f19,f3,f24,f16
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f16.f64));
	// fmuls f9,f9,f24
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmadds f28,f23,f4,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmadds f26,f29,f6,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fnmsubs f30,f29,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmuls f24,f22,f1
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f23,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f1,f31
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f31,f10,f27,f19
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f19.f64));
	// fnmsubs f29,f29,f12,f28
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f28.f64)));
	// fnmsubs f4,f11,f4,f26
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f30,f23,f12,f30
	ctx.f30.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fadds f12,f9,f24
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f24.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// fmuls f1,f31,f10
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmuls f10,f29,f6
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f27,f30,f4
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmuls f28,f4,f4
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f31,f11,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f5,f27,f0
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f9,f28,f0
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f1,f30,f6
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f29,f4
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// fmuls f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f28,f29,f29
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f29,f30
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,156(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f18
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f2,f28,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f13,152(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,168(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,160(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f5,164(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83092574:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83092574
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83092574;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830925A0:
	// lfs f13,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f13,f8
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// lfs f10,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// stfs f11,108(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfs f9,112(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// b 0x83092c18
	goto loc_83092C18;
loc_830925C8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830927bc
	if (ctx.cr6.eq) goto loc_830927BC;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830927bc
	if (ctx.cr6.eq) goto loc_830927BC;
	// lfs f12,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f6
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f31,f12
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f29,f3,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f27
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f25,f4
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f2,f3,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f1,f31,f3,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f31,f6,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f20,f25,f10,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f31,f31,f8,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f30.f64));
	// fmadds f30,f29,f8,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fnmsubs f1,f29,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmsubs f28,f27,f4,f17
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmuls f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f26,f5,f25,f23
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f23.f64));
	// fnmsubs f8,f2,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f20
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f25,f3,f24
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f30
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f2,f2,f12,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// fnmsubs f1,f29,f12,f31
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fmuls f12,f26,f4
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fadds f4,f15,f25
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f31,f1,f8
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f29,f2,f6
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fmuls f10,f31,f0
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f5,f13,f28
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f31,f10,f4
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f31,f2,f8
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f5,144(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f5,f1,f6
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// fmuls f6,f1,f2
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f1,f1
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,152(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,160(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,176(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83092790:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83092790
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83092790;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830927BC:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,96(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f11,100(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f10,104(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// beq cr6,0x830929cc
	if (ctx.cr6.eq) goto loc_830929CC;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830929cc
	if (ctx.cr6.eq) goto loc_830929CC;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,148(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,144(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,152(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,160(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,176(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830929A0:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830929a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830929A0;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830929CC:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f7,f12,f11
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// lfs f10,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,108(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f11,112(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f10,116(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f6,88(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// beq cr6,0x83092bf4
	if (ctx.cr6.eq) goto loc_83092BF4;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83092bf4
	if (ctx.cr6.eq) goto loc_83092BF4;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f29,f12
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f27,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f11,f6
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f25,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f24,f10
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f27,f1,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f25,f3
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f23,f2
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// fmuls f16,f24,f2
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmsubs f30,f29,f1,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f26,f31,f1,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f24,f9
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f14,f25,f9
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmsubs f22,f25,f2,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f22.f64));
	// fmadds f5,f29,f4,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f19,f23,f10,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f24,f24,f3,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmadds f17,f23,f3,f16
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fmadds f29,f29,f6,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f28.f64));
	// fnmsubs f30,f27,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmadds f28,f27,f6,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fmuls f9,f23,f9
	ctx.f9.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// fmuls f26,f22,f1
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f31,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f19,f1
	ctx.f5.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmadds f25,f25,f10,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fnmsubs f29,f27,f12,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f4,f11,f4,f28
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// fadds f12,f9,f26
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f1,f10,f25
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fmuls f10,f6,f29
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f30,f4,f4
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f27,f11,f0
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f9,f30,f0
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f12,f13,f27
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f1,f31,f6
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f4,f29
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f30,f29,f29
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f31,f29
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f29.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,156(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f10,f3,f18
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f2,f30,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f13,152(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,168(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,160(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f5,164(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f3,f2,f27
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83092BC8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83092bc8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83092BC8;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83092BF4:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f8
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// lfs f11,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f7
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// stfs f12,108(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f8,f11,f9
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f10,112(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
loc_83092C18:
	// stfs f8,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// addi r6,r4,24
	ctx.r6.s64 = ctx.r4.s64 + 24;
	// addi r5,r4,12
	ctx.r5.s64 = ctx.r4.s64 + 12;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x83137248
	ctx.lr = 0x83092C34;
	sub_83137248(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,14704(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 14704);
	ctx.f0.f64 = double(temp.f32);
	// li r11,1
	ctx.r11.s64 = 1;
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x83092c4c
	if (ctx.cr6.lt) goto loc_83092C4C;
	// li r11,0
	ctx.r11.s64 = 0;
loc_83092C4C:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6afc
	ctx.lr = 0x83092C5C;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83092C68"))) PPC_WEAK_FUNC(sub_83092C68);
PPC_FUNC_IMPL(__imp__sub_83092C68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6ab4
	ctx.lr = 0x83092C7C;
	__savefpr_15(ctx, base);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lfs f13,6140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,7676(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f9,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f9.f64 = double(temp.f32);
	// beq cr6,0x83092e98
	if (ctx.cr6.eq) goto loc_83092E98;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83092e98
	if (ctx.cr6.eq) goto loc_83092E98;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f11,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// lfs f31,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f6
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f31,f12
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f10,f27
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f29,f3,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f27,f5
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f25,f4
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// addi r11,r31,12
	ctx.r11.s64 = ctx.r31.s64 + 12;
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f2,f3,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f1,f31,f3,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f10,f24
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// fmuls f15,f27,f26
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f16,f24,f26
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmadds f23,f25,f5,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f23.f64));
	// fmadds f7,f31,f6,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f20,f10,f25,f20
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 - ctx.f20.f64));
	// fmsubs f18,f24,f5,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fmadds f31,f31,f8,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f30.f64));
	// fmadds f30,f29,f8,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fnmsubs f1,f29,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmsubs f28,f27,f4,f17
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmuls f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmadds f26,f24,f4,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f8,f2,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f20,f3
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f25,f18,f3
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fnmsubs f6,f11,f6,f30
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f2,f2,f12,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// fnmsubs f1,f29,f12,f31
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fmuls f12,f4,f26
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fadds f4,f15,f25
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f31,f8,f1
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f29,f2,f6
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fmuls f10,f31,f0
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f5,f13,f28
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f31,f10,f4
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f31,132(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f31,f2,f8
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f5,128(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f5,f6,f1
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// fmuls f6,f2,f1
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f1,f1
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,140(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f10,f19,f3
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,136(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,152(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,148(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,144(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,156(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,160(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83092E6C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83092e6c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83092E6C;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_83092E98:
	// lfs f12,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// addi r8,r31,12
	ctx.r8.s64 = ctx.r31.s64 + 12;
	// lfs f11,28(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// fneg f10,f12
	ctx.f10.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// lfs f8,40(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f8.f64 = double(temp.f32);
	// fneg f7,f11
	ctx.f7.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// fneg f6,f8
	ctx.f6.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// stfs f10,88(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f7,92(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// beq cr6,0x830930b0
	if (ctx.cr6.eq) goto loc_830930B0;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830930b0
	if (ctx.cr6.eq) goto loc_830930B0;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f11,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f10,f29
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f4,f27
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f10,f24
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// fmuls f16,f24,f26
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// fmadds f23,f4,f24,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f10,f27,f20
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 - ctx.f20.f64));
	// fmsubs f24,f24,f5,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f27,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f29,f4,f29,f17
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f17.f64));
	// fmadds f27,f27,f5,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f2,f24,f3
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f4,f27
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f8,f31
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,132(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f5,f6,f31
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,128(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// fmuls f6,f1,f31
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,140(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f10,f19,f3
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,136(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,152(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,148(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,144(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,156(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,160(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_83093084:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x83093084
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83093084;
	// stfs f11,44(r8)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + 44, temp.u32);
	// stfs f12,40(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 40, temp.u32);
	// stfs f10,36(r8)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + 36, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_830930B0:
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// addi r5,r31,48
	ctx.r5.s64 = ctx.r31.s64 + 48;
	// lfs f12,48(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// blt cr6,0x8309310c
	if (ctx.cr6.lt) goto loc_8309310C;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bgt cr6,0x8309310c
	if (ctx.cr6.gt) goto loc_8309310C;
	// lfs f12,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// blt cr6,0x8309310c
	if (ctx.cr6.lt) goto loc_8309310C;
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bgt cr6,0x8309310c
	if (ctx.cr6.gt) goto loc_8309310C;
	// lfs f12,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// blt cr6,0x8309310c
	if (ctx.cr6.lt) goto loc_8309310C;
	// lfs f11,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// fcmpu cr6,f12,f11
	ctx.cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// ble cr6,0x83093110
	if (!ctx.cr6.gt) goto loc_83093110;
loc_8309310C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_83093110:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x83093124
	if (ctx.cr6.eq) goto loc_83093124;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x83093354
	goto loc_83093354;
loc_83093124:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83093314
	if (ctx.cr6.eq) goto loc_83093314;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83093314
	if (ctx.cr6.eq) goto loc_83093314;
	// lfs f12,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,112
	ctx.r10.s64 = ctx.r31.s64 + 112;
	// lfs f11,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f31,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f27,132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f9,f3,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f26,128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f25,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f27,f10
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f23,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f22,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f29,f5
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f20,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f26,f4
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmuls f17,f27,f9
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmuls f16,f29,f9
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fmsubs f24,f29,f4,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f26,f10,f21
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 - ctx.f21.f64));
	// fmsubs f27,f27,f5,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// fmadds f21,f26,f5,f18
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f18.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmuls f9,f26,f9
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmuls f26,f24,f3
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmadds f2,f29,f10,f21
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 + ctx.f21.f64));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fadds f12,f9,f26
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f9,f17,f7
	ctx.f9.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// fadds f7,f16,f3
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmuls f3,f10,f2
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f10,f8,f31
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f9,f4
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fadds f9,f7,f3
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmuls f7,f10,f0
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f30,f1,f8
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fsubs f10,f13,f2
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f5,f11,f0
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f9,f0
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fsubs f9,f7,f3
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f9,132(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f12,f10,f4
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f12,128(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f12,f23,f5
	ctx.f12.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fadds f11,f22,f11
	ctx.f11.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// fmuls f5,f6,f31
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// fmuls f6,f1,f31
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// li r9,9
	ctx.r9.s64 = 9;
	// fmuls f29,f31,f31
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fadds f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f3,140(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f10,f20,f9
	ctx.f10.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// fmuls f9,f30,f0
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f5,f8,f0
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f3,f6,f0
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f7,f29,f0,f13
	ctx.f7.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f0,f9,f1
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// stfs f9,152(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f8,f5,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f6,156(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f13,f7,f4
	ctx.f13.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f13,144(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f5,f7,f2
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// stfs f5,160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_830932E8:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x830932e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830932E8;
	// stfs f10,36(r8)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + 36, temp.u32);
	// stfs f12,40(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 40, temp.u32);
	// stfs f11,44(r8)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + 44, temp.u32);
	// lwz r11,264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_83093314:
	// addi r4,r3,12
	ctx.r4.s64 = ctx.r3.s64 + 12;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// addi r7,r1,104
	ctx.r7.s64 = ctx.r1.s64 + 104;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// bl 0x831be890
	ctx.lr = 0x83093328;
	sub_831BE890(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x83093354
	if (ctx.cr6.eq) goto loc_83093354;
	// lfs f0,644(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// li r11,1
	ctx.r11.s64 = 1;
	// lfs f13,640(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f12
	ctx.cr6.compare(ctx.f11.f64, ctx.f12.f64);
	// ble cr6,0x83093350
	if (!ctx.cr6.gt) goto loc_83093350;
	// li r11,0
	ctx.r11.s64 = 0;
loc_83093350:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
loc_83093354:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6b00
	ctx.lr = 0x83093360;
	__restfpr_15(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83093370"))) PPC_WEAK_FUNC(sub_83093370);
PPC_FUNC_IMPL(__imp__sub_83093370) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6ab0
	ctx.lr = 0x83093384;
	__savefpr_14(ctx, base);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,712(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,7676(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x83093a10
	if (ctx.cr6.eq) goto loc_83093A10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830935ac
	if (ctx.cr6.eq) goto loc_830935AC;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830935ac
	if (ctx.cr6.eq) goto loc_830935AC;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// fmuls f16,f24,f26
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmadds f23,f27,f5,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f20,f24,f5,f18
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f26,f24,f4,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f26,f4
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,112(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,124(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f10,f19,f3
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,120(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,136(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,128(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,140(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,144(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83093580:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83093580
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83093580;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830935AC:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f5,f6,f12
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f8,124(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f7,128(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f5,132(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// beq cr6,0x830937cc
	if (ctx.cr6.eq) goto loc_830937CC;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x830937cc
	if (ctx.cr6.eq) goto loc_830937CC;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f7,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f11,f12
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f5,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// fmr f4,f7
	ctx.f4.f64 = ctx.f7.f64;
	// fmr f3,f5
	ctx.f3.f64 = ctx.f5.f64;
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f31,f11,f7
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f1,f7
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f9
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f9.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f30,f2,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f6.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f4
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f14,f28,f25
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmsubs f22,f28,f3,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f1,f1,f5,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f6.f64));
	// fmsubs f6,f24,f10,f19
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f26,f26,f4,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f19,f24,f4,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f5,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fmadds f29,f23,f5,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fmadds f27,f30,f7,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmuls f7,f2,f6
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f6,f2,f26
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f2,f28,f10,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f31,f23,f12,f31
	ctx.f31.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f5,f11,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f11,f1,f1
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 + ctx.f7.f64));
	// fadds f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f27,f31,f5
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f28,f5,f5
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f7,f3
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmuls f7,f29,f0
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f3,f27,f0
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fmuls f6,f28,f0
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f31,f1
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fsubs f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f29,f7,f3
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f29,164(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f29,f12,f0
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfs f4,160(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f4,f30,f5
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f10
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f10.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fadds f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f3,172(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f7,f4,f0
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f28,f0
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f10,f29,f18
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f31,f4,f7
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f31,168(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f4,f7,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f4,184(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfs f6,176(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f7,f1,f5
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f7,180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// stfs f6,188(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f5,f3,f2
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f5,192(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_8309379C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x8309379c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8309379C;
	// stfs f11,44(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f10,36(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f7,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f7.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
loc_830937CC:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f8,f12
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// lfs f6,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f11,f7
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f10,112(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f3,120(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// beq cr6,0x830939e8
	if (ctx.cr6.eq) goto loc_830939E8;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x830939e8
	if (ctx.cr6.eq) goto loc_830939E8;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f29,f12
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f27,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f11,f6
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f25,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f10,f24
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f27,f1,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f3,f25
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f2,f23
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// fmuls f16,f2,f24
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmsubs f30,f29,f1,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f26,f31,f1,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f9,f24
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmuls f14,f9,f25
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmsubs f22,f2,f25,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 - ctx.f22.f64));
	// fmadds f5,f29,f4,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f19,f10,f23,f19
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f23.f64 - ctx.f19.f64));
	// fmsubs f24,f3,f24,f17
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 - ctx.f17.f64));
	// fmadds f17,f3,f23,f16
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f16.f64));
	// fmadds f29,f29,f6,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f28.f64));
	// fnmsubs f30,f27,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmadds f28,f27,f6,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// fmuls f26,f22,f1
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f31,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f1,f19
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmadds f25,f10,f25,f17
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f17.f64));
	// fnmsubs f29,f27,f12,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f4,f11,f4,f28
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// fadds f12,f9,f26
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmuls f1,f25,f10
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f10,f29,f6
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f30,f4,f4
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f27,f11,f0
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f9,f30,f0
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f12,f13,f27
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f1,f31,f6
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f29,f4
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// fmuls f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f30,f29,f29
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f29,f31
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,172(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f10,f18,f3
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f2,f30,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f13,168(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,184(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,176(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f5,180(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f4,188(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f3,f2,f27
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// stfs f3,192(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830939BC:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830939bc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830939BC;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830939E8:
	// lfs f13,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f13,f8
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// lfs f10,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// stfs f11,124(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfs f9,128(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// b 0x83094060
	goto loc_83094060;
loc_83093A10:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83093c04
	if (ctx.cr6.eq) goto loc_83093C04;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83093c04
	if (ctx.cr6.eq) goto loc_83093C04;
	// lfs f12,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,164(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,160(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,184(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,180(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,188(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,192(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83093BD8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83093bd8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83093BD8;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83093C04:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,112(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f11,116(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f10,120(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// beq cr6,0x83093e14
	if (ctx.cr6.eq) goto loc_83093E14;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83093e14
	if (ctx.cr6.eq) goto loc_83093E14;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f6
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f31,f12
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f29,f3,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f27
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f25,f4
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f2,f3,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f1,f31,f3,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f31,f6,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f20,f25,f10,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f31,f31,f8,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f30.f64));
	// fmadds f30,f29,f8,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fnmsubs f1,f29,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmsubs f28,f27,f4,f17
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmuls f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f26,f5,f25,f23
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f23.f64));
	// fnmsubs f8,f2,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f20
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f25,f3,f24
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f30
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f2,f2,f12,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// fnmsubs f1,f29,f12,f31
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fmuls f12,f26,f4
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fadds f4,f15,f25
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fmuls f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmuls f31,f1,f8
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f29,f2,f6
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fmuls f10,f31,f0
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f5,f13,f28
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f31,f10,f4
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f31,164(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f31,f2,f8
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f5,160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f5,f1,f6
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// fmuls f6,f1,f2
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f1,f1
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,184(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,180(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,188(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,192(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83093DE8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83093de8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83093DE8;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83093E14:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f7,f12,f11
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// lfs f10,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,124(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f11,128(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f10,132(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// beq cr6,0x8309403c
	if (ctx.cr6.eq) goto loc_8309403C;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8309403c
	if (ctx.cr6.eq) goto loc_8309403C;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f31,f12
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f11,f6
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f25,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f31,f6
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f25,f10
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f29,f1,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f27,f3
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f2
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// fmuls f16,f25,f2
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmsubs f30,f31,f1,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f25,f9
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmuls f14,f27,f9
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmsubs f22,f27,f2,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f22.f64));
	// fmadds f5,f31,f4,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f31,f24,f10,f19
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f25,f25,f3,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmadds f19,f24,f3,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fmuls f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmadds f28,f23,f4,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmadds f26,f29,f6,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fnmsubs f30,f29,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmuls f24,f22,f1
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f23,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fmuls f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// fmadds f31,f27,f10,f19
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f29,f29,f12,f28
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f28.f64)));
	// fnmsubs f4,f11,f4,f26
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f30,f23,f12,f30
	ctx.f30.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fadds f12,f9,f24
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f24.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f10,f6,f29
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f27,f30,f4
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmuls f28,f4,f4
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f31,f11,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f5,f27,f0
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f9,f28,f0
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f1,f30,f6
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f4,f29
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f28,f29,f29
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f30,f29
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f29.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,172(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f10,f18,f3
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f2,f28,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f13,168(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f6,184(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,176(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f5,180(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f4,188(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f3,192(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83094010:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83094010
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83094010;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_8309403C:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f8
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// lfs f11,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f7
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// stfs f12,124(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f8,f11,f9
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f10,128(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
loc_83094060:
	// stfs f8,132(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x831373b8
	ctx.lr = 0x83094078;
	sub_831373B8(ctx, base);
	// lfs f0,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// li r11,1
	ctx.r11.s64 = 1;
	// fcmpu cr6,f1,f13
	ctx.cr6.compare(ctx.f1.f64, ctx.f13.f64);
	// blt cr6,0x83094090
	if (ctx.cr6.lt) goto loc_83094090;
	// li r11,0
	ctx.r11.s64 = 0;
loc_83094090:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// addi r12,r1,-16
	ctx.r12.s64 = ctx.r1.s64 + -16;
	// bl 0x82cb6afc
	ctx.lr = 0x830940A0;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830940B0"))) PPC_WEAK_FUNC(sub_830940B0);
PPC_FUNC_IMPL(__imp__sub_830940B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ab0
	ctx.lr = 0x830940C0;
	__savefpr_14(ctx, base);
	// lis r11,-32222
	ctx.r11.s64 = -2111700992;
	// lis r10,-32222
	ctx.r10.s64 = -2111700992;
	// addi r6,r4,12
	ctx.r6.s64 = ctx.r4.s64 + 12;
	// lfs f0,-18264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18264);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,-18268(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18268);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f0,4(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// stfs f0,8(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// stfs f13,12(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// stfs f13,16(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// stfs f13,20(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// lwz r9,712(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// rlwinm r8,r9,0,26,26
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x83094768
	if (ctx.cr6.eq) goto loc_83094768;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f9,6380(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6380);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,6140(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// stfs f9,-272(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// beq cr6,0x83094310
	if (ctx.cr6.eq) goto loc_83094310;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83094310
	if (ctx.cr6.eq) goto loc_83094310;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f6
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f31,f12
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f27,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f25,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f29,f3,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f25,f5
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f24,f4
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmuls f17,f27,f4
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f2,f3,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f1,f31,f3,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f16,f27,f26
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f15,f25,f26
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmsubs f23,f25,f4,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 - ctx.f23.f64));
	// fmadds f7,f31,f6,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f20,f24,f10,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f27,f27,f5,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fmadds f25,f25,f10,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fmadds f31,f31,f8,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f30.f64));
	// fmadds f30,f29,f8,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmuls f28,f24,f26
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fnmsubs f1,f29,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f23,f3
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fnmsubs f8,f2,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f20,f3
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmadds f27,f24,f5,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fnmsubs f31,f29,f12,f31
	ctx.f31.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f6,f11,f6,f30
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f2,f2,f12,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fadds f1,f28,f26
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fmuls f12,f8,f8
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f11,f16,f7
	ctx.f11.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fadds f7,f15,f3
	ctx.f7.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fmuls f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f3,f27,f10
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fmuls f10,f8,f31
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f29,f2,f6
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f28,f12,f0
	ctx.f28.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fadds f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f4.f64));
	// fadds f3,f7,f3
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f30,f29,f0
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f1,f13,f28
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f12,f4,f0
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f11,f3,f0
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f5,f6,f31
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fsubs f4,f10,f30
	ctx.f4.f64 = double(float(ctx.f10.f64 - ctx.f30.f64));
	// stfs f4,-236(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fmuls f4,f2,f8
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fsubs f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f1,-240(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,-240
	ctx.r10.s64 = ctx.r1.s64 + -240;
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f6,f2,f31
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f2,f30,f10
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f10.f64));
	// stfs f2,-228(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// fadds f10,f19,f3
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f2,f8,f0
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f3,f1,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f8,-232(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f6,-216(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -216, temp.u32);
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfs f7,-224(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fsubs f5,f2,f1
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f5,-220(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f4,-212(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -212, temp.u32);
	// fsubs f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// stfs f3,-208(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -208, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830942E4:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830942e4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830942E4;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83094310:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// stfs f8,-220(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// beq cr6,0x83094528
	if (ctx.cr6.eq) goto loc_83094528;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83094528
	if (ctx.cr6.eq) goto loc_83094528;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f8
	ctx.f3.f64 = ctx.f8.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f29,f12
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f27,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f11,f8
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f25,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f10,f24
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f27,f1,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f3,f25
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f2,f23
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f16,f2,f24
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmsubs f30,f29,f1,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f26,f31,f1,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmuls f15,f9,f24
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmuls f14,f9,f25
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmsubs f22,f2,f25,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 - ctx.f22.f64));
	// fmadds f5,f29,f4,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f19,f10,f23,f19
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f23.f64 - ctx.f19.f64));
	// fmsubs f24,f3,f24,f17
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 - ctx.f17.f64));
	// fmadds f17,f3,f23,f16
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f16.f64));
	// fmadds f29,f29,f8,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fnmsubs f30,f27,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmadds f28,f27,f8,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f8.f64 + ctx.f26.f64));
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// fmuls f26,f22,f1
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f8,f31,f8,f5
	ctx.f8.f64 = double(float(-(ctx.f31.f64 * ctx.f8.f64 - ctx.f5.f64)));
	// fmuls f5,f1,f19
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmadds f25,f10,f25,f17
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f17.f64));
	// fnmsubs f29,f27,f12,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f4,f11,f4,f28
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// fadds f12,f9,f26
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f9,f15,f5
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f5,f14,f1
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmuls f1,f25,f10
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f10,f29,f8
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f30,f4,f4
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// fmuls f27,f11,f0
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f9,f30,f0
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f12,f13,f27
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fsubs f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfs f1,-188(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfs f1,-192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f1,f31,f8
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f29,f4
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// fmuls f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f30,f29,f29
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f29,f31
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f10,-180(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f10,f18,f3
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f8,f0
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f2,f30,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f4,f3,f5
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfs f4,-184(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f5,-168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// stfs f9,-176(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f4,f1,f8
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f8.f64));
	// stfs f4,-172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f3,f8,f1
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f1.f64));
	// stfs f3,-164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// stfs f2,-160(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830944F8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830944f8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830944F8;
	// stfs f11,44(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f10,36(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f9,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
loc_83094528:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// fadds f4,f7,f12
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// fadds f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// lfs f8,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f8.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// stfs f4,-240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// stfs f11,-236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// stfs f10,-232(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// beq cr6,0x83094750
	if (ctx.cr6.eq) goto loc_83094750;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83094750
	if (ctx.cr6.eq) goto loc_83094750;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f8
	ctx.f3.f64 = ctx.f8.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f31,f12
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f8
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// lfs f25,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f11,f8
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f9,f1,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f9.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f10,f25
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f29,f1,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f3,f27
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f2,f25
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f17,f2,f24
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmsubs f30,f31,f1,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmuls f15,f9,f25
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f14,f9,f27
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmsubs f22,f2,f27,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f22.f64));
	// fmadds f5,f31,f4,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f31,f10,f24,f19
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f24.f64 - ctx.f19.f64));
	// fmadds f19,f3,f24,f16
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f16.f64));
	// fmsubs f25,f3,f25,f17
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 - ctx.f17.f64));
	// fmadds f28,f23,f4,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmadds f26,f29,f8,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f26.f64));
	// fmuls f9,f9,f24
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fnmsubs f30,f29,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmuls f24,f22,f1
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f8,f23,f8,f5
	ctx.f8.f64 = double(float(-(ctx.f23.f64 * ctx.f8.f64 - ctx.f5.f64)));
	// fmuls f5,f1,f31
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmadds f31,f10,f27,f19
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f19.f64));
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fnmsubs f29,f29,f12,f28
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f28.f64)));
	// fnmsubs f11,f11,f4,f26
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f4,f23,f12,f30
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fadds f12,f9,f24
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f24.f64));
	// fmuls f9,f8,f8
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f5,f15,f5
	ctx.f5.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fmuls f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmuls f30,f29,f8
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f27,f4,f11
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f28,f11,f11
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f31,f9,f0
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fadds f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// fadds f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fmuls f10,f30,f0
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f10,f30
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f30.f64));
	// stfs f1,-188(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fsubs f1,f12,f5
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// stfs f1,-192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f1,f4,f8
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fadds f12,f21,f9
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f9.f64));
	// fadds f9,f20,f2
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f29,f11
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// fmuls f28,f29,f29
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// fadds f8,f3,f18
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// fmuls f3,f2,f0
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fadds f10,f30,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f10.f64));
	// stfs f10,-180(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fnmsubs f1,f28,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f4,f0
	ctx.f11.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f10,f2,f3
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f10,-184(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f4,-168(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f5,-176(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// stfs f1,-160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// fsubs f3,f13,f11
	ctx.f3.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f3,-172(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f2,f11,f13
	ctx.f2.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f2,-164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83094718:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83094718
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83094718;
	// stfs f12,40(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f9,44(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// stfs f8,36(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f11,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f4.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83094750:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f7.f64));
	// lfs f9,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// b 0x83094dc8
	goto loc_83094DC8;
loc_83094768:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f13,6140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,7676(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lfs f7,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f7.f64 = double(temp.f32);
	// beq cr6,0x83094974
	if (ctx.cr6.eq) goto loc_83094974;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83094974
	if (ctx.cr6.eq) goto loc_83094974;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f9,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f9
	ctx.f5.f64 = ctx.f9.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f9
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f9
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f7.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f8,f31,f3,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f8.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f8,f2,f6,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f8.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f9,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f9.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f9,f25,f9,f8
	ctx.f9.f64 = double(float(-(ctx.f25.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// fmuls f8,f3,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f11,f9,f9
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// fmuls f2,f31,f9
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f8,f30,f0
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,-188(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// stfs f2,-192(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f2,f1,f9
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// addi r10,r1,-192
	ctx.r10.s64 = ctx.r1.s64 + -192;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,-180(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,-184(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f2,f9,f6
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// stfs f2,-172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fsubs f4,f1,f8
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f8.f64));
	// stfs f4,-176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// stfs f9,-164(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f8,f1,f28
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f8,-160(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83094948:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83094948
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83094948;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83094974:
	// lfs f4,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// stfs f4,-240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// stfs f11,-236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// stfs f10,-232(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// beq cr6,0x83094b8c
	if (ctx.cr6.eq) goto loc_83094B8C;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83094b8c
	if (ctx.cr6.eq) goto loc_83094B8C;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f9,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f9
	ctx.f5.f64 = ctx.f9.f64;
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f11,f9
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f7
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f7.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f1,f9
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f8,f30,f2,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f8.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f5,f28
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f25,f26
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmuls f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// fmsubs f22,f28,f3,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f1,f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f8.f64));
	// fmsubs f8,f24,f10,f19
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f26,f5,f26,f17
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 - ctx.f17.f64));
	// fmadds f19,f5,f24,f16
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f6,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f6.f64 - ctx.f31.f64)));
	// fmadds f27,f30,f9,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmadds f29,f23,f6,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f29.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f9,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f9.f64 - ctx.f1.f64)));
	// fmuls f9,f2,f8
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmuls f8,f2,f26
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f2,f28,f10,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f11,f11,f6,f27
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f6,f23,f12,f31
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f31,f1,f1
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f9,f15,f9
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f9.f64));
	// fadds f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f28,f11,f11
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f27,f6,f11
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fadds f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fadds f5,f12,f5
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fmuls f10,f28,f0
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f31,f27,f0
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f28,f6,f1
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fsubs f12,f13,f2
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fsubs f29,f3,f31
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfs f29,-188(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f29,f30,f11
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfs f12,-192(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fadds f12,f21,f9
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f9.f64));
	// fadds f9,f20,f8
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// addi r10,r1,-192
	ctx.r10.s64 = ctx.r1.s64 + -192;
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-180(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f8,f5,f18
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f18.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fadds f31,f5,f1
	ctx.f31.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// stfs f31,-184(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f5,-168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfs f10,-176(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f10,f3,f2
	ctx.f10.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f10,-160(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// fsubs f1,f11,f6
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// stfs f1,-172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// stfs f11,-164(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83094B58:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83094b58
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83094B58;
	// stfs f8,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f9,44(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lfs f10,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f11.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83094B8C:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f9,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f9.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f8,f12,f9
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// lfs f6,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// stfs f2,-256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f6,f8,f5
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f5,f8,f3
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// beq cr6,0x83094db4
	if (ctx.cr6.eq) goto loc_83094DB4;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83094db4
	if (ctx.cr6.eq) goto loc_83094DB4;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f9,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f9
	ctx.f3.f64 = ctx.f9.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f31,f12
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f9
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// lfs f25,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f11,f9
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f7,f1,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f7.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f25,f10
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f8,f29,f1,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f8.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f27,f3
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f25,f2
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f17,f24,f2
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmsubs f30,f31,f1,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmadds f28,f11,f1,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmuls f15,f25,f7
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmuls f14,f27,f7
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmsubs f22,f27,f2,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f22.f64));
	// fmadds f8,f31,f4,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f8.f64));
	// fmsubs f31,f24,f10,f19
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmadds f19,f24,f3,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fmsubs f25,f25,f3,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmadds f26,f29,f9,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f26.f64));
	// fnmsubs f30,f29,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmadds f28,f23,f4,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmuls f7,f24,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmuls f24,f22,f1
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f8,f23,f9,f8
	ctx.f8.f64 = double(float(-(ctx.f23.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// fmuls f9,f31,f1
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fmadds f31,f27,f10,f19
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fmuls f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// fnmsubs f11,f11,f4,f26
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f4,f23,f12,f30
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f29,f29,f12,f28
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f28.f64)));
	// fadds f12,f7,f24
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f24.f64));
	// fmuls f7,f8,f8
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f9,f15,f9
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f9.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f30,f8,f29
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fmuls f27,f4,f11
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f28,f11,f11
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fadds f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fadds f9,f12,f3
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f10,f30,f0
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f31,f28,f0
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f3,f13,f7
	ctx.f3.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f28,f9,f0
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fsubs f12,f10,f30
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f30.f64));
	// stfs f12,-188(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fsubs f9,f3,f31
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfs f9,-192(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f3,f11,f29
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fadds f12,f21,f2
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// fmuls f2,f4,f8
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fadds f9,f20,f1
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f1.f64));
	// fmuls f1,f29,f29
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f10,f30,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f10.f64));
	// stfs f10,-180(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f8,f18,f28
	ctx.f8.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fnmsubs f1,f1,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f4,f0
	ctx.f11.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f10,f2,f3
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f10,-184(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f4,f1,f31
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// stfs f4,-176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f2,-172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f0,f11,f13
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f0,-164(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f13,f1,f7
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f13,-160(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83094D7C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83094d7c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83094D7C;
	// stfs f8,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f9,44(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lfs f10,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f4.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83094DB4:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// lfs f9,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
loc_83094DC8:
	// lfs f12,8(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// lfs f9,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// lfs f6,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f7,f4
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fsubs f3,f6,f10
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fsel f2,f8,f9,f11
	ctx.f2.f64 = ctx.f8.f64 >= 0.0 ? ctx.f9.f64 : ctx.f11.f64;
	// stfs f2,4(r6)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r6.u32 + 4, temp.u32);
	// fsel f1,f5,f7,f4
	ctx.f1.f64 = ctx.f5.f64 >= 0.0 ? ctx.f7.f64 : ctx.f4.f64;
	// stfs f1,0(r6)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsel f9,f3,f6,f10
	ctx.f9.f64 = ctx.f3.f64 >= 0.0 ? ctx.f6.f64 : ctx.f10.f64;
	// stfs f9,8(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 8, temp.u32);
	// lfs f5,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f2,f5,f11
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// lfs f8,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fsel f9,f2,f11,f5
	ctx.f9.f64 = ctx.f2.f64 >= 0.0 ? ctx.f11.f64 : ctx.f5.f64;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f7,f4
	ctx.f6.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fsubs f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// stfs f9,4(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// fsel f1,f6,f4,f7
	ctx.f1.f64 = ctx.f6.f64 >= 0.0 ? ctx.f4.f64 : ctx.f7.f64;
	// stfs f1,0(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsel f10,f3,f10,f8
	ctx.f10.f64 = ctx.f3.f64 >= 0.0 ? ctx.f10.f64 : ctx.f8.f64;
	// stfs f10,8(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f3,f8,f12
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// fsubs f5,f6,f13
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f13.f64));
	// fsubs f4,f7,f0
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f0.f64));
	// fsel f11,f3,f8,f12
	ctx.f11.f64 = ctx.f3.f64 >= 0.0 ? ctx.f8.f64 : ctx.f12.f64;
	// stfs f11,8(r6)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r6.u32 + 8, temp.u32);
	// fsel f2,f5,f6,f13
	ctx.f2.f64 = ctx.f5.f64 >= 0.0 ? ctx.f6.f64 : ctx.f13.f64;
	// stfs f2,4(r6)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r6.u32 + 4, temp.u32);
	// fsel f1,f4,f7,f0
	ctx.f1.f64 = ctx.f4.f64 >= 0.0 ? ctx.f7.f64 : ctx.f0.f64;
	// stfs f1,0(r6)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfs f10,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f5,f10,f12
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fsubs f7,f8,f13
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fsubs f6,f9,f0
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// fsel f2,f5,f12,f10
	ctx.f2.f64 = ctx.f5.f64 >= 0.0 ? ctx.f12.f64 : ctx.f10.f64;
	// stfs f2,8(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// fsel f4,f7,f13,f8
	ctx.f4.f64 = ctx.f7.f64 >= 0.0 ? ctx.f13.f64 : ctx.f8.f64;
	// stfs f4,4(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// fsel f3,f6,f0,f9
	ctx.f3.f64 = ctx.f6.f64 >= 0.0 ? ctx.f0.f64 : ctx.f9.f64;
	// stfs f3,0(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6afc
	ctx.lr = 0x83094E98;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83094EA4"))) PPC_WEAK_FUNC(sub_83094EA4);
PPC_FUNC_IMPL(__imp__sub_83094EA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83094EA8"))) PPC_WEAK_FUNC(sub_83094EA8);
PPC_FUNC_IMPL(__imp__sub_83094EA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ab0
	ctx.lr = 0x83094EB8;
	__savefpr_14(ctx, base);
	// lwz r11,712(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r10,r11,6380
	ctx.r10.s64 = ctx.r11.s64 + 6380;
	// lfs f13,6140(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,7676(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lfs f9,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// beq cr6,0x83095520
	if (ctx.cr6.eq) goto loc_83095520;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830950dc
	if (ctx.cr6.eq) goto loc_830950DC;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830950dc
	if (ctx.cr6.eq) goto loc_830950DC;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f27,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f27,f4
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmuls f18,f25,f4
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f24,f3,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmuls f16,f27,f26
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// fmsubs f23,f29,f4,f23
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f25,f10,f20
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmadds f20,f25,f5,f17
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f17.f64));
	// fmsubs f27,f27,f5,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmadds f30,f24,f6,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f25,f23,f3
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fnmsubs f8,f24,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f24.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmadds f2,f29,f10,f20
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 + ctx.f20.f64));
	// fmuls f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fnmsubs f1,f24,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fadds f12,f26,f25
	ctx.f12.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fmuls f30,f31,f8
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f28,f1,f6
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f29,f6,f6
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f7,f4
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f3,f28,f0
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fsubs f5,f13,f2
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f30,f7,f3
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f30,-236(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fmuls f30,f12,f0
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,-240(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fadds f12,f22,f11
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// fadds f11,f21,f10
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,-240
	ctx.r10.s64 = ctx.r1.s64 + -240;
	// fmuls f28,f31,f31
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f3,-228(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// fmuls f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f7,f29,f0
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f10,f19,f30
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f5,f28,f0,f13
	ctx.f5.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f8,f6,f0
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fadds f6,f7,f1
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// stfs f6,-232(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// fsubs f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f1,-216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -216, temp.u32);
	// fsubs f4,f5,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f4,-224(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fsubs f7,f3,f8
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// stfs f7,-220(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// fadds f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f6,-212(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -212, temp.u32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f5,-208(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -208, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830950B0:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830950b0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830950B0;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830950DC:
	// lfs f12,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f7,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f10,f12
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f8,-224(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fmuls f6,f12,f7
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f5,-220(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// beq cr6,0x830952f4
	if (ctx.cr6.eq) goto loc_830952F4;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x830952f4
	if (ctx.cr6.eq) goto loc_830952F4;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f5,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// fmr f4,f8
	ctx.f4.f64 = ctx.f8.f64;
	// fmr f3,f5
	ctx.f3.f64 = ctx.f5.f64;
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f31,f11,f8
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f9
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f9.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f7,f30,f2,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f7.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f4
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f14,f28,f25
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmsubs f22,f28,f3,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f1,f1,f5,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f7.f64));
	// fmsubs f7,f24,f10,f19
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f26,f26,f4,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f19,f24,f4,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f5,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fmadds f29,f23,f5,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fmadds f27,f30,f8,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 + ctx.f27.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f8,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f8.f64 - ctx.f1.f64)));
	// fmuls f8,f2,f7
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f7,f2,f26
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f2,f28,f10,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f31,f23,f12,f31
	ctx.f31.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fnmsubs f5,f11,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f11,f1,f1
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 + ctx.f8.f64));
	// fadds f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f27,f31,f5
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f28,f5,f5
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f5.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f8,f3
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fmuls f8,f29,f0
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f3,f27,f0
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fmuls f7,f28,f0
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f31,f1
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fsubs f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fsubs f29,f8,f3
	ctx.f29.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// stfs f29,-188(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f29,f12,f0
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f4,f4,f7
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// stfs f4,-192(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f4,f30,f5
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f10
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f10.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fadds f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// stfs f3,-180(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f28,f0
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f10,f18,f29
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f31,f4,f8
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// stfs f31,-184(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f4,f8,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfs f4,-168(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfs f7,-176(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f8,f1,f5
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f8,-172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f7,f5,f1
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// stfs f7,-164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f5,f3,f2
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f5,-160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830952C8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830952c8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830952C8;
	// stfs f12,40(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f10,36(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
loc_830952F4:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f8,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f7.f64 = double(temp.f32);
	// fadds f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fadds f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// stfs f12,-240(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// stfs f11,-236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// stfs f10,-232(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// beq cr6,0x83095514
	if (ctx.cr6.eq) goto loc_83095514;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83095514
	if (ctx.cr6.eq) goto loc_83095514;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f5,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// fmr f4,f8
	ctx.f4.f64 = ctx.f8.f64;
	// fmr f3,f5
	ctx.f3.f64 = ctx.f5.f64;
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f11,f8
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f9
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f9.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f10,f26
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f7,f30,f2,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f7.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f4,f28
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f16,f3,f26
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f25,f26
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmuls f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// fmsubs f22,f3,f28,f22
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f28.f64 - ctx.f22.f64));
	// fmadds f1,f1,f5,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f7.f64));
	// fmsubs f7,f10,f24,f19
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f24.f64 - ctx.f19.f64));
	// fmsubs f26,f4,f26,f17
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64 - ctx.f17.f64));
	// fmadds f19,f4,f24,f16
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f5,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fmadds f27,f30,f8,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 + ctx.f27.f64));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmadds f29,f23,f5,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f8,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f8.f64 - ctx.f1.f64)));
	// fmuls f8,f2,f7
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f7,f2,f26
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f2,f10,f28,f19
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 + ctx.f19.f64));
	// fnmsubs f11,f11,f5,f27
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// fnmsubs f5,f23,f12,f31
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f31,f1,f1
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 + ctx.f8.f64));
	// fadds f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f28,f11,f11
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f27,f5,f11
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// fadds f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fmuls f10,f28,f0
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f31,f27,f0
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f28,f5,f1
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fsubs f12,f13,f2
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fsubs f29,f3,f31
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfs f29,-188(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f29,f30,f11
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfs f12,-192(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fadds f12,f21,f8
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fadds f8,f20,f7
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f7.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-180(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f7,f18,f4
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f4.f64));
	// fmuls f4,f28,f0
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f5,f0
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f5,f4,f1
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// stfs f5,-184(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f0,f3,f10
	ctx.f0.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfs f0,-176(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f10,f1,f4
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// stfs f10,-168(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f5,f13,f11
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f5,-172(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f4,f11,f13
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f4,-164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-160(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830954E8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830954e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830954E8;
	// stfs f7,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f8,44(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83095514:
	// lfs f11,-224(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f10.f64 = double(temp.f32);
	// b 0x83095b4c
	goto loc_83095B4C;
loc_83095520:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83095714
	if (ctx.cr6.eq) goto loc_83095714;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83095714
	if (ctx.cr6.eq) goto loc_83095714;
	// lfs f12,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f11,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f11,f0
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmuls f10,f2,f0
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// stfs f5,-188(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,-192(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f12,f22,f12
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r10,r1,-192
	ctx.r10.s64 = ctx.r1.s64 + -192;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// stfs f4,-180(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f10,f3,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,-184(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,-172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,-176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,-164(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,-160(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830956E8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830956e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830956E8;
	// stfs f10,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f12,40(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f11,44(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83095714:
	// lfs f12,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r3,48
	ctx.r7.s64 = ctx.r3.s64 + 48;
	// lfs f11,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,-240(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// stfs f11,-236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// stfs f10,-232(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// beq cr6,0x83095924
	if (ctx.cr6.eq) goto loc_83095924;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83095924
	if (ctx.cr6.eq) goto loc_83095924;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f9
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f9.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// fmadds f30,f11,f3,f30
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f10,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f7,f25,f8,f7
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f8,f3,f24
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f31,f31,f12,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// fnmsubs f11,f11,f6,f28
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f6,f29,f3
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f12,f27,f10
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fadds f10,f16,f2
	ctx.f10.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// fadds f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 + ctx.f8.f64));
	// fmuls f3,f7,f7
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// fmuls f2,f31,f7
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f7.f64));
	// fmuls f30,f11,f11
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// fmuls f29,f1,f11
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fadds f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// fadds f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f4,f2,f0
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f30,f0
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// fmuls f30,f29,f0
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f5,f10,f0
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f10,f8,f0
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f6,f13,f3
	ctx.f6.f64 = double(float(ctx.f13.f64 - ctx.f3.f64));
	// fmuls f29,f12,f0
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f8,f4,f30
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stfs f8,-188(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fadds f12,f22,f5
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fadds f8,f21,f10
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// stfs f6,-192(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f5,f31,f11
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmuls f10,f1,f7
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// addi r10,r1,-192
	ctx.r10.s64 = ctx.r1.s64 + -192;
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// fmuls f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f7,f30,f4
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f7,-180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fmuls f4,f10,f0
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f7,f29,f19
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f19.f64));
	// fnmsubs f10,f6,f0,f13
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f6,f11,f0
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fadds f11,f4,f5
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f11,-184(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f11,f5,f4
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f11,-168(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// stfs f2,-176(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f3,f10,f3
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// stfs f3,-160(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// fsubs f5,f6,f1
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// stfs f5,-172(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f4,f1,f6
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// stfs f4,-164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_830958F8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x830958f8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830958F8;
	// stfs f12,40(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f8,44(r11)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// stfs f7,36(r11)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83095924:
	// lfs f12,640(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// lfs f11,644(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f11.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// fadds f10,f12,f11
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// lfs f8,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f10,f8
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// stfs f5,-252(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f4,f10,f7
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f4,-248(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmuls f6,f10,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// beq cr6,0x83095b44
	if (ctx.cr6.eq) goto loc_83095B44;
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x83095b44
	if (ctx.cr6.eq) goto loc_83095B44;
	// lfs f12,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r3,112
	ctx.r9.s64 = ctx.r3.s64 + 112;
	// lfs f11,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f5,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// fmr f4,f8
	ctx.f4.f64 = ctx.f8.f64;
	// fmr f3,f5
	ctx.f3.f64 = ctx.f5.f64;
	// lfs f1,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f11,f8
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f30,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f1,f12
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f28,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f25,f2,f2,f9
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 - ctx.f9.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f26,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// addi r9,r11,244
	ctx.r9.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f7,f30,f2,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f7.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f4
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmsubs f31,f1,f2,f31
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f31.f64));
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f29,f11,f2,f29
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f29.f64));
	// fmuls f14,f28,f25
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmsubs f22,f28,f3,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f1,f1,f5,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f7.f64));
	// fmsubs f7,f24,f10,f19
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmsubs f26,f26,f4,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f19,f24,f4,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f16.f64));
	// fnmsubs f31,f30,f5,f31
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fmadds f27,f30,f8,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 + ctx.f27.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmadds f29,f23,f5,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fmuls f24,f22,f2
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f1,f23,f8,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f8.f64 - ctx.f1.f64)));
	// fmuls f8,f7,f2
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f2.f64));
	// fmuls f7,f26,f2
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// fmadds f2,f28,f10,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fnmsubs f11,f11,f5,f27
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// fnmsubs f5,f23,f12,f31
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fnmsubs f30,f30,f12,f29
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fadds f12,f25,f24
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f31,f1,f1
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 + ctx.f8.f64));
	// fadds f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f10,f10,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f28,f11,f11
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmuls f29,f1,f30
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f27,f5,f11
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// fadds f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fmuls f10,f28,f0
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f31,f27,f0
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f28,f5,f1
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fsubs f12,f13,f2
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fsubs f29,f3,f31
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfs f29,-188(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f29,f11,f30
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfs f12,-192(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fadds f12,f21,f8
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fadds f8,f20,f7
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f7.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-180(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f7,f18,f4
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f4.f64));
	// fmuls f4,f28,f0
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fnmsubs f3,f27,f0,f13
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f5,f0
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f5,f4,f1
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// stfs f5,-184(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f0,f3,f10
	ctx.f0.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfs f0,-176(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f10,f1,f4
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// stfs f10,-168(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f5,f13,f11
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f5,-172(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f4,f11,f13
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f4,-164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-160(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83095B18:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x83095b18
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83095B18;
	// stfs f7,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f8,44(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83095B44:
	// lfs f11,-252(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f10.f64 = double(temp.f32);
loc_83095B4C:
	// lfs f12,8(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f0,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// lfs f11,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f10.f64 = double(temp.f32);
	// lfs f7,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f7.f64 = double(temp.f32);
	// fadds f5,f12,f7
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f7.f64));
	// fadds f6,f13,f10
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fadds f8,f11,f0
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fmuls f2,f5,f9
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// stfs f2,8(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// fmuls f3,f6,f9
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// stfs f3,4(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// fmuls f4,f8,f9
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f4,0(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f1,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,644(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f0.f64 = double(temp.f32);
	// fadds f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// fmuls f12,f13,f9
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// stfs f12,12(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6afc
	ctx.lr = 0x83095BB0;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83095BBC"))) PPC_WEAK_FUNC(sub_83095BBC);
PPC_FUNC_IMPL(__imp__sub_83095BBC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83095BC0"))) PPC_WEAK_FUNC(sub_83095BC0);
PPC_FUNC_IMPL(__imp__sub_83095BC0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83095BC4"))) PPC_WEAK_FUNC(sub_83095BC4);
PPC_FUNC_IMPL(__imp__sub_83095BC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83095BC8"))) PPC_WEAK_FUNC(sub_83095BC8);
PPC_FUNC_IMPL(__imp__sub_83095BC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6ab0
	ctx.lr = 0x83095BD8;
	__savefpr_14(ctx, base);
	// lwz r11,712(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,7676(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 7676);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,6380(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6380);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,6140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6140);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x830962a0
	if (ctx.cr6.eq) goto loc_830962A0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83095df8
	if (ctx.cr6.eq) goto loc_83095DF8;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83095df8
	if (ctx.cr6.eq) goto loc_83095DF8;
	// lfs f11,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f11.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmr f9,f11
	ctx.f9.f64 = ctx.f11.f64;
	// lfs f10,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmr f6,f8
	ctx.f6.f64 = ctx.f8.f64;
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f4,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// lfs f27,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f4,f8
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f5,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f10,f8
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f29,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f10,f5
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f5.f64));
	// lfs f2,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f2.f64 = double(temp.f32);
	// fmr f28,f5
	ctx.f28.f64 = ctx.f5.f64;
	// fmsubs f25,f27,f27,f12
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f27.f64 - ctx.f12.f64));
	// lfs f31,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f31.f64 = double(temp.f32);
	// lfs f26,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r3,12
	ctx.r9.s64 = ctx.r3.s64 + 12;
	// fmuls f23,f29,f9
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f2,f6
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f7,f4,f5,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f7.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f31,f9
	ctx.f18.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// fmsubs f10,f10,f27,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 - ctx.f30.f64));
	// fmadds f3,f4,f27,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f27.f64 + ctx.f3.f64));
	// fmuls f30,f31,f28
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f17,f31,f25
	ctx.f17.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fmadds f1,f26,f27,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f27.f64 + ctx.f1.f64));
	// fmuls f16,f2,f25
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmsubs f31,f31,f6,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f6.f64 - ctx.f23.f64));
	// fmsubs f23,f29,f28,f20
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 - ctx.f20.f64));
	// fmadds f7,f24,f27,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 + ctx.f7.f64));
	// fmadds f20,f29,f6,f18
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f18.f64));
	// fnmsubs f10,f24,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmadds f3,f26,f11,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f3.f64));
	// fmsubs f30,f2,f9,f30
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 - ctx.f30.f64));
	// fmuls f29,f29,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// fmadds f1,f24,f8,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f1.f64));
	// fmuls f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f27.f64));
	// fnmsubs f8,f26,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f26.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmadds f2,f2,f28,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64 + ctx.f20.f64));
	// fmuls f7,f23,f27
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// fnmsubs f3,f24,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f24.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fnmsubs f5,f26,f5,f10
	ctx.f5.f64 = double(float(-(ctx.f26.f64 * ctx.f5.f64 - ctx.f10.f64)));
	// fnmsubs f1,f4,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fmuls f4,f30,f27
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// fadds f11,f16,f31
	ctx.f11.f64 = double(float(ctx.f16.f64 + ctx.f31.f64));
	// fmuls f10,f8,f8
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f7,f17,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// fmuls f31,f2,f28
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmuls f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmuls f30,f3,f8
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f28,f1,f1
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fadds f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fmuls f27,f5,f1
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f29,f5,f8
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f10,f7,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f9,f11,f31
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f31.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f31,f28,f0
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fsubs f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f9,f7,f30
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// stfs f9,-188(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fsubs f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// stfs f4,-192(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f4,f3,f1
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// fadds f11,f22,f11
	ctx.f11.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// fadds f10,f21,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fmuls f1,f1,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// fmuls f28,f3,f3
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f9,f19,f6
	ctx.f9.f64 = double(float(ctx.f19.f64 + ctx.f6.f64));
	// fmuls f6,f4,f0
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f5,f29,f0
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// stfs f7,-180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f8,f0
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f4,f28,f0,f13
	ctx.f4.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f8,-184(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfs f6,-168(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f5,f3,f1
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// stfs f5,-172(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fsubs f7,f4,f31
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// stfs f7,-176(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fadds f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f3,-164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfs f2,-160(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83095DCC:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x83095dcc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83095DCC;
	// stfs f9,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// stfs f11,40(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// stfs f10,44(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83095DF8:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// addi r9,r3,12
	ctx.r9.s64 = ctx.r3.s64 + 12;
	// stfs f11,12(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// addi r10,r4,12
	ctx.r10.s64 = ctx.r4.s64 + 12;
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,16(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// fmr f7,f10
	ctx.f7.f64 = ctx.f10.f64;
	// lfs f9,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// fmr f5,f9
	ctx.f5.f64 = ctx.f9.f64;
	// stfs f9,20(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// lfs f6,644(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f7,f6
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f4,f5,f6
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// stfs f3,16(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// fmuls f2,f6,f8
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// stfs f2,12(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// stfs f4,20(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83096034
	if (ctx.cr6.eq) goto loc_83096034;
	// lwz r8,280(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r7,8(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x83096034
	if (ctx.cr6.eq) goto loc_83096034;
	// lfs f11,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// addi r8,r3,112
	ctx.r8.s64 = ctx.r3.s64 + 112;
	// lfs f10,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmr f9,f11
	ctx.f9.f64 = ctx.f11.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f11
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f1,f10,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f27,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f12
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f12.f64));
	// lfs f25,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// addi r8,r11,244
	ctx.r8.s64 = ctx.r11.s64 + 244;
	// lfs f24,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f27,f9
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f27,f4
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f18,f25,f4
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmadds f30,f10,f3,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f28,f24,f3,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmuls f16,f27,f26
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// fmsubs f23,f29,f4,f23
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f25,f9,f20
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 - ctx.f20.f64));
	// fmadds f20,f25,f5,f17
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f17.f64));
	// fmsubs f27,f27,f5,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmadds f30,f24,f6,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f25,f23,f3
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fnmsubs f8,f24,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f24.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmadds f2,f29,f9,f20
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f20.f64));
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fnmsubs f1,f24,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fnmsubs f31,f31,f11,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// fnmsubs f6,f10,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fadds f11,f26,f25
	ctx.f11.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fmuls f10,f8,f8
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fmuls f30,f31,f8
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f28,f1,f6
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f29,f6,f6
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f10,f7,f4
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f3,f28,f0
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fsubs f5,f13,f2
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fsubs f30,f7,f3
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f30,-188(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f30,f11,f0
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,-192(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fadds f11,f22,f10
	ctx.f11.f64 = double(float(ctx.f22.f64 + ctx.f10.f64));
	// fadds f10,f21,f9
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f9.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// fmuls f28,f31,f31
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r7,9
	ctx.r7.s64 = 9;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fadds f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f3,-180(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fmuls f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f7,f29,f0
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f9,f30,f19
	ctx.f9.f64 = double(float(ctx.f30.f64 + ctx.f19.f64));
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f5,f28,f0,f13
	ctx.f5.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f8,f6,f0
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fadds f6,f7,f1
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// stfs f6,-184(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f1,-168(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f4,f5,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f4,-176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f7,f3,f8
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// stfs f7,-172(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f6,-164(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f5,-160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_83096008:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x83096008
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83096008;
	// stfs f11,40(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// stfs f10,44(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// stfs f9,36(r9)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r8,280(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r8,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r8.u32);
loc_83096034:
	// lfs f11,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// addi r6,r3,48
	ctx.r6.s64 = ctx.r3.s64 + 48;
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,48(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f7.f64 = double(temp.f32);
	// fadds f6,f8,f11
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// lfs f5,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f10,f7
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fadds f3,f9,f5
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f4,4(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// stfs f3,8(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8309625c
	if (ctx.cr6.eq) goto loc_8309625C;
	// lwz r8,280(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r7,8(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x8309625c
	if (ctx.cr6.eq) goto loc_8309625C;
	// lfs f11,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f11.f64 = double(temp.f32);
	// addi r8,r3,112
	ctx.r8.s64 = ctx.r3.s64 + 112;
	// lfs f10,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f9,f11,f11,f12
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 - ctx.f12.f64));
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f8,f2
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f12,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f29,f3,f2
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f27,f8,f12
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f30,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f28.f64 = double(temp.f32);
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// lfs f26,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// addi r8,r11,244
	ctx.r8.s64 = ctx.r11.s64 + 244;
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f9,f28
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfs f23,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f7,f3,f12,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f22,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f5,f30
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f20,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f4,f28
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f19,f4,f26
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmadds f31,f12,f11,f31
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f31.f64));
	// fmsubs f27,f2,f11,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 - ctx.f27.f64));
	// fmadds f29,f8,f10,f29
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f29.f64));
	// fmuls f17,f1,f28
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmadds f7,f6,f2,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f7.f64));
	// fmsubs f2,f1,f26,f21
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 - ctx.f21.f64));
	// fmadds f26,f5,f26,f18
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmsubs f28,f5,f28,f19
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f28.f64 - ctx.f19.f64));
	// fmadds f31,f6,f25,f31
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f31.f64));
	// fnmsubs f27,f6,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// fmadds f29,f25,f11,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fmsubs f21,f4,f30,f17
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f17.f64));
	// fnmsubs f8,f8,f25,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f25.f64 - ctx.f7.f64)));
	// fmuls f7,f11,f2
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// fmadds f30,f1,f30,f26
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fmuls f2,f11,f28
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fnmsubs f10,f3,f10,f31
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f31.f64)));
	// fnmsubs f3,f3,f25,f27
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f25.f64 - ctx.f27.f64)));
	// fnmsubs f6,f6,f12,f29
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fmuls f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f11,f8,f8
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fadds f7,f24,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f7.f64));
	// fmuls f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fadds f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// fmuls f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f31,f10,f8
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f28,f3,f6
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fmuls f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fmuls f29,f6,f6
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f4,f2,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fmuls f2,f31,f0
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f31,f28,f0
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fadds f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f5,f4,f0
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fsubs f4,f2,f31
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f4,-188(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f4,f12,f0
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fsubs f12,f11,f1
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// stfs f12,-192(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fadds f12,f23,f7
	ctx.f12.f64 = double(float(ctx.f23.f64 + ctx.f7.f64));
	// fmuls f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fadds f11,f22,f5
	ctx.f11.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fmuls f5,f3,f8
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// fmuls f30,f10,f10
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// li r7,9
	ctx.r7.s64 = 9;
	// fmuls f6,f10,f3
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// fadds f3,f31,f2
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f3,-180(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fmuls f2,f7,f0
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f5,f0
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f10,f20,f4
	ctx.f10.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// fmuls f4,f8,f0
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f5,f30,f0,f13
	ctx.f5.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f3,f6,f0
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fadds f0,f7,f2
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfs f0,-184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f8,f2,f7
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f8,-168(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f13,f5,f1
	ctx.f13.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// stfs f13,-176(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f7,-172(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f6,-164(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfs f5,-160(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_83096230:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x83096230
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83096230;
	// stfs f10,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// stfs f12,40(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// stfs f11,44(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r9,280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
loc_8309625C:
	// lfs f0,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f7,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f8,4(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// stfs f6,8(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6afc
	ctx.lr = 0x83096294;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_830962A0:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x83096494
	if (ctx.cr6.eq) goto loc_83096494;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x83096494
	if (ctx.cr6.eq) goto loc_83096494;
	// lfs f11,252(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f10,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmr f9,f11
	ctx.f9.f64 = ctx.f11.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f11
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f10,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f12
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f12.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r3,12
	ctx.r9.s64 = ctx.r3.s64 + 12;
	// fmuls f23,f9,f29
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f4,f27
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f10,f3,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f9,f24
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f4,f24,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f9,f27,f20
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f4,f29,f17
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f10,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f11,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f11,f27,f4
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f10,f8,f8
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f10,f0
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f10,f4,f9
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fmuls f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f5,f9,f4
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f5,-188(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,-192(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f10,f21,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fadds f11,f22,f11
	ctx.f11.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// stfs f4,-180(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f9,f3,f19
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,-184(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,-172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,-176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,-164(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,-160(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_83096468:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x83096468
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_83096468;
	// stfs f9,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// stfs f10,44(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// stfs f11,40(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83096494:
	// lfs f11,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// addi r6,r3,48
	ctx.r6.s64 = ctx.r3.s64 + 48;
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f10,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,4(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// lfs f9,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,8(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x830966a8
	if (ctx.cr6.eq) goto loc_830966A8;
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x830966a8
	if (ctx.cr6.eq) goto loc_830966A8;
	// lfs f11,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// addi r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 + 112;
	// lfs f10,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmr f9,f11
	ctx.f9.f64 = ctx.f11.f64;
	// lfs f8,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f6,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f8
	ctx.f5.f64 = ctx.f8.f64;
	// fmr f4,f6
	ctx.f4.f64 = ctx.f6.f64;
	// lfs f2,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f2,f11
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f31,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f29,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f10,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f3,f3,f12
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f3.f64 - ctx.f12.f64));
	// lfs f25,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r11,244
	ctx.r10.s64 = ctx.r11.s64 + 244;
	// lfs f24,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// addi r9,r3,12
	ctx.r9.s64 = ctx.r3.s64 + 12;
	// fmuls f23,f29,f9
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f31,f3,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f7.f64));
	// lfs f21,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f27,f4
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmadds f28,f25,f3,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f28.f64));
	// fmadds f30,f10,f3,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f1,f2,f3,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fmuls f17,f24,f9
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmadds f23,f24,f4,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmadds f7,f2,f6,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f7.f64));
	// fmsubs f2,f27,f9,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f20.f64));
	// fmsubs f24,f5,f24,f18
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f18.f64));
	// fmadds f28,f31,f8,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 + ctx.f28.f64));
	// fmadds f30,f25,f6,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f30.f64));
	// fnmsubs f1,f31,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f31.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmsubs f29,f29,f4,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f27,f5,f27,f23
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f8,f25,f8,f7
	ctx.f8.f64 = double(float(-(ctx.f25.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// fmuls f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fnmsubs f6,f10,f6,f28
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// fnmsubs f31,f31,f11,f30
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// fnmsubs f1,f25,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmuls f11,f27,f4
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f10,f8,f8
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmuls f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fadds f4,f15,f2
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fadds f7,f16,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// fmuls f2,f31,f8
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f30,f6,f6
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmuls f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f28,f10,f0
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f10,f4,f9
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fmuls f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f2,f13,f28
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f5,f9,f4
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f5,-188(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f5,f31,f6
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// stfs f2,-192(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f2,f1,f8
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fadds f10,f21,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f10.f64));
	// fadds f11,f22,f11
	ctx.f11.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// fmuls f30,f31,f31
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// li r8,9
	ctx.r8.s64 = 9;
	// fadds f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// stfs f4,-180(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fadds f9,f3,f19
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f1,f30,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f5,-184(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f3,-168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f2,-172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fsubs f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f4,-176(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,-164(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f7,-160(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_8309667C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8309667c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8309667C;
	// stfs f9,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 36, temp.u32);
	// stfs f11,40(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 40, temp.u32);
	// stfs f10,44(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830966A8:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// stfs f11,12(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// fmr f8,f11
	ctx.f8.f64 = ctx.f11.f64;
	// addi r9,r4,12
	ctx.r9.s64 = ctx.r4.s64 + 12;
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,16(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// fmr f7,f10
	ctx.f7.f64 = ctx.f10.f64;
	// lfs f9,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,20(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// fmr f3,f9
	ctx.f3.f64 = ctx.f9.f64;
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lfs f6,644(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,640(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f6,f5
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// fmuls f2,f3,f4
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f2,-200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -200, temp.u32);
	// fmuls f9,f4,f8
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmuls f8,f7,f4
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// beq cr6,0x830968e4
	if (ctx.cr6.eq) goto loc_830968E4;
	// lwz r8,280(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// lwz r7,8(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x830968e4
	if (ctx.cr6.eq) goto loc_830968E4;
	// lfs f11,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// addi r8,r3,112
	ctx.r8.s64 = ctx.r3.s64 + 112;
	// lfs f10,112(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmr f7,f11
	ctx.f7.f64 = ctx.f11.f64;
	// lfs f6,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f10,f11
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f4,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f6
	ctx.f3.f64 = ctx.f6.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// lfs f31,124(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f31,f11
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// lfs f29,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f6
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// lfs f27,136(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f10,f6
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f25,132(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f12,f1,f1,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f1.f64 - ctx.f12.f64));
	// lfs f24,128(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// addi r8,r11,244
	ctx.r8.s64 = ctx.r11.s64 + 244;
	// lfs f23,120(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f25,f7
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// lfs f21,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f5,f29,f1,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f20,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f27,f3
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f18,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f25,f2
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// addi r11,r1,-192
	ctx.r11.s64 = ctx.r1.s64 + -192;
	// fmuls f17,f24,f2
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmadds f28,f10,f1,f28
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmsubs f30,f31,f1,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmuls f15,f25,f12
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmuls f14,f27,f12
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmsubs f22,f27,f2,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f22.f64));
	// fmadds f5,f31,f4,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f31,f24,f7,f19
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fmadds f19,f24,f3,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fmsubs f25,f25,f3,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmadds f28,f23,f4,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmadds f26,f29,f6,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fnmsubs f30,f29,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f4.f64 - ctx.f30.f64)));
	// fmuls f12,f24,f12
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f24,f22,f1
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fnmsubs f6,f23,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// fmadds f31,f27,f7,f19
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f19.f64));
	// fmuls f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// fnmsubs f29,f29,f11,f28
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fnmsubs f10,f10,f4,f26
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f4,f23,f11,f30
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// fadds f12,f12,f24
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f24.f64));
	// fmuls f11,f6,f6
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fadds f5,f15,f5
	ctx.f5.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f30,f6,f29
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f27,f4,f10
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f28,f10,f10
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fmuls f31,f11,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fadds f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// fadds f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fmuls f7,f30,f0
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmuls f5,f28,f0
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f1,f0
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fsubs f1,f7,f30
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// stfs f1,-188(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -188, temp.u32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f1,f12,f5
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// stfs f1,-192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fmuls f1,f4,f6
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fadds f12,f21,f11
	ctx.f12.f64 = double(float(ctx.f21.f64 + ctx.f11.f64));
	// fadds f11,f20,f2
	ctx.f11.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fmuls f2,f10,f29
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fmuls f28,f29,f29
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f29.f64));
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// fmuls f6,f10,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// li r7,9
	ctx.r7.s64 = 9;
	// fmuls f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fadds f10,f30,f7
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// stfs f10,-180(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -180, temp.u32);
	// fmuls f7,f2,f0
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fadds f10,f18,f3
	ctx.f10.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fnmsubs f2,f28,f0,f13
	ctx.f2.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f13,f3,f7
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f13,-184(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -184, temp.u32);
	// fsubs f6,f2,f5
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfs f6,-176(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -176, temp.u32);
	// fsubs f5,f7,f3
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f5,-168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -168, temp.u32);
	// fsubs f4,f1,f0
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfs f4,-172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -172, temp.u32);
	// fadds f3,f0,f1
	ctx.f3.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f3,-164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -164, temp.u32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f2,-160(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -160, temp.u32);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_830968B8:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x830968b8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_830968B8;
	// stfs f10,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// stfs f12,40(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// stfs f11,44(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lwz r11,264(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 264);
	// lwz r10,280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_830968E4:
	// lfs f0,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f9
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f11,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f8
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// lfs f9,-200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -200);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f11,f9
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// stfs f10,4(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 4, temp.u32);
	// stfs f8,8(r9)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + 8, temp.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82cb6afc
	ctx.lr = 0x83096914;
	__restfpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096920"))) PPC_WEAK_FUNC(sub_83096920);
PPC_FUNC_IMPL(__imp__sub_83096920) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096924"))) PPC_WEAK_FUNC(sub_83096924);
PPC_FUNC_IMPL(__imp__sub_83096924) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096928"))) PPC_WEAK_FUNC(sub_83096928);
PPC_FUNC_IMPL(__imp__sub_83096928) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8309692C"))) PPC_WEAK_FUNC(sub_8309692C);
PPC_FUNC_IMPL(__imp__sub_8309692C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096930"))) PPC_WEAK_FUNC(sub_83096930);
PPC_FUNC_IMPL(__imp__sub_83096930) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096934"))) PPC_WEAK_FUNC(sub_83096934);
PPC_FUNC_IMPL(__imp__sub_83096934) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096938"))) PPC_WEAK_FUNC(sub_83096938);
PPC_FUNC_IMPL(__imp__sub_83096938) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096940"))) PPC_WEAK_FUNC(sub_83096940);
PPC_FUNC_IMPL(__imp__sub_83096940) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096948"))) PPC_WEAK_FUNC(sub_83096948);
PPC_FUNC_IMPL(__imp__sub_83096948) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,640(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 640, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096950"))) PPC_WEAK_FUNC(sub_83096950);
PPC_FUNC_IMPL(__imp__sub_83096950) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,640(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 640);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096958"))) PPC_WEAK_FUNC(sub_83096958);
PPC_FUNC_IMPL(__imp__sub_83096958) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 644, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096960"))) PPC_WEAK_FUNC(sub_83096960);
PPC_FUNC_IMPL(__imp__sub_83096960) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,644(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 644);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096968"))) PPC_WEAK_FUNC(sub_83096968);
PPC_FUNC_IMPL(__imp__sub_83096968) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,708(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 708, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096970"))) PPC_WEAK_FUNC(sub_83096970);
PPC_FUNC_IMPL(__imp__sub_83096970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,708(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 708);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096978"))) PPC_WEAK_FUNC(sub_83096978);
PPC_FUNC_IMPL(__imp__sub_83096978) {
	PPC_FUNC_PROLOGUE();
	// stw r4,712(r3)
	PPC_STORE_U32(ctx.r3.u32 + 712, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096980"))) PPC_WEAK_FUNC(sub_83096980);
PPC_FUNC_IMPL(__imp__sub_83096980) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,712(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096988"))) PPC_WEAK_FUNC(sub_83096988);
PPC_FUNC_IMPL(__imp__sub_83096988) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,716(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 716, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096990"))) PPC_WEAK_FUNC(sub_83096990);
PPC_FUNC_IMPL(__imp__sub_83096990) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,716(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 716);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096998"))) PPC_WEAK_FUNC(sub_83096998);
PPC_FUNC_IMPL(__imp__sub_83096998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,720(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 720, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830969A0"))) PPC_WEAK_FUNC(sub_830969A0);
PPC_FUNC_IMPL(__imp__sub_830969A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,720(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 720);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830969A8"))) PPC_WEAK_FUNC(sub_830969A8);
PPC_FUNC_IMPL(__imp__sub_830969A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,724(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 724, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830969B0"))) PPC_WEAK_FUNC(sub_830969B0);
PPC_FUNC_IMPL(__imp__sub_830969B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,724(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 724);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830969B8"))) PPC_WEAK_FUNC(sub_830969B8);
PPC_FUNC_IMPL(__imp__sub_830969B8) {
	PPC_FUNC_PROLOGUE();
	// std r4,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r4.u64);
	// std r5,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r5.u64);
	// lwz r10,36(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// lwz r9,40(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lwz r11,32(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stw r11,648(r3)
	PPC_STORE_U32(ctx.r3.u32 + 648, ctx.r11.u32);
	// stw r10,652(r3)
	PPC_STORE_U32(ctx.r3.u32 + 652, ctx.r10.u32);
	// stw r9,656(r3)
	PPC_STORE_U32(ctx.r3.u32 + 656, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830969DC"))) PPC_WEAK_FUNC(sub_830969DC);
PPC_FUNC_IMPL(__imp__sub_830969DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_830969E0"))) PPC_WEAK_FUNC(sub_830969E0);
PPC_FUNC_IMPL(__imp__sub_830969E0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,648(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 648);
	// lwz r10,652(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 652);
	// lwz r9,656(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 656);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830969FC"))) PPC_WEAK_FUNC(sub_830969FC);
PPC_FUNC_IMPL(__imp__sub_830969FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096A00"))) PPC_WEAK_FUNC(sub_83096A00);
PPC_FUNC_IMPL(__imp__sub_83096A00) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A04"))) PPC_WEAK_FUNC(sub_83096A04);
PPC_FUNC_IMPL(__imp__sub_83096A04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096A08"))) PPC_WEAK_FUNC(sub_83096A08);
PPC_FUNC_IMPL(__imp__sub_83096A08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f1,6048(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 6048);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A14"))) PPC_WEAK_FUNC(sub_83096A14);
PPC_FUNC_IMPL(__imp__sub_83096A14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096A18"))) PPC_WEAK_FUNC(sub_83096A18);
PPC_FUNC_IMPL(__imp__sub_83096A18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lwz r11,712(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 712);
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// stfs f1,512(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 512, temp.u32);
	// stfs f1,412(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 412, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A34"))) PPC_WEAK_FUNC(sub_83096A34);
PPC_FUNC_IMPL(__imp__sub_83096A34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_83096A38"))) PPC_WEAK_FUNC(sub_83096A38);
PPC_FUNC_IMPL(__imp__sub_83096A38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,412(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 412);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A40"))) PPC_WEAK_FUNC(sub_83096A40);
PPC_FUNC_IMPL(__imp__sub_83096A40) {
	PPC_FUNC_PROLOGUE();
	// stw r4,728(r3)
	PPC_STORE_U32(ctx.r3.u32 + 728, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A48"))) PPC_WEAK_FUNC(sub_83096A48);
PPC_FUNC_IMPL(__imp__sub_83096A48) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,728(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 728);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A50"))) PPC_WEAK_FUNC(sub_83096A50);
PPC_FUNC_IMPL(__imp__sub_83096A50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// stfs f0,664(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 664, temp.u32);
	// lfs f13,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,-1496
	ctx.r10.s64 = ctx.r11.s64 + -1496;
	// stfs f13,668(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 668, temp.u32);
	// lfs f12,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,672(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 672, temp.u32);
	// lfs f11,16(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,676(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 676, temp.u32);
	// lfs f10,20(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,680(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 680, temp.u32);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096A88"))) PPC_WEAK_FUNC(sub_83096A88);
PPC_FUNC_IMPL(__imp__sub_83096A88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f0,664(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 664);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,668(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 668);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,-1496
	ctx.r10.s64 = ctx.r11.s64 + -1496;
	// lfs f12,672(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 672);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,676(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 676);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,680(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 680);
	ctx.f10.f64 = double(temp.f32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f13,8(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f12,12(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// stfs f11,16(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// stfs f10,20(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_83096AC0"))) PPC_WEAK_FUNC(sub_83096AC0);
PPC_FUNC_IMPL(__imp__sub_83096AC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// stfs f0,688(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 688, temp.u32);
	// lfs f13,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,-1496
	ctx.r10.s64 = ctx.r11.s64 + -1496;
	// stfs f13,692(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 692, temp.u32);
	// lfs f12,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,696(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 696, temp.u32);
	// lfs f11,16(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,700(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 700, temp.u32);
	// lfs f10,20(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,704(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 704, temp.u32);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

